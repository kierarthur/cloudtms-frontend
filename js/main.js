/**
 * CloudTMS Broker (Cloudflare Worker) — Auth + Timesheets API (no Google Sheets)
 *
 * Endpoints:
 *  - POST   /auth/login
 *  - POST   /auth/refresh
 *  - POST   /auth/logout
 *  - POST   /auth/forgot
 *  - POST   /auth/reset
 *
 *  - POST   /timesheets/presign
 *  - PUT    /upload?key=...&booking_id=...&role=nurse|authoriser&token=...
 *  - POST   /timesheets/submit
 *  - POST   /timesheets/revoke
 *  - POST   /timesheets/revoke-and-presign
 *  - GET    /timesheets/:booking_id           (current; add ?version=2 or ?current_only=false)
 *  - GET    /timesheets
 *  - POST   /timesheets/query
 *  - POST   /timesheets/authorised-status
 *  - POST   /signatures/presign-get 
 *  - POST   /signatures/presign-get/batch
 *  - GET    /signatures/get?key=...&booking_id=...&role=...&token=...
 *  - GET    /healthz
 *  - GET    /readyz
 *  - GET    /version
 */

import * as XLSX from 'xlsx';
// QR code generation
import QRCode from 'qrcode';

const textEncoder = new TextEncoder();

// Enable verbose import logging for Wrangler tail
const wranglerimportlog = true;

console.log('[BOOT] worker version 2025-11-13-unplan-log');

const JSON_HEADERS = { "content-type": "application/json; charset=utf-8" };
const TEXT_PLAIN = { "content-type": "text/plain; charset=utf-8" };

const DEFAULT_GRID_PREFS = {
  grid: {
    clients: {
      labels: {
        name: "Client Name",
        cli_ref: "Client Ref",
        ap_phone: "A/P Phone",
        postcode: "Postcode",
        created_at: "Creation Date",
        updated_at: "Last Updated",
        vat_chargeable: "VAT",
        invoice_address: "Invoice Address",
        ts_queries_email: "TS Queries Email",
        payment_terms_days: "Payment Terms",
        mileage_charge_rate: "Mileage Charge Rate",
        primary_invoice_email: "Invoice Email"
      },
      columns: {
        name:                 { order: 1,  width: 357, visible: true  },
        cli_ref:              { order: 0,  width: 114, visible: true  },
        ap_phone:             { order: 5,  width: 129, visible: true  },
        postcode:             { order: 4,  width: 121, visible: true  },
        created_at:           { order: 8,  width: 161, visible: true  },
        updated_at:           { order: 9,  width: 159, visible: true  },
        vat_chargeable: { order: 6, visible: true },
        invoice_address:      { order: 3,  width: 326, visible: true  },
        ts_queries_email:     { order: 11,              visible: false },
        payment_terms_days:   { order: 7,  width: 93,  visible: true  },
        mileage_charge_rate:  { order: 10,             visible: false },
        primary_invoice_email:{ order: 2,  width: 246, visible: true }
      },
      columns_meta: {},
      use_friendly_labels: true
    },

    contracts: {
      labels: {
        band: "Band",
        role: "Role",
        client: "client",
        end_date: "End Date",
        candidate: "candidate",
        ward_hint: "Rota only Ward Hints",
        created_at: "Creation Date",
        rates_json: "rates_json",
        start_date: "Start Date",
        updated_at: "Last Updated",
        client_name: "Client",
        auto_invoice: "Auto Invoice",
        display_site: "Site Location",
        mileage_pay_rate: "Mileage Pay Rate",
        candidate_display: "Candidate",
        mileage_charge_rate: "Mileage Charge Rate",
        pay_method_snapshot: "Pay Method",
        bucket_labels_preview: "Buckets",
        default_submission_mode: "Submission Mode",
        require_reference_to_pay: "Pay needs Ref",
        require_reference_to_invoice: "Invoice needs Ref",
        week_ending_weekday_snapshot: "Week Ending Day"
      },
      columns: {
        band:                        { order: 3,  width: 86,  visible: true  },
        role:                        { order: 2,  width: 83,  visible: true  },
        client:                      { order: 21,             visible: false },
        end_date:                    { order: 7,  width: 95,  visible: true  },
        candidate:                   { order: 20,             visible: false },
        ward_hint:                   { order: 10,             visible: false },
        created_at:                  { order: 16,            visible: true  },
        rates_json:                  { order: 11,            visible: false },
        start_date:                  { order: 6,  width: 0,   visible: true  },
        updated_at:                  { order: 17,            visible: true  },
        client_name:                 { order: 1,  width: 201, visible: true  },
        auto_invoice:                { order: 13,            visible: true  },
        display_site:                { order: 9,             visible: true  },
        mileage_pay_rate:            { order: 18,            visible: false },
        candidate_display:           { order: 0,  width: 91,  visible: true  },
        mileage_charge_rate:         { order: 19, width: 158, visible: false },
        pay_method_snapshot:         { order: 4,             visible: true  },
        bucket_labels_preview: { order: 8,  width: 272, visible: false },
        default_submission_mode:     { order: 5,             visible: true  },
        require_reference_to_pay:    { order: 14,            visible: true  },
        require_reference_to_invoice:{ order: 15,            visible: true  },
        week_ending_weekday_snapshot:{ order: 12,            visible: false }
      },
      columns_meta: {},
      use_friendly_labels: true
    },

    candidates: {
      labels: {
        role: "Care Package Roles",        
        email: "Email",
        notes: "Notes",
        phone: "Phone",
        roles: "Roles",
        active: "Active",
        tms_ref: "TMS Ref",
        postcode: "Postcode",
        last_name: "Last Name",
        sort_code: "Sort Code",
        created_at: "Creation Date",
        first_name: "First Name",
        pay_method: "Pay Type",
        updated_at: "Last Updated",
        display_name: "Display Name",
        job_titles_display: "Job Titles",
        account_holder: "Account Holder",
        account_number: "Account number",
        mileage_pay_rate: "Mileage Pay Rate"
      },
      columns: {
        role:             { order: 4,  width: 110, visible: true  },
        email:            { order: 5,  width: 252, visible: true  },
        notes:            { order: 16,             visible: false },
        phone:            { order: 6,  width: 121, visible: true  },
        roles:            { order: 15,             visible: false },
        active:           { order: 8,  width: 80,  visible: true  },
        tms_ref:          { order: 0,  width: 116, visible: true  },
        postcode:         { order: 3,              visible: false },
        last_name:        { order: 2,  width: 103, visible: true  },
        sort_code:        { order: 12,             visible: false },
        created_at:       { order: 9,  width: 167, visible: true  },
        first_name:       { order: 3,  width: 156, visible: true  },
        pay_method:       { order: 7,  width: 121, visible: true  },
        updated_at:       { order: 10,            visible: true  },
        display_name:     { order: 1,  width: 150, visible: true  },
        job_titles_display: { order: 14, width: 150, visible: true }, // pick order/width that fits your layout
        account_holder:   { order: 11,            visible: false },
        account_number:   { order: 13,            visible: false },
        mileage_pay_rate: { order: 12,            visible: false }
      },
      columns_meta: {},
      use_friendly_labels: true
    }
  }
};



// worker.mjs (Cloudflare Worker, module syntax)
import puppeteer from "@cloudflare/puppeteer";

// --- Helpers ---------------------------------------------------------------

async function withBrowser(env, fn) {
  const browser = await puppeteer.launch(env.BROWSER); // <-- BROWSER binding from wrangler.toml
  try { return await fn(browser); }
  finally { await browser.close(); }
}


const fmtGBP = (n) =>
  new Intl.NumberFormat("en-GB", {
    style: "currency",
    currency: "GBP",
    minimumFractionDigits: 2,
    maximumFractionDigits: 2
  }).format(Number(n || 0));

const fmtDateGB = (iso) => {
  if (!iso) return "";
  const d = new Date(iso);
  return new Intl.DateTimeFormat("en-GB", { timeZone: "UTC" }).format(d);
};
// KEEP ONLY THIS (unified helper)
function pick(obj, keyOrKeys, defaults = undefined) {
  // Single key form: pick(obj, 'key', defaultVal)
  if (!Array.isArray(keyOrKeys)) {
    return obj && obj[keyOrKeys] != null ? obj[keyOrKeys] : defaults;
  }
  // Multi-key form: pick(obj, ['a','b'], { a: 1 }) -> { a: valOr1, b: valOrUndefined }
  const out = { ...(defaults || {}) };
  for (const k of keyOrKeys) {
    out[k] = obj && obj[k] != null ? obj[k] : (defaults ? defaults[k] : undefined);
  }
  return out;
}

const escapeHtml = (s = "") =>
  String(s)
    .replace(/&/g, "&amp;")
    .replace(/</g, "&lt;")
    .replace(/>/g, "&gt;")
    .replace(/"/g, "&quot;")
    .replace(/'/g, "&#039;");

const escapeUrl = (s = "") =>
  String(s).replace(/['")\\]/g, (m) => ({ "'": "%27", '"': "%22", ")": "%29", "\\": "%5C" }[m]));

// Safer base64 for large Uint8Array in Workers (chunked)
function toBase64(u8) {
  let binary = "";
  const chunk = 0x8000;
  for (let i = 0; i < u8.length; i += chunk) {
    binary += String.fromCharCode(...u8.subarray(i, i + chunk));
  }
  return btoa(binary);
}

// --- HTML builder ----------------------------------------------------------
// ====== PDF + TS RENDER HELPERS ======
import { PDFDocument, StandardFonts, rgb } from 'pdf-lib';

// MM→points for A4 placement
const MM_TO_PT = 72 / 25.4;
const mmToPt = (mm) => mm * MM_TO_PT;

// UK time formatting helpers
const UK_TZ = 'Europe/London';
const fmtUKDate = (d) => {
  // accepts ISO string or YYYY-MM-DD
  if (!d) return '';
  if (/^\d{4}-\d{2}-\d{2}$/.test(d)) {
    const [y, m, dd] = d.split('-').map(Number);
    // dd/mm/yy
    return `${String(dd).padStart(2,'0')}/${String(m).padStart(2,'0')}/${String(y % 100).padStart(2,'0')}`;
  }
  const dt = new Date(d);
  const parts = new Intl.DateTimeFormat('en-GB', { timeZone: UK_TZ, day: '2-digit', month: '2-digit', year: '2-digit' }).formatToParts(dt);
  const day = parts.find(p => p.type === 'day')?.value ?? '01';
  const mon = parts.find(p => p.type === 'month')?.value ?? '01';
  const yr2 = parts.find(p => p.type === 'year')?.value ?? '00';
  return `${day}/${mon}/${yr2}`;
};
const fmtUKTime = (d) => {
  if (!d) return '';
  const dt = new Date(d);
  return new Intl.DateTimeFormat('en-GB', { timeZone: UK_TZ, hour: '2-digit', minute: '2-digit', hour12: false }).format(dt);
};
// Monday=0 … Sunday=6 based on UK-local start time
const ukWeekdayIndexMon0 = (iso) => {
  if (!iso) return 0;
  const name = new Intl.DateTimeFormat('en-GB', { timeZone: UK_TZ, weekday: 'short' }).format(new Date(iso));
  const map = { Mon: 0, Tue: 1, Wed: 2, Thu: 3, Fri: 4, Sat: 5, Sun: 6 };
  return map[name] ?? 0;
};

// === R2 JSON convenience ===
const TS_LAYOUT_R2_KEY = 'Assets/Stationery/Timesheet/layout.json';

async function r2Put(env, key, bytesOrString, opts = {}) {
  const bucket = env.R2_BUCKET || env.R2;
  const cleanKey = normalizeKey(key);
  const body =
    bytesOrString instanceof Uint8Array ? bytesOrString
    : bytesOrString instanceof ArrayBuffer ? new Uint8Array(bytesOrString)
    : typeof bytesOrString === 'string' ? bytesOrString
    : new Uint8Array(); // fallback to empty

  return bucket.put(cleanKey, body, opts);
}
// ---------- Shared helpers (local to this patch block) ----------
const DOW_MAP = { mon:1, tue:2, wed:3, thu:4, fri:5, sat:6, sun:0 }; // JS: 0=Sun..6=Sat

function parseHHMM(s) {
  if (!s || typeof s !== 'string') return null;
  const m = s.trim().match(/^(\d{1,2}):(\d{2})$/);
  if (!m) return null;
  const h = +m[1], mi = +m[2];
  if (h<0||h>23||mi<0||mi>59) return null;
  return h*60 + mi;
}
function addDays(ymd, d) { const dt = new Date(ymd+'T00:00:00Z'); dt.setUTCDate(dt.getUTCDate()+d); return dt.toISOString().slice(0,10); }
function dow(ymd) { return (new Date(ymd+'T00:00:00Z')).getUTCDay(); } // 0=Sun..6=Sat
function minutesDiff(startMin, endMin, overnight=false) {
  if (startMin==null || endMin==null) return 0;
  if (overnight || endMin <= startMin) return (24*60 - startMin) + endMin;
  return endMin - startMin;
}
function isBH(ymd, bhSet) { return bhSet && bhSet.has(ymd); }

// Derive per-day total hours (decimal) from std_schedule_json {mon..sun:{start,end,break_minutes}}

// Build planned_schedule_json (7 dated entries) from template (mon..sun) for a given week ending

function buildPlannedScheduleFromTemplate(stdSched, weekEndingYmd) {
  const days = [];
  if (!stdSched || typeof stdSched!=='object') return days;
  const weekDates = Array.from({length:7}, (_,i)=> addDays(weekEndingYmd, - (6-i)));
  const mapDateByDow = Object.fromEntries(weekDates.map(d => [dow(d), d]));
  for (const [k, jsDow] of Object.entries(DOW_MAP)) {
    const dCfg = stdSched[k];
    const date = mapDateByDow[jsDow];
    if (!date) continue;
    // Skip non-templated weekdays completely (no placeholder rows)
    if (!dCfg) continue;
    const s = parseHHMM(dCfg.start), e = parseHHMM(dCfg.end);
    if (s==null || e==null) throw new Error(`Invalid HH:MM in std_schedule_json.${k}`);
    const br = Math.max(0, Number(dCfg.break_minutes||0));
    const overnight = (e<=s);
    const mins = Math.max(0, minutesDiff(s, e, overnight) - br);
    days.push({
      date, start: dCfg.start, end: dCfg.end,
      breaks: Array.isArray(dCfg.breaks)? dCfg.breaks : [],
      break_minutes: br, overnight, expected_minutes: mins
    });
  }
  return days;
}


function deriveStdHoursFromSchedule(stdSched) {
  if (!stdSched || typeof stdSched !== 'object') return null;
  const out = {};
  for (const k of Object.keys(DOW_MAP)) {
    const d = stdSched[k];
    if (!d) { out[k] = 0; continue; }
    const s = parseHHMM(d.start), e = parseHHMM(d.end);
    if (s==null || e==null) throw new Error(`Invalid HH:MM in std_schedule_json.${k}`);
    const br = Math.max(0, Number(d.break_minutes||0));
    const mins = Math.max(0, minutesDiff(s, e, e<=s) - br);   // ← infer overnight
    out[k] = +(mins/60).toFixed(2);
  }
  return out;
}


// ============================================================================
// SETTINGS DEFAULTS (UPDATED):
// - Adds TSFIN knobs from import_config_json.tsfin
// - Caches in-memory with TTL to reduce subrequests across requests
// - Normalises import_config_json whether stored as object OR JSON-string-in-jsonb
// ============================================================================

// Module-scope cache (persists across requests in the same Worker isolate)
const __SETTINGS_DEFAULTS_TTL_MS = 30_000; // 30s (tune as you like)
let __SETTINGS_DEFAULTS_CACHE = { ts: 0, value: null };

function _safeJsonParseMaybe(v, fallback = null) {
  if (v == null) return fallback;
  if (typeof v === 'object') return v;             // already parsed JSON / jsonb object
  if (typeof v !== 'string') return fallback;

  const s = v.trim();
  if (!s) return fallback;
  try { return JSON.parse(s); } catch { return fallback; }
}

function _asBool(v, def) {
  if (typeof v === 'boolean') return v;
  if (v == null) return def;
  const s = String(v).trim().toLowerCase();
  if (['true','1','yes','y','on'].includes(s)) return true;
  if (['false','0','no','n','off'].includes(s)) return false;
  return def;
}

function _asNum(v, def) {
  const n = Number(v);
  return Number.isFinite(n) ? n : def;
}

function _asPosInt(v, def) {
  const n = Math.floor(Number(v));
  return Number.isFinite(n) && n > 0 ? n : def;
}
async function loadSettingsDefaults(env) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  // TTL cache hit
  try {
    const now = Date.now();
    if (__SETTINGS_DEFAULTS_CACHE.value && (now - __SETTINGS_DEFAULTS_CACHE.ts) < __SETTINGS_DEFAULTS_TTL_MS) {
      if (LOG) console.log('[SETTINGS_DEFAULTS]', JSON.stringify({ stage: 'cache_hit' }));
      return __SETTINGS_DEFAULTS_CACHE.value;
    }
  } catch {}

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/settings_defaults` +
        `?select=timezone_id,import_config_json,finance_email,finance_email_settings,max_attachments_per_email` +
        `&id=eq.1` +
        `&limit=1`
    );

    const row = rows?.[0] || {};

    // import_config_json can be:
    // - proper jsonb object  (preferred)
    // - jsonb string holding JSON (your current DB has this pattern)
    const cfgRaw = row.import_config_json;
    const cfg = (typeof cfgRaw === 'object' && cfgRaw !== null)
      ? cfgRaw
      : (_safeJsonParseMaybe(cfgRaw, {}) || {});

    const timezoneId = row.timezone_id || 'Europe/London';

    // Existing knobs
    const importConfig = {
      useBatchedClassification: _asBool(cfg.use_batched_classification, true),
      maxPreviewSubrequests: _asPosInt(cfg.max_preview_subrequests, 40),
      maxHrRowsForFullPreview: _asPosInt(cfg.max_hr_rows_for_full_preview, 500),
    };

    // New TSFIN knobs (nested under cfg.tsfin)
    const tsfinCfgRaw = cfg.tsfin;
    const tsfinCfg = (typeof tsfinCfgRaw === 'object' && tsfinCfgRaw !== null)
      ? tsfinCfgRaw
      : (_safeJsonParseMaybe(tsfinCfgRaw, {}) || {});

    importConfig.tsfin = {
      maxInlineItems: _asPosInt(tsfinCfg.max_inline_items, 3),
      maxInlineRelatedItems: _asPosInt(tsfinCfg.max_inline_related_items, 10),
      maxCronBatchItems: _asPosInt(tsfinCfg.max_cron_batch_items, 50),
      useContextRpc: _asBool(tsfinCfg.use_context_rpc, true),
      useWriteBatchRpc: _asBool(tsfinCfg.use_write_batch_rpc, true),
      useRatesBatchRpc: _asBool(tsfinCfg.use_rates_batch_rpc, true),
    };

    // ✅ NEW: finance email settings (db-driven)
    const financeEmail = row.finance_email ? String(row.finance_email).trim() : null;

    const fesRaw = row.finance_email_settings;
    const financeEmailSettings = (typeof fesRaw === 'object' && fesRaw !== null)
      ? fesRaw
      : (_safeJsonParseMaybe(fesRaw, {}) || {});

    const maxAttachments = (() => {
      const n = Number(row.max_attachments_per_email);
      const v = Number.isFinite(n) ? Math.trunc(n) : 30;
      return (v >= 1 && v <= 100) ? v : 30;
    })();

    const out = {
      timezone_id: timezoneId,
      importConfig,

      // ✅ NEW (cached)
      finance_email: financeEmail,
      finance_email_settings: financeEmailSettings,
      max_attachments_per_email: maxAttachments
    };

    // Store TTL cache
    __SETTINGS_DEFAULTS_CACHE = { ts: Date.now(), value: out };

    if (LOG) {
      console.log('[SETTINGS_DEFAULTS]', JSON.stringify({
        stage: 'loaded',
        timezone_id: timezoneId,
        importConfig,
        finance_email: financeEmail,
        max_attachments_per_email: maxAttachments
      }));
    }

    return out;
  } catch (e) {
    if (LOG) {
      console.warn('[SETTINGS_DEFAULTS]', JSON.stringify({
        stage: 'load_failed',
        err: e?.message || String(e)
      }));
    }

    // Safe fallbacks
    const out = {
      timezone_id: 'Europe/London',
      importConfig: {
        useBatchedClassification: true,
        maxPreviewSubrequests: 40,
        maxHrRowsForFullPreview: 500,
        tsfin: {
          maxInlineItems: 3,
          maxInlineRelatedItems: 10,
          maxCronBatchItems: 50,
          useContextRpc: true,
          useWriteBatchRpc: true,
          useRatesBatchRpc: true,
        }
      },

      // ✅ NEW fallbacks
      finance_email: null,
      finance_email_settings: {},
      max_attachments_per_email: 30
    };

    __SETTINGS_DEFAULTS_CACHE = { ts: Date.now(), value: out };
    return out;
  }
}

// ============================================================================
// GET SETTINGS (UNCHANGED except optional normalisation comment)
// - Already includes import_config_json in explicit select list.
// - No structural change required.
// ============================================================================

// ============================================================================
// GET SETTINGS (UPDATED):
// - Removes legacy finance fields from settings_defaults payload
// - Adds finance_windows[] from RPC settings_finance_list() in the same response
//   (no new GET endpoint needed for FE; single extra RPC call)
// ============================================================================

// ============================================================================
// GET SETTINGS (UPDATED):
// - Removes legacy finance fields from settings_defaults payload
// - Adds finance_windows[] from RPC settings_finance_list() in the same response
//   (no new GET endpoint needed for FE; single extra RPC call)
// ============================================================================
async function handleGetSettings(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized('Unauthorized');

  try {
    const select =
      [
        'id',

        // Agency branding
        'agency_name',
        'agency_logo',

        // Timesheet PDF text blocks
        'timesheet_header_json',
        'timesheet_footer_json',

        // Global shift patterns + timezone
        'timezone_id',
        'day_start','day_end',
        'night_start','night_end',
        'sat_start','sat_end',
        'sun_start','sun_end',
        'bh_start','bh_end',

        // BH calendar config
        'bh_source','bh_list','bh_feed_url',

        // Global policy flags
        'ts_reference_required',

        // ✅ Adaptability config
        'import_config_json',

        // Bank details still live on settings_defaults
        'bank_name','bank_sort_code','bank_account_number','vat_registration_number',

        // ✅ NEW: Finance email settings (global)
        'finance_email',
        'finance_email_settings',
        'max_attachments_per_email'
      ].join(',');

    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=${select}`
    );

    // Finance windows list (new) — SQL-first RPC, single call
    let finance_windows = [];
    try {
      const fw = await sbRpc(env, 'settings_finance_list', {});
      finance_windows = Array.isArray(fw) ? fw : [];
    } catch {
      finance_windows = [];
    }

    if (!rows.length) {
      const { rows: alt } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/settings_defaults?select=${select}&limit=1`
      );
      if (!alt.length) return notFound("settings_defaults not found");

      const s2 = { ...alt[0] };
      delete s2.id;

      return withCORS(env, req, ok({
        settings: s2,
        finance_windows
      }));
    }

    const settings = { ...rows[0] };
    delete settings.id;

    return withCORS(env, req, ok({
      settings,
      finance_windows
    }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to fetch settings_defaults"));
  }
}

// ============================================================================
// UPDATE SETTINGS (UPDATED - OPTION A):
// - Stops writing legacy finance fields on settings_defaults
// - Keeps existing behaviour for non-finance fields (timezone, buckets, BH list, bank, import_config_json, etc.)
// - Finance windows are managed via the new handler below
// ============================================================================
async function handleUpdateSettings(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized('Unauthorized');

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  const allowed = [
    'timezone_id',
    'day_start','day_end','night_start','night_end',
    'sat_start','sat_end','sun_start','sun_end',
    'bh_start','bh_end',
    'bh_source','bh_list','bh_feed_url',

    'bank_name','bank_sort_code','bank_account_number','vat_registration_number',
    'ts_reference_required',

    // ✅ Adaptability config
    'import_config_json',

    // ✅ NEW: global finance email settings
    'finance_email',
    'finance_email_settings',
    'max_attachments_per_email'
  ];

  const payload = { updated_at: new Date().toISOString() };

  for (const k of allowed) {
    if (!(k in data)) continue;

    if (k === 'import_config_json') {
      const raw = data.import_config_json;
      let parsed = null;

      if (raw && typeof raw === 'object') {
        parsed = raw;
      } else if (typeof raw === 'string') {
        parsed = _safeJsonParseMaybe(raw, null);
      } else if (raw == null) {
        parsed = {};
      }

      if (!parsed || typeof parsed !== 'object') {
        return withCORS(env, req, badRequest("import_config_json must be a JSON object (or a JSON string that parses to an object)."));
      }

      payload.import_config_json = parsed;
      continue;
    }

    if (k === 'finance_email_settings') {
      const raw = data.finance_email_settings;
      let parsed = null;

      if (raw && typeof raw === 'object') {
        parsed = raw;
      } else if (typeof raw === 'string') {
        parsed = _safeJsonParseMaybe(raw, null);
      } else if (raw == null) {
        parsed = {};
      }

      if (!parsed || typeof parsed !== 'object') {
        return withCORS(env, req, badRequest("finance_email_settings must be a JSON object (or a JSON string that parses to an object)."));
      }

      payload.finance_email_settings = parsed;
      continue;
    }

    if (k === 'max_attachments_per_email') {
      const n = Number(data.max_attachments_per_email);
      const v = Number.isFinite(n) ? Math.trunc(n) : NaN;

      if (!(v >= 1 && v <= 100)) {
        return withCORS(env, req, badRequest("max_attachments_per_email must be an integer between 1 and 100."));
      }

      payload.max_attachments_per_email = v;
      continue;
    }

    if (k === 'finance_email') {
      const v = (data.finance_email == null) ? null : String(data.finance_email).trim();
      payload.finance_email = v && v.length ? v : null;
      continue;
    }

    // Normal field passthrough
    payload[k] = data[k];
  }

  try {
    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1`, {
      method: "PATCH",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify(payload)
    });

    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Update failed: ${err}`));
    }

    const json = await res.json().catch(() => ({}));
    const settings = Array.isArray(json) ? json[0] : json;
    delete settings.id;

    // Bust TTL cache so next loadSettingsDefaults fetches fresh values
    __SETTINGS_DEFAULTS_CACHE = { ts: 0, value: null };

    return withCORS(env, req, ok({ settings }));
  } catch {
    return withCORS(env, req, serverError("Failed to update settings_defaults"));
  }
}

// ============================================================================
// NEW HANDLER (OPTION A): Finance windows CRUD (global VAT/ERNI/Holiday Pay)
// Suggested routes:
// - GET    /api/settings/finance-windows
// - POST   /api/settings/finance-windows
// - PATCH  /api/settings/finance-windows/:id
// - DELETE /api/settings/finance-windows/:id
//
// Notes:
// - Uses settings_finance_windows table directly for writes (single REST call).
// - Uses settings_finance_list RPC for list (single RPC call).
// - Overlap prevention is enforced by the DB exclusion constraint.
// ============================================================================

async function handleSettingsFinanceWindows(env, req, windowId = null) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized('Unauthorized'));

  const enc = encodeURIComponent;
  const method = (req.method || 'GET').toUpperCase();

  // --------------------------
  // helpers
  // --------------------------
  const numOrNull = (v) => {
    if (v == null) return null;
    if (typeof v === 'string' && v.trim() === '') return null;
    const n = Number(v);
    return Number.isFinite(n) ? n : null;
  };

  const assertNonNegOrNull = (n, fieldName) => {
    if (n == null) return null;
    if (!Number.isFinite(n)) return `Field ${fieldName} must be a number or null`;
    if (n < 0) return `Field ${fieldName} must be >= 0`;
    return null;
  };

  // --------------------------
  // GET
  // --------------------------
  if (method === 'GET') {
    try {
      const rows = await sbRpc(env, 'settings_finance_list', {});
      return withCORS(env, req, ok({ finance_windows: Array.isArray(rows) ? rows : [] }));
    } catch (e) {
      return withCORS(env, req, serverError('Failed to load finance windows'));
    }
  }

  // All non-GET need JSON body except DELETE
  let body = null;
  if (method !== 'DELETE') {
    try {
      body = await parseJSONBody(req);
    } catch {
      return withCORS(env, req, badRequest('Invalid JSON'));
    }
  }

  // --------------------------
  // POST
  // --------------------------
  if (method === 'POST') {
    const date_from = body?.date_from || null;
    const date_to = body?.date_to ?? null;

    if (!date_from) return withCORS(env, req, badRequest('date_from is required (YYYY-MM-DD)'));
    if (!body || body.vat_rate_pct == null || body.erni_pct == null || body.holiday_pay_pct == null) {
      return withCORS(env, req, badRequest('vat_rate_pct, erni_pct, holiday_pay_pct are required'));
    }

    const vat_rate_pct = Number(body.vat_rate_pct);
    const erni_pct = Number(body.erni_pct);
    const holiday_pay_pct = Number(body.holiday_pay_pct);

    if (!Number.isFinite(vat_rate_pct) || !Number.isFinite(erni_pct) || !Number.isFinite(holiday_pay_pct)) {
      return withCORS(env, req, badRequest('vat_rate_pct, erni_pct, holiday_pay_pct must be numbers'));
    }

    // ✅ NEW: global mileage defaults (nullable, but if present must be >= 0)
    const mileage_pay_defaults = numOrNull(body.mileage_pay_defaults);
    const mileage_charge_defaults = numOrNull(body.mileage_charge_defaults);

    const mpErr = assertNonNegOrNull(mileage_pay_defaults, 'mileage_pay_defaults');
    if (mpErr) return withCORS(env, req, badRequest(mpErr));
    const mcErr = assertNonNegOrNull(mileage_charge_defaults, 'mileage_charge_defaults');
    if (mcErr) return withCORS(env, req, badRequest(mcErr));

    const payload = {
      date_from,
      date_to: (date_to === '' ? null : date_to),

      vat_rate_pct,
      erni_pct,
      holiday_pay_pct,

      // ✅ NEW fields persisted to settings_finance_windows
      mileage_pay_defaults,
      mileage_charge_defaults,

      apply_holiday_to: body.apply_holiday_to ?? null,
      apply_erni_to: body.apply_erni_to ?? null,
      margin_includes: (body.margin_includes && typeof body.margin_includes === 'object') ? body.margin_includes : null
    };

    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/settings_finance_windows`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload)
    });

    if (!res.ok) {
      const t = await res.text().catch(() => '');
      return withCORS(env, req, badRequest(`Create finance window failed: ${t || res.status}`));
    }

    const json = await res.json().catch(() => ([]));
    const row = Array.isArray(json) ? json[0] : json;
    return withCORS(env, req, ok({ finance_window: row }));
  }

  // --------------------------
  // PATCH
  // --------------------------
  if (method === 'PATCH') {
    if (!windowId) return withCORS(env, req, badRequest('finance window id is required'));

    const patch = {};
    const keys = [
      'date_from', 'date_to',
      'vat_rate_pct', 'erni_pct', 'holiday_pay_pct',

      // ✅ NEW mileage defaults
      'mileage_pay_defaults', 'mileage_charge_defaults',

      'apply_holiday_to', 'apply_erni_to', 'margin_includes'
    ];

    for (const k of keys) {
      if (!(k in (body || {}))) continue;

      if (k === 'margin_includes') {
        patch[k] = (body[k] && typeof body[k] === 'object') ? body[k] : null;
        continue;
      }

      if (k === 'date_to') {
        patch[k] = (body[k] === '' ? null : body[k]);
        continue;
      }

      if (
        k === 'vat_rate_pct' || k === 'erni_pct' || k === 'holiday_pay_pct' ||
        k === 'mileage_pay_defaults' || k === 'mileage_charge_defaults'
      ) {
        // allow null/blank -> null for mileage defaults, but require numbers for vat/erni/holiday if supplied
        const n = numOrNull(body[k]);

        if (k === 'vat_rate_pct' || k === 'erni_pct' || k === 'holiday_pay_pct') {
          // these should not be null if provided
          if (n == null) return withCORS(env, req, badRequest(`${k} must be a number`));
          patch[k] = n;
          continue;
        }

        // mileage defaults: nullable, but if present must be >=0
        const err = assertNonNegOrNull(n, k);
        if (err) return withCORS(env, req, badRequest(err));
        patch[k] = n;
        continue;
      }

      patch[k] = body[k];
    }

    if (!Object.keys(patch).length) {
      return withCORS(env, req, badRequest('No fields to update'));
    }

    patch.updated_at = new Date().toISOString();

    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/settings_finance_windows?id=eq.${enc(windowId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify(patch)
      }
    );

    if (!res.ok) {
      const t = await res.text().catch(() => '');
      return withCORS(env, req, badRequest(`Update finance window failed: ${t || res.status}`));
    }

    const json = await res.json().catch(() => ([]));
    const row = Array.isArray(json) ? json[0] : json;
    return withCORS(env, req, ok({ finance_window: row }));
  }

  // --------------------------
  // DELETE
  // --------------------------
  if (method === 'DELETE') {
    if (!windowId) return withCORS(env, req, badRequest('finance window id is required'));

    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/settings_finance_windows?id=eq.${enc(windowId)}`,
      {
        method: 'DELETE',
        headers: { ...sbHeaders(env), Prefer: 'return=minimal' }
      }
    );

    if (!res.ok) {
      const t = await res.text().catch(() => '');
      return withCORS(env, req, badRequest(`Delete finance window failed: ${t || res.status}`));
    }

    return withCORS(env, req, ok({ deleted: true, id: windowId }));
  }

  return withCORS(env, req, badRequest('Unsupported method'));
}

// ============================================================================
// UPDATE SETTINGS (UPDATED):
// - Allows import_config_json
// - Validates it (object or JSON string)
// - Writes it as a proper JSON object (preferred) to avoid double-encoding
// - Keeps existing behaviour for other fields
// ============================================================================



// Load client windows & BH list (fallback to defaults if missing)
async function loadClientTimePolicy(env, clientId) {
  const enc = encodeURIComponent;

  const cs = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/client_settings?client_id=eq.${enc(
      clientId
    )}&select=day_start,day_end,night_start,night_end,sat_start,sat_end,sun_start,sun_end,bh_start,bh_end,bh_list`
  );

  const defaults = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=day_start,day_end,night_start,night_end,sat_start,sat_end,sun_start,sun_end,bh_start,bh_end,bh_list`
  );

  const src = { ...(defaults || {}), ...(cs || {}) };

  // Normalise "HH:MM:SS" → "HH:MM" before parseHHMM
  const toHHMM = (val, fallback) => {
    const raw = (val ?? fallback ?? "").toString().trim();
    if (!raw) return fallback;

    const parts = raw.split(":"); // "06:00:00" → ["06","00","00"]
    const hh = (parts[0] ?? "00").padStart(2, "0");
    const mm = (parts[1] ?? "00").padStart(2, "0");
    return `${hh}:${mm}`;
  };

  const dayStart   = parseHHMM(toHHMM(src.day_start,   "06:00"));
  const dayEnd     = parseHHMM(toHHMM(src.day_end,     "20:00"));
  const nightStart = parseHHMM(toHHMM(src.night_start, "20:00"));
  const nightEnd   = parseHHMM(toHHMM(src.night_end,   "06:00"));
  const satStart   = parseHHMM(toHHMM(src.sat_start,   "00:00"));
  const satEnd     = parseHHMM(toHHMM(src.sat_end,     "00:00"));
  const sunStart   = parseHHMM(toHHMM(src.sun_start,   "00:00"));
  const sunEnd     = parseHHMM(toHHMM(src.sun_end,     "00:00"));

  // ✅ BH window (00:00–00:00 = full BH day). Prefer client override, else global.
  const bhStart = parseHHMM(
    toHHMM(
      (cs && cs.bh_start) ||
        (defaults && defaults.bh_start) ||
        "00:00",
      "00:00"
    )
  );
  const bhEnd = parseHHMM(
    toHHMM(
      (cs && cs.bh_end) ||
        (defaults && defaults.bh_end) ||
        "00:00",
      "00:00"
    )
  );

  // ✅ BH LIST IS GLOBAL-ONLY (ignore client_settings.bh_list entirely)
  // Normalise BH list (array or JSON string → array → Set)
  const rawBhList = (defaults && defaults.bh_list) ?? [];

  let bhListArr = [];
  if (Array.isArray(rawBhList)) {
    bhListArr = rawBhList;
  } else if (typeof rawBhList === "string") {
    try {
      const parsed = JSON.parse(rawBhList);
      if (Array.isArray(parsed)) bhListArr = parsed;
    } catch {
      // leave as []
    }
  }

  const bhList = new Set(bhListArr);

  return {
    dayStart,
    dayEnd,
    nightStart,
    nightEnd,
    satStart,
    satEnd,
    sunStart,
    sunEnd,
    bhStart,
    bhEnd,
    bhList,
  };
}


// ─────────────────────────────────────────────────────────────
// Shared helper: reference completeness (matches DB view truth)
// ─────────────────────────────────────────────────────────────

function strTrim(x) { return (x == null) ? '' : String(x).trim(); }

function dayRefsHasAny(dayRefs) {
  if (!dayRefs || typeof dayRefs !== 'object') return false;
  return Object.values(dayRefs).some(v => strTrim(v));
}

function weeklyManualScheduleHasCompleteRefs(schedule) {
  const arr = Array.isArray(schedule) ? schedule : [];
  if (!arr.length) return false;

  for (const seg of arr) {
    if (!seg || typeof seg !== 'object') continue;
    const start = strTrim(seg.start);
    const end   = strTrim(seg.end);

    // Only enforce ref on “real shift” segments
    if (start && end) {
      const ref = strTrim(seg.ref_num);
      if (!ref) return false;
    }
  }
  return true;
}

function timesheetHasInvoiceReference(ts) {
  const scope = strTrim(ts?.sheet_scope).toUpperCase();
  const mode  = strTrim(ts?.submission_mode).toUpperCase();

  // WEEKLY + MANUAL is schedule-driven
  if (scope === 'WEEKLY' && mode === 'MANUAL') {
    return weeklyManualScheduleHasCompleteRefs(ts?.actual_schedule_json);
  }

  // WEEKLY non-manual uses legacy weekly reference model
  if (scope === 'WEEKLY') {
    return !!strTrim(ts?.reference_number) || dayRefsHasAny(ts?.day_references_json);
  }

  // DAILY (and anything else) uses reference_number
  return !!strTrim(ts?.reference_number);
}

// Segment one day's chunk [a,b) in minutes (0..1440), allocate into day/night using client windows.
// Weekend/BH overlay wins over day/night; precedence BH > Sun > Sat > Night > Day.

function segmentChunkIntoBuckets(dateYmd, a, b, policy, acc) {
  const len = Math.max(0, b - a);
  if (len === 0) return;

  const clamp0_1440 = (v) => Math.max(0, Math.min(1440, v));
  const d = dow(dateYmd); // 0=Sun..6=Sat

  // Normalise BH list
  const bhList =
    policy && policy.bhList instanceof Set
      ? policy.bhList
      : new Set(Array.isArray(policy?.bhList) ? policy.bhList : []);

  const isBhDate = isBH(dateYmd, bhList);

  // Start with full segment as “remaining”; we may carve out BH & Sat/Sun sub-ranges
  let rem = [{ from: a, to: b }];

  // ──────────────────────────────
  // 1) Split out Bank Holiday time
  // ──────────────────────────────
  if (isBhDate) {
    const bhStart = typeof policy.bhStart === 'number' ? clamp0_1440(policy.bhStart) : 0;
    const bhEnd   = typeof policy.bhEnd   === 'number' ? clamp0_1440(policy.bhEnd)   : 0;

    const bhIntervals = [];

    if (bhStart === 0 && bhEnd === 0) {
      // Full BH day: all minutes on this date are BH
      bhIntervals.push({ from: 0, to: 1440 });
    } else if (bhStart < bhEnd) {
      // Simple window
      bhIntervals.push({ from: bhStart, to: bhEnd });
    } else {
      // Wrap-around window (e.g. 20:00 → 06:00)
      bhIntervals.push({ from: bhStart, to: 1440 });
      bhIntervals.push({ from: 0,       to: bhEnd });
    }

    const bhSegments = [];

    for (const wi of bhIntervals) {
      const nextRem = [];
      for (const r of rem) {
        const start = r.from;
        const end   = r.to;
        const x1 = Math.max(start, wi.from);
        const x2 = Math.min(end,   wi.to);
        if (x1 < x2) {
          // BH portion
          bhSegments.push({ from: x1, to: x2 });
          // Non-BH leftovers
          if (x1 > start) nextRem.push({ from: start, to: x1 });
          if (x2 < end)   nextRem.push({ from: x2,    to: end });
        } else {
          // No overlap; keep as-is
          nextRem.push(r);
        }
      }
      rem = nextRem;
      if (!rem.length) break;
    }

    // Accumulate BH minutes
    for (const s of bhSegments) acc.bh += (s.to - s.from);
    if (!rem.length) return;
  }

  // ──────────────────────────────
  // 2) Weekend windows (Sat/Sun)
  // ──────────────────────────────
  const satStart = typeof policy.satStart === 'number' ? policy.satStart : 0;
  const satEnd   = typeof policy.satEnd   === 'number' ? policy.satEnd   : 0;
  const sunStart = typeof policy.sunStart === 'number' ? policy.sunStart : 0;
  const sunEnd   = typeof policy.sunEnd   === 'number' ? policy.sunEnd   : 0;

  // Interpret Sat/Sun windows as:
  //  - Saturday: from sat_start on Saturday up to sat_end on Sunday (next day)
  //  - Sunday:   from sun_start on Sunday up to sun_end on Monday (next day)
  const satEndAbs = 1440 + satEnd; // minutes from Sat 00:00
  const sunEndAbs = 1440 + sunEnd; // minutes from Sun 00:00

  const weekendIntervals = [];

  if (d === 6) { // Saturday
    const fromSat = clamp0_1440(satStart);
    const toSat   = 1440; // portion of [satStart, satEndAbs] that lies on Saturday
    if (toSat > fromSat) weekendIntervals.push({ from: fromSat, to: toSat, bucket: 'sat' });
  }

  if (d === 0) { // Sunday
    // Tail of Saturday window spilling into Sunday (Sat → Sun)
    const satTail = satEndAbs - 1440;
    if (satTail > 0) {
      const from = 0;
      const to   = clamp0_1440(satTail);
      if (to > from) weekendIntervals.push({ from, to, bucket: 'sat' });
    }
    // Sunday window itself
    const fromSun = clamp0_1440(sunStart);
    let toSun = sunEndAbs > 1440 ? 1440 : clamp0_1440(sunEndAbs);
    if (toSun < fromSun) toSun = fromSun;
    if (toSun > fromSun) weekendIntervals.push({ from: fromSun, to: toSun, bucket: 'sun' });
  }

  if (d === 1) { // Monday: tail of Sunday window
    const sunTail = sunEndAbs - 1440;
    if (sunTail > 0) {
      const from = 0;
      const to   = clamp0_1440(sunTail);
      if (to > from) weekendIntervals.push({ from, to, bucket: 'sun' });
    }
  }

  for (const wi of weekendIntervals) {
    const nextRem = [];
    for (const r of rem) {
      const start = r.from;
      const end   = r.to;
      const x1 = Math.max(start, wi.from);
      const x2 = Math.min(end,   wi.to);
      if (x1 < x2) {
        acc[wi.bucket] += (x2 - x1);
        if (x1 > start) nextRem.push({ from: start, to: x1 });
        if (x2 < end)   nextRem.push({ from: x2,    to: end });
      } else {
        nextRem.push(r);
      }
    }
    rem = nextRem;
    if (!rem.length) break;
  }

  if (!rem.length) return;

  // ──────────────────────────────
  // 3) Day / Night – using dayStart/dayEnd split
  // ──────────────────────────────
  const ds = typeof policy.dayStart === 'number' ? policy.dayStart : 0;
  const de = typeof policy.dayEnd   === 'number' ? policy.dayEnd   : 1440;

  const seg = [
    { from: 0,  to: ds, bucket:'night' },
    { from: ds, to: de, bucket:'day'   },
    { from: de, to: 1440, bucket:'night' }
  ];

  for (const r of rem) {
    const start = r.from;
    const end   = r.to;
    for (const s of seg) {
      const x1 = Math.max(start, s.from);
      const x2 = Math.min(end,   s.to);
      if (x2 > x1) acc[s.bucket] += (x2 - x1);
    }
  }
}

// Apply duration-only break: subtract from largest bucket; ties: BH > Sun > Sat > Night > Day
function applyDurationBreak(acc, breakMin) {
  if (!breakMin || breakMin<=0) return;
  const order = ['bh','sun','sat','night','day'];
  let remaining = breakMin;
  while (remaining>0) {
    // find largest bucket by minutes following precedence order for ties
    let bestK = null, bestVal = -1;
    for (const k of order) {
      const v = acc[k]||0;
      if (v > bestVal) { bestVal = v; bestK = k; }
    }
    if (!bestK || bestVal<=0) break;
    const take = Math.min(remaining, bestVal);
    acc[bestK] -= take;
    remaining -= take;
  }
}

// Resolve hours (minutes) by bucket from an actual_schedule_json array
async function resolveBucketsFromSchedule(env, contract, actualDays /* array */, policyOverride = null) {
  // ✅ Ensure schedule has no internal overlaps / bad breaks before bucketing
  validateScheduleStructure(actualDays);

  // If caller provides SQL policy (string times + bh_list), derive numeric policy
  const toNumericPolicyFromSql = (p) => {
    const hhmmssToMin = (val, fallback = '00:00:00') => {
      const s = String(val ?? fallback).trim();
      if (!s) return 0;
      const parts = s.split(':');
      const h = parseInt(parts[0] || '0', 10) || 0;
      const m = parseInt(parts[1] || '0', 10) || 0;
      return (h * 60) + m;
    };

    const bhArr = Array.isArray(p?.bh_list) ? p.bh_list.map(String) : [];
    return {
      dayStart:   hhmmssToMin(p?.day_start,   '06:00:00'),
      dayEnd:     hhmmssToMin(p?.day_end,     '20:00:00'),
      nightStart: hhmmssToMin(p?.night_start, '20:00:00'), // not used by segmentChunkIntoBuckets but kept for completeness
      nightEnd:   hhmmssToMin(p?.night_end,   '06:00:00'), // not used by segmentChunkIntoBuckets but kept for completeness
      satStart:   hhmmssToMin(p?.sat_start,   '00:00:00'),
      satEnd:     hhmmssToMin(p?.sat_end,     '00:00:00'),
      sunStart:   hhmmssToMin(p?.sun_start,   '00:00:00'),
      sunEnd:     hhmmssToMin(p?.sun_end,     '00:00:00'),
      bhStart:    hhmmssToMin(p?.bh_start,    '00:00:00'),
      bhEnd:      hhmmssToMin(p?.bh_end,      '00:00:00'),
      bhList:     new Set(bhArr),
    };
  };

  // ✅ Choose policy: override if provided; else legacy REST path
  // If policyOverride already looks like a numeric policy (dayStart is a number), use it directly.
  const policy = policyOverride
    ? (typeof policyOverride?.dayStart === 'number' ? policyOverride : toNumericPolicyFromSql(policyOverride))
    : await loadClientTimePolicy(env, contract.client_id);

  const acc = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };

  // ✅ Self-contained date add helper (avoid relying on a global addDays())
  const addDays = (ymd, days) => {
    try {
      const baseYmd = String(ymd || '').slice(0, 10);
      const d = new Date(`${baseYmd}T00:00:00Z`);
      if (!Number.isFinite(d.getTime())) return baseYmd || String(ymd || '');
      d.setUTCDate(d.getUTCDate() + Number(days || 0));
      const yyyy = d.getUTCFullYear();
      const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
      const dd   = String(d.getUTCDate()).padStart(2, '0');
      return `${yyyy}-${mm}-${dd}`;
    } catch {
      return String(ymd || '').slice(0, 10);
    }
  };

  if (typeof segmentChunkIntoBuckets !== 'function') {
    throw new Error('segmentChunkIntoBuckets is missing (required for BH/Sun/Sat/Night/Day precedence bucketing)');
  }
  if (typeof applyDurationBreak !== 'function') {
    throw new Error('applyDurationBreak is missing (required for floating break_minutes bucketing)');
  }

  const logBuckets = (label, payload) => {
    try {
      console.log('[BUCKETS]', label, JSON.stringify(payload));
    } catch {}
  };

  const normYmd = (v) => {
    const s = String(v || '').trim();
    if (!s) return '';
    const ymd = s.slice(0, 10);
    if (!/^\d{4}-\d{2}-\d{2}$/.test(ymd)) return '';
    return ymd;
  };

  logBuckets('policy', { client_id: contract.client_id, contract_id: contract.id, policy });

  for (const d of (actualDays || [])) {
    if (!d || !d.date || !d.start || !d.end) continue;

    const ymd = normYmd(d.date);
    if (!ymd) continue;

    const s = parseHHMM(d.start);
    const e = parseHHMM(d.end);

    if (s == null || e == null) {
      throw new Error(`Invalid HH:MM in actual_schedule_json for ${ymd}`);
    }

    const overnight = (e <= s);

    logBuckets('day-entry', {
      date: ymd,
      start: d.start,
      end: d.end,
      parsed_start_min: s,
      parsed_end_min: e,
      overnight,
      breaks: d.breaks || null,
      break_minutes: d.break_minutes || null
    });

    const chunk1 = { date: ymd, from: s, to: overnight ? 1440 : e };
    const chunks = [chunk1];
    if (overnight) {
      const next = addDays(ymd, 1);
      chunks.push({ date: next, from: 0, to: e });
    }

    for (const c of chunks) {
      const before = { ...acc };
      segmentChunkIntoBuckets(c.date, c.from, c.to, policy, acc);

      const diff = {};
      for (const k of Object.keys(acc)) {
        const delta = (acc[k] || 0) - (before[k] || 0);
        if (delta !== 0) diff[k] = delta;
      }

      logBuckets('work-chunk', {
        chunk_date: c.date,
        from_min: c.from,
        to_min: c.to,
        added_minutes: diff,
        acc_after: acc
      });
    }

    // ── Breaks by explicit windows ──
    if (Array.isArray(d.breaks) && d.breaks.length) {
      for (const br of d.breaks) {
        const bs = parseHHMM(br.start);
        const be = parseHHMM(br.end);
        if (bs == null || be == null) {
          logBuckets('break-skip-invalid', { date: ymd, break: br });
          continue;
        }

        const bOver = (be <= bs);
        const bChunk1 = { date: ymd, from: bs, to: bOver ? 1440 : be };
        const bChunks = [bChunk1];
        if (bOver) bChunks.push({ date: addDays(ymd, 1), from: 0, to: be });

        const tmp = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
        for (const c of bChunks) {
          segmentChunkIntoBuckets(c.date, c.from, c.to, policy, tmp);
        }

        logBuckets('break-window', {
          date: ymd,
          break_start: br.start,
          break_end: br.end,
          parsed_start_min: bs,
          parsed_end_min: be,
          overnight: bOver,
          break_minutes_per_bucket: tmp
        });

        const beforeAcc = { ...acc };
        for (const k of Object.keys(acc)) {
          acc[k] = Math.max(0, acc[k] - (tmp[k] || 0));
        }

        const diffAfter = {};
        for (const k of Object.keys(acc)) {
          const delta = (acc[k] || 0) - (beforeAcc[k] || 0);
          if (delta !== 0) diffAfter[k] = delta;
        }

        logBuckets('break-applied', { date: ymd, delta_minutes: diffAfter, acc_after: acc });
      }
    }
    // ── Floating break minutes (no explicit windows) ──
    else if (Number(d.break_minutes) > 0) {
      const mins = Number(d.break_minutes) || 0;
      const beforeAcc = { ...acc };
      applyDurationBreak(acc, mins);

      const diffAfter = {};
      for (const k of Object.keys(acc)) {
        const delta = (acc[k] || 0) - (beforeAcc[k] || 0);
        if (delta !== 0) diffAfter[k] = delta;
      }

      logBuckets('floating-break-applied', { date: ymd, break_minutes: mins, delta_minutes: diffAfter, acc_after: acc });
    }

    logBuckets('day-summary', { date: ymd, acc_after_day: { ...acc } });
  }

  logBuckets('final-accumulator', acc);
  return acc;
}




// Validate that, within a single timesheet schedule:
// - Each shift has valid start/end HH:MM
// - No shift overlaps another shift on the same date
// - Break windows (primary + extras) are inside their shift window
// Throws Error with a descriptive message if invalid.
function validateScheduleStructure(actualDays /* array of {date,start,end,breaks?,break_start?,break_end?,break_minutes?} */) {
  if (!Array.isArray(actualDays) || !actualDays.length) return;

  const byDate = new Map();
  const hasText = (v) => v != null && String(v).trim() !== '';

  const breakMinutesValue = (d) => {
    if (!d) return null;
    // accept break_minutes or break_mins
    const raw = (d.break_minutes != null) ? d.break_minutes : d.break_mins;
    if (raw == null || raw === '') return null;

    const n = Number(raw);
    if (!Number.isFinite(n)) {
      throw new Error(`Invalid break_minutes (must be numeric) on ${String(d.date || '').trim() || 'unknown date'}`);
    }
    if (n < 0) {
      throw new Error(`Invalid break_minutes (must be >= 0) on ${String(d.date || '').trim() || 'unknown date'}`);
    }
    return Math.floor(n);
  };

  const hasAnyBreakTimes = (d) => {
    if (!d) return false;
    if (hasText(d.break_start) || hasText(d.break_end)) return true;
    if (Array.isArray(d.breaks)) {
      return d.breaks.some(b => b && (hasText(b.start) || hasText(b.end)));
    }
    return false;
  };

  for (const d of actualDays) {
    if (!d || !d.date) continue;
    const date = d.date;

    const hasStart = hasText(d.start);
    const hasEnd   = hasText(d.end);

    // shift start/end must both exist or neither
    if (hasStart !== hasEnd) {
      throw new Error(`Shift start/end must both be set (or both blank) for ${date}`);
    }

    const hasWindowBreaks = hasAnyBreakTimes(d);
    const bm = breakMinutesValue(d);
    const hasBreakMins = (bm != null && bm > 0);

    // If no shift, there must be no breaks of any kind
    if (!hasStart && !hasEnd) {
      if (hasWindowBreaks || hasBreakMins) {
        throw new Error(`Breaks require a valid shift start/end on ${date}`);
      }
      continue;
    }

    const s = parseHHMM(d.start);
    const e = parseHHMM(d.end);

    // hard error if invalid HH:MM
    if (s == null || e == null) {
      throw new Error(`Invalid HH:MM in actual_schedule_json for ${date}`);
    }

    // start != end
    if (s === e) {
      throw new Error(`Shift start and end cannot be the same on ${date}`);
    }

    // start after end allowed only as overnight (wrap)
    const shiftStartMin = s;
    const shiftEndMin   = (e > s) ? e : (e + 1440); // overnight ok
    const shiftMinutes  = shiftEndMin - shiftStartMin;

    // Disallow mixing break minutes with break windows on the same segment
    if (hasBreakMins && hasWindowBreaks) {
      throw new Error(`Use either break_minutes OR break start/end windows (not both) on ${date}`);
    }

    // Sanity check floating break minutes
    if (hasBreakMins) {
      if (bm >= shiftMinutes) {
        throw new Error(`break_minutes must be less than shift duration on ${date}`);
      }
    }

    if (!byDate.has(date)) byDate.set(date, []);
    byDate.get(date).push({
      startMin: shiftStartMin,
      endMin:   shiftEndMin,
      entry:    d,
    });

    // Validate breaks for this shift (all rules, overnight-aware)
    // - validateBreaksForShift already checks window breaks; we only call it if windows exist
    // - break_minutes is validated above
    if (hasWindowBreaks) {
      validateBreaksForShift(date, shiftStartMin, shiftEndMin, shiftMinutes, d);
    }
  }

  // Overlapping shifts per date (overnight-aware because endMin may exceed 1440)
  for (const [date, segments] of byDate.entries()) {
    if (!Array.isArray(segments) || segments.length < 2) continue;

    segments.sort((a, b) => a.startMin - b.startMin);

    for (let i = 1; i < segments.length; i++) {
      const prev = segments[i - 1];
      const cur  = segments[i];
      if (cur.startMin < prev.endMin) {
        throw new Error(`Overlapping shifts detected on ${date}`);
      }
    }
  }
}

function validateBreaksForShift(date, shiftStartMin, shiftEndMin, shiftMinutes, d) {
  const hasText = (v) => v != null && String(v).trim() !== '';

  // ✅ If break_minutes/break_mins is used, do not accept break windows too.
  // validateScheduleStructure already validates bm < shiftMinutes, but keep it defensive here too.
  const rawBm = (d && (d.break_minutes != null ? d.break_minutes : d.break_mins));
  const bm = (rawBm == null || rawBm === '') ? null : Number(rawBm);
  const hasBreakMins = (bm != null && Number.isFinite(bm) && bm > 0);

  const hasWindow =
    (hasText(d?.break_start) || hasText(d?.break_end)) ||
    (Array.isArray(d?.breaks) && d.breaks.some(b => b && (hasText(b.start) || hasText(b.end))));

  if (hasBreakMins) {
    if (hasWindow) {
      throw new Error(`Use either break_minutes OR break windows (not both) on ${date}`);
    }
    if (bm >= shiftMinutes) {
      throw new Error(`break_minutes must be less than shift length on ${date}`);
    }
    return; // nothing else to validate
  }

  // Choose canonical break windows:
  // - if breaks[] has any populated entries, use that
  // - else fall back to break_start/break_end
  let windows = [];
  const breaksArr = Array.isArray(d.breaks) ? d.breaks.filter(b => b && (hasText(b.start) || hasText(b.end))) : [];

  if (breaksArr.length) {
    windows = breaksArr.map((b, i) => ({ start: b.start, end: b.end, idx: i }));
  } else if (hasText(d.break_start) || hasText(d.break_end)) {
    windows = [{ start: d.break_start, end: d.break_end, idx: -1 }];
  }

  // break windows must both exist or neither; start!=end; ordering allows overnight only if still within shift span
  const ranges = []; // { bsAdj, beAdj }

  for (const w of windows) {
    const hasBStart = hasText(w.start);
    const hasBEnd   = hasText(w.end);

    if (hasBStart !== hasBEnd) {
      throw new Error(`Break start/end must both be set (or both blank) on ${date}`);
    }
    if (!hasBStart && !hasBEnd) continue;

    const bs0 = parseHHMM(w.start);
    const be0 = parseHHMM(w.end);

    if (bs0 == null || be0 == null) {
      throw new Error(`Invalid HH:MM in break window on ${date}`);
    }
    if (bs0 === be0) {
      throw new Error(`Break start and end cannot be the same on ${date}`);
    }

    // Place break on same timeline as shift (overnight-aware)
    let bsAdj = bs0;
    if (bsAdj < shiftStartMin) bsAdj += 1440;

    let beAdj = be0;
    if (beAdj <= bsAdj) beAdj += 1440; // break overnight allowed

    // Must be fully within shift span
    if (bsAdj < shiftStartMin || beAdj > shiftEndMin || beAdj <= bsAdj) {
      throw new Error(`Break must be within shift on ${date} (${w.start}-${w.end})`);
    }

    ranges.push({ bsAdj, beAdj });
  }

  // break windows must not overlap each other
  ranges.sort((a, b) => a.bsAdj - b.bsAdj);
  for (let i = 1; i < ranges.length; i++) {
    if (ranges[i].bsAdj < ranges[i - 1].beAdj) {
      throw new Error(`Overlapping breaks detected on ${date}`);
    }
  }

  // Optional sanity: total break minutes < shift minutes (prevents break >= shift)
  const totalBreakMin = ranges.reduce((sum, r) => sum + (r.beAdj - r.bsAdj), 0);
  if (totalBreakMin >= shiftMinutes) {
    throw new Error(`Total break time must be less than shift length on ${date}`);
  }
}



async function r2GetJSON(env, key) {
  const u8 = await r2GetBytes(env, key);
  if (!u8) return null;
  try { return JSON.parse(new TextDecoder().decode(u8)); }
  catch { return null; }
}

async function r2PutJSON(env, key, obj, opts = {}) {
  const json = JSON.stringify(obj, null, 2);
  return r2Put(env, key, json, { httpMetadata: { contentType: 'application/json' }, ...opts });
}

// Minimal safe fallback (edit once via calibrator UI; persisted copy lives at TS_LAYOUT_R2_KEY)
const TS_LAYOUT_FALLBACK = {
  page: { width_mm: 210, height_mm: 297 },
  rows: [
    { date:{x_mm:22,y_mm:210}, start:{x_mm:60,y_mm:210}, finish:{x_mm:85,y_mm:210}, brkStart:{x_mm:110,y_mm:210}, brkEnd:{x_mm:130,y_mm:210}, role:{x_mm:155,y_mm:210} },
    { date:{x_mm:22,y_mm:200}, start:{x_mm:60,y_mm:200}, finish:{x_mm:85,y_mm:200}, brkStart:{x_mm:110,y_mm:200}, brkEnd:{x_mm:130,y_mm:200}, role:{x_mm:155,y_mm:200} },
    { date:{x_mm:22,y_mm:190}, start:{x_mm:60,y_mm:190}, finish:{x_mm:85,y_mm:190}, brkStart:{x_mm:110,y_mm:190}, brkEnd:{x_mm:130,y_mm:190}, role:{x_mm:155,y_mm:190} },
    { date:{x_mm:22,y_mm:180}, start:{x_mm:60,y_mm:180}, finish:{x_mm:85,y_mm:180}, brkStart:{x_mm:110,y_mm:180}, brkEnd:{x_mm:130,y_mm:180}, role:{x_mm:155,y_mm:180} },
    { date:{x_mm:22,y_mm:170}, start:{x_mm:60,y_mm:170}, finish:{x_mm:85,y_mm:170}, brkStart:{x_mm:110,y_mm:170}, brkEnd:{x_mm:130,y_mm:170}, role:{x_mm:155,y_mm:170} },
    { date:{x_mm:22,y_mm:160}, start:{x_mm:60,y_mm:160}, finish:{x_mm:85,y_mm:160}, brkStart:{x_mm:110,y_mm:160}, brkEnd:{x_mm:130,y_mm:160}, role:{x_mm:155,y_mm:160} },
    { date:{x_mm:22,y_mm:150}, start:{x_mm:60,y_mm:150}, finish:{x_mm:85,y_mm:150}, brkStart:{x_mm:110,y_mm:150}, brkEnd:{x_mm:130,y_mm:150}, role:{x_mm:155,y_mm:150} },
  ],
  fields: {
    hospital:{x_mm:20,y_mm:270}, ward:{x_mm:110,y_mm:270},
    candidate:{x_mm:20,y_mm:260}, job_title:{x_mm:110,y_mm:260}, band:{x_mm:180,y_mm:260},
    booking_ref:{x_mm:20,y_mm:250}, week_ending:{x_mm:110,y_mm:250}, ts_number:{x_mm:180,y_mm:250},
    nurse_sign_date:{x_mm:45,y_mm:85}, nurse_signature:{x_mm:20,y_mm:90,w_mm:60,h_mm:20},
    auth_name:{x_mm:120,y_mm:85}, auth_job_title:{x_mm:120,y_mm:80}, auth_sign_date:{x_mm:165,y_mm:85},
    auth_signature:{x_mm:120,y_mm:90,w_mm:60,h_mm:20},
  },
  text: { fontSize: 10 },
  debug: { enabled: false, grid_mm: 5 },
};

function validateTsLayout(l) {
  const e = (msg) => new Error(`Invalid timesheet layout: ${msg}`);
  if (!l || typeof l !== 'object') throw e('missing object');
  const { page, rows, fields } = l;
  if (!page || typeof page.width_mm !== 'number' || typeof page.height_mm !== 'number') throw e('page dims required');
  if (!Array.isArray(rows) || rows.length !== 7) throw e('rows must be length=7 (Mon..Sun)');
  const needPoint = (o, n) => (o && typeof o.x_mm === 'number' && typeof o.y_mm === 'number') || (()=>{throw e(`row field ${n} missing x_mm/y_mm`)})();
  rows.forEach((r, i) => {
    needPoint(r.date, `rows[${i}].date`);
    needPoint(r.start, `rows[${i}].start`);
    needPoint(r.finish, `rows[${i}].finish`);
    needPoint(r.brkStart, `rows[${i}].brkStart`);
    needPoint(r.brkEnd, `rows[${i}].brkEnd`);
    needPoint(r.role, `rows[${i}].role`);
  });
  const needBox = (o, n) => (o && typeof o.x_mm==='number' && typeof o.y_mm==='number' && typeof o.w_mm==='number' && typeof o.h_mm==='number' && o.w_mm>0 && o.h_mm>0) || (()=>{throw e(`field ${n} needs x/y/w/h (w/h>0)`)} )();
  ['hospital','ward','candidate','job_title','band','booking_ref','week_ending','ts_number','nurse_sign_date','auth_name','auth_job_title','auth_sign_date'].forEach(k=>{
    needPoint(fields[k], `fields.${k}`);
  });
  needBox(fields.nurse_signature, 'fields.nurse_signature');
  needBox(fields.auth_signature, 'fields.auth_signature');
  return l;
}

async function loadTsLayout(env) {
  const fromR2 = await r2GetJSON(env, TS_LAYOUT_R2_KEY);
  try { return validateTsLayout(fromR2 || TS_LAYOUT_FALLBACK); }
  catch { return TS_LAYOUT_FALLBACK; }
}

// Draw an image inside a fixed box while preserving aspect ratio (no distortion).
// Draw an image inside a fixed box (box is mm-from-top) while preserving aspect ratio.
async function drawImageInBox(page, pdfDoc, bytesU8, box, contentType) {
  if (!page || !pdfDoc) return;
  if (!bytesU8 || bytesU8.length === 0) return;
  if (!box || typeof box !== 'object') return;

  const mmToPt = (mm) => (Number(mm) || 0) * 72 / 25.4;

  const pageH = Number(box.page_h_mm ?? 210) || 210;
  const x_mm  = Number(box.x_mm ?? 0) || 0;
  const w_mm  = Number(box.w_mm ?? 0) || 0;
  const h_mm  = Number(box.h_mm ?? 0) || 0;

  // We expect y_from_top_mm for your PDF generator (mm from top)
  const yTop  = Number(box.y_from_top_mm ?? 0) || 0;

  if (!(w_mm > 0 && h_mm > 0)) return;

  // ✅ convert top-origin to bottom-origin (pdf-lib uses bottom-left origin)
  const y_mm_bottom = Math.max(0, pageH - yTop - h_mm);

  // ✅ signatures are PNG by design; embed as PNG to preserve alpha
  let img = null;
  try {
    img = await pdfDoc.embedPng(bytesU8);
  } catch {
    // If you ever re-use this helper for non-signature images, keep a JPG fallback.
    try { img = await pdfDoc.embedJpg(bytesU8); } catch { return; }
  }

  const { width, height } = img;

  const boxWpt = mmToPt(w_mm);
  const boxHpt = mmToPt(h_mm);

  // ✅ never scale UP (prevents blur); scale down only to fit box
  const scale = Math.min(boxWpt / width, boxHpt / height, 1);

  const drawW = width * scale;
  const drawH = height * scale;

  const x = mmToPt(x_mm) + (boxWpt - drawW) / 2;
  const y = mmToPt(y_mm_bottom) + (boxHpt - drawH) / 2;

  // ✅ No background is drawn here; PNG alpha stays transparent over the PDF
  page.drawImage(img, { x, y, width: drawW, height: drawH });
}

async function drawSignatureKeyInBox(bucket, page, pdfDoc, keyRaw, box, pageH_mm = 210) {
  const key = String(keyRaw || '').trim().replace(/^\/+/, '');
  if (!key) return;

  const obj = await bucket.get(key);
  if (!obj) return;

  const bytesU8 = new Uint8Array(await new Response(obj.body).arrayBuffer());

  // box.{x,y,w,h} are mm-from-top in your generator
  await drawImageInBox(page, pdfDoc, bytesU8, {
    x_mm: box.x,
    y_from_top_mm: box.y,
    w_mm: box.w,
    h_mm: box.h,
    page_h_mm: pageH_mm
  }, 'image/png');
}

// Basic R2 helpers
const normalizeKey = (k) => (k || '').replace(/^\/+/, '');
async function r2Exists(env, key) {
  const bucket = env.R2_BUCKET || env.R2;
  const obj = await bucket.head(normalizeKey(key)).catch(() => null);
  return !!obj;
}
async function r2GetBytes(env, key) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const bucket   = env.R2_BUCKET || env.R2;
  const cleanKey = normalizeKey(key);

  let obj;
  try {
    obj = await bucket.get(cleanKey);
  } catch (e) {
    if (LOG) {
      console.error('[R2_GET_BYTES]', JSON.stringify({
        stage: 'error',
        key,
        cleanKey,
        err: e?.message || String(e)
      }));
    }
    return null;
  }

  if (!obj) {
    if (LOG) {
      console.warn('[R2_GET_BYTES]', JSON.stringify({
        stage: 'not_found',
        key,
        cleanKey
      }));
    }
    return null;
  }

  const ab = await new Response(obj.body).arrayBuffer();
  const u8 = new Uint8Array(ab);

  if (LOG) {
    console.log('[R2_GET_BYTES]', JSON.stringify({
      stage: 'ok',
      key,
      cleanKey,
      length: u8.length
    }));
  }

  return u8;
}

// Signed public download URL (for stationery fetching inside invoice HTML)
async function presignR2Url(env, req, key, ttlSeconds = 300) {
  const cleanKey = normalizeKey(key);
  const exp = Math.floor(Date.now() / 1000) + (ttlSeconds | 0);
  const tokenPayload = { typ: "dl", key: cleanKey, exp };

  // ✅ FIX: createToken is async in your codebase → must await
  const token = await createToken(env.UPLOAD_TOKEN_SECRET, tokenPayload);

  const base = env.PUBLIC_DOWNLOAD_BASE_URL || new URL(new URL(req.url).origin + '/api/files/download').toString();
  const u = new URL(base);
  u.searchParams.set('key', cleanKey);
  u.searchParams.set('token', token);
  return u.toString();
}

// ===== Timesheet field layout (edit these mm coordinates once, keep forever) =====
// A4: 210 × 297mm, origin at bottom-left (pdf-lib)
// Fill in real coordinates with debug overlay once.
const TS_FIELD_MAP = {
  page: { width_mm: 210, height_mm: 297 },
  // Row anchors for Mon..Sun (index 0..6). Replace with your exact positions.
  rows: [
    { // Monday
      date: { x_mm: 22, y_mm: 210 },
      start: { x_mm: 60, y_mm: 210 },
      finish:{ x_mm: 85, y_mm: 210 },
      brkStart:{ x_mm: 110, y_mm: 210 },
      brkEnd:  { x_mm: 130, y_mm: 210 },
      role:    { x_mm: 155, y_mm: 210 },
    },
    { date: { x_mm: 22, y_mm: 200 }, start:{ x_mm: 60, y_mm: 200 }, finish:{ x_mm:85, y_mm:200 }, brkStart:{ x_mm:110, y_mm:200 }, brkEnd:{ x_mm:130, y_mm:200 }, role:{ x_mm:155, y_mm:200 } },
    { date: { x_mm: 22, y_mm: 190 }, start:{ x_mm: 60, y_mm: 190 }, finish:{ x_mm:85, y_mm:190 }, brkStart:{ x_mm:110, y_mm:190 }, brkEnd:{ x_mm:130, y_mm:190 }, role:{ x_mm:155, y_mm:190 } },
    { date: { x_mm: 22, y_mm: 180 }, start:{ x_mm: 60, y_mm: 180 }, finish:{ x_mm:85, y_mm:180 }, brkStart:{ x_mm:110, y_mm:180 }, brkEnd:{ x_mm:130, y_mm:180 }, role:{ x_mm:155, y_mm:180 } },
    { date: { x_mm: 22, y_mm: 170 }, start:{ x_mm: 60, y_mm: 170 }, finish:{ x_mm:85, y_mm:170 }, brkStart:{ x_mm:110, y_mm:170 }, brkEnd:{ x_mm:130, y_mm:170 }, role:{ x_mm:155, y_mm:170 } },
    { date: { x_mm: 22, y_mm: 160 }, start:{ x_mm: 60, y_mm: 160 }, finish:{ x_mm:85, y_mm:160 }, brkStart:{ x_mm:110, y_mm:160 }, brkEnd:{ x_mm:130, y_mm:160 }, role:{ x_mm:155, y_mm:160 } },
    { date: { x_mm: 22, y_mm: 150 }, start:{ x_mm: 60, y_mm: 150 }, finish:{ x_mm:85, y_mm:150 }, brkStart:{ x_mm:110, y_mm:150 }, brkEnd:{ x_mm:130, y_mm:150 }, role:{ x_mm:155, y_mm:150 } },
  ],
  fields: {
    hospital:      { x_mm: 20,  y_mm: 270 },
    ward:          { x_mm: 110, y_mm: 270 },
    candidate:     { x_mm: 20,  y_mm: 260 },
    job_title:     { x_mm: 110, y_mm: 260 },
    band:          { x_mm: 180, y_mm: 260 },
    booking_ref:   { x_mm: 20,  y_mm: 250 },
    week_ending:   { x_mm: 110, y_mm: 250 },
    ts_number:     { x_mm: 180, y_mm: 250 },

    nurse_sign_date: { x_mm: 45,  y_mm: 85 },
    nurse_signature: { x_mm: 20,  y_mm: 90, w_mm: 60, h_mm: 20 },

    auth_name:       { x_mm: 120, y_mm: 85 },
    auth_job_title:  { x_mm: 120, y_mm: 80 },
    auth_sign_date:  { x_mm: 165, y_mm: 85 },
    auth_signature:  { x_mm: 120, y_mm: 90, w_mm: 60, h_mm: 20 },
  },
  text: { fontSize: 10 },
  debug: { enabled: false, grid_mm: 5 }, // flip enabled=true temporarily for calibration
};

// Draw debug grid + labels (dev-only)
// Draw debug grid + labels (dev-only). Pass the runtime layout.
function drawDebugOverlay(page, font, layout) {
  if (!layout?.debug?.enabled) return;
  const mmToPt = (mm) => mm * (72 / 25.4);
  const light = rgb(0.8, 0.8, 0.8);
  const wPt = mmToPt(layout.page.width_mm);
  const hPt = mmToPt(layout.page.height_mm);
  const step = mmToPt(layout.debug.grid_mm || 5);

  for (let x = 0; x <= wPt; x += step) page.drawLine({ start: { x, y: 0 }, end: { x, y: hPt }, color: light, thickness: 0.3 });
  for (let y = 0; y <= hPt; y += step) page.drawLine({ start: { x: 0, y }, end: { x: wPt, y }, color: light, thickness: 0.3 });

  const label = (txt, mm) => page.drawText(txt, { x: mmToPt(mm.x_mm), y: mmToPt(mm.y_mm), size: 6, font, color: rgb(0.2, 0.2, 0.2) });
  // Markers on row anchors
  layout.rows.forEach((r, i) => {
    label(`Row${i} date`, r.date); label(`Row${i} start`, r.start); label(`Row${i} finish`, r.finish);
    label(`Row${i} brkStart`, r.brkStart); label(`Row${i} brkEnd`, r.brkEnd); label(`Row${i} role`, r.role);
  });
  // Field labels
  Object.entries(layout.fields).forEach(([k, v]) => { if ('x_mm' in v) label(k, v); });

  // Signature rectangles with size readout (so you can eyeball sizing)
  const drawBox = (b, name) => {
    const x = mmToPt(b.x_mm), y = mmToPt(b.y_mm), w = mmToPt(b.w_mm), h = mmToPt(b.h_mm);
    page.drawRectangle({ x, y, width: w, height: h, borderColor: rgb(0.2,0.2,0.2), borderWidth: 0.5, color: undefined, opacity: 0.2 });
    page.drawText(`${name} ${Math.round(b.w_mm)}×${Math.round(b.h_mm)}mm`, { x: x + 1, y: y + h + 2, size: 6, font, color: rgb(0.2,0.2,0.2) });
  };
  if (layout.fields.nurse_signature?.w_mm) drawBox(layout.fields.nurse_signature, 'nurse_signature');
  if (layout.fields.auth_signature?.w_mm) drawBox(layout.fields.auth_signature, 'auth_signature');
}

// Numeric short ref rule
function printableShortRef(s) {
  if (typeof s !== 'string') return '';
  const clean = s.trim();
  if (!/^\d{1,10}$/.test(clean)) return '';
  return clean;
}

// Render a single timesheet to PDF, save to R2 (idempotent), return the R2 key.

// ─────────────────────────────────────────────────────────────
// TS PDF outbox RPC helpers
// ─────────────────────────────────────────────────────────────

function _rows(v) {
  if (Array.isArray(v)) return v;
  if (v && Array.isArray(v.rows)) return v.rows;
  return [];
}

async function rpcTspdfEnqueueReadyForInvoice(env, { limit = 500 } = {}) {
  // returns int (count inserted) via RPC result shape
  return await sbRpc(env, "tspdf_enqueue_ready_for_invoice", { p_limit: limit });
}

async function rpcTspdfDequeueBatchIds(env, { limit = 10 } = {}) {
  const res = await sbRpc(env, "tspdf_dequeue_batch_ids", { p_limit: limit });
  return _rows(res);
}

async function rpcTimesheetPdfLoadContextBatch(env, { timesheetIds = [] } = {}) {
  if (!Array.isArray(timesheetIds) || timesheetIds.length === 0) return [];
  const res = await sbRpc(env, "timesheet_pdf_load_context_batch", { p_timesheet_ids: timesheetIds });
  return _rows(res);
}

async function rpcTspdfWorkSuccessBulk(env, { outboxIds = [] } = {}) {
  if (!Array.isArray(outboxIds) || outboxIds.length === 0) return 0;
  return await sbRpc(env, "tspdf_work_success_bulk", { p_ids: outboxIds });
}

async function rpcTspdfWorkFailBulk(env, { fails = [] } = {}) {
  if (!Array.isArray(fails) || fails.length === 0) return 0;
  // p_rows expects JSONB array [{outbox_id, error}, ...]
  return await sbRpc(env, "tspdf_work_fail_bulk", { p_rows: fails });
}

// ─────────────────────────────────────────────────────────────
// TS PDF Outbox worker (single batch runner)
// Aligns with SQL RPCs:
// - tspdf_enqueue_ready_for_invoice(p_limit)
// - tspdf_dequeue_batch_ids(p_limit)
// - timesheet_pdf_load_context_batch(p_timesheet_ids)
// - tspdf_work_success_bulk(p_ids)
// - tspdf_work_fail_bulk(p_rows)
// ─────────────────────────────────────────────────────────────
async function runTsPdfWorkerOnce(env, { limit = 5, enqueueFirst = true, enqueueLimit = 500 } = {}) {
  const report = {
    enqueued: 0,
    picked: 0,
    reused: 0,
    rendered: 0,
    ok: 0,
    failed: 0
  };

  // 0) Optional enqueue (cheap, SQL-side filtering)
  if (enqueueFirst) {
    try {
      const enqRes = await rpcTspdfEnqueueReadyForInvoice(env, { limit: enqueueLimit });
      report.enqueued =
        (typeof enqRes === "number") ? enqRes :
        (typeof enqRes?.data === "number") ? enqRes.data :
        (typeof enqRes?.rows?.[0] === "number") ? enqRes.rows[0] :
        (typeof enqRes?.rows?.[0]?.tspdf_enqueue_ready_for_invoice === "number") ? enqRes.rows[0].tspdf_enqueue_ready_for_invoice :
        0;
    } catch {
      report.enqueued = 0;
    }
  }

  // 1) Dequeue a batch
  const leased = await rpcTspdfDequeueBatchIds(env, { limit });
  report.picked = leased.length;
  if (leased.length === 0) return report;

  // 2) Batch load PDF render context
  const timesheetIds = leased.map(r => String(r.timesheet_id)).filter(Boolean);
  const ctxRows = await rpcTimesheetPdfLoadContextBatch(env, { timesheetIds });

  // Map timesheet_id -> ctx row
  const ctxByTsId = new Map();
  for (const row of ctxRows) {
    const id = String(row?.timesheet_id || "");
    if (id) ctxByTsId.set(id, row);
  }

  // 2b) Cache agency logo bytes ONCE per invocation (avoid 1x R2 GET per timesheet)
  const bucket = env.R2_BUCKET || env.R2;
  let cachedLogoKeyRaw = null;
  let cachedLogoBytesU8 = null;
  let cachedLogoContentType = null;

  try {
    if (bucket?.get) {
      const def0 = ctxRows?.[0]?.out_def ?? null;
      let defObj = def0;
      if (typeof defObj === "string") {
        try { defObj = JSON.parse(defObj); } catch { defObj = null; }
      }

      const logoKeyRaw = defObj?.agency_logo ? String(defObj.agency_logo).trim() : null;
      const logoKey = logoKeyRaw ? normalizeKey(logoKeyRaw) : null;

      if (logoKey) {
        const obj = await bucket.get(logoKey).catch(() => null);
        if (obj) {
          const bytesU8 = new Uint8Array(await new Response(obj.body).arrayBuffer());

          // match your renderer’s safety cap
          const MAX_LOGO_BYTES = 250_000;
          if (bytesU8.length <= MAX_LOGO_BYTES) {
            const ct = String(obj.httpMetadata?.contentType || "").toLowerCase();
            cachedLogoKeyRaw = logoKeyRaw;
            cachedLogoBytesU8 = bytesU8;

            // content-type fallback from extension if metadata missing
            cachedLogoContentType =
              ct ||
              (logoKey.toLowerCase().endsWith(".png") ? "image/png" :
               logoKey.toLowerCase().endsWith(".jpg") || logoKey.toLowerCase().endsWith(".jpeg") ? "image/jpeg" :
               "application/octet-stream");
          }
        }
      }
    }
  } catch {
    cachedLogoKeyRaw = null;
    cachedLogoBytesU8 = null;
    cachedLogoContentType = null;
  }

  const okOutboxIds = [];
  const fails = [];

  // 3) For each leased outbox row: reuse (DB-flag) or render
  for (const job of leased) {
    const outboxId = job?.outbox_id ? String(job.outbox_id) : null;
    const tsId = job?.timesheet_id ? String(job.timesheet_id) : null;
    const forceRegen = !!job?.force_regen;

    if (!outboxId || !tsId) {
      fails.push({ outbox_id: outboxId || null, error: "Missing outbox_id or timesheet_id" });
      continue;
    }

    try {
      const ctx = ctxByTsId.get(tsId) || null;
      if (!ctx) throw new Error("Missing batch context for timesheet_id");

      // ✅ Avoid per-timesheet R2 head(): trust DB flag on timesheets row
      const alreadyGeneratedAt = ctx?.out_ts?.generated_pdf_at_utc || null;
      if (!forceRegen && alreadyGeneratedAt) {
        report.reused++;
        okOutboxIds.push(outboxId);
        continue;
      }

      const preload = {
        ts: ctx.out_ts || null,
        summary: ctx.out_summary || null,
        contract: ctx.out_contract || null,
        client: ctx.out_client || null,
        candidate: ctx.out_candidate || null,
        fin: ctx.out_fin || null,
        def: ctx.out_def || null,

        // cached logo (renderer can use these to avoid bucket.get per timesheet)
        logo_key: cachedLogoKeyRaw,
        logo_bytes_u8: cachedLogoBytesU8,
        logo_content_type: cachedLogoContentType
      };

      await renderTimesheetPDFGeneratedAndSave(env, tsId, preload);

      report.rendered++;
      okOutboxIds.push(outboxId);
    } catch (e) {
      fails.push({
        outbox_id: outboxId,
        error: e?.message || String(e || "Unknown error")
      });
    }
  }

  // 4) Bulk ACKs
  if (okOutboxIds.length > 0) {
    try {
      await rpcTspdfWorkSuccessBulk(env, { outboxIds: okOutboxIds });
      report.ok += okOutboxIds.length;
    } catch {
      // If ack fails, treat as failure (rows will retry later due to next_attempt_at)
      report.failed += okOutboxIds.length;
    }
  }

  if (fails.length > 0) {
    try {
      await rpcTspdfWorkFailBulk(env, { fails });
      report.failed += fails.length;
    } catch {
      // If fail-ack fails, rows will retry later due to next_attempt_at already set on dequeue
      report.failed += fails.length;
    }
  }

  return report;
}




// ─────────────────────────────────────────────────────────────
// Admin endpoint: drain TS PDF outbox once (manual ops/testing)
// POST /api/tspdf/queue/drain
// Body: { "limit": 5, "enqueue_first": true, "enqueue_limit": 500 }
// ─────────────────────────────────────────────────────────────
async function handleTsPdfDrain(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const limit = Math.max(1, Math.min(50, Number(body?.limit ?? 5) || 5));
  const enqueueFirst = (body?.enqueue_first === false) ? false : true;
  const enqueueLimit = Math.max(1, Math.min(2000, Number(body?.enqueue_limit ?? 500) || 500));

  const report = await runTsPdfWorkerOnce(env, {
    limit,
    enqueueFirst,
    enqueueLimit
  });

  return withCORS(env, req, ok({
    ...report,
    limit,
    enqueue_first: enqueueFirst,
    enqueue_limit: enqueueLimit
  }));
}




async function renderTimesheetPDFGeneratedAndSave(env, timesheetId, preload = null) {
  const bucket = env.R2_BUCKET || env.R2;
  if (!bucket?.get || !bucket?.put) throw new Error("Storage not configured");

  const T0 = Date.now();
  const LOGP = `[TS_PDF_GEN][${timesheetId}]`;
  const L = (step, obj) => { try { console.log(`${LOGP} ${step}`, obj || {}); } catch {} };

  L("START", { tsid: timesheetId });

  // ---------- helpers ----------
  const mmToPt = (mm) => (Number(mm) || 0) * 72 / 25.4;
  const ptToMm = (pt) => (Number(pt) || 0) * 25.4 / 72;

  const PAGE_W = 297;  // A4 landscape mm
  const PAGE_H = 210;

  // pdf-lib bottom-left origin; we use "mm from top"
  const yFromTop = (mmFromTop) => PAGE_H - (Number(mmFromTop) || 0);

  const clamp = (n, a, b) => Math.max(a, Math.min(b, n));
  const safeStr = (v) => (v == null ? "" : String(v));

  const fmtDmy = (ymd) => {
    const s = safeStr(ymd).slice(0, 10);
    const m = s.match(/^(\d{4})-(\d{2})-(\d{2})$/);
    if (!m) return "";
    return `${m[3]}/${m[2]}/${m[1]}`;
  };

  const weekdayName = (ymd) => {
    const s = safeStr(ymd).slice(0, 10);
    const d = new Date(s + "T00:00:00Z");
    if (Number.isNaN(d.getTime())) return "";
    return ["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"][d.getUTCDay()] || "";
  };

  const buildWeekDates = (weekEndingYmd) => {
    const out = [];
    try {
      const base = new Date(String(weekEndingYmd) + "T00:00:00Z");
      if (!Number.isNaN(base.getTime())) {
        for (let offset = 6; offset >= 0; offset--) {
          const d = new Date(base);
          d.setUTCDate(base.getUTCDate() - offset);
          const yyyy = d.getUTCFullYear();
          const mm = String(d.getUTCMonth() + 1).padStart(2, "0");
          const dd = String(d.getUTCDate()).padStart(2, "0");
          const ymd = `${yyyy}-${mm}-${dd}`;
          out.push({ ymd, dow: d.getUTCDay(), dowName: ["Sun","Mon","Tue","Wed","Thu","Fri","Sat"][d.getUTCDay()] });
        }
      }
    } catch {}
    while (out.length < 7) out.push({ ymd: "", dow: null, dowName: "" });
    return out;
  };

  // DAILY rule: next Sunday (inclusive)
  const nextSundayYmd = (ymd) => {
    const s = safeStr(ymd).slice(0, 10);
    const m = s.match(/^(\d{4})-(\d{2})-(\d{2})$/);
    if (!m) return "";
    const dt = new Date(`${s}T00:00:00Z`);
    if (Number.isNaN(dt.getTime())) return "";
    const dow = dt.getUTCDay(); // 0=Sun
    const add = (dow === 0) ? 0 : (7 - dow);
    dt.setUTCDate(dt.getUTCDate() + add);
    const yyyy = dt.getUTCFullYear();
    const mm = String(dt.getUTCMonth() + 1).padStart(2, "0");
    const dd = String(dt.getUTCDate()).padStart(2, "0");
    return `${yyyy}-${mm}-${dd}`;
  };

  // FNV-1a 32-bit → 8 digits (Timesheet No)
  const timesheetNumber8 = (id) => {
    const s = safeStr(id);
    let h = 0x811c9dc5;
    for (let i = 0; i < s.length; i++) {
      h ^= s.charCodeAt(i);
      h = Math.imul(h, 0x01000193);
    }
    const n = (h >>> 0) % 100000000;
    return String(n).padStart(8, "0");
  };

  const parseHHMM = (t) => {
    const s = safeStr(t).trim();
    const m = s.match(/^(\d{1,2}):(\d{2})$/);
    if (!m) return null;
    const hh = Number(m[1]);
    const mm = Number(m[2]);
    if (!Number.isFinite(hh) || !Number.isFinite(mm)) return null;
    if (hh < 0 || hh > 23 || mm < 0 || mm > 59) return null;
    return hh * 60 + mm;
  };

  // 0..99 to words (ALL CAPS)
  const twoDigitWords = (n) => {
    const ones = ["ZERO","ONE","TWO","THREE","FOUR","FIVE","SIX","SEVEN","EIGHT","NINE"];
    const teens = ["TEN","ELEVEN","TWELVE","THIRTEEN","FOURTEEN","FIFTEEN","SIXTEEN","SEVENTEEN","EIGHTEEN","NINETEEN"];
    const tens = ["","","TWENTY","THIRTY","FORTY","FIFTY","SIXTY","SEVENTY","EIGHTY","NINETY"];
    if (n < 10) return ones[n];
    if (n < 20) return teens[n - 10];
    const t = Math.floor(n / 10);
    const o = n % 10;
    return o ? `${tens[t]} ${ones[o]}` : tens[t];
  };

  // scheme-based minutes → words (ALL CAPS)
  const minutesToWordsUpper = (totalMinutes) => {
    const m = Math.round(Number(totalMinutes) || 0);
    if (!Number.isFinite(m) || m <= 0) return "";

    const hours = Math.floor(m / 60);
    const mins  = m % 60;

    const hW = twoDigitWords(clamp(hours, 0, 99));
    const mW = twoDigitWords(clamp(mins, 0, 59));

    if (hours === 0) return `${mW} ${(mins === 1) ? "MINUTE" : "MINS"}`;
    if (mins === 0) {
      if (hours === 1) return "ONE HOUR";
      if (hours === 2) return "TWO HOURS";
      return `${hW} HRS`;
    }
    if (mins === 30) return `${hW} AND A HALF HRS`;

    const minLabel = (mins === 1) ? "MINUTE" : "MINS";
    if (hours === 1) return `ONE HOUR ${mW} ${minLabel}`;
    if (hours === 2) return `TWO HOURS ${mW} ${minLabel}`;
    return `${hW} HRS ${mW} ${minLabel}`;
  };

  const hoursToWordsUpper = (hours) => {
    const h = Number(hours);
    if (!Number.isFinite(h) || h <= 0) return "";
    return minutesToWordsUpper(Math.round(h * 60));
  };

  const getSegTimes = (seg) => {
    if (!seg || typeof seg !== "object") return { start: "", end: "" };
    if (typeof seg.start === "string" && typeof seg.end === "string") return { start: seg.start, end: seg.end };

    if (seg.start_utc && seg.end_utc) {
      try {
        if (typeof toLocalParts === "function") {
          const a = toLocalParts(seg.start_utc, null);
          const b = toLocalParts(seg.end_utc, null);
          return { start: a?.hhmm || "", end: b?.hhmm || "" };
        }
      } catch {}
      return { start: safeStr(seg.start_utc).slice(11, 16), end: safeStr(seg.end_utc).slice(11, 16) };
    }
    return { start: "", end: "" };
  };

  // Break rule: if break_start+break_end exist, show both; else if break_minutes, show "30mins" in Break Start.
  const getBreakDisplay = (seg) => {
    if (!seg || typeof seg !== "object") return { brkStart: "", brkEnd: "" };

    const bs = safeStr(seg.break_start || "");
    const be = safeStr(seg.break_end || "");
    if (bs && be) return { brkStart: bs, brkEnd: be };

    const arr = Array.isArray(seg.breaks) ? seg.breaks : [];
    if (arr.length) {
      const b0 = arr.find(b => b && (safeStr(b.start).trim() || safeStr(b.end).trim())) || null;
      const s = safeStr(b0?.start || "").trim();
      const e = safeStr(b0?.end || "").trim();
      if (s && e) return { brkStart: s, brkEnd: e };
    }

    const bm =
      (seg.break_minutes != null) ? Number(seg.break_minutes) :
      (seg.break_mins != null) ? Number(seg.break_mins) :
      null;

    if (Number.isFinite(bm) && bm > 0) return { brkStart: `${Math.round(bm)}mins`, brkEnd: "" };
    return { brkStart: "", brkEnd: "" };
  };

  const computePaidMinutes = (seg) => {
    const { start, end } = getSegTimes(seg);
    const s0 = parseHHMM(start);
    const e0 = parseHHMM(end);
    if (s0 == null || e0 == null) return 0;

    let s = s0;
    let e = e0;
    if (e <= s) e += 1440; // overnight

    let breakMins = 0;
    const b = getBreakDisplay(seg);

    if (b.brkStart && b.brkEnd) {
      const bs0 = parseHHMM(b.brkStart);
      const be0 = parseHHMM(b.brkEnd);
      if (bs0 != null && be0 != null) {
        let bs = bs0;
        let be = be0;
        if (bs < s0) bs += 1440;
        if (be <= bs0) be += 1440;
        if (bs >= s && be <= e && be > bs) breakMins = (be - bs);
      }
    } else {
      const m = (seg.break_minutes != null) ? Number(seg.break_minutes) :
                (seg.break_mins != null) ? Number(seg.break_mins) : 0;
      if (Number.isFinite(m) && m > 0) breakMins = Math.round(m);
    }

    const total = e - s;
    return Math.max(0, total - breakMins);
  };

  const computePaidHours = (seg) => {
    const mins = computePaidMinutes(seg);
    if (!mins) return { paid: "", paidWords: "" };
    const h = Math.round((mins / 60) * 100) / 100;
    return { paid: h.toFixed(2), paidWords: minutesToWordsUpper(mins) };
  };

  const parseJsonMaybe = (v) => {
    if (!v) return null;
    if (typeof v === "object") return v;
    if (typeof v === "string") {
      const s = v.trim();
      if (!s) return null;
      try { return JSON.parse(s); } catch { return null; }
    }
    return null;
  };

  // Declarations: prefer TEXT columns if present; else fall back to *_declaration_json
  const buildDeclSpec = (fallbackTitle, textVal, jsonVal) => {
    const txt = safeStr(textVal).trim();
    if (txt) {
      return {
        title: fallbackTitle,
        bodyText: txt,
        title_align: "center",
        title_bold: true,
        font_size: 7.0,
        line_height_mm: 3.35
      };
    }
    const j = parseJsonMaybe(jsonVal);
    const lines = Array.isArray(j?.lines) ? j.lines.map(safeStr).filter(Boolean) : [];
    const bodyText = lines.join(" ");

    return {
      title: safeStr(j?.title || fallbackTitle),
      bodyText,
      title_align: safeStr(j?.title_align || "center").toLowerCase(),
      title_bold: (j?.title_bold !== false),
      font_size: Number(j?.font_size) || 7.0,
      line_height_mm: Number(j?.line_height_mm) || 3.35
    };
  };

  // Drawing primitives
  const drawRect = (page, x, yTop, w, h, opts = {}) => {
    const lw = opts.lineWidth ?? 0.35;
    const stroke = opts.borderColor ?? rgb(0, 0, 0);
    page.drawRectangle({
      x: mmToPt(x),
      y: mmToPt(yFromTop(yTop + h)),
      width: mmToPt(w),
      height: mmToPt(h),
      borderWidth: lw,
      borderColor: stroke,
      color: opts.fillColor,
    });
  };

  const drawLine = (page, x1, yTop1, x2, yTop2, lw = 0.3) => {
    page.drawLine({
      start: { x: mmToPt(x1), y: mmToPt(yFromTop(yTop1)) },
      end:   { x: mmToPt(x2), y: mmToPt(yFromTop(yTop2)) },
      thickness: lw,
      color: rgb(0, 0, 0),
    });
  };

  const drawText = (page, font, text, x, yTop, size, opts = {}) => {
    const s = safeStr(text);
    if (!s) return;
    page.drawText(s, {
      x: mmToPt(x),
      y: mmToPt(yFromTop(yTop)),
      size,
      font,
      maxWidth: opts.maxWidth ? mmToPt(opts.maxWidth) : undefined
    });
  };

  const drawTextFit = (page, font, text, x, yTop, maxWmm, sizeMax, sizeMin) => {
    const s = safeStr(text);
    if (!s) return;
    let size = sizeMax;
    while (size > sizeMin) {
      const wPt = font.widthOfTextAtSize(s, size);
      if (ptToMm(wPt) <= maxWmm) break;
      size -= 0.5;
    }
    drawText(page, font, s, x, yTop, size, { maxWidth: maxWmm });
  };

  const drawCenteredText = (page, font, text, x, yTop, w, size) => {
    const s = safeStr(text);
    if (!s) return;
    const tw = font.widthOfTextAtSize(s, size);
    const xMm = x + (w - ptToMm(tw)) / 2;
    drawText(page, font, s, xMm, yTop, size);
  };

  const drawRightText = (page, font, text, xRight, yTop, size) => {
    const s = safeStr(text);
    if (!s) return;
    const tw = font.widthOfTextAtSize(s, size);
    const xMm = xRight - ptToMm(tw);
    drawText(page, font, s, xMm, yTop, size);
  };

  // Simple word-wrap (pdf-lib does NOT wrap automatically)
  const wrapText = (font, text, fontSize, maxWidthMm) => {
    const raw = safeStr(text);
    if (!raw) return [];
    const maxWpt = mmToPt(maxWidthMm);

    const out = [];
    const paras = raw.replace(/\r\n/g, "\n").split(/\n+/);

    for (let pi = 0; pi < paras.length; pi++) {
      const para = paras[pi].trim();
      if (!para) { out.push(""); continue; }

      const words = para.split(/\s+/).filter(Boolean);
      let line = "";
      for (const w of words) {
        const test = line ? (line + " " + w) : w;
        const wpt = font.widthOfTextAtSize(test, fontSize);
        if (wpt <= maxWpt) {
          line = test;
        } else {
          if (line) out.push(line);
          line = w;
        }
      }
      if (line) out.push(line);
    }

    while (out.length && out[out.length - 1] === "") out.pop();
    return out;
  };

  // QR drawer — clamp + clear background (reduces “blob” artifacts)
  const drawQrInBox = async (page, qrText, box) => {
    if (!qrText || !box) return;
    if (typeof QRCode === "undefined" || typeof QRCode.create !== "function") {
      L("QR.SKIP", { reason: "QRCode not available in bundle" });
      return;
    }

    // Clear box interior to white
    page.drawRectangle({
      x: mmToPt(box.x + 0.4),
      y: mmToPt(yFromTop(box.y + box.h - 0.4)),
      width: mmToPt(Math.max(0, box.w - 0.8)),
      height: mmToPt(Math.max(0, box.h - 0.8)),
      color: rgb(1, 1, 1),
      borderWidth: 0,
    });

    const qr = QRCode.create(qrText, { errorCorrectionLevel: "L" });
    const modules = qr?.modules;
    const size = modules?.size;
    const data = modules?.data;
    if (!size || !data) return;

    const marginModules = 2;
    const grid = size + marginModules * 2;
    const cell = Math.min(box.w / grid, box.h / grid);
    if (!(cell > 0)) return;

    const x0 = box.x + (box.w - cell * grid) / 2;
    const y0 = box.y + (box.h - cell * grid) / 2;

    const xMin = box.x - 1e-6;
    const yMin = box.y - 1e-6;
    const xMax = box.x + box.w + 1e-6;
    const yMax = box.y + box.h + 1e-6;

    for (let r = 0; r < size; r++) {
      for (let c = 0; c < size; c++) {
        const idx = r * size + c;
        if (!data[idx]) continue;

        const x = x0 + (c + marginModules) * cell;
        const yTop = y0 + (r + marginModules) * cell;

        if (x < xMin || yTop < yMin) continue;
        if (x + cell > xMax || yTop + cell > yMax) continue;

        page.drawRectangle({
          x: mmToPt(x),
          y: mmToPt(yFromTop(yTop + cell)),
          width: mmToPt(cell),
          height: mmToPt(cell),
          color: rgb(0, 0, 0),
          borderWidth: 0,
        });
      }
    }

    drawRect(page, box.x, box.y, box.w, box.h, { lineWidth: 0.35, borderColor: rgb(0,0,0) });
  };

  // Local helpers for DAILY synthesis
  const isoToLocalYmd = (iso) => {
    const s = safeStr(iso);
    if (!s) return "";
    try {
      if (typeof toLocalParts === "function") {
        const p = toLocalParts(s, null);
        if (p?.ymd) return String(p.ymd);
      }
    } catch {}
    return s.slice(0, 10);
  };

  const isoToLocalHHMM = (iso) => {
    const s = safeStr(iso);
    if (!s) return "";
    try {
      if (typeof toLocalParts === "function") {
        const p = toLocalParts(s, null);
        if (p?.hhmm) return String(p.hhmm);
      }
    } catch {}
    return s.slice(11, 16);
  };

  try {
    // ---------- DB LOAD ----------
    // preload shape expected (optional):
    // { ts, summary, contract, client, candidate, fin, def }
  const P = (preload && typeof preload === "object") ? preload : null;
const preloadMode = !!P;

let ts = P?.ts || null;
let summary = P?.summary || null;
let contract = P?.contract || null;
let client = P?.client || null;
let cand = P?.candidate || null;
let fin = P?.fin || null;
let def = P?.def || null;


   // 1) Timesheet row (CURRENT)
if (!ts) {
  if (preloadMode) throw new Error("Preload missing ts (queued mode must pass ts)");
  L("DB.LOAD.timesheets", {});
  const { rows: tsRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${encodeURIComponent(timesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  ts = tsRows?.[0];
}
if (!ts) throw new Error("Timesheet not found");


    const sheetScope = String(ts.sheet_scope || "").toUpperCase();
    const isDaily = (sheetScope === "DAILY");

    L("DB.LOAD.ok", {
      sheet_scope: sheetScope,
      has_week_ending_date: !!ts.week_ending_date,
      has_actual_schedule_json: Array.isArray(ts.actual_schedule_json) && ts.actual_schedule_json.length > 0,
      has_worked_start_iso: !!ts.worked_start_iso,
      has_worked_end_iso: !!ts.worked_end_iso,
      qr_status: ts.qr_status || null,
      has_qr_payload: !!ts.qr_payload_json
    });

  // AFTER (only query v_timesheets_summary when needed)
//
// Rule:
// - If we already have a contract_id on the timesheet AND we are only going to use contract-based data,
//   we skip the view.
// - We fetch the view when contract_id is missing (DAILY) OR when we need a fallback for any key fields.
// Only DAILY (no contract) needs v_timesheets_summary.
// Weekly should remain contract-driven and not touch the view here.
const needsSummary = !summary && !ts.contract_id;
if (needsSummary) {
  if (preloadMode) {
    throw new Error("Preload missing summary for DAILY timesheet (queued mode must pass out_summary)");
  }
  try {
    L("DB.LOAD.v_timesheets_summary", { reason: "daily_no_contract" });
    summary = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
        `?timesheet_id=eq.${encodeURIComponent(ts.timesheet_id)}` +
        `&select=timesheet_id,candidate_id,client_id,candidate_name,client_name,contract_id` +
        `&limit=1`
    );
  } catch {
    summary = null;
  }
}






 // 3) TSFIN row (optional, used for additional units + possible fallback data)
if (!fin) {
  if (preloadMode) {
    fin = null; // queued mode must pass fin if it needs it
  } else {
    L("DB.LOAD.tsfin", {});
    fin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${encodeURIComponent(ts.timesheet_id)}` +
        `&is_current=eq.true` +
        `&select=*` +
        `&limit=1`
    ).catch(() => null);
  }
}


  // 4) Contract (weekly may have it; daily normally not)
const contractIdEff = ts.contract_id || summary?.contract_id || null;
if (!contract && contractIdEff) {
  if (preloadMode) {
    contract = null; // queued mode must pass contract if required
  } else {
    L("DB.LOAD.contract", { contract_id: contractIdEff });
    contract = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${encodeURIComponent(contractIdEff)}&select=*`
    ).catch(() => null);
  }
}


    // 5) Resolve effective candidate/client IDs (DAILY uses summary; WEEKLY uses contract but summary works too)
    const effCandidateId = contract?.candidate_id || summary?.candidate_id || null;
    const effClientId    = contract?.client_id    || summary?.client_id    || null;

 if (!client && effClientId) {
  if (preloadMode) {
    client = null; // queued mode must pass client if required
  } else {
    L("DB.LOAD.client", { client_id: effClientId });
    client = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${encodeURIComponent(effClientId)}&select=*`
    ).catch(() => null);
  }
}

if (!cand && effCandidateId) {
  if (preloadMode) {
    cand = null; // queued mode must pass candidate if required
  } else {
    L("DB.LOAD.candidate", { candidate_id: effCandidateId });
    cand = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${encodeURIComponent(effCandidateId)}&select=*`
    ).catch(() => null);
  }
}


    // 6) settings_defaults (NON-FINANCE ONLY — do not select *)
if (!def) {
  if (preloadMode) {
    throw new Error("Preload missing def (queued mode must pass out_def as def)");
  }
  L("DB.LOAD.settings_defaults", {});
  def = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=` +
      [
        "agency_name",
        "agency_logo",
        "timesheet_header_json",
        "timesheet_footer_json",
        "temporary_worker_declaration_json",
        "client_declaration_json"
      ].join(",")
  ).catch(() => null);
} // ✅ CLOSE the if-block


const agencyName = def?.agency_name ? String(def.agency_name) : "ARMS";
const agencyLogoKey = def?.agency_logo ? String(def.agency_logo).trim() : null;

const headerJson = def?.timesheet_header_json ?? null;
const footerJson = def?.timesheet_footer_json ?? null;

// Declarations: TEXT + JSON fallback (TEXT cols don't exist in your DB)
const tempDeclText = null;
const clientDeclText = null;
const tempDeclJson = def?.temporary_worker_declaration_json ?? null;
const clientDeclJson = def?.client_declaration_json ?? null;

const tempDeclSpec = buildDeclSpec("Temporary Worker Declaration", tempDeclText, tempDeclJson);
const clientDeclSpec = buildDeclSpec("Client Declaration", clientDeclText, clientDeclJson);


    // Candidate/client fallbacks for DAILY (no contract)
    const hint = parseJsonMaybe(ts?.candidate_hint_text) || null;

    let resolvedFirstName = safeStr(cand?.first_name || hint?.first_name || hint?.first || "").toUpperCase();
    let resolvedSurname   = safeStr(cand?.last_name || cand?.surname || hint?.surname || hint?.last_name || hint?.last || "").toUpperCase();

    // If still missing, try summary.candidate_name as "First Last"
    if (!resolvedFirstName && !resolvedSurname) {
      const cn = safeStr(summary?.candidate_name).trim();
      if (cn) {
        const parts = cn.split(/\s+/).filter(Boolean);
        if (parts.length === 1) {
          resolvedSurname = parts[0].toUpperCase();
        } else if (parts.length >= 2) {
          resolvedFirstName = parts.shift().toUpperCase();
          resolvedSurname = parts.join(" ").toUpperCase();
        }
      }
    }

    const resolvedClientName =
      safeStr(client?.name || summary?.client_name || ts?.hospital_norm || "").trim();

const resolvedRole =
  safeStr(contract?.role || ts?.job_title_norm || "").trim();

const resolvedSiteWard =
  safeStr(contract?.display_site || ts?.ward_norm || ts?.hospital_norm || "").trim();

const resolvedBandText =
  safeStr(contract?.band || ts?.band || "").trim();


    // ---------- SCHEDULE (weekly or synth daily) ----------
    let schedule = Array.isArray(ts.actual_schedule_json) ? ts.actual_schedule_json : [];

    const workedYmd = isDaily ? isoToLocalYmd(ts.worked_start_iso) : "";
    const workedStartHHMM = isDaily ? isoToLocalHHMM(ts.worked_start_iso) : "";
    const workedEndHHMM   = isDaily ? isoToLocalHHMM(ts.worked_end_iso)   : "";

    let weekEndingYmd = safeStr(ts.week_ending_date).slice(0, 10);
    if (isDaily) {
      const computed = nextSundayYmd(workedYmd);
      weekEndingYmd = computed || weekEndingYmd || "";
    }

    if (isDaily && (!Array.isArray(schedule) || schedule.length === 0)) {
      const seg = {
        date: workedYmd || "",
        start: workedStartHHMM || "",
        end: workedEndHHMM || "",
        start_utc: ts.worked_start_iso || null,
        end_utc: ts.worked_end_iso || null
      };

      if (ts.break_start_iso && ts.break_end_iso) {
        const bs = isoToLocalHHMM(ts.break_start_iso);
        const be = isoToLocalHHMM(ts.break_end_iso);
        if (bs && be) {
          seg.break_start = bs;
          seg.break_end = be;
          seg.breaks = [{ start: bs, end: be }];
        }
      }
      if (seg.breaks == null && ts.break_minutes != null) {
        seg.break_minutes = Number(ts.break_minutes) || 0;
      }

      schedule = [seg];
      L("DAILY.SYNTHESIZED", { workedYmd, weekEndingYmd });
    }

    const weekEndingDayName = weekdayName(weekEndingYmd);
    const weekDates = buildWeekDates(weekEndingYmd);

    // group schedule by ymd
    const byDate = new Map();
    for (const seg of schedule) {
      const ymd = safeStr(seg?.date).slice(0, 10);
      if (!ymd) continue;
      if (!byDate.has(ymd)) byDate.set(ymd, []);
      byDate.get(ymd).push(seg);
    }
    for (const [ymd, arr] of byDate.entries()) {
      arr.sort((a, b) => (getSegTimes(a).start || "").localeCompare(getSegTimes(b).start || ""));
    }

    // ---------- additional units flatten ----------
    let additionalUnitsObj = {};
    if (fin?.additional_units_json) {
      if (typeof fin.additional_units_json === "string") {
        try { additionalUnitsObj = JSON.parse(fin.additional_units_json); } catch { additionalUnitsObj = {}; }
      } else if (typeof fin.additional_units_json === "object") {
        additionalUnitsObj = fin.additional_units_json;
      }
    } else if (fin?.invoice_breakdown_json?.additional?.units) {
      additionalUnitsObj = fin.invoice_breakdown_json.additional.units;
    }

    const additionalRows = [];
    if (additionalUnitsObj && typeof additionalUnitsObj === "object") {
      for (const [code, cfg] of Object.entries(additionalUnitsObj)) {
        if (!cfg || typeof cfg !== "object") continue;
        const bucketName = cfg.bucket_name || code;
        const unitName = cfg.unit_name || "";
        const unitCount = Number(cfg.unit_count || 0);
        const days = (cfg.days && typeof cfg.days === "object") ? cfg.days : null;

        if (days && Object.keys(days).length) {
          for (const [ymd, qtyRaw] of Object.entries(days)) {
            const qty = Number(qtyRaw || 0);
            if (!qty) continue;
            additionalRows.push({ bucket: bucketName, date: ymd, qty, unit: unitName });
          }
        } else if (unitCount) {
          additionalRows.push({ bucket: bucketName, date: "", qty: unitCount, unit: unitName });
        }
      }
    }

    // ---------- LAYOUT PREFLIGHT (NORMAL → COMPACT → ULTRA) ----------
    const headerLinesCount =
      (headerJson && typeof headerJson === "object" && Array.isArray(headerJson.lines))
        ? headerJson.lines.map(safeStr).filter(Boolean).length
        : 0;

    const realCounts = weekDates.map(d => {
      const segs = (d.ymd && byDate.get(d.ymd)) ? byDate.get(d.ymd) : [];
      const real = segs.filter(s => {
        const t = getSegTimes(s);
        return !!(t.start && t.end);
      });
      return Math.max(1, real.length);
    });
    const totalLinesWanted = realCounts.reduce((a,b)=>a+b,0);
    const hasAddl = (additionalRows.length > 0);

    // NOTE: QR moved into details strip (between Nurse and Client)
    const NORMAL = {
      // header (no QR here)
      logoW: 34, logoH: 18,
      headerRowSize: 10.0, // single-line header on the right
      headerTopPad: 1.0,
      headerBottomPad: 1.0,

      // details strip (3 boxes Nurse | QR | Client)
      qrW: 24, qrH: 24,
      detailsGap: 3.0,
      detailsPadY: 2.0,
      detailsTitleSize: 8.6,
      detailsLabelSize: 7.4,
      detailsValueSize: 7.4,

      // statement block
      headerFontSize: 8,
      headerLineH: 3.8,
      yCursorGap: 2.4,
      yCursorAfterHeaderPad: 1.2,

      // schedule table
      tsHeaderRowH: 7.5,
      tsTotalRowH: 8.0,
      tsHeaderFontSize: 7.0,
      tsBodyFontSize: 8.0,
      tsWordsFontSize: 7.3,
      tsLineTextOffset: 5.2,
      minLineH: 4.8,

      // additional
      addlH: 22,
      addlGap: 3,
      blockGap: 3,
      addlHeaderH: 7.0,
      addlRowH: 4.8,

      // declarations + footer
      declH: 50,
      declTitleSize: 8.8,
      declBodyTopPad: 9.8,
      declSigReserve: 12,
      footerFontSize: 7.0,
      footerLineH: 3.6
    };

    const COMPACT = {
      logoW: 30, logoH: 16,
      headerRowSize: 9.0,
      headerTopPad: 0.8,
      headerBottomPad: 0.8,

      qrW: 22, qrH: 22,
      detailsGap: 2.5,
      detailsPadY: 1.6,
      detailsTitleSize: 8.0,
      detailsLabelSize: 6.9,
      detailsValueSize: 6.9,

      headerFontSize: 7.2,
      headerLineH: 3.0,
      yCursorGap: 1.6,
      yCursorAfterHeaderPad: 0.8,

      tsHeaderRowH: 7.0,
      tsTotalRowH: 7.4,
      tsHeaderFontSize: 6.6,
      tsBodyFontSize: 7.4,
      tsWordsFontSize: 6.8,
      tsLineTextOffset: 4.8,
      minLineH: 3.8,

      addlH: 18,
      addlGap: 2,
      blockGap: 2,
      addlHeaderH: 6.0,
      addlRowH: 4.0,

      declH: 34,
      declTitleSize: 8.2,
      declBodyTopPad: 8.6,
      declSigReserve: 10,
      footerFontSize: 6.6,
      footerLineH: 3.2
    };

    const ULTRA = {
      logoW: 26, logoH: 14,
      headerRowSize: 8.0,
      headerTopPad: 0.5,
      headerBottomPad: 0.5,

      qrW: 20, qrH: 20,
      detailsGap: 2.0,
      detailsPadY: 1.2,
      detailsTitleSize: 7.4,
      detailsLabelSize: 6.2,
      detailsValueSize: 6.2,

      headerFontSize: 6.4,
      headerLineH: 2.6,
      yCursorGap: 1.0,
      yCursorAfterHeaderPad: 0.6,

      tsHeaderRowH: 6.2,
      tsTotalRowH: 6.8,
      tsHeaderFontSize: 6.0,
      tsBodyFontSize: 6.8,
      tsWordsFontSize: 6.0,
      tsLineTextOffset: 4.0,
      minLineH: 3.0,

      addlH: 16,
      addlGap: 1,
      blockGap: 1,
      addlHeaderH: 5.5,
      addlRowH: 3.6,

      declH: 26,
      declTitleSize: 7.6,
      declBodyTopPad: 7.4,
      declSigReserve: 8,
      footerFontSize: 6.0,
      footerLineH: 2.8
    };

    const maxLinesFitFor = (LAY) => {
      const M = 8;

      // Header (logo + single-line header row on the right)
      const headerTop = M + LAY.headerTopPad;
      const headerBottom = headerTop + Math.max(LAY.logoH, 6) + LAY.headerBottomPad;

      // Details (QR lives here, so details height must accommodate QR + padding)
      const detailsTop = headerBottom + 1;
      const detailsH = LAY.qrH + (2 * LAY.detailsPadY);

      const yCursor =
        detailsTop + detailsH + LAY.yCursorGap +
        (headerLinesCount ? (headerLinesCount * LAY.headerLineH + LAY.yCursorAfterHeaderPad) : 0);

      const reservedBottom =
        (hasAddl ? LAY.addlGap : LAY.blockGap) +
        (hasAddl ? (LAY.addlH + LAY.addlGap) : 0) +
        (LAY.declH + LAY.blockGap) +
        (14 + 8);

      const maxTableH = Math.max(60, (PAGE_H - M) - yCursor - reservedBottom);
      const bodyMaxH = Math.max(30, maxTableH - LAY.tsHeaderRowH - LAY.tsTotalRowH);

      return Math.max(7, Math.floor(bodyMaxH / LAY.minLineH));
    };

    const maxLinesNormal = maxLinesFitFor(NORMAL);
    const maxLinesCompact = maxLinesFitFor(COMPACT);

    let LAY = NORMAL;
    if (totalLinesWanted > maxLinesNormal) LAY = COMPACT;
    if (totalLinesWanted > maxLinesCompact) LAY = ULTRA;

    const isTight = (LAY !== NORMAL);

    // ---------- PDF CREATE ----------
    L("PDF.CREATE", {});
    const pdfDoc = await PDFDocument.create();
    const page = pdfDoc.addPage([mmToPt(PAGE_W), mmToPt(PAGE_H)]);

    const font = await pdfDoc.embedFont(StandardFonts.Helvetica);
    const fontBold = await pdfDoc.embedFont(StandardFonts.HelveticaBold);

    // ---------- page layout constants ----------
    const M = 8;
    const contentX = M;
    const contentW = PAGE_W - 2 * M;
    const contentRight = contentX + contentW;

    // ---------- HEADER (small, QR moved out) ----------
    const headerTop = M + LAY.headerTopPad;
    const logoBox = { x: contentX, y: headerTop, w: LAY.logoW, h: LAY.logoH };

  // Draw logo (no border) — prefer preload cache, fallback to R2
if (agencyLogoKey) {
  try {
    const P = (preload && typeof preload === "object") ? preload : null;

    let bytesU8 = null;
    let ct = "";

    // 1) Use cached logo bytes (from queue worker) if present
    if (P?.logo_bytes_u8 && (P.logo_bytes_u8 instanceof Uint8Array) && P.logo_bytes_u8.length > 0) {
      bytesU8 = P.logo_bytes_u8;
      ct = String(P.logo_content_type || "").toLowerCase();
    } else {
      // 2) Fallback: fetch from R2 as before
      const key = normalizeKey(agencyLogoKey);
      const obj = await bucket.get(key);
      if (obj) {
        bytesU8 = new Uint8Array(await new Response(obj.body).arrayBuffer());
        ct = String(obj.httpMetadata?.contentType || "").toLowerCase();
      }
    }

    const MAX_LOGO_BYTES = 250_000;
    if (bytesU8 && bytesU8.length <= MAX_LOGO_BYTES) {
      const keyForExt = normalizeKey(agencyLogoKey);
      const isPng = ct.includes("png") || keyForExt.toLowerCase().endsWith(".png");
      const img = isPng ? await pdfDoc.embedPng(bytesU8) : await pdfDoc.embedJpg(bytesU8);

      const pad = 0.8;
      const maxW = logoBox.w - pad * 2;
      const maxH = logoBox.h - pad * 2;
      const scale = Math.min(maxW / img.width, maxH / img.height);

      const w = img.width * scale;
      const h = img.height * scale;
      const x = logoBox.x + (logoBox.w - w) / 2;
      const yImg = logoBox.y + (logoBox.h - h) / 2;

      page.drawImage(img, {
        x: mmToPt(x),
        y: mmToPt(yFromTop(yImg + h)),
        width: mmToPt(w),
        height: mmToPt(h)
      });
    }
  } catch (e) {
    L("LOGO.FAIL", { err: e?.message || String(e) });
  }
}


    // Header right line: TIMESHEET | Time Sheet No | Week ending  (single line, top-right)
    const tsNo = timesheetNumber8(ts.timesheet_id);
    const weLabel = weekEndingDayName ? `Week ending (${weekEndingDayName})` : "Week ending";
    const headerRightText = `TIMESHEET   Time Sheet No. ${tsNo}   ${weLabel}: ${fmtDmy(weekEndingYmd)}`;

    // Always show agency name next to the logo (keeps branding even when logo is present)
    const brandX = logoBox.x + logoBox.w + 3;
    const brandMaxW = Math.max(60, (contentW * 0.45) - (logoBox.w + 3));
    drawTextFit(page, fontBold, agencyName, brandX, headerTop + 2.0, brandMaxW, LAY.headerRowSize, 8.0);

    // Right aligned header
    drawRightText(page, fontBold, headerRightText, contentRight, headerTop + 3.2, LAY.headerRowSize);

    const headerBottom = headerTop + Math.max(LAY.logoH, 8) + LAY.headerBottomPad;

    // ---------- DETAILS STRIP: Nurse | QR | Client ----------
    const detailsTop = headerBottom + 1;
    const detailsH = LAY.qrH + (2 * LAY.detailsPadY);
    const gap = LAY.detailsGap;

    const nurseW = (contentW - LAY.qrW - 2 * gap) / 2;
    const nurseBox = { x: contentX, y: detailsTop, w: nurseW, h: detailsH };
    const qrMidBox  = { x: nurseBox.x + nurseBox.w + gap, y: detailsTop, w: LAY.qrW, h: detailsH };
    const clientBox = { x: qrMidBox.x + qrMidBox.w + gap, y: detailsTop, w: nurseW, h: detailsH };

    drawRect(page, nurseBox.x, nurseBox.y, nurseBox.w, nurseBox.h, { lineWidth: 0.45 });
    drawRect(page, clientBox.x, clientBox.y, clientBox.w, clientBox.h, { lineWidth: 0.45 });

    // Nurse/Client titles
    drawCenteredText(page, fontBold, "Temporary Worker Details", nurseBox.x, nurseBox.y + 4.2, nurseBox.w, LAY.detailsTitleSize);
    drawCenteredText(page, fontBold, "Client Details", clientBox.x, clientBox.y + 4.2, clientBox.w, LAY.detailsTitleSize);

 const surname   = safeStr(resolvedSurname).trim().toUpperCase();
const firstName = safeStr(resolvedFirstName).trim().toUpperCase();
const role      = safeStr(resolvedRole).trim().toUpperCase();


    const clientName = safeStr(resolvedClientName);
    const siteWard = safeStr(resolvedSiteWard);
    const bandText = safeStr(resolvedBandText);

    // Field Y positions inside Nurse/Client boxes (scaled to box height)
    const line1Y = nurseBox.y + (detailsH * 0.44);
    const line2Y = nurseBox.y + (detailsH * 0.64);
    const line3Y = nurseBox.y + (detailsH * 0.84);

    drawText(page, fontBold, "Surname:", nurseBox.x + 2, line1Y, LAY.detailsLabelSize);
    drawText(page, font, surname, nurseBox.x + 20, line1Y, LAY.detailsValueSize, { maxWidth: nurseBox.w - 22 });

    drawText(page, fontBold, "First name:", nurseBox.x + 2, line2Y, LAY.detailsLabelSize);
    drawText(page, font, firstName, nurseBox.x + 20, line2Y, LAY.detailsValueSize, { maxWidth: nurseBox.w - 22 });

    drawText(page, fontBold, "Job Profile Title:", nurseBox.x + 2, line3Y, LAY.detailsLabelSize);
    drawText(page, font, role, nurseBox.x + 30, line3Y, LAY.detailsValueSize, { maxWidth: nurseBox.w - 32 });

    const cLine1Y = clientBox.y + (detailsH * 0.52);
    const cLine2Y = clientBox.y + (detailsH * 0.78);

    drawText(page, fontBold, "Client Name / Hospital:", clientBox.x + 2, cLine1Y, LAY.detailsLabelSize);
    drawText(page, font, clientName, clientBox.x + 36, cLine1Y, LAY.detailsValueSize, { maxWidth: clientBox.w - 38 });

    drawText(page, fontBold, "Site / Ward:", clientBox.x + 2, cLine2Y, LAY.detailsLabelSize);
    drawText(page, font, siteWard, clientBox.x + 20, cLine2Y, LAY.detailsValueSize, { maxWidth: clientBox.w - 22 });

    // QR lives between nurse & client: draw square centered vertically in qrMidBox
    const qrSquare = {
      x: qrMidBox.x,
      y: qrMidBox.y + (detailsH - LAY.qrH) / 2,
      w: LAY.qrW,
      h: LAY.qrH
    };
    drawRect(page, qrSquare.x, qrSquare.y, qrSquare.w, qrSquare.h, { lineWidth: 0.35 });

    try {
      const qrStatus = safeStr(ts.qr_status).toUpperCase();
      const hasPayloadObj = ts.qr_payload_json && typeof ts.qr_payload_json === "object";
      const shouldDrawQr = (qrStatus === "PENDING") && hasPayloadObj;

      if (shouldDrawQr) {
        const qrText = await buildTsq1String(ts.qr_payload_json, env);
        await drawQrInBox(page, qrText, qrSquare);
      }
    } catch (e) {
      L("QR.FAIL", { err: e?.message || String(e) });
    }

    // ---------- Header statement block ----------
    const headerLines =
      (headerJson && typeof headerJson === "object" && Array.isArray(headerJson.lines))
        ? headerJson.lines.map(safeStr).filter(Boolean)
        : [];

    const stmtFontSize =
      isTight
        ? LAY.headerFontSize
        : ((headerJson && Number(headerJson.font_size)) ? Number(headerJson.font_size) : 8);

    const stmtLineH =
      isTight
        ? LAY.headerLineH
        : ((headerJson && Number(headerJson.line_height_mm)) ? Number(headerJson.line_height_mm) : 3.8);

    let yCursor = detailsTop + detailsH + LAY.yCursorGap;
    if (headerLines.length) {
      for (const line of headerLines) {
        drawText(page, font, line, contentX, yCursor, stmtFontSize, { maxWidth: contentW });
        yCursor += stmtLineH;
      }
      yCursor += LAY.yCursorAfterHeaderPad;
    }

    // ---------- Totals ----------
    let totalPaidMinutes = 0;
    for (const segs of byDate.values()) {
      for (const s of segs) {
        const t = getSegTimes(s);
        if (!t.start || !t.end) continue;
        totalPaidMinutes += computePaidMinutes(s);
      }
    }
    const totalPaidHours = Math.round((totalPaidMinutes / 60) * 100) / 100;

    // Reserve bottom blocks (decl + footer + optional addl)
    const DECL_H = LAY.declH;
    const FOOT_H = 14;
    const ADDL_H = (additionalRows.length > 0) ? LAY.addlH : 0;

    const reservedBottom =
      (additionalRows.length > 0 ? LAY.addlGap : LAY.blockGap) +
      (ADDL_H ? (ADDL_H + LAY.addlGap) : 0) +
      (DECL_H + LAY.blockGap) +
      (FOOT_H + 8);

    const tableTop = yCursor;

    const maxTableH = Math.max(60, (PAGE_H - M) - tableTop - reservedBottom);
    const bodyMaxH = Math.max(30, maxTableH - LAY.tsHeaderRowH - LAY.tsTotalRowH);

    // NO TRUNCATION MARKERS: always show all shifts; adjust line height & fonts to fit.
    const visibleLinesPerDay = realCounts.slice();
    const totalLinesVisible = totalLinesWanted;

    const idealLineH = (totalLinesVisible > 0) ? (bodyMaxH / totalLinesVisible) : bodyMaxH;

    // Never force lineH above idealLineH (that’s what can push declarations off-page).
    // Let it get as small as needed to preserve the layout blocks below.
    const lineH = Math.min(10.5, idealLineH);

    // Dynamic schedule text baseline offset so lines NEVER collide with text
    const textPad = Math.max(0.12, lineH * 0.10); // keep baseline safely inside the row
    const textOffset = Math.min(
      LAY.tsLineTextOffset,
      lineH * 0.72,
      Math.max(0, lineH - textPad)
    );

    // Dynamic font scaling for extreme compression
    const bodyFontSize = (lineH < 2.6) ? Math.min(LAY.tsBodyFontSize, 6.0) : LAY.tsBodyFontSize;
    const wordsFontSize = (lineH < 2.6) ? Math.min(LAY.tsWordsFontSize, 5.4) : LAY.tsWordsFontSize;
    const headerFontSizeTable = (lineH < 2.6) ? Math.min(LAY.tsHeaderFontSize, 5.6) : LAY.tsHeaderFontSize;

    const bodyHUsed = lineH * totalLinesVisible;
    const tableHUsed = LAY.tsHeaderRowH + bodyHUsed + LAY.tsTotalRowH;

    const hoursBox = { x: contentX, y: tableTop, w: contentW, h: tableHUsed };
    drawRect(page, hoursBox.x, hoursBox.y, hoursBox.w, hoursBox.h, { lineWidth: 0.5 });

    // Columns
    const colNames = ["Day","Date","Shift Start","Shift End","Break Start","Break End","Paid hrs","Paid hrs (words)","Band","Booking Ref"];
    const colW = [14, 22, 18, 18, 18, 18, 18, 52, 14, 0];
    const fixedW = colW.slice(0, -1).reduce((a, b) => a + b, 0);
    colW[colW.length - 1] = Math.max(20, hoursBox.w - fixedW);

    const colX = [];
    let cx = hoursBox.x;
    for (let i = 0; i < colW.length; i++) { colX.push(cx); cx += colW[i]; }

    const bodyTop = hoursBox.y + LAY.tsHeaderRowH;
    const totalTop = bodyTop + bodyHUsed;

    // Header divider + total divider
    drawLine(page, hoursBox.x, bodyTop, hoursBox.x + hoursBox.w, bodyTop, 0.4);
    drawLine(page, hoursBox.x, totalTop, hoursBox.x + hoursBox.w, totalTop, 0.45);

    // verticals only through header+body (NOT into total row)
    for (let i = 1; i < colW.length; i++) {
      drawLine(page, colX[i], hoursBox.y, colX[i], totalTop, 0.3);
    }

    // Header labels (bold)
    const headerTextY = hoursBox.y + (LAY.tsHeaderRowH - 1.9);
    for (let i = 0; i < colW.length; i++) {
      drawText(page, fontBold, colNames[i], colX[i] + 1.0, headerTextY, headerFontSizeTable, { maxWidth: colW[i] - 2 });
    }

    // Body rows
    let yRow = bodyTop;
    for (let di = 0; di < 7; di++) {
      const meta = weekDates[di];
      const ymd = meta.ymd;

      const segs = (ymd && byDate.get(ymd)) ? byDate.get(ymd).slice() : [];
      const realSegs = segs.filter(s => {
        const t = getSegTimes(s);
        return !!(t.start && t.end);
      });

      const dayLines = visibleLinesPerDay[di] || 1;
      const rowH = lineH * dayLines;

      // day boundary line
      drawLine(page, hoursBox.x, yRow + rowH, hoursBox.x + hoursBox.w, yRow + rowH, 0.3);

      // Day/Date once
      drawText(page, font, meta.dowName || "", colX[0] + 1.2, yRow + textOffset, bodyFontSize);
      drawText(page, font, fmtDmy(ymd),        colX[1] + 1.2, yRow + textOffset, bodyFontSize);

      // INTERNAL separators (Shift Start -> Booking Ref) that NEVER cross text:
      if (realSegs.length > 1) {
        const xSep1 = colX[2];
        const xSep2 = colX[9] + colW[9];
        const sepPad = Math.max(0.10, Math.min(0.35, lineH * 0.10));
        const sepLw = (lineH < 3.0) ? 0.15 : 0.22;

        for (let si = 1; si < realSegs.length; si++) {
          const ySep = yRow + (si * lineH) - sepPad;
          drawLine(page, xSep1, ySep, xSep2, ySep, sepLw);
        }
      }

      for (let li = 0; li < realSegs.length; li++) {
        const seg = realSegs[li];
        const t = getSegTimes(seg);
        const b = getBreakDisplay(seg);
        const ph = computePaidHours(seg);

        // Booking ref: strictly per shift
        const ref =
          safeStr(seg?.ref_num || "").trim() ||
          safeStr(seg?.booking_ref || "").trim() ||
          "";

        const lineY = yRow + textOffset + (li * lineH);

        drawText(page, font, t.start, colX[2] + 1.2, lineY, bodyFontSize);
        drawText(page, font, t.end,   colX[3] + 1.2, lineY, bodyFontSize);

        drawText(page, font, b.brkStart, colX[4] + 1.2, lineY, bodyFontSize, { maxWidth: colW[4] - 2.4 });
        drawText(page, font, b.brkEnd,   colX[5] + 1.2, lineY, bodyFontSize, { maxWidth: colW[5] - 2.4 });

        drawText(page, font, ph.paid,      colX[6] + 1.2, lineY, bodyFontSize);
        drawText(page, font, ph.paidWords, colX[7] + 1.2, lineY, wordsFontSize, { maxWidth: colW[7] - 2.4 });

        drawText(page, font, bandText, colX[8] + 1.2, lineY, bodyFontSize);
        drawText(page, font, ref,      colX[9] + 1.2, lineY, bodyFontSize, { maxWidth: colW[9] - 2.4 });
      }

      yRow += rowH;
    }

    // TOTAL HOURS ROW
    const totalLabel = "Total overall hours claimed (excluding breaks):";
    const totalTextY = totalTop + (LAY.tsTotalRowH - 2.6);
    drawText(page, fontBold, totalLabel, hoursBox.x + 2, totalTextY, Math.min(8.5, bodyFontSize + 0.5), { maxWidth: hoursBox.w - 90 });

    const totalTxt = `${totalPaidHours.toFixed(2)}  (${minutesToWordsUpper(totalPaidMinutes)})`;
    drawText(page, fontBold, totalTxt, hoursBox.x + hoursBox.w - 88, totalTextY, Math.min(8.5, bodyFontSize + 0.5), { maxWidth: 86 });

    // ---------- Additional rates / units ----------
    let yAfterTable =
      hoursBox.y + hoursBox.h + (additionalRows.length > 0 ? LAY.addlGap : LAY.blockGap);

    if (additionalRows.length > 0) {
      const addlBox = { x: contentX, y: yAfterTable, w: contentW, h: ADDL_H };
      drawRect(page, addlBox.x, addlBox.y, addlBox.w, addlBox.h, { lineWidth: 0.45 });

      // Title gets its own line ABOVE the column headers (guaranteed separation)
      const addlTitleY = addlBox.y + Math.min(2.8, LAY.addlHeaderH * 0.45);
      const addlColsY  = addlBox.y + (LAY.addlHeaderH - 1.4);

      drawText(page, fontBold, "Additional rates / units",
        addlBox.x + 2,
        addlTitleY,
        Math.min(8.2, bodyFontSize + 0.5)
      );

      const aHeaderY = addlBox.y + LAY.addlHeaderH;
      drawLine(page, addlBox.x, aHeaderY, addlBox.x + addlBox.w, aHeaderY, 0.35);

      const aCols = ["Rate Type", "Date", "Quantity", "Unit"];
      const aW = [70, 28, 22, 0];
      const aFixed = aW.slice(0, -1).reduce((a, b) => a + b, 0);
      aW[aW.length - 1] = Math.max(30, addlBox.w - aFixed);

      // Divider under the title row (so title is "full width")
      const addlTitleDividerY = addlBox.y + Math.min(3.4, LAY.addlHeaderH * 0.55);
      drawLine(page, addlBox.x, addlTitleDividerY, addlBox.x + addlBox.w, addlTitleDividerY, 0.25);

      let ax = addlBox.x;
      for (let i = 0; i < aW.length; i++) {
        if (i > 0) drawLine(page, ax, addlTitleDividerY, ax, addlBox.y + addlBox.h, 0.3);
        drawText(page, fontBold, aCols[i], ax + 1.2,
          addlColsY,
          Math.min(7.2, headerFontSizeTable)
        );
        ax += aW[i];
      }

      // No (+N more): show as many as fit silently
      const maxRows = Math.max(0, Math.floor((addlBox.h - LAY.addlHeaderH) / LAY.addlRowH));
      const rowsToShow = additionalRows.slice(0, maxRows);

      let ry = aHeaderY + Math.min(3.8, LAY.addlRowH - 0.2);
      for (const r of rowsToShow) {
        drawText(page, font, safeStr(r.bucket), addlBox.x + 1.2, ry, Math.min(bodyFontSize, 7.2), { maxWidth: aW[0] - 2.4 });
        drawText(page, font, r.date ? fmtDmy(r.date) : "", addlBox.x + aW[0] + 1.2, ry, Math.min(bodyFontSize, 7.2), { maxWidth: aW[1] - 2.4 });
        drawText(page, font, safeStr(r.qty), addlBox.x + aW[0] + aW[1] + 1.2, ry, Math.min(bodyFontSize, 7.2), { maxWidth: aW[2] - 2.4 });
        drawText(page, font, safeStr(r.unit), addlBox.x + aW[0] + aW[1] + aW[2] + 1.2, ry, Math.min(bodyFontSize, 7.2), { maxWidth: aW[3] - 2.4 });
        ry += LAY.addlRowH;
      }

      yAfterTable = addlBox.y + addlBox.h + LAY.addlGap;
    }

    // ---------- Declarations strip ----------
    const declGap = 6;
    const declBoxW = (contentW - declGap) / 2;

    const leftDecl = { x: contentX, y: yAfterTable, w: declBoxW, h: DECL_H };
    const rightDecl = { x: contentX + declBoxW + declGap, y: yAfterTable, w: declBoxW, h: DECL_H };

    drawRect(page, leftDecl.x, leftDecl.y, leftDecl.w, leftDecl.h, { lineWidth: 0.45, borderColor: rgb(0,0,0) });
    drawRect(page, rightDecl.x, rightDecl.y, rightDecl.w, rightDecl.h, { lineWidth: 0.45, borderColor: rgb(0,0,0) });

    const drawDeclTitle = (box, spec) => {
      const titleFont = spec.title_bold ? fontBold : font;
      const title = safeStr(spec.title);
      if (!title) return;
      const y = box.y + (isTight ? 4.0 : 4.8);
      const size = LAY.declTitleSize;
      drawCenteredText(page, titleFont, title, box.x, y, box.w, size);
    };

    drawDeclTitle(leftDecl, tempDeclSpec);
    drawDeclTitle(rightDecl, clientDeclSpec);

    const declBodyTopPad = LAY.declBodyTopPad;
    const declBodyBottomReserve = LAY.declSigReserve;
    const maxBodyH = leftDecl.h - declBodyTopPad - declBodyBottomReserve;

   const renderDecl = (box, spec) => {
  const maxW = box.w - 4;
  const baseText = safeStr(spec.bodyText);
  if (!baseText.trim()) return null;

  let fontSize = Number(spec.font_size) || 7.0;
  let lineH = Number(spec.line_height_mm) || 3.35;

  if (isTight) {
    fontSize = Math.min(fontSize, 6.6);
    lineH = Math.min(lineH, LAY.headerLineH);
  }

  for (let attempt = 0; attempt < 4; attempt++) {
    const lines = wrapText(font, baseText, fontSize, maxW);
    const neededH = lines.length * lineH;
    if (neededH <= maxBodyH) {
      let yT = box.y + declBodyTopPad;
 for (const ln of lines) {
  if (yT > box.y + box.h - declBodyBottomReserve - 0.5) break;
  drawText(page, font, ln, box.x + 2, yT, fontSize, { maxWidth: maxW });
  yT += lineH;
}
return (yT > (box.y + declBodyTopPad)) ? (yT - lineH) : (box.y + declBodyTopPad);

    }
    fontSize = Math.max(5.8, fontSize - 0.4);
    lineH = Math.max(2.4, lineH - 0.15);
  }

  // last resort: clip silently (no "+N more")
  const lines = wrapText(font, baseText, 5.8, maxW);
  const maxLines = Math.max(1, Math.floor(maxBodyH / 2.4));
  let yT = box.y + declBodyTopPad;
for (const ln of lines.slice(0, maxLines)) {
  drawText(page, font, ln, box.x + 2, yT, 5.8, { maxWidth: maxW });
  yT += 2.4;
}
return (yT > (box.y + declBodyTopPad)) ? (yT - 2.4) : (box.y + declBodyTopPad);

};

// ✅ capture where the declaration text ended (so signatures can use unused whitespace)
const lastDeclBodyEndYLeft  = renderDecl(leftDecl, tempDeclSpec);
const lastDeclBodyEndYRight = renderDecl(rightDecl, clientDeclSpec);


    // Signature lines (fixed inside each box)
    const sigY = leftDecl.y + leftDecl.h - 6.5;
    const sigLineW = leftDecl.w - 28;
    drawLine(page, leftDecl.x + 2, sigY, leftDecl.x + 2 + sigLineW, sigY, 0.35);
    drawText(page, font, "Signature", leftDecl.x + 2, sigY - 1.2, 7.0);
    drawLine(page, leftDecl.x + 2 + sigLineW + 4, sigY, leftDecl.x + leftDecl.w - 2, sigY, 0.35);
    drawText(page, font, "Date", leftDecl.x + 2 + sigLineW + 4, sigY - 1.2, 7.0);

    const sigY2 = rightDecl.y + rightDecl.h - 6.5;
    const sigLineW2 = rightDecl.w - 28;
    drawLine(page, rightDecl.x + 2, sigY2, rightDecl.x + 2 + sigLineW2, sigY2, 0.35);
    drawText(page, font, "Signature", rightDecl.x + 2, sigY2 - 1.2, 7.0);
    drawLine(page, rightDecl.x + 2 + sigLineW2 + 4, sigY2, rightDecl.x + rightDecl.w - 2, sigY2, 0.35);
    drawText(page, font, "Date", rightDecl.x + 2 + sigLineW2 + 4, sigY2 - 1.2, 7.0);

    // ✅ render ELECTRONIC signatures + dates
    try {
      const submissionMode = String(ts.submission_mode || "").toUpperCase();
      if (submissionMode === "ELECTRONIC") {
        const authDate = fmtDmy(String(ts.authorised_at_server || "").slice(0, 10));

const sigMaxH = 18.0; // ✅ allow larger signatures when whitespace exists
const sigLiftMm = 0.6; // "few pixels" ≈ 0.6mm

// ✅ Use where the declaration body actually ended (if known), otherwise allow using the full body area.
// This avoids the ~5–6mm trap caused by (leftDecl.h - declBodyBottomReserve).
const sigTextPad = 0.8;

const sigReserveTopLeft =
  (typeof lastDeclBodyEndYLeft === 'number')
    ? (lastDeclBodyEndYLeft + sigTextPad)
    : (leftDecl.y + declBodyTopPad);

const sigReserveTopRight =
  (typeof lastDeclBodyEndYRight === 'number')
    ? (lastDeclBodyEndYRight + sigTextPad)
    : (rightDecl.y + declBodyTopPad);

// We anchor the BOTTOM of the image to the signature LINE (minus lift)
const nurseSigBottom  = sigY  - sigLiftMm;
const clientSigBottom = sigY2 - sigLiftMm;

// Height can now use *real whitespace*, not just the small reserved strip
const nurseAvailH  = Math.max(2.0, nurseSigBottom  - sigReserveTopLeft);
const clientAvailH = Math.max(2.0, clientSigBottom - sigReserveTopRight);

const nurseSigH  = Math.min(sigMaxH, nurseAvailH);
const clientSigH = Math.min(sigMaxH, clientAvailH);

// Top computed from bottom - height (bottom stays on the signature line)
const nurseSigTopY  = Math.max(leftDecl.y + 2.0,  nurseSigBottom  - nurseSigH);
const clientSigTopY = Math.max(rightDecl.y + 2.0, clientSigBottom - clientSigH);

const nurseSigBox  = { x: leftDecl.x + 2,  y: nurseSigTopY,  w: sigLineW,  h: nurseSigH };
const clientSigBox = { x: rightDecl.x + 2, y: clientSigTopY, w: sigLineW2, h: clientSigH };


        await drawSignatureKeyInBox(bucket, page, pdfDoc, ts.r2_nurse_key, nurseSigBox, PAGE_H);
        await drawSignatureKeyInBox(bucket, page, pdfDoc, ts.r2_auth_key, clientSigBox, PAGE_H);

        if (authDate) {
          const datePad = 0.6;

          const dateX1 = leftDecl.x + 2 + sigLineW + 4;
          const dateW1 = (leftDecl.x + leftDecl.w - 2) - dateX1;

          const dateX2 = rightDecl.x + 2 + sigLineW2 + 4;
          const dateW2 = (rightDecl.x + rightDecl.w - 2) - dateX2;

   const dateLabelSize = 7.0; // you draw "Date" at 7.0
const dateLabelWmm  = ptToMm(font.widthOfTextAtSize("Date", dateLabelSize));
const gapAfterLabel = 1.2; // mm

const dateTextX1 = dateX1 + dateLabelWmm + gapAfterLabel;
const dateTextW1 = Math.max(1, (dateX1 + dateW1) - dateTextX1 - 0.6);
drawTextFit(page, font, authDate, dateTextX1, sigY - 1.2, dateTextW1, 6.6, 4.8);

const dateTextX2 = dateX2 + dateLabelWmm + gapAfterLabel;
const dateTextW2 = Math.max(1, (dateX2 + dateW2) - dateTextX2 - 0.6);
drawTextFit(page, font, authDate, dateTextX2, sigY2 - 1.2, dateTextW2, 6.6, 4.8);

        }
      }
    } catch (e) {
      L("SIG.FAIL", { err: e?.message || String(e) });
    }

    // ---------- Footer under declarations ----------
    const footerLines =
      (footerJson && typeof footerJson === "object" && Array.isArray(footerJson.lines))
        ? footerJson.lines.map(safeStr).filter(Boolean)
        : [];

    const fSize = isTight
      ? LAY.footerFontSize
      : ((footerJson && Number(footerJson.font_size)) ? Number(footerJson.font_size) : 7.0);

    const fLineH = isTight
      ? LAY.footerLineH
      : ((footerJson && Number(footerJson.line_height_mm)) ? Number(footerJson.line_height_mm) : 3.6);

    const footerTop = yAfterTable + DECL_H + LAY.blockGap;
    drawLine(page, contentX, footerTop, contentX + contentW, footerTop, 0.35);

    let fy = footerTop + 3.2;
    for (const raw of footerLines) {
      if (fy > PAGE_H - M - 1) break;

      const wrapped = wrapText(font, raw, fSize, contentW);
      for (const ln of wrapped) {
        if (fy > PAGE_H - M - 1) break;
        drawText(page, font, ln, contentX, fy, fSize, { maxWidth: contentW });
        fy += fLineH;
      }
    }

    // ---------- Save to R2 ----------
    const outKey = normalizeKey(`docs-pdf/timesheets/ts_${timesheetId}.pdf`);
    L("PDF.SAVE", { outKey });

    const outBytes = await pdfDoc.save();
    L("PDF.BYTES", { bytes: outBytes?.length || null });

    await bucket.put(outKey, outBytes, { httpMetadata: { contentType: "application/pdf" } });

    L("DONE", { outKey, ms: Date.now() - T0 });
    return outKey;

  } catch (e) {
    L("FAIL", { err: e?.message || String(e), ms: Date.now() - T0 });
    throw e;
  }
}


async function renderTimesheetPDFAndSave(env, timesheetId) {
  const bucket = env.R2_BUCKET || env.R2;
  if (!bucket?.get || !bucket?.put) throw new Error("Storage not configured");

  const T0 = Date.now();
  const LOGP = `[TS_PDF][${timesheetId}]`;
  const L = (step, obj) => { try { console.log(`${LOGP} ${step}`, obj || {}); } catch {} };

  L("START", { timesheetId });

  // Load TS row (CURRENT VERSION ONLY)
  let ts = null;
  try {
    const { rows: tsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${encodeURIComponent(timesheetId)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,qr_token,qr_status,qr_payload_json` +
        `&limit=1`
    );
    ts = tsRows?.[0] || null;
  } catch (e) {
    L("DB.FAIL", { err: e?.message || String(e) });
    throw e;
  }

  if (!ts) {
    L("DB.MISS", {});
    throw new Error("Timesheet not found");
  }

  const outKey = normalizeKey(`docs-pdf/timesheets/ts_${timesheetId}.pdf`);

  const qrStatus = String(ts.qr_status || "").toUpperCase();

  // payload could be object, stringified JSON, null
  let payloadObj = null;
  const payloadType = (ts.qr_payload_json === null) ? "null" : typeof ts.qr_payload_json;

  if (ts.qr_payload_json && typeof ts.qr_payload_json === "object") {
    payloadObj = ts.qr_payload_json;
  } else if (typeof ts.qr_payload_json === "string") {
    try {
      payloadObj = JSON.parse(ts.qr_payload_json);
    } catch (e) {
      payloadObj = null;
      L("PAYLOAD.PARSE_FAIL", { err: e?.message || String(e) });
    }
  }

  const payloadTok = payloadObj && typeof payloadObj === "object"
    ? String(payloadObj.tok || "").trim()
    : "";

  const qrToken = String(ts.qr_token || "").trim();
  const hasAnyTok = !!(payloadTok || qrToken);

  // ✅ Correct notion of “needs QR printable”
  // We treat *any* PENDING QR as needing QR PDF behaviour, but we REQUIRE a token to avoid emailing blank/invalid QR.
  const qrPending = (qrStatus === "PENDING");

  if (qrPending && !hasAnyTok) {
    L("DECIDE.ERROR", { qrStatus, payloadType, qrToken_present: !!qrToken, payloadTok_present: !!payloadTok });
    throw new Error("QR is PENDING but no token found in qr_payload_json.tok or timesheets.qr_token");
  }

  // Check cache existence
  let exists = false;
  try {
    exists = await r2Exists(env, outKey);
  } catch (e) {
    L("R2.EXISTS_FAIL", { outKey, err: e?.message || String(e) });
    exists = false;
  }

  // Policy:
  // - If NOT pending: reuse cached PDF if it exists
  // - If pending: render (safe for reissue; guarantees current QR is embedded)
  const action = (!qrPending && exists) ? "REUSE" : "RENDER";

  L("DECIDE", {
    outKey,
    qrStatus,
    payloadType,
    payloadTok_present: !!payloadTok,
    qrToken_present: !!qrToken,
    r2Exists: exists,
    action
  });

  if (action === "REUSE") {
    L("REUSE", { outKey, ms: Date.now() - T0 });
    return outKey;
  }

  // Render (overwrite if exists)
  try {
    const key = await renderTimesheetPDFGeneratedAndSave(env, timesheetId);
    L("RENDER.OK", { outKey: key, ms: Date.now() - T0 });
    return key;
  } catch (e) {
    L("RENDER.FAIL", { err: e?.message || String(e), ms: Date.now() - T0 });
    throw e;
  }
}



// Ensure a TS PDF exists; return its key (render/snapshot if missing)

async function ensureTimesheetPdf(env, timesheetId, opts) {
  const enc = encodeURIComponent;

  const force_regen = !!(opts && typeof opts === 'object' && opts.force_regen);
  const prefer_generated = !!(opts && typeof opts === 'object' && opts.prefer_generated);

  // Always look at CURRENT VERSION ONLY
  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(timesheetId)}` +
      `&is_current=eq.true` +
      `&select=manual_pdf_r2_key,qr_token,qr_status,qr_payload_json` +
      `&limit=1`
  );

  // If QR is pending and payload exists, we MUST return the generated printable PDF (not a manual scan),
  // because the QR is part of the printable.
  const needsQrPrintable =
    String(ts?.qr_status || "").toUpperCase() === "PENDING" &&
    ts?.qr_payload_json && typeof ts.qr_payload_json === "object";

  // ✅ NEW: force_regen / prefer_generated path
  if (force_regen || prefer_generated || needsQrPrintable) {
    return await renderTimesheetPDFAndSave(env, timesheetId);
  }

  // Prefer a manual uploaded PDF when present (scanned evidence path)
  if (ts?.manual_pdf_r2_key) {
    const mk = normalizeKey(ts.manual_pdf_r2_key);
    if (await r2Exists(env, mk)) return mk;
  }

  const key = normalizeKey(`docs-pdf/timesheets/ts_${timesheetId}.pdf`);
  if (await r2Exists(env, key)) return key;

  // Otherwise generate the system PDF
  return await renderTimesheetPDFAndSave(env, timesheetId);
}


// ============================================================================
// NEW: Weekly / Manual contracts API handlers
// ============================================================================

// Small local helpers (reuse existing utils from your file)
const enc = (s) => encodeURIComponent(String(s ?? ''));

function toYmd(d) {
  const dt = (typeof d === 'string') ? new Date(d + 'T00:00:00Z') : d;
  const yyyy = dt.getUTCFullYear();
  const mm = String(dt.getUTCMonth() + 1).padStart(2, '0');
  const dd = String(dt.getUTCDate()).padStart(2, '0');
  return `${yyyy}-${mm}-${dd}`;
}
function ymdCompact(ymd) { return (ymd || '').replace(/-/g, ''); }
function clampBool(v, def=false){ return v === true || v === 'true' ? true : v === false || v === 'false' ? false : def; }

/** Compute week-ending for a given date and weekEndingWeekday (0=Sun..6=Sat) */
function computeWeekEnding(ymd, weekEndingWeekday=0) {
  const d = new Date(ymd + 'T00:00:00Z');
  const dow = d.getUTCDay(); // 0..6
  const delta = (weekEndingWeekday - dow + 7) % 7;
  d.setUTCDate(d.getUTCDate() + delta);
  return toYmd(d);
}

/** Generate all week-ending dates between start..end (inclusive), aligned to 'wew' (0=Sun..6=Sat) */
function enumerateWeekEndings(startYmd, endYmd, wew=0) {
  const startWE = computeWeekEnding(startYmd, wew);
  const out = [];
  let d = new Date(startWE + 'T00:00:00Z');
  const end = new Date(toYmd(endYmd) + 'T00:00:00Z');
  while (d <= end) {
    out.push(toYmd(d));
    d.setUTCDate(d.getUTCDate() + 7);
  }
  return out;
}

/** Load one row helper */
async function sbGetOne(env, url) {
  const { rows } = await sbFetch(env, url, false);
  return (rows && rows[0]) || null;
}

/** Numeric guard */
const n = (v) => (v == null || Number.isNaN(Number(v))) ? 0 : Number(v);

/** Pick pay/charge rates from contracts.rates_json by pay method snapshot */
function payChargeFromContract(contract) {
  const R = contract?.rates_json || {};
  const method = (contract?.pay_method_snapshot || '').toUpperCase();
  const pay = (method === 'PAYE')
    ? { day: R.paye_day, night: R.paye_night, sat: R.paye_sat, sun: R.paye_sun, bh: R.paye_bh }
    : { day: R.umb_day,  night: R.umb_night,  sat: R.umb_sat,  sun: R.umb_sun,  bh: R.umb_bh  };
  const charge = { day: R.charge_day, night: R.charge_night, sat: R.charge_sat, sun: R.charge_sun, bh: R.charge_bh };
  return { pay, charge, method };
}

/** Compose a weekly booking id using existing helper */
// AFTER (replace makeWeeklyBookingId)
async function makeWeeklyBookingId(candidateId, contract, cw) {
  const hospital = contract?.display_site || contract?.client_id || 'client';
  const ward     = contract?.ward_hint   || 'contract';
  const role     = contract?.role        || 'weekly';
  const shift    = `WEEKLY-${String(cw?.additional_seq ?? 0)}`;

  const id = await makeBookingId(
    String(candidateId || ''),
    String(cw?.week_ending_date || ''),
    String(hospital || ''),
    String(ward || ''),
    String(role || ''),
    shift
  );

  return String(id || '').trim();
}

/** Upsert convenience (PostgREST) */
async function postgrestUpsert(env, table, rows, onConflictCols) {
  const url = `${env.SUPABASE_URL}/rest/v1/${table}?on_conflict=${onConflictCols}`;
  const res = await fetch(url, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'resolution=merge-duplicates,return=representation' },
    body: JSON.stringify(rows)
  });
  if (!res.ok) {
    const t = await res.text();
    throw new Error(`${table} upsert failed: ${t}`);
  }
  const json = await res.json().catch(()=>[]);
  return Array.isArray(json) ? json : [json];
}

/** Attach / replace manual scan key on a contract_week (guard invoiced if linked) */
async function patchContractWeekScan(env, cwId, r2Key) {
  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cwId)}`, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify({ uploaded_pdf_r2_key: r2Key, updated_at: nowIso() })
  });
  if (!res.ok) {
    throw new Error(`contract_weeks scan patch failed: ${await res.text()}`);
  }
  const j = await res.json().catch(()=>[]);
  return (j && j[0]) || null;
}

// ----------------------------------------------------------------------------
// A) CONTRACTS (CRUD + lifecycle)
// ----------------------------------------------------------------------------

async function handleContractsCreate(env, req) {
  const user = await requireUser(env, req, ['admin']); // backoffice only
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  // 🔄 Relaxed: candidate_id is now optional (can be null/unassigned)
  const required = ['client_id','start_date','end_date','pay_method_snapshot'];
  for (const k of required) if (!body[k]) return withCORS(env, req, badRequest(`${k} is required`));

  const normaliseAdditionalRates = (raw) => {
    if (!raw) return null;
    const arr = Array.isArray(raw) ? raw : [];
    const out = [];
    const seen = new Set();
    const ALLOWED = new Set(['ONE_PER_WEEK','ONE_PER_DAY','WEEKENDS_AND_BH_ONLY','WEEKDAYS_EXCL_BH_ONLY']);

    const ensureCode = (code, idx) => {
      const c = String(code || '').toUpperCase();
      if (/^EX[1-5]$/.test(c)) return c;
      return `EX${idx + 1}`;
    };

    arr.slice(0, 5).forEach((row, idx) => {
      if (!row || typeof row !== 'object') return;
      const code = ensureCode(row.code, idx);
      if (seen.has(code)) return;
      seen.add(code);

      let bucketName = (row.bucket_name || '').trim();
      const unitName   = (row.unit_name != null && String(row.unit_name).trim())
        ? String(row.unit_name).trim()
        : null;

      let freq = String(row.frequency || 'ONE_PER_WEEK').toUpperCase();
      if (!ALLOWED.has(freq)) freq = 'ONE_PER_WEEK';

      let pay    = (row.pay_rate    !== undefined && row.pay_rate    !== null) ? Number(row.pay_rate)    : null;
      let charge = (row.charge_rate !== undefined && row.charge_rate !== null) ? Number(row.charge_rate) : null;
      if (pay != null && (!Number.isFinite(pay) || pay < 0)) pay = null;
      if (charge != null && (!Number.isFinite(charge) || charge < 0)) charge = null;

      const hasAny = bucketName || pay != null || charge != null || unitName;
      if (!hasAny) return;

      // ✅ Ensure bucket_name is never blank for a persisted row
      if (!bucketName) bucketName = code;

      out.push({
        code,
        bucket_name: bucketName,
        unit_name: unitName,
        frequency: freq,
        pay_rate: pay,
        charge_rate: charge
      });
    });

    return out.length ? out : null;
  };

  // Track whether flags were explicitly supplied so we can decide when to derive from client defaults
  const hasRequireRefToPay      = Object.prototype.hasOwnProperty.call(body, 'require_reference_to_pay');
  const hasRequireRefToInvoice  = Object.prototype.hasOwnProperty.call(body, 'require_reference_to_invoice');
  const hasDefaultSubmission    = Object.prototype.hasOwnProperty.call(body, 'default_submission_mode');
  const hasAutoInvoice          = Object.prototype.hasOwnProperty.call(body, 'auto_invoice');

  // NEW: contract route/calc flags (treat explicit null as "not supplied" so we can derive defaults)
  const hasIsNhsp               = Object.prototype.hasOwnProperty.call(body, 'is_nhsp') && body.is_nhsp !== null;
  const hasAutoprocessHr        = Object.prototype.hasOwnProperty.call(body, 'autoprocess_hr') && body.autoprocess_hr !== null;
  const hasRequiresHr           = Object.prototype.hasOwnProperty.call(body, 'requires_hr') && body.requires_hr !== null;
  const hasNoTimesheetRequired  = Object.prototype.hasOwnProperty.call(body, 'no_timesheet_required') && body.no_timesheet_required !== null;
  const hasDailyCalc            = Object.prototype.hasOwnProperty.call(body, 'daily_calc_of_invoices') && body.daily_calc_of_invoices !== null;
  const hasGroupBuckets         = Object.prototype.hasOwnProperty.call(body, 'group_nightsat_sunbh') && body.group_nightsat_sunbh !== null;
  const hasSelfBill             = Object.prototype.hasOwnProperty.call(body, 'self_bill') && body.self_bill !== null;

  // ✅ NEW: attachments (treat explicit null as "not supplied" so we can derive defaults)
  const hasHrAttachToInvoice    = Object.prototype.hasOwnProperty.call(body, 'hr_attach_to_invoice') && body.hr_attach_to_invoice !== null;
  const hasTsAttachToInvoice    = Object.prototype.hasOwnProperty.call(body, 'ts_attach_to_invoice') && body.ts_attach_to_invoice !== null;

  // Normalise booleans we already support
  if (hasRequireRefToPay)     body.require_reference_to_pay     = clampBool(body.require_reference_to_pay, false);
  if (hasRequireRefToInvoice) body.require_reference_to_invoice = clampBool(body.require_reference_to_invoice, false);

  // Optional per-contract bucket labels
  const validateLabels = (obj) => {
    if (!obj || typeof obj !== 'object') return null;
    const keys = ['day','night','sat','sun','bh'];
    const out = {};
    for (const k of keys) {
      const v = obj[k];
      if (typeof v !== 'string' || !v.trim()) return null;
      out[k] = v.trim();
    }
    return out;
  };
  const bucketLabels = validateLabels(body.bucket_labels_json) || null;

  // accept std_schedule_json and derive std_hours_json
  let std_schedule_json = null;
  let derived_hours = null;
  if (body.std_schedule_json) {
    try {
      std_schedule_json = body.std_schedule_json;
      derived_hours = deriveStdHoursFromSchedule(std_schedule_json);
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid std_schedule_json'));
    }
  }
  const std_hours_json = (derived_hours || body.std_hours_json || null);

  // Pre-fetch latest client_settings to use for week-ending snapshot and ref/submission defaults
  // ✅ NEW: also fetch attachments defaults
  let clientSettings = null;
  try {
    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
        `?client_id=eq.${enc(body.client_id)}` +
        `&select=` +
          [
            'week_ending_weekday',
            'pay_reference_required',
            'invoice_reference_required',
            'default_submission_mode',
            'is_nhsp',
            'autoprocess_hr',
            'requires_hr',
            'no_timesheet_required',
            'self_bill_no_invoices_sent',
            'daily_calc_of_invoices',
            'group_nightsat_sunbh',
            'auto_invoice_default',
            'hr_attach_to_invoice',
            'ts_attach_to_invoice'
          ].join(',') +
        `&order=effective_from.desc,created_at.desc&limit=1`
    );
    clientSettings = (csRows && csRows[0]) || null;
  } catch {
    // Safety fallback to old select set if schema not yet migrated (non-fatal)
    try {
      const { rows: csRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_settings` +
          `?client_id=eq.${enc(body.client_id)}` +
          `&select=week_ending_weekday,pay_reference_required,invoice_reference_required,default_submission_mode` +
          `&order=effective_from.desc,created_at.desc&limit=1`
      );
      clientSettings = (csRows && csRows[0]) || null;
    } catch {
      clientSettings = null;
    }
  }

  // Derive week_ending_weekday_snapshot from body or client_settings (fallback 0)
  let weekEndingSnapshot = null;
  if (
    Number.isInteger(Number(body.week_ending_weekday_snapshot)) &&
    Number(body.week_ending_weekday_snapshot) >= 0 &&
    Number(body.week_ending_weekday_snapshot) <= 6
  ) {
    weekEndingSnapshot = Number(body.week_ending_weekday_snapshot);
  } else {
    const we = Number(clientSettings?.week_ending_weekday);
    weekEndingSnapshot = (Number.isInteger(we) && we >= 0 && we <= 6) ? we : 0;
  }

  // Derive reference flags + default submission mode from client_settings if missing from body
  if (!hasRequireRefToPay || !hasRequireRefToInvoice || !hasDefaultSubmission) {
    const payRefDefault  = !!(clientSettings && clientSettings.pay_reference_required);
    const invRefDefault  = !!(clientSettings && clientSettings.invoice_reference_required);
    const dsmRaw         = String(clientSettings?.default_submission_mode || '').toUpperCase();
    const dsmFromClient  = ['ELECTRONIC','MANUAL','QR'].includes(dsmRaw) ? dsmRaw : 'ELECTRONIC';

    if (!hasRequireRefToPay)     body.require_reference_to_pay     = payRefDefault;
    if (!hasRequireRefToInvoice) body.require_reference_to_invoice = invRefDefault;
    if (!hasDefaultSubmission)   body.default_submission_mode      = dsmFromClient;
  }

  // Final normalisation for ref flags & default submission
  body.require_reference_to_pay     = clampBool(body.require_reference_to_pay, false);
  body.require_reference_to_invoice = clampBool(body.require_reference_to_invoice, false);

  let defaultSubmissionMode = String(body.default_submission_mode || '').toUpperCase();
  if (!['ELECTRONIC','MANUAL','QR'].includes(defaultSubmissionMode)) {
    defaultSubmissionMode = 'ELECTRONIC';
  }

  // NEW: derive contract route/calc defaults from client_settings when not supplied
  const is_nhsp = hasIsNhsp
    ? clampBool(body.is_nhsp, false)
    : clampBool(clientSettings?.is_nhsp, false);

  const autoprocess_hr = hasAutoprocessHr
    ? clampBool(body.autoprocess_hr, false)
    : clampBool(clientSettings?.autoprocess_hr, false);

  const requires_hr = hasRequiresHr
    ? clampBool(body.requires_hr, false)
    : clampBool(clientSettings?.requires_hr, false);

  const no_timesheet_required = hasNoTimesheetRequired
    ? clampBool(body.no_timesheet_required, false)
    : clampBool(clientSettings?.no_timesheet_required, false);

  const daily_calc_of_invoices = hasDailyCalc
    ? clampBool(body.daily_calc_of_invoices, false)
    : clampBool(clientSettings?.daily_calc_of_invoices, false);

  const group_nightsat_sunbh = hasGroupBuckets
    ? clampBool(body.group_nightsat_sunbh, false)
    : clampBool(clientSettings?.group_nightsat_sunbh, false);

  const self_bill = hasSelfBill
    ? clampBool(body.self_bill, false)
    : clampBool(clientSettings?.self_bill_no_invoices_sent, false);

  // NEW: derive contract auto_invoice from client_settings auto_invoice_default if not explicitly supplied
  const auto_invoice = hasAutoInvoice
    ? clampBool(body.auto_invoice, false)
    : clampBool(clientSettings?.auto_invoice_default, false);

  // ✅ NEW: derive attachments from body or client_settings (fallback false)
  let hr_attach_to_invoice = hasHrAttachToInvoice
    ? clampBool(body.hr_attach_to_invoice, false)
    : clampBool(clientSettings?.hr_attach_to_invoice, false);

  let ts_attach_to_invoice = hasTsAttachToInvoice
    ? clampBool(body.ts_attach_to_invoice, false)
    : clampBool(clientSettings?.ts_attach_to_invoice, false);

  // Friendly validation mirroring DB constraints
  if (is_nhsp === true && autoprocess_hr === true) {
    return withCORS(env, req, badRequest('Invalid contract route: is_nhsp=true and autoprocess_hr=true cannot both be true.'));
  }
  if (no_timesheet_required === true && autoprocess_hr !== true) {
    return withCORS(env, req, badRequest('Invalid contract route: no_timesheet_required=true requires autoprocess_hr=true.'));
  }

  // ✅ Canonical attachment rules on create (safe)
  if (is_nhsp === true) {
    hr_attach_to_invoice = false;
    ts_attach_to_invoice = false;
  }
  if (autoprocess_hr !== true) {
    // Manual route: HR attach false, TS attach true
    hr_attach_to_invoice = false;
    ts_attach_to_invoice = true;
  }
  if (no_timesheet_required === true) {
    // HR no-timesheets: TS attach must be false
    ts_attach_to_invoice = false;
  }

  // Mileage: accept from body, or derive from client.mileage_charge_rate if both omitted
  const hasMileagePay    = Object.prototype.hasOwnProperty.call(body, 'mileage_pay_rate');
  const hasMileageCharge = Object.prototype.hasOwnProperty.call(body, 'mileage_charge_rate');

  let mileage_pay_rate = null;
  let mileage_charge_rate = null;

  if (hasMileagePay) {
    if (body.mileage_pay_rate === '' || body.mileage_pay_rate === null || body.mileage_pay_rate === undefined) {
      mileage_pay_rate = null;
    } else {
      const n = Number(body.mileage_pay_rate);
      if (!Number.isFinite(n) || n < 0) {
        return withCORS(env, req, badRequest('mileage_pay_rate must be a non-negative number if provided'));
      }
      mileage_pay_rate = n;
    }
  }

  if (hasMileageCharge) {
    if (body.mileage_charge_rate === '' || body.mileage_charge_rate === null || body.mileage_charge_rate === undefined) {
      mileage_charge_rate = null;
    } else {
      const n = Number(body.mileage_charge_rate);
      if (!Number.isFinite(n) || n < 0) {
        return withCORS(env, req, badRequest('mileage_charge_rate must be a non-negative number if provided'));
      }
      mileage_charge_rate = n;
    }
  }

  // If BOTH mileage fields omitted, derive defaults from client.mileage_charge_rate (if available)
  if (!hasMileagePay && !hasMileageCharge) {
    try {
      const { rows: cliRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=eq.${enc(body.client_id)}` +
          `&select=mileage_charge_rate&limit=1`
      );
      const cli = (cliRows && cliRows[0]) || null;
      if (cli && cli.mileage_charge_rate != null) {
        const charge = Number(cli.mileage_charge_rate);
        if (Number.isFinite(charge) && charge >= 0) {
          mileage_charge_rate = charge;
          const rawPay = charge - 0.10;
          const clamped = rawPay < 0 ? 0 : rawPay;
          mileage_pay_rate = Math.round(clamped * 100) / 100;
        }
      }
    } catch {
      // leave mileage_* as null if lookup fails
    }
  }

  // Normalise pay_method_snapshot and prune rate buckets appropriately
  const pmSnap = String(body.pay_method_snapshot || '').toUpperCase() === 'UMBRELLA' ? 'UMBRELLA' : 'PAYE';
  const rawRates = (body.rates_json && typeof body.rates_json === 'object') ? body.rates_json : {};
  const keepPrefixesCreate =
    pmSnap === 'PAYE'     ? ['paye_','charge_'] :
    pmSnap === 'UMBRELLA' ? ['umb_','charge_'] :
                            ['charge_'];
  const prunedRates = {};
  for (const [k, v] of Object.entries(rawRates)) {
    if (keepPrefixesCreate.some(pre => k.startsWith(pre))) {
      prunedRates[k] = v;
    }
  }

  // NEW: normalise additional_rates_json
  const additional_rates_json = normaliseAdditionalRates(body.additional_rates_json);

  // Insert contract
  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify({
      // 🔄 candidate_id can be null/unassigned
      candidate_id: (body.candidate_id === undefined ? null : body.candidate_id),
      client_id: body.client_id,
      role: body.role || null,
      band: body.band ?? null,
      display_site: body.display_site || null,
      ward_hint: body.ward_hint || null,
      start_date: body.start_date,
      end_date: body.end_date,

      // NEW: contract route / calc overrides
      is_nhsp,
      autoprocess_hr,
      requires_hr,
      no_timesheet_required,
      daily_calc_of_invoices,
      group_nightsat_sunbh,
      self_bill,

      // ✅ NEW: attachments
      hr_attach_to_invoice,
      ts_attach_to_invoice,

      pay_method_snapshot: pmSnap,
      rates_json: prunedRates,
      std_schedule_json,
      std_hours_json,
      bucket_labels_json: bucketLabels,
      additional_rates_json,                    // NEW
      default_submission_mode: defaultSubmissionMode,
      week_ending_weekday_snapshot: weekEndingSnapshot,
      auto_invoice,
      require_reference_to_pay: body.require_reference_to_pay,
      require_reference_to_invoice: body.require_reference_to_invoice,
      mileage_pay_rate,
      mileage_charge_rate,
      created_at: nowIso(),
      updated_at: nowIso()
    })
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const json = await res.json().catch(()=>[]);
  const row = Array.isArray(json) ? json[0] : json;

  // ── NEW: server-side safety net to generate weeks after create (non-fatal on failure)
  try {
    const shouldGenerate = !!row?.id && (!!row.std_schedule_json || !!row.std_hours_json);
    console.log('[CONTRACTS][CREATE] post-insert', {
      id: row?.id,
      start: row?.start_date,
      end: row?.end_date,
      hasTemplate: !!row?.std_schedule_json,
      hasHours: !!row?.std_hours_json,
      weekEnding: row?.week_ending_weekday_snapshot,
      willGenerateWeeks: shouldGenerate
    });

    if (shouldGenerate) {
      if (typeof handleContractsGenerateWeeks === 'function') {
        await handleContractsGenerateWeeks(env, req, row.id);
        console.log('[CONTRACTS][CREATE] generate-weeks via internal handler ok', { id: row.id });
      } else {
        console.log('[CONTRACTS][CREATE] no internal handler found; generation skipped (safe)');
      }
    } else {
      console.log('[CONTRACTS][CREATE] skipped generate-weeks (no template/hours on row)', { id: row?.id });
    }
  } catch (e) {
    console.warn('[CONTRACTS][CREATE] generate-weeks failed (non-fatal)', { id: row?.id, error: String(e?.message || e) });
  }

  return withCORS(env, req, ok(row));
}




// ──────────────────────────────────────────────────────────────────────────────
// BACKEND: handleContractsList (amended) — adds paging + extended filters
// ──────────────────────────────────────────────────────────────────────────────
// handleContractsList — enriched with candidate/client names and relationship-aware free-text filtering
// (joins based on FK: contracts.candidate_id → candidates.id, contracts.client_id → clients.id)  :contentReference[oaicite:0]{index=0}

 async function handleContractsList(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const url = new URL(req.url);
  const q  = (k) => url.searchParams.get(k);
  const qs = (k) => url.searchParams.getAll(k);
  const encQ = (v) => enc(v); // short alias

  // Sorting
  const orderByParam = (q('order_by') || '').toLowerCase();
  const orderDirParam = (q('order_dir') || '').toLowerCase();

  const sortMap = {
    // IMPORTANT: we cannot order the top-level resource by embedded values
    // candidate.display_name / client.name with PostgREST directly.
    // For now, approximate by candidate_id / client_id.
    candidate_display:             'candidate_id',
    client_name:                   'client_id',

    role:                          'role',
    band:                          'band',
    start_date:                    'start_date',
    end_date:                      'end_date',
    created_at:                    'created_at',
    updated_at:                    'updated_at',
    auto_invoice:                  'auto_invoice',
    display_site:                  'display_site',
    pay_method_snapshot:           'pay_method_snapshot',
    default_submission_mode:       'default_submission_mode',
    week_ending_weekday_snapshot:  'week_ending_weekday_snapshot',
    require_reference_to_pay:      'require_reference_to_pay',
    require_reference_to_invoice:  'require_reference_to_invoice',
    mileage_pay_rate:              'mileage_pay_rate',
    mileage_charge_rate:           'mileage_charge_rate'
  };

  const defaultSortCol = 'start_date';
  const orderCol = sortMap[orderByParam] || defaultSortCol;
  const orderDir = (orderDirParam === 'asc' || orderDirParam === 'desc') ? orderDirParam : 'desc';

  // SELECT with relationships (optionally includes an aggregate to avoid dupes when status=active via join fallback)
  let selectParts = [
    '*',
    'candidate:candidates(display_name,first_name,last_name)',
    'client:clients(name)'
  ];

  let api = `${env.SUPABASE_URL}/rest/v1/contracts?select=${selectParts.join(',')}`;

  const filters = [];

  // ── ID / IDs filters (used by Focus & selection presets) ────────────────────
  const idExpr = q('id');   // expects "in.(uuid,uuid,...)"
  const idsRaw = q('ids');  // optional "uuid1,uuid2,..."

  if (idExpr && /^in\.\(.+\)$/.test(idExpr.trim())) {
    // Forward the expression as-is: "id=in.(uuid1,uuid2,...)"
    filters.push(`id=${idExpr.trim()}`);
  } else if (idsRaw) {
    const ids = idsRaw.split(',').map(s => s.trim()).filter(Boolean);
    if (ids.length) {
      filters.push(`id=in.(${ids.map(encQ).join(',')})`);
    }
  }

  // ── Core filters ────────────────────────────────────────────────────────────
  if (q('candidate_id'))        filters.push(`candidate_id=eq.${encQ(q('candidate_id'))}`);
  if (q('client_id'))           filters.push(`client_id=eq.${encQ(q('client_id'))}`);
  if (q('pay_method_snapshot')) filters.push(`pay_method_snapshot=eq.${encQ(q('pay_method_snapshot').toUpperCase())}`);
  if (q('role')) {
    const like = `*${q('role')}*`;
    filters.push(`role=ilike.${encQ(like)}`);
  }
  if (q('band'))                filters.push(`band=eq.${encQ(q('band'))}`);

  // Name-only filters (separate from free-text q)
  if (q('candidate_name')) {
    const like = `*${q('candidate_name')}*`;
    filters.push(`candidate.display_name=ilike.${encQ(like)}`);
  }
  if (q('client_name')) {
    const like = `*${q('client_name')}*`;
    filters.push(`client.name=ilike.${encQ(like)}`);
  }

  if (q('active_on')) {
    const d = q('active_on');
    filters.push(`start_date=lte.${encQ(d)}`);
    filters.push(`end_date=gte.${encQ(d)}`);
  }

  if (q('auto_invoice')) {
    filters.push(`auto_invoice=eq.${encQ(String(clampBool(q('auto_invoice'))))}`);
  }

  // Free text across related names + role
  if (q('q')) {
    const like = `%${q('q')}%`;
    filters.push(
      `or=(client.name.ilike.${encQ(like)},` +
      `candidate.display_name.ilike.${encQ(like)},` +
      `candidate.first_name.ilike.${encQ(like)},` +
      `candidate.last_name.ilike.${encQ(like)},` +
      `role.ilike.${encQ(like)})`
    );
  }

  // default_submission_mode (accept alias submission_mode)
  const dsm = q('default_submission_mode') || q('submission_mode');
  if (dsm) filters.push(`default_submission_mode=eq.${encQ(dsm.toUpperCase())}`);

  // week_ending_weekday_snapshot
  if (q('week_ending_weekday_snapshot')) {
    filters.push(`week_ending_weekday_snapshot=eq.${encQ(q('week_ending_weekday_snapshot'))}`);
  }

  // require_reference_* gates
  if (q('require_reference_to_pay')) {
    filters.push(`require_reference_to_pay=eq.${encQ(String(clampBool(q('require_reference_to_pay'))))}`);
  }
  if (q('require_reference_to_invoice')) {
    filters.push(`require_reference_to_invoice=eq.${encQ(String(clampBool(q('require_reference_to_invoice'))))}`);
  }

  // has_custom_labels → bucket_labels_json null/not null
  if (q('has_custom_labels')) {
    const yes = clampBool(q('has_custom_labels'));
    filters.push(yes ? `bucket_labels_json=not.is.null` : `bucket_labels_json=is.null`);
  }

  // created_from / created_to
  if (q('created_from')) filters.push(`created_at=gte.${encQ(q('created_from'))}`);
  if (q('created_to'))   filters.push(`created_at=lte.${encQ(q('created_to'))}`);

  // updated_from / updated_to
  if (q('updated_from')) filters.push(`updated_at=gte.${encQ(q('updated_from'))}`);
  if (q('updated_to'))   filters.push(`updated_at=lte.${encQ(q('updated_to'))}`);

  // start_date_from / start_date_to
  if (q('start_date_from')) filters.push(`start_date=gte.${encQ(q('start_date_from'))}`);
  if (q('start_date_to'))   filters.push(`start_date=lte.${encQ(q('start_date_to'))}`);

  // end_date_from / end_date_to
  if (q('end_date_from')) filters.push(`end_date=gte.${encQ(q('end_date_from'))}`);
  if (q('end_date_to'))   filters.push(`end_date=lte.${encQ(q('end_date_to'))}`);

  // mileage filters
  if (q('mileage_pay_rate')) {
    filters.push(`mileage_pay_rate=eq.${encQ(q('mileage_pay_rate'))}`);
  }
  if (q('mileage_charge_rate')) {
    filters.push(`mileage_charge_rate=eq.${encQ(q('mileage_charge_rate'))}`);
  }

  // ── status=active|completed|unassigned ──────────────────────────────────────
  const statusParam = (q('status') || '').toLowerCase();
  const INCOMPLETE_STATUSES = ['OPEN','PLANNED','SUBMITTED','AUTHORISED'];

  if (statusParam === 'unassigned') {
    filters.push('candidate_id=is.null');
  } else if (statusParam === 'active' || statusParam === 'completed') {
    const fetchActiveContractIds = async () => {
      const limit = 1000;
      let offset = 0;
      const acc = new Set();
      while (true) {
        const cwApi =
          `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?select=contract_id` +
          `&status=in.(${INCOMPLETE_STATUSES.map(encQ).join(',')})` +
          `&contract_id=not.is.null` +
          `&limit=${limit}&offset=${offset}`;
        const { rows } = await sbFetch(env, cwApi);
        (rows || []).forEach(r => { if (r && r.contract_id) acc.add(r.contract_id); });
        if (!rows || rows.length < limit) break;
        offset += limit;
      }
      return Array.from(acc);
    };

    const activeIds = await fetchActiveContractIds();

    const safeJoinFallbackForActive = () => {
      // Use inner join filter to ensure we don't blow URL length.
      selectParts.push('cw_active:contract_weeks!inner(count)');
      const joined = `contract_weeks!inner.status=in.(${INCOMPLETE_STATUSES.map(encQ).join(',')})`;
      filters.push(joined);
    };

    if (statusParam === 'active') {
      if (activeIds.length === 0) {
        return withCORS(env, req, ok([]));
      } else if (activeIds.length <= 300) {
        filters.push(`id=in.(${activeIds.map(encQ).join(',')})`);
      } else {
        safeJoinFallbackForActive();
      }
    } else if (statusParam === 'completed') {
      if (activeIds.length > 0 && activeIds.length <= 300) {
        filters.push(`id=not.in.(${activeIds.map(encQ).join(',')})`);
      } else if (activeIds.length === 0) {
        // everyone qualifies as completed; no extra filter
      } else {
        // anti-join fallback: left join + is.null on alias that only links incomplete rows
        selectParts.push('cw_open:contract_weeks!left(count)');
        filters.push(`cw_open:contract_weeks!left.status=in.(${INCOMPLETE_STATUSES.map(encQ).join(',')})`);
        filters.push(`cw_open.id=is.null`);
      }
    }
  }

  // Rebuild api in case selectParts changed (aggregates)
  api = `${env.SUPABASE_URL}/rest/v1/contracts?select=${selectParts.join(',')}`;
  if (filters.length) api += `&${filters.join('&')}`;

  // Sorting: primary on requested column, secondary on created_at for stability
  api += `&order=${encQ(orderCol)}.${orderDir}`;
  if (orderCol !== 'created_at') {
    api += `&order=created_at.desc`;
  }

  // paging → limit/offset
  const page     = Math.max(parseInt(url.searchParams.get('page') || '1', 10) || 1, 1);
  const pageSizeRaw = url.searchParams.get('page_size');
  const pageSize = (pageSizeRaw === 'ALL') ? null :
                    Math.max(parseInt(pageSizeRaw || '50', 10) || 50, 1);

  if (pageSize != null) {
    const limit  = pageSize;
    const offset = (page - 1) * pageSize;
    api += `&limit=${encQ(limit)}&offset=${encQ(offset)}`;
  }

  let rows = [];
  try {
    ({ rows } = await sbFetch(env, api));
  } catch (err) {
    // Ensure we always respond with CORS, even on Supabase error
    console.error('[CONTRACTS] handleContractsList failed', err);
    return withCORS(env, req, ok({ error: String(err?.message || err), rows: [] }));
  }

  // Flatten related names into top-level fields (keep nested for back-compat)
  const out = (rows || []).map(r => {
    const candidateDisplay =
      r?.candidate?.display_name ||
      ([r?.candidate?.first_name, r?.candidate?.last_name].filter(Boolean).join(' ') || null);
    const clientName = r?.client?.name || null;

    const { cw_active, cw_open, ...rest } = (r || {});
    return {
      ...rest,
      candidate_display: candidateDisplay,
      client_name: clientName
    };
  });

  return withCORS(env, req, ok(out));
}

// BACKEND — handleUserGridPrefsGet
 async function handleUserGridPrefsGet(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const api =
    `${env.SUPABASE_URL}/rest/v1/tms_users` +
    `?id=eq.${enc(user.id)}&select=id,grid_prefs_json&limit=1`;
  const { rows } = await sbFetch(env, api);
  const row = (rows && rows[0]) || null;

  let prefs = (row && row.grid_prefs_json) || null;

  // If nothing stored yet, seed with backend defaults
  if (!prefs || typeof prefs !== 'object') {
    prefs = (typeof DEFAULT_GRID_PREFS === 'object')
      ? JSON.parse(JSON.stringify(DEFAULT_GRID_PREFS))
      : { grid: {} };
  } else {
    // Ensure we always have a .grid object
    if (!prefs.grid || typeof prefs.grid !== 'object') {
      prefs.grid = {};
    }

    // Merge in any new default sections/keys for existing users,
    // deep-merging nested labels/columns/meta so backend defaults always flow through.
    if (typeof DEFAULT_GRID_PREFS === 'object' && DEFAULT_GRID_PREFS.grid) {
      for (const [sec, defSecRaw] of Object.entries(DEFAULT_GRID_PREFS.grid)) {
        const defSec = defSecRaw || {};
        const existing = (prefs.grid[sec] && typeof prefs.grid[sec] === 'object')
          ? prefs.grid[sec]
          : {};

        // Start with backend defaults, then overlay existing section-level keys
        const mergedSection = {
          ...(defSec || {}),
          ...(existing || {})
        };

        // Deep-merge important nested objects: backend defaults + user overrides
        mergedSection.labels = {
          ...(defSec.labels || {}),
          ...(existing.labels || {})
        };

        mergedSection.columns = {
          ...(defSec.columns || {}),
          ...(existing.columns || {})
        };

        mergedSection.columns_meta = {
          ...(defSec.columns_meta || {}),
          ...(existing.columns_meta || {})
        };

        prefs.grid[sec] = mergedSection;
      }
    }
  }

  return withCORS(env, req, ok(prefs));
}


// BACKEND — handleUserGridPrefsPatch
// BACKEND — handleUserGridPrefsPatch
 async function handleUserGridPrefsPatch(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await req.json().catch(() => ({}));

  // Deep merge helper: merges b into a, with `null` meaning "delete"
  const deepMerge = (a, b) => {
    if (Array.isArray(a) && Array.isArray(b)) {
      return b.slice(); // replace arrays
    }
    if (a && typeof a === 'object' && b && typeof b === 'object') {
      const out = { ...a };
      for (const key of Object.keys(b)) {
        const val = b[key];
        if (val === undefined) continue;
        if (val === null) {
          // allow explicit delete
          delete out[key];
          continue;
        }
        out[key] = deepMerge(out[key], val);
      }
      return out;
    }
    return (b === undefined ? a : b);
  };

  const normalize = (existing, incoming) => {
    let result = existing;
    if (!result || typeof result !== 'object') {
      result = { grid: {} };
    }
    if (!result.grid || typeof result.grid !== 'object') {
      result.grid = {};
    }

    // Case 1: full grid object provided: { grid: { ... } }
    if (incoming && incoming.grid && typeof incoming.grid === 'object') {
      result.grid = deepMerge(result.grid, incoming.grid);
      return result;
    }

    // Case 2: section-scoped update: { section: 'contracts', prefs: { ... } } or { section, reset:true }
    if (incoming && typeof incoming.section === 'string') {
      const sec = incoming.section;
      result.grid = result.grid || {};

      // Hard reset for this section if requested
      if (incoming.reset === true) {
        if (typeof DEFAULT_GRID_PREFS === 'object' &&
            DEFAULT_GRID_PREFS.grid &&
            DEFAULT_GRID_PREFS.grid[sec]) {
          result.grid[sec] = JSON.parse(JSON.stringify(DEFAULT_GRID_PREFS.grid[sec]));
        } else {
          result.grid[sec] = {};
        }
        return result;
      }

      // Merge prefs into this section
      if (incoming.prefs && typeof incoming.prefs === 'object') {
        const prev = (result.grid[sec] && typeof result.grid[sec] === 'object')
          ? result.grid[sec]
          : {};
        result.grid[sec] = deepMerge(prev, incoming.prefs);
        return result;
      }
    }

    return result;
  };

  // Load current prefs
  const getApi =
    `${env.SUPABASE_URL}/rest/v1/tms_users` +
    `?id=eq.${enc(user.id)}&select=id,grid_prefs_json&limit=1`;
  const { rows: rows0 } = await sbFetch(env, getApi);
  const currentRaw = (rows0 && rows0[0] && rows0[0].grid_prefs_json) || null;

  let current;
  if (!currentRaw || typeof currentRaw !== 'object') {
    // Seed with backend defaults if nothing exists yet
    current = (typeof DEFAULT_GRID_PREFS === 'object')
      ? JSON.parse(JSON.stringify(DEFAULT_GRID_PREFS))
      : { grid: {} };
  } else {
    current = {
      ...currentRaw,
      grid: (currentRaw.grid && typeof currentRaw.grid === 'object')
        ? currentRaw.grid
        : {}
    };
  }

  const merged = normalize(current, body);

  // Persist updated prefs
  const patchApi = `${env.SUPABASE_URL}/rest/v1/tms_users?id=eq.${enc(user.id)}`;
  const { rows: rows1 } = await sbFetch(env, patchApi, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify({ grid_prefs_json: merged })
  });
  const saved = (rows1 && rows1[0] && rows1[0].grid_prefs_json) || merged;

  return withCORS(env, req, ok(saved));
}



// handleContractsGet — embed names and flatten convenience fields for FE
// (joins via FK: contracts.candidate_id → candidates.id, contracts.client_id → clients.id)  :contentReference[oaicite:1]{index=1}

// handleContractsGet — embed names and flatten convenience fields for FE
// (joins via FK: contracts.candidate_id → candidates.id, contracts.client_id → clients.id)

async function handleContractsGet(env, req, contractId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!contractId) return withCORS(env, req, badRequest('contract_id required'));

  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts` +
    `?id=eq.${enc(contractId)}` +
    `&select=*,candidate:candidates(display_name,first_name,last_name),client:clients(name)`
  );
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  const candidate_display =
    contract?.candidate?.display_name ||
    ([contract?.candidate?.first_name, contract?.candidate?.last_name].filter(Boolean).join(' ') || null);
  const client_name = contract?.client?.name || null;

  const { rows: weeks } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
    `?contract_id=eq.${enc(contractId)}` +
    `&select=id,week_ending_date,additional_seq,status,submission_mode_snapshot,timesheet_id,uploaded_pdf_r2_key` +
    `&order=week_ending_date.desc,additional_seq.asc`
  );
  const counts = (weeks || []).reduce((a, w) => {
    a[w.status] = (a[w.status] || 0) + 1;
    return a;
  }, {});

  // ── Deletion eligibility ─────────────────────────────
  // Keep this logic aligned with handleContractsDelete:
  // a contract is only deletable if NO timesheets exist at all for this contract.
  let hasTimesheets = false;
  try {
    const ts = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?contract_id=eq.${enc(contractId)}` +
      `&select=timesheet_id&limit=1`
    );
    hasTimesheets = !!ts;
  } catch (e) {
    // If we fail to check, be pessimistic and treat as non-deletable
    try { console.warn('[CONTRACTS][GET] timesheet existence check failed', { contractId, error: String(e?.message || e) }); } catch {}
    hasTimesheets = true;
  }

  const contractOut = {
    ...contract,
    candidate_display,
    client_name,
    // FE uses this to decide whether to show the "Delete contract" button
    can_delete: !hasTimesheets,
    has_timesheets: hasTimesheets
  };

  // ── Finance window (VAT/ERNI/etc) + server margin preview ─────────────────────────────
  const toLondonYmd = (dt) => {
    try {
      const d = (dt instanceof Date) ? dt : new Date(dt);
      if (!d || Number.isNaN(d.getTime())) return null;

      const parts = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).formatToParts(d);

      const y  = parts.find(p => p.type === 'year')?.value || '';
      const m  = parts.find(p => p.type === 'month')?.value || '';
      const dd = parts.find(p => p.type === 'day')?.value || '';
      if (!y || !m || !dd) return null;

      return `${y}-${m}-${dd}`;
    } catch {
      return null;
    }
  };

  const asYmd = (v) => {
    if (!v) return null;
    const s = String(v).trim();
    if (!s) return null;
    const ymd = s.slice(0, 10);
    return /^\d{4}-\d{2}-\d{2}$/.test(ymd) ? ymd : null;
  };

  const pctToMultiplier = (pctMaybe) => {
    let p = Number(pctMaybe);
    if (!Number.isFinite(p) || p <= 0) return 1;
    if (p > 1) p = p / 100; // support 15 vs 0.15
    const m = 1 + p;
    return (Number.isFinite(m) && m > 0) ? m : 1;
  };

  const toNum = (v) => {
    if (v === '' || v === null || v === undefined) return null;
    const n = Number(v);
    return Number.isFinite(n) ? n : null;
  };

  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  // Anchor rule (matches your FE helper):
  // - finished contract -> anchor = start_date
  // - ongoing           -> anchor = today (London)
  const todayYmd = toLondonYmd(new Date()) || null;
  const startYmd = asYmd(contractOut?.start_date);
  const endYmd   = asYmd(contractOut?.end_date);
  const finished = !!(endYmd && todayYmd && endYmd < todayYmd);
  const anchor_ymd  = (finished && startYmd) ? startYmd : (todayYmd || startYmd || null);
  const anchor_kind = (finished && startYmd) ? 'CONTRACT_START' : 'TODAY';

  let finance_window = null;
  try {
    const fwRows = await sbRpc(env, 'settings_finance_pick', { p_date: anchor_ymd || null });
    const fw = Array.isArray(fwRows) ? fwRows[0] : fwRows;
    finance_window = (fw && typeof fw === 'object') ? fw : null;
  } catch (e) {
    try { console.warn('[CONTRACTS][GET] settings_finance_pick failed', { contractId, anchor_ymd, err: String(e?.message || e) }); } catch {}
    finance_window = null;
  }

  const apply_erni_to = String(finance_window?.apply_erni_to || 'PAYE_ONLY').toUpperCase();
  const erni_pct      = (finance_window?.erni_pct ?? 0);
  const erni_multiplier = pctToMultiplier(erni_pct);

  const vat_rate_pct  = (finance_window?.vat_rate_pct ?? 0);
  const vat_multiplier = pctToMultiplier(vat_rate_pct);

  const pay_method_snapshot = String(contractOut?.pay_method_snapshot || 'PAYE').toUpperCase();

  const erni_applies =
    (apply_erni_to === 'ALL') ||
    (apply_erni_to === 'PAYE_ONLY' && pay_method_snapshot === 'PAYE');

  const payCost = (payEx) => (erni_applies ? round2(Number(payEx || 0) * erni_multiplier) : round2(Number(payEx || 0)));

  // Compute per-bucket margin preview from rates_json
  const R = (contractOut?.rates_json && typeof contractOut.rates_json === 'object') ? contractOut.rates_json : {};
  const buckets = ['day','night','sat','sun','bh'];

  const bucket_margins = {};
  for (const b of buckets) {
    const payRate =
      (pay_method_snapshot === 'PAYE')
        ? toNum(R[`paye_${b}`])
        : toNum(R[`umb_${b}`]);

    const chargeRate = toNum(R[`charge_${b}`]);

    if (payRate == null || chargeRate == null) {
      bucket_margins[b] = null;
      continue;
    }

    const payCostRate = (erni_applies ? (payRate * erni_multiplier) : payRate);
    bucket_margins[b] = round2(chargeRate - payCostRate);
  }

  // ✅ UPDATED: Mileage margin preview (per mile) with finance-window defaults fallback
  // Order:
  // 1) contract mileage_* if present
  // 2) finance_window mileage_*_defaults if present
  // (Further fallbacks like candidates/clients/presets are handled elsewhere in TSFIN; not added here.)
  const mileage_charge_rate_contract = toNum(contractOut?.mileage_charge_rate);
  const mileage_pay_rate_contract    = toNum(contractOut?.mileage_pay_rate);

  const mileage_charge_rate_default  = toNum(finance_window?.mileage_charge_defaults);
  const mileage_pay_rate_default     = toNum(finance_window?.mileage_pay_defaults);

  const eff_mileage_charge_rate =
    (mileage_charge_rate_contract == null) ? mileage_charge_rate_default : mileage_charge_rate_contract;

  const eff_mileage_pay_rate =
    (mileage_pay_rate_contract == null) ? mileage_pay_rate_default : mileage_pay_rate_contract;

  const mileage_rate_source =
    (mileage_charge_rate_contract != null || mileage_pay_rate_contract != null)
      ? 'CONTRACT'
      : (mileage_charge_rate_default != null || mileage_pay_rate_default != null)
        ? 'FINANCE_WINDOW_DEFAULT'
        : null;

  const mileage_margin_per_unit =
    (eff_mileage_charge_rate == null || eff_mileage_pay_rate == null)
      ? null
      : round2(eff_mileage_charge_rate - (erni_applies ? (eff_mileage_pay_rate * erni_multiplier) : eff_mileage_pay_rate));

  // Additional rates margin preview (per unit)
  let additional_rates_margin_preview = [];
  try {
    const arr = Array.isArray(contractOut?.additional_rates_json) ? contractOut.additional_rates_json : [];
    additional_rates_margin_preview = (arr || []).map(x => {
      const code = String(x?.code || '').toUpperCase();
      const pay_rate = toNum(x?.pay_rate);
      const charge_rate = toNum(x?.charge_rate);
      const margin_per_unit =
        (pay_rate == null || charge_rate == null)
          ? null
          : round2(charge_rate - (erni_applies ? (pay_rate * erni_multiplier) : pay_rate));
      return {
        code: code || null,
        bucket_name: x?.bucket_name ?? null,
        unit_name: x?.unit_name ?? null,
        frequency: x?.frequency ?? null,
        pay_rate: (pay_rate == null ? null : round2(pay_rate)),
        charge_rate: (charge_rate == null ? null : round2(charge_rate)),
        margin_per_unit
      };
    });
  } catch {
    additional_rates_margin_preview = [];
  }

  const finance = {
    anchor_ymd,
    anchor_kind,

    finance_window,

    vat_rate_pct: round2(vat_rate_pct),
    vat_multiplier,

    apply_erni_to,
    erni_pct: round2(erni_pct),
    erni_multiplier,
    erni_applies
  };

  const margins = {
    pay_method_snapshot,
    bucket_margins,

    // ✅ UPDATED: include effective mileage rates + source for FE transparency
    mileage_margin_per_unit,
    effective_mileage_pay_rate:   (eff_mileage_pay_rate == null ? null : round2(eff_mileage_pay_rate)),
    effective_mileage_charge_rate:(eff_mileage_charge_rate == null ? null : round2(eff_mileage_charge_rate)),
    mileage_rate_source,

    additional_rates_margin_preview
  };

  const warnings = await computePayMethodWarnings(env, contractOut);

  return withCORS(
    env,
    req,
    ok({
      contract: contractOut,
      counts,
      weeks: weeks || [],
      warnings,
      finance,
      margins
    })
  );
}

async function handleContractsFinanceGlobals(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const toLondonYmd = (dt) => {
    try {
      const d = (dt instanceof Date) ? dt : new Date(dt);
      if (!d || Number.isNaN(d.getTime())) return null;

      const parts = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).formatToParts(d);

      const y  = parts.find(p => p.type === 'year')?.value || '';
      const m  = parts.find(p => p.type === 'month')?.value || '';
      const dd = parts.find(p => p.type === 'day')?.value || '';
      if (!y || !m || !dd) return null;

      return `${y}-${m}-${dd}`;
    } catch {
      return null;
    }
  };

  const pctToMultiplier = (pctMaybe) => {
    let p = Number(pctMaybe);
    if (!Number.isFinite(p) || p <= 0) return 1;
    if (p > 1) p = p / 100; // support 15 vs 0.15
    const m = 1 + p;
    return (Number.isFinite(m) && m > 0) ? m : 1;
  };

  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  // For create: anchor is always TODAY (London)
  const anchor_ymd  = toLondonYmd(new Date()) || null;
  const anchor_kind = 'TODAY';

  let finance_window = null;
  try {
    const fwRows = await sbRpc(env, 'settings_finance_pick', { p_date: anchor_ymd || null });
    const fw = Array.isArray(fwRows) ? fwRows[0] : fwRows;
    finance_window = (fw && typeof fw === 'object') ? fw : null;
  } catch (e) {
    try { console.warn('[CONTRACTS][FINANCE_GLOBALS] settings_finance_pick failed', { anchor_ymd, err: String(e?.message || e) }); } catch {}
    finance_window = null;
  }

  const apply_erni_to = String(finance_window?.apply_erni_to || 'PAYE_ONLY').toUpperCase();
  const erni_pct      = (finance_window?.erni_pct ?? 0);
  const erni_multiplier = pctToMultiplier(erni_pct);

  const vat_rate_pct  = (finance_window?.vat_rate_pct ?? 0);
  const vat_multiplier = pctToMultiplier(vat_rate_pct);

  return withCORS(env, req, ok({
    finance: {
      anchor_ymd,
      anchor_kind,
      finance_window,
      vat_rate_pct: round2(vat_rate_pct),
      vat_multiplier,
      apply_erni_to,
      erni_pct: round2(erni_pct),
      erni_multiplier
    }
  }));
}

async function handleContractsUpdate(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  try { console.log('[CONTRACTS][UPDATE] incoming', { contractId, body }); } catch {}

  const current = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=*`
  );
  if (!current) return withCORS(env, req, notFound('Contract not found'));

  // "Real timesheets exist" = any row exists in timesheets for contract_id
  const hasSubmitted = !!(await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets?contract_id=eq.${enc(contractId)}&select=timesheet_id&limit=1`
  ));

  const hasWeeks = !!(await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(contractId)}&select=id&limit=1`
  ));

  const normaliseAdditionalRates = (raw) => {
    if (!raw) return null;
    const arr = Array.isArray(raw) ? raw : [];
    const out = [];
    const seen = new Set();
    const ALLOWED = new Set(['ONE_PER_WEEK','ONE_PER_DAY','WEEKENDS_AND_BH_ONLY','WEEKDAYS_EXCL_BH_ONLY']);

    const ensureCode = (code, idx) => {
      const c = String(code || '').toUpperCase();
      if (/^EX[1-5]$/.test(c)) return c;
      return `EX${idx + 1}`;
    };

    arr.slice(0, 5).forEach((row, idx) => {
      if (!row || typeof row !== 'object') return;
      const code = ensureCode(row.code, idx);
      if (seen.has(code)) return;
      seen.add(code);

      let bucketName = (row.bucket_name || '').trim();
      const unitName   = (row.unit_name != null && String(row.unit_name).trim())
        ? String(row.unit_name).trim()
        : null;

      let freq = String(row.frequency || 'ONE_PER_WEEK').toUpperCase();
      if (!ALLOWED.has(freq)) freq = 'ONE_PER_WEEK';

      let pay    = (row.pay_rate    !== undefined && row.pay_rate    !== null) ? Number(row.pay_rate)    : null;
      let charge = (row.charge_rate !== undefined && row.charge_rate !== null) ? Number(row.charge_rate) : null;
      if (pay != null && (!Number.isFinite(pay) || pay < 0)) pay = null;
      if (charge != null && (!Number.isFinite(charge) || charge < 0)) charge = null;

      const hasAny = bucketName || pay != null || charge != null || unitName;
      if (!hasAny) return;

      // ✅ Ensure bucket_name is never blank for a persisted row
      if (!bucketName) bucketName = code;

      out.push({
        code,
        bucket_name: bucketName,
        unit_name: unitName,
        frequency: freq,
        pay_rate: pay,
        charge_rate: charge
      });
    });

    return out.length ? out : null;
  };

  let schedulePatch = {};
  if ('std_schedule_json' in body) {
    try {
      const std_schedule_json = body.std_schedule_json || null;
      const std_hours_json = std_schedule_json ? deriveStdHoursFromSchedule(std_schedule_json) : null;
      schedulePatch.std_schedule_json = std_schedule_json;
      schedulePatch.std_hours_json = std_hours_json;
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid std_schedule_json'));
    }
  }
  if ('std_hours_json' in body && !('std_schedule_json' in body)) {
    const gh = body.std_hours_json;
    const days = ['mon','tue','wed','thu','fri','sat','sun'];
    if (gh !== null && !(gh && typeof gh === 'object' && days.every(d => d in gh && Number.isFinite(Number(gh[d])) && Number(gh[d])>=0))) {
      return withCORS(env, req, badRequest('std_hours_json must be null or numbers for mon..sun'));
    }
    schedulePatch.std_hours_json = gh;
  }

  const patch = { ...schedulePatch };
  const extraWarnings = [];

  const boolOrNull = (v, fallbackBool) => {
    if (v === null) return null;
    return clampBool(v, fallbackBool);
  };

  if ('display_site' in body) patch.display_site = (body.display_site ?? '').toString().trim();
  if ('ward_hint'    in body) patch.ward_hint    = (body.ward_hint ?? '').toString().trim();
  if ('default_submission_mode' in body) {
    const dsm = String(body.default_submission_mode||'').toUpperCase();
    // UPDATED: allow QR as well
    if (!['ELECTRONIC','MANUAL','QR'].includes(dsm)) {
      return withCORS(env, req, badRequest('default_submission_mode must be ELECTRONIC, MANUAL or QR'));
    }
    patch.default_submission_mode = dsm;
  }
  if ('bucket_labels_json' in body) {
    const obj = body.bucket_labels_json;
    const keys = ['day','night','sat','sun','bh'];
    if (obj === null) patch.bucket_labels_json = null;
    else if (obj && typeof obj === 'object' && keys.every(k => typeof obj[k] === 'string' && obj[k].trim()))
      patch.bucket_labels_json = Object.fromEntries(keys.map(k => [k, obj[k].trim()]));
    else return withCORS(env, req, badRequest('bucket_labels_json must include day|night|sat|sun|bh as non-empty strings or be null'));
  }
  if ('auto_invoice' in body)                 patch.auto_invoice = clampBool(body.auto_invoice, current.auto_invoice);
  if ('require_reference_to_pay' in body)     patch.require_reference_to_pay = clampBool(body.require_reference_to_pay, current.require_reference_to_pay);
  if ('require_reference_to_invoice' in body) patch.require_reference_to_invoice = clampBool(body.require_reference_to_invoice, current.require_reference_to_invoice);

  // NEW: contract-level route/calc/group/self-bill overrides
  if ('self_bill' in body)               patch.self_bill = boolOrNull(body.self_bill, !!current.self_bill);
  if ('is_nhsp' in body)                patch.is_nhsp = boolOrNull(body.is_nhsp, !!current.is_nhsp);
  if ('autoprocess_hr' in body)         patch.autoprocess_hr = boolOrNull(body.autoprocess_hr, !!current.autoprocess_hr);
  if ('requires_hr' in body)            patch.requires_hr = boolOrNull(body.requires_hr, !!current.requires_hr);
  if ('no_timesheet_required' in body)  patch.no_timesheet_required = boolOrNull(body.no_timesheet_required, !!current.no_timesheet_required);
  if ('daily_calc_of_invoices' in body) patch.daily_calc_of_invoices = boolOrNull(body.daily_calc_of_invoices, !!current.daily_calc_of_invoices);
  if ('group_nightsat_sunbh' in body)   patch.group_nightsat_sunbh = boolOrNull(body.group_nightsat_sunbh, !!current.group_nightsat_sunbh);

  // ✅ NEW: attachments (tri-state)
  if ('hr_attach_to_invoice' in body)   patch.hr_attach_to_invoice = boolOrNull(body.hr_attach_to_invoice, !!current.hr_attach_to_invoice);
  if ('ts_attach_to_invoice' in body)   patch.ts_attach_to_invoice = boolOrNull(body.ts_attach_to_invoice, !!current.ts_attach_to_invoice);

  // Friendly validation mirroring DB constraints (validate resulting state: current + patch)
  const eff_is_nhsp = Object.prototype.hasOwnProperty.call(patch, 'is_nhsp') ? patch.is_nhsp : current.is_nhsp;
  const eff_autoprocess_hr = Object.prototype.hasOwnProperty.call(patch, 'autoprocess_hr') ? patch.autoprocess_hr : current.autoprocess_hr;
  const eff_no_ts = Object.prototype.hasOwnProperty.call(patch, 'no_timesheet_required') ? patch.no_timesheet_required : current.no_timesheet_required;

  if (eff_is_nhsp === true && eff_autoprocess_hr === true) {
    return withCORS(env, req, badRequest('Invalid contract route: is_nhsp=true and autoprocess_hr=true cannot both be true.'));
  }
  if (eff_no_ts === true && eff_autoprocess_hr !== true) {
    return withCORS(env, req, badRequest('Invalid contract route: no_timesheet_required=true requires autoprocess_hr=true.'));
  }

  // ✅ Attachment rules (consistent with your settings model)
  const eff_hr_attach = Object.prototype.hasOwnProperty.call(patch, 'hr_attach_to_invoice') ? patch.hr_attach_to_invoice : current.hr_attach_to_invoice;
  const eff_ts_attach = Object.prototype.hasOwnProperty.call(patch, 'ts_attach_to_invoice') ? patch.ts_attach_to_invoice : current.ts_attach_to_invoice;

  if (eff_is_nhsp === true) {
    if (eff_hr_attach === true || eff_ts_attach === true) {
      return withCORS(env, req, badRequest('NHSP route: attachments must be disabled (hr_attach_to_invoice/ts_attach_to_invoice cannot be true).'));
    }
  }
  if (eff_no_ts === true) {
    if (eff_ts_attach === true) {
      return withCORS(env, req, badRequest('No-timesheets route: ts_attach_to_invoice cannot be true.'));
    }
  }

  if (hasSubmitted) {
    // Existing rules for immutable fields after submission
    if ('candidate_id' in body || 'client_id' in body || 'rates_json' in body || 'pay_method_snapshot' in body) {
      return withCORS(env, req, badRequest('Cannot change candidate/client/rates/pay_method after timesheets have been submitted'));
    }
    if ('mileage_pay_rate' in body || 'mileage_charge_rate' in body) {
      return withCORS(env, req, badRequest('Cannot change mileage rates after timesheets have been submitted'));
    }
    if ('additional_rates_json' in body) {
      return withCORS(env, req, badRequest('Cannot change additional rates after timesheets have been submitted'));
    }

    // ✅ NEW: contract settings immutability once real timesheets exist
    const changed = [];
    const curTri = (v) => (v === undefined ? null : v);

    const triKeys = [
      'is_nhsp',
      'autoprocess_hr',
      'requires_hr',
      'no_timesheet_required',
      'self_bill',
      'daily_calc_of_invoices',
      'group_nightsat_sunbh',
      'hr_attach_to_invoice',
      'ts_attach_to_invoice'
    ];

    for (const k of triKeys) {
      if (!Object.prototype.hasOwnProperty.call(body, k)) continue;
      const desired = patch[k];
      const cur = curTri(current[k]);
      if (desired !== cur) changed.push(k);
    }

    const boolKeys = [
      'auto_invoice',
      'require_reference_to_pay',
      'require_reference_to_invoice'
    ];

    for (const k of boolKeys) {
      if (!Object.prototype.hasOwnProperty.call(body, k)) continue;
      const desired = !!patch[k];
      const cur = !!current[k];
      if (desired !== cur) changed.push(k);
    }

    if (changed.length) {
      return withCORS(env, req, badRequest(
        `Cannot change contract settings because real timesheets already exist for this contract. Blocked fields: ${changed.join(', ')}`
      ));
    }

  } else {
    if ('candidate_id' in body) patch.candidate_id = body.candidate_id || null;
    if ('client_id'    in body) patch.client_id    = body.client_id || null;
    if ('rates_json'   in body) {
      const R = body.rates_json || {};
      const buckets = [
        'paye_day','paye_night','paye_sat','paye_sun','paye_bh',
        'umb_day','umb_night','umb_sat','umb_sun','umb_bh',
        'charge_day','charge_night','charge_sat','charge_sun','charge_bh'
      ];
      for (const k of buckets) {
        if (R[k] != null && (!Number.isFinite(Number(R[k])) || Number(R[k]) < 0)) {
          return withCORS(env, req, badRequest(`rates_json.${k} must be a non-negative number`));
        }
      }
      patch.rates_json = R;
    }
    if ('pay_method_snapshot' in body) {
      const pm = String(body.pay_method_snapshot||'').toUpperCase();
      if (!['PAYE','UMBRELLA'].includes(pm)) return withCORS(env, req, badRequest('pay_method_snapshot must be PAYE or UMBRELLA'));
      patch.pay_method_snapshot = pm;
    }
    if ('mileage_pay_rate' in body) {
      if (body.mileage_pay_rate === '' || body.mileage_pay_rate === null || body.mileage_pay_rate === undefined) {
        patch.mileage_pay_rate = null;
      } else {
        const n = Number(body.mileage_pay_rate);
        if (!Number.isFinite(n) || n < 0) {
          return withCORS(env, req, badRequest('mileage_pay_rate must be a non-negative number if provided'));
        }
        patch.mileage_pay_rate = n;
      }
    }
    if ('mileage_charge_rate' in body) {
      if (body.mileage_charge_rate === '' || body.mileage_charge_rate === null || body.mileage_charge_rate === undefined) {
        patch.mileage_charge_rate = null;
      } else {
        const n = Number(body.mileage_charge_rate);
        if (!Number.isFinite(n) || n < 0) {
          return withCORS(env, req, badRequest('mileage_charge_rate must be a non-negative number if provided'));
        }
        patch.mileage_charge_rate = n;
      }
    }
    // NEW: additional_rates_json can be edited while no submitted TS exist
    if ('additional_rates_json' in body) {
      patch.additional_rates_json = normaliseAdditionalRates(body.additional_rates_json);
    }
  }

  if ('week_ending_weekday_snapshot' in body) {
    if (hasSubmitted || hasWeeks) {
      extraWarnings.push('Week-ending day change ignored because weeks/timesheets exist.');
    } else {
      let we = Number(body.week_ending_weekday_snapshot);
      if (!Number.isInteger(we) || we < 0 || we > 6) {
        try {
          const targetClientId = ('client_id' in patch ? patch.client_id : current.client_id);
          const { rows: csRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/client_settings` +
              `?client_id=eq.${enc(targetClientId)}` +
              `&select=week_ending_weekday` +
              `&order=effective_from.desc,created_at.desc&limit=1`
          );
          const cs = (csRows && csRows[0]) || null;
          const derived = Number(cs?.week_ending_weekday);
          we = (Number.isInteger(derived) && derived >= 0 && derived <= 6) ? derived : 0;
        } catch { we = 0; }
      }
      patch.week_ending_weekday_snapshot = we;
    }
  } else {
    if (!hasSubmitted && !hasWeeks && ('client_id' in patch) && patch.client_id && patch.client_id !== current.client_id) {
      try {
        const { rows: csRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/client_settings` +
            `?client_id=eq.${enc(patch.client_id)}` +
            `&select=week_ending_weekday` +
            `&order=effective_from.desc,created_at.desc&limit=1`
        );
        const cs = (csRows && csRows[0]) || null;
        const derived = Number(cs?.week_ending_weekday);
        patch.week_ending_weekday_snapshot = (Number.isInteger(derived) && derived >= 0 && derived <= 6) ? derived : 0;
      } catch { patch.week_ending_weekday_snapshot = 0; }
    }
  }

  const newStart = ('start_date' in body) ? toYmd(body.start_date) : current.start_date;
  const newEnd   = ('end_date'   in body) ? toYmd(body.end_date)   : current.end_date;

  patch.start_date = newStart;
  patch.end_date   = newEnd;

  const windowChanged =
    (('start_date' in body) && toYmd(body.start_date) !== (current.start_date || '')) ||
    (('end_date'   in body) && toYmd(body.end_date)   !== (current.end_date   || ''));

  // Prune PAYE vs Umbrella buckets based on pay_method_snapshot
  const pmSnapUpdate = String((patch.pay_method_snapshot ?? current.pay_method_snapshot) || '').toUpperCase();
  if (patch.rates_json && pmSnapUpdate) {
    const keepPrefixesUpdate =
      pmSnapUpdate === 'PAYE'     ? ['paye_','charge_'] :
      pmSnapUpdate === 'UMBRELLA' ? ['umb_','charge_'] :
                                    ['charge_'];
    const cleaned = {};
    for (const [k, v] of Object.entries(patch.rates_json)) {
      if (keepPrefixesUpdate.some(pre => k.startsWith(pre))) {
        cleaned[k] = v;
      }
    }
    patch.rates_json = cleaned;
  }

  if (!Object.keys(patch).length) {
    const warnings0 = await computePayMethodWarnings(env, current);
    const warnings = Array.isArray(warnings0) ? [...warnings0, ...extraWarnings] : [...extraWarnings];
    return withCORS(env, req, ok({ contract: current, warnings }));
  }

  patch.updated_at = nowIso();

  try { console.log('[CONTRACTS][UPDATE] patch', { contractId, patch }); } catch {}

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), 'Prefer': 'return-representation' },
    body: JSON.stringify(patch)
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  let updated = (await res.json().catch(()=>[]))[0];

  if (windowChanged) {
    const del = await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(contractId)}&timesheet_id=is.null&or=(week_ending_date.lt.${enc(newStart)},week_ending_date.gt.${enc(newEnd)})`,
      { method:'DELETE', headers: { ...sbHeaders(env), 'Prefer':'return-minimal' } }
    );
    try { await del.arrayBuffer(); } catch {}
    if (!body.skip_generate_weeks) {
      try {
        await handleContractsGenerateWeeks(env, req, contractId);
      } catch (e) {
        try { console.warn('[CONTRACTS][UPDATE] regenerate weeks failed', { contractId, error: e?.message || String(e) }); } catch {}
      }
    }
  }

  let min_ts_date = null, max_ts_date = null;
  try {
    const { rows: tsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?contract_id=eq.${enc(contractId)}` +
      `&select=work_date,status`
    );
    const bad = new Set(['DRAFT','VOID','VOIDED','CANCELLED','CANCELED']);
    for (const r of (tsRows||[])) {
      const st = String(r?.status||'').toUpperCase();
      if (bad.has(st)) continue;
      const d = r?.work_date;
      if (!d) continue;
      if (!min_ts_date || d < min_ts_date) min_ts_date = d;
      if (!max_ts_date || d > max_ts_date) max_ts_date = d;
    }
  } catch {}

  let min_plan_date = null, max_plan_date = null;
  if (!min_ts_date && !max_ts_date) {
    try {
      const { rows: wkRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(contractId)}&select=planned_schedule_json`
      );
      for (const w of (wkRows||[])) {
        const arr = Array.isArray(w?.planned_schedule_json) ? w.planned_schedule_json : [];
        for (const d of arr.map(x=>x?.date).filter(Boolean)) {
          if (!min_plan_date || d < min_plan_date) min_plan_date = d;
          if (!max_plan_date || d > max_plan_date) max_plan_date = d;
        }
      }
    } catch {}
  }

  let normStart = updated?.start_date || newStart;
  let normEnd   = updated?.end_date   || newEnd;
  if (min_ts_date && max_ts_date) {
    normStart = min_ts_date;
    normEnd   = max_ts_date;
  } else if (min_plan_date && max_plan_date) {
    normStart = min_plan_date;
    normEnd   = max_plan_date;
  } else if (normStart) {
    normEnd = normStart;
  }

  if ((normStart && normStart !== updated.start_date) || (normEnd && normEnd !== updated.end_date)) {
    const normRes = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), 'Prefer': 'return-representation' },
      body: JSON.stringify({ start_date: normStart, end_date: normEnd, updated_at: nowIso() })
    });
    if (normRes.ok) updated = (await normRes.json().catch(()=>[]))[0] || updated;
  }

  const warnings0 = await computePayMethodWarnings(env, { ...current, ...updated });
  const warnings = Array.isArray(warnings0) ? [...warnings0, ...extraWarnings] : [...extraWarnings];
  return withCORS(env, req, ok({ contract: updated, warnings }));
}



// Lightweight checker for FE: returns real-timesheet boundary info for proposed window
 async function handleContractsCheckTimesheetBoundary(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const contract_id = body?.contract_id || body?.id || null;
  const startIsoRaw = body?.start_date || body?.start || null;
  const endIsoRaw   = body?.end_date   || body?.end   || null;
  if (!contract_id) return withCORS(env, req, badRequest('contract_id is required'));
  if (!startIsoRaw || !endIsoRaw) return withCORS(env, req, badRequest('start_date and end_date are required'));

  const start_date = toYmd(startIsoRaw);
  const end_date   = toYmd(endIsoRaw);
  if (!start_date || !end_date) return withCORS(env, req, badRequest('Invalid start_date or end_date'));
  if (start_date > end_date)    return withCORS(env, req, badRequest('start_date cannot be after end_date'));

  let tsRows = [];
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?contract_id=eq.${enc(contract_id)}` +
      `&select=id,timesheet_id,work_date,status,client_id`
    );
    tsRows = rows || [];
  } catch (e) {
    return withCORS(env, req, serverError('Boundary check failed to load timesheets'));
  }

  const badStatuses = new Set(['DRAFT','VOID','VOIDED','CANCELLED','CANCELED']);
  const realTs = (tsRows || []).filter(r => {
    const st = String(r?.status || '').toUpperCase();
    return !st || !badStatuses.has(st);
  });

  let min_ts_date = null, max_ts_date = null;
  for (const r of realTs) {
    const d = r?.work_date || null;
    if (!d) continue;
    if (!min_ts_date || d < min_ts_date) min_ts_date = d;
    if (!max_ts_date || d > max_ts_date) max_ts_date = d;
  }

  const violations = realTs.filter(r => {
    const d = r?.work_date;
    if (!d) return false;
    if (d < start_date) return true;
    if (d > end_date)   return true;
    return false;
  });

  let namesById = {};
  if (violations.length) {
    const clientIds = [...new Set(violations.map(v => v?.client_id).filter(Boolean))];
    if (clientIds.length) {
      try {
        const { rows: cRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/clients?id=in.(${clientIds.map(enc).join(',')})&select=id,name`
        );
        for (const c of (cRows||[])) namesById[String(c.id)] = c.name || null;
      } catch {}
    }
  }

  const payload = {
    ok: violations.length === 0,
    min_ts_date,
    max_ts_date,
    violations: violations.map(v => ({
      timesheet_id: v?.timesheet_id ?? v?.id ?? null,
      date: v?.work_date ?? null,
      status: v?.status ?? null,
      client_id: v?.client_id ?? null,
      client_name: namesById[String(v?.client_id)] || null
    }))
  };

  return withCORS(env, req, ok(payload));
}

// === NEW: strict full-replace handler (PUT /api/contracts/:id) ===
// === Strict full-replace (PUT) ===

// === Strict full-replace (PUT /api/contracts/:id) ===

async function handleContractsReplace(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  try { console.log('[CONTRACTS][REPLACE] incoming', { contractId, body }); } catch {}

  const current = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=*`
  );
  if (!current) return withCORS(env, req, notFound('Contract not found'));

  const hasSubmitted = !!(await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets?contract_id=eq.${enc(contractId)}&select=timesheet_id&limit=1`
  ));

  const hasWeeks = !!(await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(contractId)}&select=id&limit=1`
  ));

  const normaliseAdditionalRates = (raw) => {
    if (!raw) return null;
    const arr = Array.isArray(raw) ? raw : [];
    const out = [];
    const seen = new Set();
    const ALLOWED = new Set(['ONE_PER_WEEK','ONE_PER_DAY','WEEKENDS_AND_BH_ONLY','WEEKDAYS_EXCL_BH_ONLY']);

    const ensureCode = (code, idx) => {
      const c = String(code || '').toUpperCase();
      if (/^EX[1-5]$/.test(c)) return c;
      return `EX${idx + 1}`;
    };

    arr.slice(0, 5).forEach((row, idx) => {
      if (!row || typeof row !== 'object') return;
      const code = ensureCode(row.code, idx);
      if (seen.has(code)) return;
      seen.add(code);

      let bucketName = (row.bucket_name || '').trim();
      const unitName   = (row.unit_name != null && String(row.unit_name).trim())
        ? String(row.unit_name).trim()
        : null;

      let freq = String(row.frequency || 'ONE_PER_WEEK').toUpperCase();
      if (!ALLOWED.has(freq)) freq = 'ONE_PER_WEEK';

      let pay    = (row.pay_rate    !== undefined && row.pay_rate    !== null) ? Number(row.pay_rate)    : null;
      let charge = (row.charge_rate !== undefined && row.charge_rate !== null) ? Number(row.charge_rate) : null;
      if (pay != null && (!Number.isFinite(pay) || pay < 0)) pay = null;
      if (charge != null && (!Number.isFinite(charge) || charge < 0)) charge = null;

      const hasAny = bucketName || pay != null || charge != null || unitName;
      if (!hasAny) return;

      // ✅ Ensure bucket_name is never blank for a persisted row
      if (!bucketName) bucketName = code;

      out.push({
        code,
        bucket_name: bucketName,
        unit_name: unitName,
        frequency: freq,
        pay_rate: pay,
        charge_rate: charge
      });
    });

    // ✅ deterministic ordering for safe comparison
    out.sort((a, b) => String(a.code).localeCompare(String(b.code)));

    return out.length ? out : null;
  };

  // ✅ Normalise rates for “did they change?” checks (ignore irrelevant keysets/order)
  const normaliseRatesForCompare = (rawRates, payMethodSnapshot) => {
    const r = (rawRates && typeof rawRates === 'object') ? rawRates : {};
    const pm = String(payMethodSnapshot || '').toUpperCase();

    const keepPrefixes =
      pm === 'PAYE'     ? ['paye_','charge_'] :
      pm === 'UMBRELLA' ? ['umb_','charge_'] :
                          ['charge_'];

    const out = {};
    for (const [k, v] of Object.entries(r)) {
      if (!keepPrefixes.some(pre => k.startsWith(pre))) continue;
      if (v === '' || v === null || v === undefined) continue;
      const n = Number(v);
      if (!Number.isFinite(n)) continue;
      out[k] = n;
    }

    const sorted = {};
    Object.keys(out).sort().forEach(k => { sorted[k] = out[k]; });
    return sorted;
  };

  // 🔄 Relaxed: candidate_id no longer required in body (can be omitted/null)
  const requiredKeys = ['client_id','start_date','end_date','pay_method_snapshot','default_submission_mode','week_ending_weekday_snapshot','rates_json'];
  const missing = requiredKeys.filter(k => !(k in body));
  if (missing.length) return withCORS(env, req, badRequest(`Missing required fields: ${missing.join(', ')}`));

  let std_schedule_json = null, std_hours_json = null;
  if ('std_schedule_json' in body) {
    try {
      std_schedule_json = body.std_schedule_json || null;
      std_hours_json = std_schedule_json ? deriveStdHoursFromSchedule(std_schedule_json) : null;
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid std_schedule_json'));
    }
  } else if ('std_hours_json' in body) {
    std_hours_json = body.std_hours_json;
  } else {
    std_hours_json = current.std_hours_json ?? null;
  }

  const boolOrNull = (v, fallbackBool) => {
    if (v === null) return null;
    return clampBool(v, fallbackBool);
  };

  // Mileage: normalise and validate before immutability checks
  let nextMileagePay    = ('mileage_pay_rate'    in body) ? body.mileage_pay_rate    : current.mileage_pay_rate;
  let nextMileageCharge = ('mileage_charge_rate' in body) ? body.mileage_charge_rate : current.mileage_charge_rate;

  if ('mileage_pay_rate' in body) {
    if (body.mileage_pay_rate === '' || body.mileage_pay_rate === null || body.mileage_pay_rate === undefined) {
      nextMileagePay = null;
    } else {
      const n = Number(body.mileage_pay_rate);
      if (!Number.isFinite(n) || n < 0) {
        return withCORS(env, req, badRequest('mileage_pay_rate must be a non-negative number if provided'));
      }
      nextMileagePay = n;
    }
  }

  if ('mileage_charge_rate' in body) {
    if (body.mileage_charge_rate === '' || body.mileage_charge_rate === null || body.mileage_charge_rate === undefined) {
      nextMileageCharge = null;
    } else {
      const n = Number(body.mileage_charge_rate);
      if (!Number.isFinite(n) || n < 0) {
        return withCORS(env, req, badRequest('mileage_charge_rate must be a non-negative number if provided'));
      }
      nextMileageCharge = n;
    }
  }

  if (hasSubmitted) {
    // ✅ Treat omitted fields as “no change” (defensive)
    const effCandidateId = ('candidate_id' in body) ? body.candidate_id : current.candidate_id;
    const effClientId    = ('client_id'    in body) ? body.client_id    : current.client_id;

    if (effCandidateId !== current.candidate_id) return withCORS(env, req, badRequest('Cannot change candidate after timesheets have been submitted'));
    if (effClientId    !== current.client_id)    return withCORS(env, req, badRequest('Cannot change client after timesheets have been submitted'));

    // ✅ FIX: compare normalised rates (ignore irrelevant keys / ordering)
    const pmBody = String(body.pay_method_snapshot || current.pay_method_snapshot || '').toUpperCase();
    const pmCur  = String(current.pay_method_snapshot || '').toUpperCase();

    if (pmBody !== pmCur) {
      return withCORS(env, req, badRequest('Cannot change pay_method_snapshot after timesheets have been submitted'));
    }

    const curNorm = normaliseRatesForCompare(current.rates_json || {}, pmCur);
    const inNorm  = normaliseRatesForCompare(body.rates_json || {}, pmCur);

    if (JSON.stringify(inNorm) !== JSON.stringify(curNorm)) {
      return withCORS(env, req, badRequest('Cannot change rates after timesheets have been submitted'));
    }

    if (nextMileagePay !== current.mileage_pay_rate || nextMileageCharge !== current.mileage_charge_rate) {
      return withCORS(env, req, badRequest('Cannot change mileage rates after timesheets have been submitted'));
    }

    // ✅ FIX: allow sending additional_rates_json if it’s unchanged; block only if it differs
    if ('additional_rates_json' in body) {
      const curA = normaliseAdditionalRates(current.additional_rates_json);
      const inA  = normaliseAdditionalRates(body.additional_rates_json);
      if (JSON.stringify(inA || null) !== JSON.stringify(curA || null)) {
        return withCORS(env, req, badRequest('Cannot change additional rates after timesheets have been submitted'));
      }
    }
  }

  const dsm = String(body.default_submission_mode||'').toUpperCase();
  // ✅ Align with create/update: allow QR as well
  if (!['ELECTRONIC','MANUAL','QR'].includes(dsm)) {
    return withCORS(env, req, badRequest('default_submission_mode must be ELECTRONIC, MANUAL or QR'));
  }

  const extraWarnings = [];
  let wew;

  if (hasSubmitted || hasWeeks) {
    wew = Number(current.week_ending_weekday_snapshot ?? 0);
    if ('week_ending_weekday_snapshot' in body && Number(body.week_ending_weekday_snapshot) !== wew) {
      extraWarnings.push('Week-ending day change ignored because weeks/timesheets exist.');
    }
  } else {
    if ('week_ending_weekday_snapshot' in body) {
      const cand = Number(body.week_ending_weekday_snapshot);
      if (Number.isInteger(cand) && cand >= 0 && cand <= 6) {
        wew = cand;
      } else {
        try {
          const targetClientId = body.client_id || current.client_id;
          const { rows: csRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/client_settings` +
              `?client_id=eq.${enc(targetClientId)}` +
              `&select=week_ending_weekday` +
              `&order=effective_from.desc,created_at.desc&limit=1`
          );
          const cs = (csRows && csRows[0]) || null;
          const derived = Number(cs?.week_ending_weekday);
          wew = (Number.isInteger(derived) && derived >= 0 && derived <= 6) ? derived : 0;
        } catch { wew = 0; }
      }
    } else if (body.client_id && body.client_id !== current.client_id) {
      try {
        const { rows: csRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/client_settings` +
            `?client_id=eq.${enc(body.client_id)}` +
            `&select=week_ending_weekday` +
            `&order=effective_from.desc,created_at.desc&limit=1`
        );
        const cs = (csRows && csRows[0]) || null;
        const derived = Number(cs?.week_ending_weekday);
        wew = (Number.isInteger(derived) && derived >= 0 && derived <= 6) ? derived : 0;
      } catch { wew = 0; }
    } else {
      wew = Number(current.week_ending_weekday_snapshot ?? 0);
    }
  }

  const newStart = toYmd(body.start_date), newEnd = toYmd(body.end_date);
  let minWE = null, maxWE = null;
  try {
    const { rows: minRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(contractId)}&timesheet_id=not.is.null&select=week_ending_date` +
      `&order=week_ending_date.asc&limit=1`
    );
    minWE = (minRows && minRows[0] && minRows[0].week_ending_date) || null;

    const { rows: maxRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(contractId)}&timesheet_id=not.is.null&select=week_ending_date` +
      `&order=week_ending_date.desc&limit=1`
    );
    maxWE = (maxRows && maxRows[0] && maxRows[0].week_ending_date) || null;
  } catch {}

  if (minWE) {
    const minWeekStart = addDays(minWE, -6);
    if (newStart > minWeekStart) {
      return withCORS(env, req, badRequest(`start_date cannot be after start of earliest submitted week (${minWeekStart})`));
    }
  }
  if (maxWE && newEnd < maxWE) {
    return withCORS(env, req, badRequest(`end_date cannot be before latest submitted week ending (${maxWE})`));
  }

  const patch = {
    candidate_id: ('candidate_id' in body ? body.candidate_id : current.candidate_id),
    client_id:    body.client_id,
    role:         body.role ?? current.role,
    band:         body.band ?? current.band,
    display_site: (body.display_site ?? current.display_site ?? '').toString().trim(),
    ward_hint:    (body.ward_hint ?? current.ward_hint ?? '').toString().trim(),
    start_date:   newStart,
    end_date:     newEnd,

    is_nhsp:               ('is_nhsp' in body)               ? boolOrNull(body.is_nhsp, !!current.is_nhsp) : (current.is_nhsp ?? null),
    autoprocess_hr:        ('autoprocess_hr' in body)        ? boolOrNull(body.autoprocess_hr, !!current.autoprocess_hr) : (current.autoprocess_hr ?? null),
    requires_hr:           ('requires_hr' in body)           ? boolOrNull(body.requires_hr, !!current.requires_hr) : (current.requires_hr ?? null),
    no_timesheet_required: ('no_timesheet_required' in body) ? boolOrNull(body.no_timesheet_required, !!current.no_timesheet_required) : (current.no_timesheet_required ?? null),
    daily_calc_of_invoices:('daily_calc_of_invoices' in body)? boolOrNull(body.daily_calc_of_invoices, !!current.daily_calc_of_invoices) : (current.daily_calc_of_invoices ?? null),
    group_nightsat_sunbh:  ('group_nightsat_sunbh' in body)  ? boolOrNull(body.group_nightsat_sunbh, !!current.group_nightsat_sunbh) : (current.group_nightsat_sunbh ?? null),
    self_bill:             ('self_bill' in body)             ? boolOrNull(body.self_bill, !!current.self_bill) : (current.self_bill ?? null),

    // ✅ NEW: attachments (tri-state)
    hr_attach_to_invoice:  ('hr_attach_to_invoice' in body)  ? boolOrNull(body.hr_attach_to_invoice, !!current.hr_attach_to_invoice) : (current.hr_attach_to_invoice ?? null),
    ts_attach_to_invoice:  ('ts_attach_to_invoice' in body)  ? boolOrNull(body.ts_attach_to_invoice, !!current.ts_attach_to_invoice) : (current.ts_attach_to_invoice ?? null),

    pay_method_snapshot: String(body.pay_method_snapshot||current.pay_method_snapshot).toUpperCase(),
    default_submission_mode: dsm,
    week_ending_weekday_snapshot: wew,
    rates_json: body.rates_json || current.rates_json || {},
    std_schedule_json,
    std_hours_json,
    bucket_labels_json: ('bucket_labels_json' in body) ? (body.bucket_labels_json || null) : (current.bucket_labels_json || null),

    // ✅ Avoid accidental changes when keys omitted
    auto_invoice: ('auto_invoice' in body) ? clampBool(body.auto_invoice, current.auto_invoice) : current.auto_invoice,
    require_reference_to_pay: ('require_reference_to_pay' in body) ? clampBool(body.require_reference_to_pay, current.require_reference_to_pay) : current.require_reference_to_pay,
    require_reference_to_invoice: ('require_reference_to_invoice' in body) ? clampBool(body.require_reference_to_invoice, current.require_reference_to_invoice) : current.require_reference_to_invoice,

    mileage_pay_rate: nextMileagePay,
    mileage_charge_rate: nextMileageCharge,
    updated_at: nowIso(),
    additional_rates_json: ('additional_rates_json' in body)
      ? normaliseAdditionalRates(body.additional_rates_json)
      : (current.additional_rates_json || null)
  };

  // Friendly validation mirroring DB constraints
  if (patch.is_nhsp === true && patch.autoprocess_hr === true) {
    return withCORS(env, req, badRequest('Invalid contract route: is_nhsp=true and autoprocess_hr=true cannot both be true.'));
  }
  if (patch.no_timesheet_required === true && patch.autoprocess_hr !== true) {
    return withCORS(env, req, badRequest('Invalid contract route: no_timesheet_required=true requires autoprocess_hr=true.'));
  }

  // ✅ Attachment constraints aligned with route semantics
  if (patch.is_nhsp === true) {
    if (patch.hr_attach_to_invoice === true || patch.ts_attach_to_invoice === true) {
      return withCORS(env, req, badRequest('NHSP route: attachments must be disabled (hr_attach_to_invoice/ts_attach_to_invoice cannot be true).'));
    }
  }
  if (patch.no_timesheet_required === true) {
    if (patch.ts_attach_to_invoice === true) {
      return withCORS(env, req, badRequest('No-timesheets route: ts_attach_to_invoice cannot be true.'));
    }
  }

  // ✅ NEW: settings immutability on replace if real timesheets exist
  if (hasSubmitted) {
    const changed = [];
    const curTri = (v) => (v === undefined ? null : v);

    const triKeys = [
      'is_nhsp',
      'autoprocess_hr',
      'requires_hr',
      'no_timesheet_required',
      'self_bill',
      'daily_calc_of_invoices',
      'group_nightsat_sunbh',
      'hr_attach_to_invoice',
      'ts_attach_to_invoice'
    ];

    for (const k of triKeys) {
      const desired = patch[k];
      const cur = curTri(current[k]);
      if (desired !== cur) changed.push(k);
    }

    const boolKeys = [
      'auto_invoice',
      'require_reference_to_pay',
      'require_reference_to_invoice'
    ];

    for (const k of boolKeys) {
      const desired = !!patch[k];
      const cur = !!current[k];
      if (desired !== cur) changed.push(k);
    }

    if (changed.length) {
      return withCORS(env, req, badRequest(
        `Cannot change contract settings because real timesheets already exist for this contract. Blocked fields: ${changed.join(', ')}`
      ));
    }
  }

  // Prune PAYE vs Umbrella buckets according to pay_method_snapshot
  const pmSnapReplace = String(patch.pay_method_snapshot || '').toUpperCase();
  if (patch.rates_json && pmSnapReplace) {
    const keepPrefixesReplace =
      pmSnapReplace === 'PAYE'     ? ['paye_','charge_'] :
      pmSnapReplace === 'UMBRELLA' ? ['umb_','charge_'] :
                                     ['charge_'];
    const cleaned = {};
    for (const [k, v] of Object.entries(patch.rates_json)) {
      if (keepPrefixesReplace.some(pre => k.startsWith(pre))) {
        cleaned[k] = v;
      }
    }
    patch.rates_json = cleaned;
  }

  // ✅ FIX: if submitted, never write rates/additional rates back (even if equivalent)
  if (hasSubmitted) {
    patch.candidate_id = current.candidate_id;
    patch.client_id    = current.client_id;
    patch.pay_method_snapshot = String(current.pay_method_snapshot || patch.pay_method_snapshot || '').toUpperCase();
    patch.rates_json = (current.rates_json && typeof current.rates_json === 'object') ? current.rates_json : (current.rates_json || {});
    patch.additional_rates_json = current.additional_rates_json || null;
  }

  try { console.log('[CONTRACTS][REPLACE] patch', { contractId, patch }); } catch {}

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(patch)
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  let updated = (await res.json().catch(()=>[]))[0];

  const windowChanged =
    (('start_date' in body) && toYmd(body.start_date) !== (current.start_date || '')) ||
    (('end_date'   in body) && toYmd(body.end_date)   !== (current.end_date   || ''));

  const weekdayChanged =
    (('week_ending_weekday_snapshot' in body) &&
     Number(body.week_ending_weekday_snapshot) !== Number(current.week_ending_weekday_snapshot ?? body.week_ending_weekday_snapshot));

  if (windowChanged) {
    const del = await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(contractId)}&timesheet_id=is.null&or=(week_ending_date.lt.${enc(newStart)},week_ending_date.gt.${enc(newEnd)})`,
      { method:'DELETE', headers: { ...sbHeaders(env), 'Prefer':'return-minimal' } }
    );
    try { await del.arrayBuffer(); } catch {}
  }

  if ((windowChanged || weekdayChanged) && !hasSubmitted && !body.skip_generate_weeks) {
    try {
      await handleContractsGenerateWeeks(env, req, contractId);
    } catch (e) {
      try { console.warn('[CONTRACTS][REPLACE] regenerate weeks failed', { contractId, error: e?.message || String(e) }); } catch {}
    }
  }

  let min_ts_date = null, max_ts_date = null;
  try {
    const { rows: tsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?contract_id=eq.${enc(contractId)}` +
      `&select=work_date,status`
    );
    const bad = new Set(['DRAFT','VOID','VOIDED','CANCELLED','CANCELED']);
    for (const r of (tsRows||[])) {
      const st = String(r?.status||'').toUpperCase();
      if (bad.has(st)) continue;
      const d = r?.work_date;
      if (!d) continue;
      if (!min_ts_date || d < min_ts_date) min_ts_date = d;
      if (!max_ts_date || d > max_ts_date) max_ts_date = d;
    }
  } catch {}

  let min_plan_date = null, max_plan_date = null;
  if (!min_ts_date && !max_ts_date) {
    try {
      const { rows: wkRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(contractId)}&select=planned_schedule_json`
      );
      for (const w of (wkRows||[])) {
        const raw = w?.planned_schedule_json;
        const arr = Array.isArray(raw) ? raw : (typeof raw === 'string' ? JSON.parse(raw) : []);
        for (const d of arr.map(x=>x?.date).filter(Boolean)) {
          if (!min_plan_date || d < min_plan_date) min_plan_date = d;
          if (!max_plan_date || d > max_plan_date) max_plan_date = d;
        }
      }
    } catch {}
  }

  let normStart = updated?.start_date || newStart;
  let normEnd   = updated?.end_date   || newEnd;
  if (min_ts_date && max_ts_date) {
    normStart = min_ts_date;
    normEnd   = max_ts_date;
  } else if (min_plan_date && max_plan_date) {
    normStart = min_plan_date;
    normEnd   = max_plan_date;
  } else if (normStart) {
    normEnd = normStart;
  }

  if ((normStart && normStart !== updated.start_date) || (normEnd && normEnd !== updated.end_date)) {
    const normRes = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
      body: JSON.stringify({ start_date: normStart, end_date: normEnd, updated_at: nowIso() })
    });
    if (normRes.ok) updated = (await normRes.json().catch(()=>[]))[0] || updated;
  }

  const warnings0 = await computePayMethodWarnings(env, { ...current, ...updated });
  const warnings = Array.isArray(warnings0) ? [...warnings0, ...extraWarnings] : [...extraWarnings];
  return withCORS(env, req, ok({ contract: updated, warnings }));
}

async function handleContractsDuplicate(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const rawCount = body?.count;
  const count = Number(rawCount);
  if (!Number.isInteger(count) || count < 1 || count > 10) {
    return withCORS(env, req, badRequest('count must be an integer between 1 and 10'));
  }

  // Load source contract
  const src = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=*`
  );
  if (!src) return withCORS(env, req, notFound('Source contract not found'));

  try {
    console.log('[CONTRACTS][DUPLICATE] source', {
      id: src.id,
      candidate_id: src.candidate_id,
      client_id: src.client_id,
      start_date: src.start_date,
      end_date: src.end_date
    });
  } catch {}

  const duplicates = [];

  // Preserve nullable flags exactly as stored (null remains null)
  const copyBoolOrNull = (v) => (v === null || v === undefined) ? null : !!v;

  for (let i = 0; i < count; i++) {
    const payload = {
      // 🔑 Explicitly unassigned
      candidate_id: null,
      client_id: src.client_id,

      role: src.role || null,
      band: src.band ?? null,
      display_site: src.display_site || null,
      ward_hint: src.ward_hint || null,

      start_date: src.start_date,
      end_date: src.end_date,

      pay_method_snapshot: String(src.pay_method_snapshot || 'PAYE').toUpperCase() === 'PAYE' ? 'PAYE' : 'UMBRELLA',
      rates_json: src.rates_json || {},

      std_schedule_json: src.std_schedule_json || null,
      std_hours_json: src.std_hours_json || null,
      bucket_labels_json: src.bucket_labels_json || null,
      additional_rates_json: src.additional_rates_json || null,

      // Allow NULL (do not force fallback)
      default_submission_mode: (src.default_submission_mode == null) ? null : String(src.default_submission_mode).toUpperCase(),
      week_ending_weekday_snapshot: Number(src.week_ending_weekday_snapshot ?? 0),

      // Existing core flags
      auto_invoice: !!src.auto_invoice,
      require_reference_to_pay: !!src.require_reference_to_pay,
      require_reference_to_invoice: !!src.require_reference_to_invoice,
      self_bill: !!src.self_bill,

      // Preserve weekly source (if used)
      weekly_timesheet_source: (src.weekly_timesheet_source == null) ? null : src.weekly_timesheet_source,

      // NEW: contract override flag + governed nullable booleans
      overrideclientsettings: !!src.overrideclientsettings,

      is_nhsp: copyBoolOrNull(src.is_nhsp),
      autoprocess_hr: copyBoolOrNull(src.autoprocess_hr),
      requires_hr: copyBoolOrNull(src.requires_hr),
      no_timesheet_required: copyBoolOrNull(src.no_timesheet_required),
      daily_calc_of_invoices: copyBoolOrNull(src.daily_calc_of_invoices),
      group_nightsat_sunbh: copyBoolOrNull(src.group_nightsat_sunbh),
      hr_attach_to_invoice: copyBoolOrNull(src.hr_attach_to_invoice),
      ts_attach_to_invoice: copyBoolOrNull(src.ts_attach_to_invoice),

      // NEW: reference and email routing fields (contract-level)
      reference_number_required_to_issue_invoice: copyBoolOrNull(src.reference_number_required_to_issue_invoice),
      send_manual_invoices_to_different_email: copyBoolOrNull(src.send_manual_invoices_to_different_email),
      manual_invoices_alt_email_address: (src.manual_invoices_alt_email_address == null) ? null : String(src.manual_invoices_alt_email_address),

      mileage_pay_rate: src.mileage_pay_rate != null ? Number(src.mileage_pay_rate) : null,
      mileage_charge_rate: src.mileage_charge_rate != null ? Number(src.mileage_charge_rate) : null,

      created_at: nowIso(),
      updated_at: nowIso()
    };

    const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts`, {
      method: 'POST',
      headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
      body: JSON.stringify(payload)
    });
    if (!ins.ok) {
      const txt = await ins.text().catch(()=> '');
      return withCORS(env, req, serverError(`Failed to duplicate contract: ${txt || ins.status}`));
    }
    const j = await ins.json().catch(()=>[]);
    const row = Array.isArray(j) ? j[0] : j;
    if (!row || !row.id) {
      return withCORS(env, req, serverError('Failed to duplicate contract (no row returned)'));
    }

    // Generate weeks for the duplicate (non-fatal if it fails)
    try {
      const shouldGenerate = !!row.std_schedule_json || !!row.std_hours_json;
      if (shouldGenerate && typeof handleContractsGenerateWeeks === 'function') {
        await handleContractsGenerateWeeks(env, req, row.id);
        console.log('[CONTRACTS][DUPLICATE] generate-weeks ok', { id: row.id });
      } else if (shouldGenerate) {
        console.log('[CONTRACTS][DUPLICATE] no internal generate-weeks handler; skipped', { id: row.id });
      }
    } catch (e) {
      console.warn('[CONTRACTS][DUPLICATE] generate-weeks failed (non-fatal)', {
        id: row.id,
        error: String(e?.message || e)
      });
    }

    duplicates.push({
      id: row.id,
      candidate_id: row.candidate_id,
      client_id: row.client_id,
      start_date: row.start_date,
      end_date: row.end_date
    });
  }

  try {
    console.log('[CONTRACTS][DUPLICATE] done', {
      source_id: src.id,
      count,
      duplicates: duplicates.map(d => d.id)
    });
  } catch {}

  return withCORS(env, req, ok({
    source_contract_id: src.id,
    count,
    duplicates
  }));
}

 

// Helper: returns ['PAY_METHOD_MISMATCH'] if candidate.pay_method != pay_method_snapshot
async function computePayMethodWarnings(env, contractRow) {
  const out = [];
  const pmSnap = String(contractRow?.pay_method_snapshot || '').toUpperCase();
  const candId = contractRow?.candidate_id;
  const contractId = contractRow?.id;

  if (!pmSnap || !candId || !contractId) return out;

  // Candidate pay method
  const cand = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/candidates` +
      `?id=eq.${enc(candId)}` +
      `&select=id,pay_method`
  );
  const pmCand = String(cand?.pay_method || '').toUpperCase();

  if (!pmCand || pmCand === pmSnap) return out;

  // Check for "eligible" timesheets (processed/authorised/invoiced etc.)
  let hasEligibleTs = false;
  try {
    const bad = new Set(['DRAFT','VOID','VOIDED','CANCELLED','CANCELED']);
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?contract_id=eq.${enc(contractId)}` +
        `&select=status&limit=1000`
    );
    for (const r of (rows || [])) {
      const st = String(r?.status || '').toUpperCase();
      if (!bad.has(st)) {
        hasEligibleTs = true;
        break;
      }
    }
  } catch {
    // If we fail to check, we leave hasEligibleTs=false (safer message)
  }

  if (hasEligibleTs) {
    out.push(
      'Candidate pay method does not match this contract’s pay method. This contract already has processed/authorised/invoiced timesheets. ' +
      'You must end this contract and create a new one using the correct pay method.'
    );
  } else {
    out.push(
      'Candidate pay method does not match this contract’s pay method. Update the candidate pay method and contract pay rates so they align before using this contract.'
    );
  }

  return out;
}

 async function handleContractsDelete(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  // Safety: only if no TS ever existed
  const ts = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/timesheets?contract_id=eq.${enc(contractId)}&select=timesheet_id&limit=1`);
  if (ts) return withCORS(env, req, badRequest('Cannot delete: timesheets exist for this contract'));

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`, {
    method: 'DELETE',
    headers: { ...sbHeaders(env), 'Prefer': 'return=minimal' },
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  return withCORS(env, req, ok({ deleted: true }));
}
 async function handleContractsGenerateWeeks(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const c = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=*`
  );
  if (!c) return withCORS(env, req, notFound('Contract not found'));

  const wew = Number(c.week_ending_weekday_snapshot || 0);
  const endWE = computeWeekEndingInclusive(c.end_date, wew);
  const allWE = enumerateWeekEndings(c.start_date, endWE, wew);
  const todayYmd = toYmd(new Date());

  let existing = [];
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(contractId)}` +
      `&additional_seq=eq.0` +
      `&select=week_ending_date,additional_seq`
    );
    existing = rows || [];
  } catch (_) {
    existing = [];
  }
  const existingSet = new Set((existing || []).map(r => r.week_ending_date));

  const missingWE = allWE.filter(we => !existingSet.has(we));
  if (!missingWE.length) {
    return withCORS(env, req, ok({ generated: 0 }));
  }

  const rowsToInsert = missingWE.map(we => {
    let planned_schedule_json = null;
    try {
      const raw = buildPlannedScheduleFromTemplate(c.std_schedule_json || null, we);
      planned_schedule_json = clampPlannedToWindow(raw, we, wew, c.start_date, endWE, c.end_date);
      if (planned_schedule_json && !Object.keys(planned_schedule_json).length) planned_schedule_json = null;
    } catch {}
    return {
      contract_id: c.id,
      week_ending_date: we,
      additional_seq: 0,
      status: (we <= todayYmd ? 'OPEN' : 'PLANNED'),
      submission_mode_snapshot: c.default_submission_mode,
      timesheet_id: null,
      planned_schedule_json,
      created_at: nowIso(),
      updated_at: nowIso(),
    };
  });

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(rowsToInsert),
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const inserted = await res.json().catch(() => []);

  return withCORS(env, req, ok({ generated: inserted.length }));
}

function computeWeekEndingInclusive(ymd, wew) {
  const d = new Date(ymd + 'T00:00:00Z');   // ymd → Date (UTC)
  const dow = d.getUTCDay();                // 0..6 (Sun..Sat)
  const delta = (wew - dow + 7) % 7;        // inclusive: 0 if already on week end
  d.setUTCDate(d.getUTCDate() + delta);
  return toYmd(d);                           // existing helper
}
function clampPlannedToWindow(plan, weekEndingYmd, wew, windowStartYmd, windowEndWEYmd, windowEndYmd) {
  // Always return an ARRAY of dated entries so downstream day views can render.
  if (!plan) return [];

  // Fast guard: if this week-ending is beyond the allowed window, nothing for this week.
  if (weekEndingYmd > windowEndWEYmd) return [];

  // Case 1: plan is already an array of { date, start, end, break_minutes, ... }
  if (Array.isArray(plan)) {
    const out = [];
    for (const d of plan) {
      if (!d || !d.date) continue;
      const ymd = d.date;

      // Keep only entries inside the contract window
      if (ymd < windowStartYmd) continue;
      if (ymd > windowEndYmd)   continue;

      // Keep only entries that actually belong to THIS week-ending
      try {
        const we = computeWeekEndingInclusive(ymd, wew);
        if (we !== weekEndingYmd) continue;
      } catch { /* if helper not available, be permissive */ }

      out.push(d);
    }
    return out;
  }

  // Case 2: legacy object shape { mon..sun: { start, end, break_minutes, ... } }
  // Convert to the array shape expected by day views.
  if (typeof plan === 'object') {
    const order   = ['mon','tue','wed','thu','fri','sat','sun'];
    const offsets = { sun: 0, sat: -1, fri: -2, thu: -3, wed: -4, tue: -5, mon: -6 };
    const out = [];
    for (const k of order) {
      if (!plan[k]) continue;
      const dayYmd = addDays(weekEndingYmd, offsets[k]);

      if (dayYmd < windowStartYmd) continue;
      if (dayYmd > windowEndYmd)   continue;

      const dCfg = plan[k] || {};
      // Preserve provided fields; expected_minutes is optional and may be 0
      out.push({ date: dayYmd, ...dCfg });
    }
    return out;
  }

  // Unknown shape → nothing to render
  return [];
}
async function handleContractsCloneAndExtend(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  // Load current contract
  const cur = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=*`
  );
  if (!cur) return withCORS(env, req, notFound('Contract not found'));

  // Inputs
  const newStart = toYmd(body.new_start_date || cur.end_date);
  const newEnd   = toYmd(body.new_end_date   || cur.end_date);
  if (!newStart || !newEnd)  return withCORS(env, req, badRequest('new_start_date and new_end_date required'));
  if (newStart  >  newEnd)   return withCORS(env, req, badRequest('new_start_date must be on or before new_end_date'));

  // Should we end existing A?
  const wantEndExisting = (typeof body.end_existing === 'boolean') ? body.end_existing : true;

  // Default close date = newStart − 1 day
  const defaultCloseD = new Date(newStart + 'T00:00:00Z'); defaultCloseD.setUTCDate(defaultCloseD.getUTCDate() - 1);
  const defaultCloseIso = toYmd(defaultCloseD);

  // If user supplied end date, use it (validated below); else use default
  let closeTo = wantEndExisting ? toYmd(body.end_existing_on || defaultCloseIso) : null;

  if (wantEndExisting) {
    if (!closeTo) return withCORS(env, req, badRequest('end_existing_on required when end_existing=true'));
    if (closeTo < cur.start_date) return withCORS(env, req, badRequest('Existing contract cannot end before its original start'));
    if (closeTo >= newStart)      return withCORS(env, req, badRequest('Existing contract end must be before the new start'));
  }

  // If we must end A, ensure no submitted TS on/after the cut
  if (wantEndExisting) {
    const submittedAfter = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(cur.id)}&timesheet_id=not.is.null&week_ending_date=gte.${enc(newStart)}` +
      `&select=week_ending_date&limit=1`
    );
    if (submittedAfter) {
      return withCORS(env, req, badRequest('Cannot close: submitted timesheets exist on or after the new start date.'));
    }
  }

  // Successor source: allow overrides from body.successor_overrides
  const ov = (body.successor_overrides && typeof body.successor_overrides === 'object') ? body.successor_overrides : {};

  // Helper: bool or null (allows explicit null in overrides to clear)
  const boolOrNull = (v, fallbackBool) => {
    if (v === null) return null;
    if (v === undefined) return fallbackBool;
    return clampBool(v, fallbackBool);
  };

  // NEW: Copy overrideclientsettings into successor (allow override if present)
  const successor_overrideclientsettings =
    ('overrideclientsettings' in ov)
      ? clampBool(ov.overrideclientsettings, !!cur.overrideclientsettings)
      : !!cur.overrideclientsettings;

  // Compose successor std_* (prefer explicit override → derived from schedule → inherit)
  let successor_std_schedule = ('std_schedule_json' in ov) ? (ov.std_schedule_json || null) : (cur.std_schedule_json || null);
  let successor_std_hours    = null;
  if (successor_std_schedule) {
    try { successor_std_hours = deriveStdHoursFromSchedule(successor_std_schedule); }
    catch (e) { return withCORS(env, req, badRequest(e.message || 'Invalid std_schedule_json for successor')); }
  } else {
    successor_std_hours = ('std_hours_json' in ov) ? (ov.std_hours_json || null) : (cur.std_hours_json || null);
  }

  // NEW: Copy contract route/calc/group flags into successor (allow override if present)
  const successor_is_nhsp =
    ('is_nhsp' in ov) ? boolOrNull(ov.is_nhsp, !!cur.is_nhsp) : (cur.is_nhsp ?? null);

  const successor_autoprocess_hr =
    ('autoprocess_hr' in ov) ? boolOrNull(ov.autoprocess_hr, !!cur.autoprocess_hr) : (cur.autoprocess_hr ?? null);

  const successor_requires_hr =
    ('requires_hr' in ov) ? boolOrNull(ov.requires_hr, !!cur.requires_hr) : (cur.requires_hr ?? null);

  const successor_no_timesheet_required =
    ('no_timesheet_required' in ov) ? boolOrNull(ov.no_timesheet_required, !!cur.no_timesheet_required) : (cur.no_timesheet_required ?? null);

  const successor_daily_calc_of_invoices =
    ('daily_calc_of_invoices' in ov) ? boolOrNull(ov.daily_calc_of_invoices, !!cur.daily_calc_of_invoices) : (cur.daily_calc_of_invoices ?? null);

  const successor_group_nightsat_sunbh =
    ('group_nightsat_sunbh' in ov) ? boolOrNull(ov.group_nightsat_sunbh, !!cur.group_nightsat_sunbh) : (cur.group_nightsat_sunbh ?? null);

  // Also copy self_bill (contract-level) for correctness (allow override if present)
  const successor_self_bill =
    ('self_bill' in ov) ? boolOrNull(ov.self_bill, !!cur.self_bill) : (cur.self_bill ?? null);

  // NEW: Copy attachment + reference/email routing flags into successor (allow override if present)
  const successor_hr_attach_to_invoice =
    ('hr_attach_to_invoice' in ov) ? boolOrNull(ov.hr_attach_to_invoice, !!cur.hr_attach_to_invoice) : (cur.hr_attach_to_invoice ?? null);

  const successor_ts_attach_to_invoice =
    ('ts_attach_to_invoice' in ov) ? boolOrNull(ov.ts_attach_to_invoice, !!cur.ts_attach_to_invoice) : (cur.ts_attach_to_invoice ?? null);

  const successor_reference_number_required_to_issue_invoice =
    ('reference_number_required_to_issue_invoice' in ov)
      ? boolOrNull(ov.reference_number_required_to_issue_invoice, !!cur.reference_number_required_to_issue_invoice)
      : (cur.reference_number_required_to_issue_invoice ?? null);

  const successor_send_manual_invoices_to_different_email =
    ('send_manual_invoices_to_different_email' in ov)
      ? boolOrNull(ov.send_manual_invoices_to_different_email, !!cur.send_manual_invoices_to_different_email)
      : (cur.send_manual_invoices_to_different_email ?? null);

  const successor_manual_invoices_alt_email_address =
    ('manual_invoices_alt_email_address' in ov)
      ? (ov.manual_invoices_alt_email_address == null ? null : String(ov.manual_invoices_alt_email_address))
      : (cur.manual_invoices_alt_email_address ?? null);

  const successor_weekly_timesheet_source =
    ('weekly_timesheet_source' in ov) ? (ov.weekly_timesheet_source ?? null) : (cur.weekly_timesheet_source ?? null);

  // Friendly validation mirroring DB constraints (validate resulting successor state)
  if (successor_is_nhsp === true && successor_autoprocess_hr === true) {
    return withCORS(env, req, badRequest('Invalid contract route for successor: is_nhsp=true and autoprocess_hr=true cannot both be true.'));
  }
  if (successor_no_timesheet_required === true && successor_autoprocess_hr !== true) {
    return withCORS(env, req, badRequest('Invalid contract route for successor: no_timesheet_required=true requires autoprocess_hr=true.'));
  }

  // Successor payload: copy from A, apply overrides
  const successorPayload = [{
    candidate_id: ('candidate_id' in ov) ? ov.candidate_id : cur.candidate_id,
    client_id:    ('client_id'    in ov) ? ov.client_id    : cur.client_id,
    role:         ('role'         in ov) ? ov.role         : cur.role,
    band:         ('band'         in ov) ? ov.band         : cur.band,
    display_site: ('display_site' in ov) ? ov.display_site : cur.display_site,
    ward_hint:    ('ward_hint'    in ov) ? ov.ward_hint    : cur.ward_hint,

    start_date: newStart,
    end_date:   newEnd,

    overrideclientsettings: successor_overrideclientsettings,

    // NEW: route/calc/group flags copied into successor
    is_nhsp: successor_is_nhsp,
    autoprocess_hr: successor_autoprocess_hr,
    requires_hr: successor_requires_hr,
    no_timesheet_required: successor_no_timesheet_required,
    daily_calc_of_invoices: successor_daily_calc_of_invoices,
    group_nightsat_sunbh: successor_group_nightsat_sunbh,
    self_bill: successor_self_bill,

    hr_attach_to_invoice: successor_hr_attach_to_invoice,
    ts_attach_to_invoice: successor_ts_attach_to_invoice,

    reference_number_required_to_issue_invoice: successor_reference_number_required_to_issue_invoice,
    send_manual_invoices_to_different_email: successor_send_manual_invoices_to_different_email,
    manual_invoices_alt_email_address: successor_manual_invoices_alt_email_address,

    weekly_timesheet_source: successor_weekly_timesheet_source,

    pay_method_snapshot: ('pay_method_snapshot' in ov) ? ov.pay_method_snapshot : cur.pay_method_snapshot,
    rates_json:          ('rates_json'          in ov) ? ov.rates_json          : (cur.rates_json || {}),

    default_submission_mode: ('default_submission_mode' in ov) ? ov.default_submission_mode : cur.default_submission_mode,
    week_ending_weekday_snapshot: (ov.week_ending_weekday_snapshot != null
                                  ? Number(ov.week_ending_weekday_snapshot)
                                  : cur.week_ending_weekday_snapshot),

    std_schedule_json: successor_std_schedule,
    std_hours_json:    successor_std_hours,

    bucket_labels_json: ('bucket_labels_json' in ov) ? ov.bucket_labels_json : (cur.bucket_labels_json || null),
    additional_rates_json: ('additional_rates_json' in ov) ? ov.additional_rates_json : (cur.additional_rates_json || null),

    // Keep existing contract-level flags as before (no override support unless you add it later)
    auto_invoice: cur.auto_invoice,
    require_reference_to_pay: cur.require_reference_to_pay,
    require_reference_to_invoice: cur.require_reference_to_invoice,

    mileage_pay_rate: cur.mileage_pay_rate,
    mileage_charge_rate: cur.mileage_charge_rate,

    created_at: nowIso(), updated_at: nowIso()
  }];

  // Insert successor
  const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts`, {
    method: 'POST', headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(successorPayload)
  });
  if (!ins.ok) return withCORS(env, req, serverError(await ins.text()));
  const successor = (await ins.json().catch(()=>[]))[0];

  // Generate weeks for successor
  try {
    await handleContractsGenerateWeeks(env, new Request(''), successor.id);
  } catch (e) {
    // non-fatal; leave successor created
    console.warn('[CLONE-EXTEND] generate-weeks failed for successor', successor.id, e?.message || e);
  }

  // End existing A (if requested)
  if (wantEndExisting) {
    // Per-day prune at/after newStart (skip TS), then patch end_date = closeTo
    try {
      const { rows: weeks } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(cur.id)}&week_ending_date=gte.${enc(newStart)}` +
        `&select=id,week_ending_date,timesheet_id,planned_schedule_json`
      );
      for (const w of (weeks || [])) {
        if (w?.timesheet_id) continue; // keep weeks with TS

        const plan = Array.isArray(w?.planned_schedule_json) ? w.planned_schedule_json : [];
        if (!plan.length) {
          await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(w.id)}`, {
            method:'DELETE', headers: { ...sbHeaders(env), 'Prefer':'return=minimal' }
          }).catch(()=>{});
          continue;
        }
        const kept = plan.filter(d => d && typeof d.date === 'string' && d.date < newStart);
        if (kept.length) {
          await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(w.id)}`, {
            method:'PATCH', headers:{ ...sbHeaders(env), 'Prefer':'return=minimal' },
            body: JSON.stringify({ planned_schedule_json: kept, updated_at: nowIso() })
          });
        } else {
          await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(w.id)}`, {
            method:'DELETE', headers: { ...sbHeaders(env), 'Prefer':'return=minimal' }
          }).catch(()=>{});
        }
      }
    } catch (_) {}

    // Patch A.end_date
    await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`, {
      method: 'PATCH', headers: { ...sbHeaders(env), 'Prefer': 'return=minimal' },
      body: JSON.stringify({ end_date: closeTo, updated_at: nowIso() })
    });
  }

  return withCORS(env, req, ok({ successor, closed_at: wantEndExisting ? closeTo : null }));
}


async function handleContractsCalendar(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!contractId) return withCORS(env, req, badRequest('contract_id required'));

  const url = new URL(req.url);
  const year = Number(url.searchParams.get('year') || (new Date()).getUTCFullYear());
  const granularity = String(url.searchParams.get('granularity') || 'week').toLowerCase(); // 'week'|'day'
  const fromQ = url.searchParams.get('from');
  const toQ   = url.searchParams.get('to');

  const winStart = fromQ ? toYmd(fromQ) : `${year}-01-01`;
  const winEnd   = toQ   ? toYmd(toQ)   : `${year}-12-31`;

  // =========================
  // DAY: RPC-backed day feed
  // =========================
  if (granularity === 'day') {
    try {
      const items = await sbRpc(env, 'calendar_contract_day_feed', {
        contract_id: contractId,
        from_date: winStart,
        to_date: winEnd
      });

      return withCORS(env, req, ok({
        contract_id: contractId,
        from: winStart,
        to: winEnd,
        granularity: 'day',
        items: Array.isArray(items) ? items : []
      }));
    } catch (e) {
      console.warn('[CONTRACT CAL DAY] rpc failed', { contract_id: contractId, err: e?.message || String(e) });
      return withCORS(env, req, serverError('contract calendar (day) failed'));
    }
  }

  // =========================
  // WEEK: keep existing behaviour
  // =========================
  const needPlan = false;
  const selectCols = needPlan
    ? 'id,contract_id,week_ending_date,additional_seq,status,submission_mode_snapshot,timesheet_id,uploaded_pdf_r2_key,planned_schedule_json'
    : 'id,contract_id,week_ending_date,additional_seq,status,submission_mode_snapshot,timesheet_id,uploaded_pdf_r2_key';

  const weeksTo = winEnd;

  const { rows: weeks } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
    `?contract_id=eq.${enc(contractId)}` +
    `&week_ending_date=gte.${enc(winStart)}&week_ending_date=lte.${enc(weeksTo)}` +
    `&select=${selectCols}` +
    `&order=week_ending_date.asc,additional_seq.asc`
  );

  const ids = (weeks || []).map(w => w.timesheet_id).filter(Boolean);
  let preMap = {};
  if (ids.length) {
    const inList = ids.map(enc).join(',');
    const { rows: pres } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/v_ts_invoice_precheck?timesheet_id=in.(${inList})`
    );
    preMap = Object.fromEntries((pres || []).map(p => [p.timesheet_id, p]));
  }

  const items = (weeks || [])
    .filter(w => w.week_ending_date >= winStart && w.week_ending_date <= winEnd)
    .map(w => {
      const pre = w.timesheet_id ? preMap[w.timesheet_id] : null;

      const preStatus = String(pre?.precheck_status || '').toUpperCase();

      // Prefer view’s computed status when available
      const missingPdf =
        (preStatus === 'BLOCK_NO_PDF') ||
        ((w.submission_mode_snapshot === 'MANUAL')
          ? (!w.uploaded_pdf_r2_key && !(pre && pre.manual_pdf_r2_key))
          : false);

      // ✅ FIX: weekly manual schedule-driven references are checked by v_ts_invoice_precheck
      // (per-shift ref_num in actual_schedule_json). Do NOT use reference_number here.
      const missingRef = (preStatus === 'BLOCK_NO_REFERENCE');

      return {
        id: w.id,
        week_ending_date: w.week_ending_date,
        additional_seq: w.additional_seq,
        status: w.status,
        submission_mode: w.submission_mode_snapshot,
        has_timesheet: !!w.timesheet_id,

        // include timesheet_id so FE weekIndex logic can rely on it
        timesheet_id: w.timesheet_id || null,

        missing_pdf: !!missingPdf,
        missing_reference: !!missingRef
      };
    });

  return withCORS(env, req, ok({
    from: winStart,
    to: winEnd,
    granularity: 'week',
    items
  }));
}


async function handleCandidateCalendar(env, req, candidateId) {
  try {
    const user = await requireUser(env, req, ['admin']);
    if (!user) return withCORS(env, req, unauthorized());
    if (!candidateId) return withCORS(env, req, badRequest('candidate_id required'));

    const url = new URL(req.url);
    const fromQ = url.searchParams.get('from');
    const toQ   = url.searchParams.get('to');
    if (!fromQ || !toQ) return withCORS(env, req, badRequest('from and to are required'));

    const winStart = toYmd(fromQ);
    const winEnd   = toYmd(toQ);

    // RPC: contract list for the window (for FE contract list + highlighting)
    const contracts = await sbRpc(env, 'calendar_candidate_contracts_range', {
      candidate_id: candidateId,
      from_date: winStart,
      to_date: winEnd
    });

    // RPC: authoritative day feed (segments-aware, holds-aware)
    const items = await sbRpc(env, 'calendar_candidate_day_feed', {
      candidate_id: candidateId,
      from_date: winStart,
      to_date: winEnd
    });

    return withCORS(env, req, ok({
      candidate_id: candidateId,
      from: winStart,
      to: winEnd,
      contracts: Array.isArray(contracts) ? contracts : [],
      items: Array.isArray(items) ? items : []
    }));
  } catch (e) {
    try { console.warn('[CANDIDATE CAL]', e?.message || e); } catch {}
    return withCORS(env, req, serverError('candidate calendar failed'));
  }
}

async function handleContractsSkipWeeks(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const from = toYmd(body.from), to = toYmd(body.to);
  if (!from || !to) return withCORS(env, req, badRequest('from and to required'));

  // NEW BEHAVIOUR:
  // We do NOT "cancel" weeks anymore. If a week is being skipped/removed, we delete the contract_weeks row
  // as long as it has no real timesheet.
  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
    `?contract_id=eq.${enc(contractId)}` +
    `&week_ending_date=gte.${enc(from)}` +
    `&week_ending_date=lte.${enc(to)}` +
    `&timesheet_id=is.null`,
    {
      method: 'DELETE',
      headers: { ...sbHeaders(env), 'Prefer': 'return=representation' }
    }
  );

  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const rows = await res.json().catch(()=>[]);
  const deletedCount = Array.isArray(rows) ? rows.length : 0;

  return withCORS(env, req, ok({ deleted: deletedCount }));
}


// ----------------------------------------------------------------------------
// B) CONTRACT WEEKS (list / switching / manual / expenses)
// ----------------------------------------------------------------------------

// ============================================================================
// NEW: handleContractWeekManualDraftUpsert
// Save a MANUAL planned contract_week as a *draft* (no timesheet creation).
// - Validates: week exists, timesheet_id is NULL, submission_mode_snapshot === 'MANUAL'
// - Accepts: actual_schedule_json (array) OR hours fallback
// - Computes canonical bucket hours from schedule via resolveBucketsFromSchedule()
// - Persists:
//     contract_weeks.planned_schedule_json
//     contract_weeks.totals_json = { ...existingTotals, hours: {day,night,sat,sun,bh}, additional_units_week?: {...} }
//     contract_weeks.day_entries_json (from day_references_json if provided)
//     contract_weeks.updated_at
// - Returns the updated contract_week row (representation)
// ============================================================================
async function handleContractWeekManualDraftUpsert(env, req, weekId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!weekId) return withCORS(env, req, badRequest('weekId is required'));

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  // Load contract_week (must be a planned/manual draft)
  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}` +
      `&select=id,contract_id,week_ending_date,timesheet_id,submission_mode_snapshot,planned_schedule_json,totals_json`
  );
  if (!cw) return withCORS(env, req, notFound('Week not found'));

  if (cw.timesheet_id) {
    return withCORS(env, req, badRequest('This week already has a timesheet; draft save is not allowed.'));
  }

  const mode = String(cw.submission_mode_snapshot || '').toUpperCase();
  if (mode !== 'MANUAL') {
    return withCORS(env, req, badRequest('Draft save is only allowed for MANUAL weeks.'));
  }

  // Load contract (needed for bucket resolution via client time policy + BH list)
  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(cw.contract_id)}&select=id,client_id`
  );
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  // ─────────────────────────────────────────────────────────────
  // ✅ Draft schedule is PLANNED (weekly manual draft)
  // Require planned_schedule_json (array) – can be EMPTY to clear the plan.
  // Accept actual_schedule_json / schedule_json as aliases (backwards compatibility).
  // ─────────────────────────────────────────────────────────────
  let planned_schedule_json = null;

  if (Array.isArray(body?.planned_schedule_json)) {
    planned_schedule_json = body.planned_schedule_json;
  } else if (typeof body?.planned_schedule_json === 'string') {
    try {
      const parsed = JSON.parse(body.planned_schedule_json);
      if (Array.isArray(parsed)) planned_schedule_json = parsed;
    } catch {}
  } else if (Array.isArray(body?.actual_schedule_json)) {
    planned_schedule_json = body.actual_schedule_json; // alias
  } else if (typeof body?.actual_schedule_json === 'string') {
    try {
      const parsed = JSON.parse(body.actual_schedule_json);
      if (Array.isArray(parsed)) planned_schedule_json = parsed;
    } catch {}
  } else if (Array.isArray(body?.schedule_json)) {
    planned_schedule_json = body.schedule_json; // alias
  } else if (typeof body?.schedule_json === 'string') {
    try {
      const parsed = JSON.parse(body.schedule_json);
      if (Array.isArray(parsed)) planned_schedule_json = parsed;
    } catch {}
  }

  if (!Array.isArray(planned_schedule_json)) {
    return withCORS(env, req, badRequest('planned_schedule_json is required (weekly manual draft)'));
  }

  // ─────────────────────────────────────────────────────────────
  // Normalise schedule (stable storage)
  // Policy:
  // - If break windows exist (breaks[] or break_start/break_end), we store ONLY breaks[]
  //   and we REMOVE break_mins/break_minutes (prevents “mixing”).
  // - If no break windows, we may store break_minutes (integer) if provided (>0).
  // - Never let string mins leak into storage.
  // ─────────────────────────────────────────────────────────────
  const parseHHMM = (s) => {
    const m = String(s || '').trim().match(/^(\d{1,2}):(\d{2})$/);
    if (!m) return null;
    const hh = Number(m[1]), mm = Number(m[2]);
    if (!Number.isFinite(hh) || !Number.isFinite(mm)) return null;
    if (hh < 0 || hh > 23 || mm < 0 || mm > 59) return null;
    return hh * 60 + mm;
  };

  const diffMins = (a, b) => {
    const am = parseHHMM(a);
    const bm = parseHHMM(b);
    if (am == null || bm == null) return null;
    let d = bm - am;
    if (d < 0) d += 1440;
    return d;
  };

  const toIntMins = (v) => {
    if (v == null) return 0;
    if (typeof v === 'number') return Number.isFinite(v) ? Math.max(0, Math.floor(v)) : 0;
    const s = String(v).trim();
    if (!s) return 0;
    const m = s.match(/^(\d{1,4})(?:\s*m)?$/i);
    if (!m) return 0;
    const n = Number(m[1]);
    return Number.isFinite(n) ? Math.max(0, Math.floor(n)) : 0;
  };

  const normaliseSchedule = (arr) => {
    const out = [];
    for (const raw of (arr || [])) {
      const seg = (raw && typeof raw === 'object') ? { ...raw } : null;
      if (!seg) continue;

      // normalise ref key
      if (seg.ref_num == null && seg.reference != null) seg.ref_num = seg.reference;

      // build breaks[] (from seg.breaks plus legacy break_start/break_end)
      let breaks = [];
      if (Array.isArray(seg.breaks)) {
        breaks = seg.breaks
          .map(b => ({
            start: String(b?.start || '').trim(),
            end:   String(b?.end   || '').trim()
          }))
          .filter(b => b.start || b.end);
      }

      const bs0 = String(seg.break_start || '').trim();
      const be0 = String(seg.break_end   || '').trim();
      if ((bs0 || be0) && !breaks.some(b => (b.start === bs0 && b.end === be0))) {
        breaks.unshift({ start: bs0, end: be0 });
      }

      // Determine whether we have *any* break window
      const hasWindow = breaks.some(b => String(b.start || '').trim() || String(b.end || '').trim());

      // If no window breaks, allow mins-only breaks
      const brMins = toIntMins(seg.break_mins ?? seg.break_minutes);

      // Keep legacy convenience fields aligned to first break (if present)
      const p = hasWindow ? (breaks[0] || null) : null;
      seg.break_start = p ? p.start : '';
      seg.break_end   = p ? p.end   : '';

      if (hasWindow) {
        // ✅ Window breaks: store ONLY breaks[]
        seg.breaks = breaks;

        // Remove mins to prevent mixing (and avoid validator rejection)
        delete seg.break_mins;
        delete seg.break_minutes;
      } else {
        // ✅ No window: store mins if present (>0), else clear both
        seg.breaks = []; // normalised empty

        if (brMins > 0) {
          seg.break_minutes = brMins;
          // don’t store break_mins separately (avoid redundant fields)
          delete seg.break_mins;
        } else {
          delete seg.break_mins;
          delete seg.break_minutes;
        }
      }

      // Remove any stray legacy keys that can confuse downstream code
      // (they’re represented by seg.breaks or seg.break_minutes now)
      delete seg.break_start;
      delete seg.break_end;

      // Re-add aligned legacy fields ONLY if you still want them present in storage.
      // If you do, uncomment below:
      // if (hasWindow && p) { seg.break_start = p.start; seg.break_end = p.end; }

      out.push(seg);
    }
    return out;
  };

  planned_schedule_json = normaliseSchedule(planned_schedule_json);

  // Validate schedule only if there is at least one shift segment
  if (planned_schedule_json.length) {
    try {
      validateScheduleStructure(planned_schedule_json);
    } catch (e) {
      return withCORS(env, req, badRequest(e?.message || 'Invalid schedule (overlap/break windows).'));
    }
  }

  // Compute minutes by bucket -> hours (canonical)
  let hours = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
  try {
    if (planned_schedule_json.length) {
      const mins = await resolveBucketsFromSchedule(env, contract, planned_schedule_json);
      hours = {
        day:   +(Number(mins?.day   || 0) / 60).toFixed(2),
        night: +(Number(mins?.night || 0) / 60).toFixed(2),
        sat:   +(Number(mins?.sat   || 0) / 60).toFixed(2),
        sun:   +(Number(mins?.sun   || 0) / 60).toFixed(2),
        bh:    +(Number(mins?.bh    || 0) / 60).toFixed(2)
      };
    }
  } catch (e) {
    return withCORS(env, req, badRequest(e?.message || 'Failed to bucket schedule'));
  }

  // ─────────────────────────────────────────────────────────────
  // Additional units (optional)
  // Persist inside totals_json.additional_units_week + totals_json.additional_units_per_day
  // (no dedicated columns).
  // ─────────────────────────────────────────────────────────────
  const normaliseUnitsWeek = (obj) => {
    if (!obj || typeof obj !== 'object') return {};
    const out = {};
    for (const [kRaw, vRaw] of Object.entries(obj)) {
      const code = String(kRaw || '').toUpperCase().trim();
      if (!code) continue;
      const n = Number(vRaw || 0);
      if (!Number.isFinite(n) || !n) continue; // strip zeros + invalid
      out[code] = n;
    }
    return out;
  };

  // Build a Set of valid YYYY-MM-DD dates for this contract_week (for per-day validation)
  const weekDateSet = (() => {
    const we = String(cw.week_ending_date || '').slice(0, 10);
    if (!/^\d{4}-\d{2}-\d{2}$/.test(we)) return null;

    const addDaysYmd = (ymd, days) => {
      try {
        const base = new Date(`${String(ymd)}T00:00:00Z`);
        if (Number.isNaN(base.getTime())) return null;
        base.setUTCDate(base.getUTCDate() + Number(days || 0));
        const yyyy = base.getUTCFullYear();
        const mm = String(base.getUTCMonth() + 1).padStart(2, '0');
        const dd = String(base.getUTCDate()).padStart(2, '0');
        return `${yyyy}-${mm}-${dd}`;
      } catch {
        return null;
      }
    };

    const s = new Set();
    for (let i = 6; i >= 0; i--) {
      const d = addDaysYmd(we, -i);
      if (d) s.add(d);
    }
    return s;
  })();

  const normaliseUnitsPerDay = (obj) => {
    if (!obj || typeof obj !== 'object') return {};
    const out = {};

    for (const [kRaw, dayMap] of Object.entries(obj)) {
      const code = String(kRaw || '').toUpperCase().trim();
      if (!code) continue;

      if (!dayMap || typeof dayMap !== 'object') continue;

      const outDays = {};
      for (const [dRaw, vRaw] of Object.entries(dayMap)) {
        const ymd = String(dRaw || '').slice(0, 10);
        if (!/^\d{4}-\d{2}-\d{2}$/.test(ymd)) {
          throw new Error(`Invalid date '${ymd}' in additional_units_per_day.${code}`);
        }
        if (weekDateSet && !weekDateSet.has(ymd)) {
          throw new Error(`Date '${ymd}' outside week in additional_units_per_day.${code}`);
        }

        const n = Number(vRaw == null ? 0 : vRaw);
        if (!Number.isFinite(n) || n < 0) {
          throw new Error(`Invalid units '${vRaw}' in additional_units_per_day.${code}.${ymd}`);
        }
        if (!n) continue; // strip zeros

        outDays[ymd] = n;
      }

      if (Object.keys(outDays).length) out[code] = outDays;
    }

    return out;
  };

  const deriveWeekFromPerDay = (perDayObj) => {
    const out = {};
    if (!perDayObj || typeof perDayObj !== 'object') return out;

    for (const [codeRaw, dayMap] of Object.entries(perDayObj)) {
      const code = String(codeRaw || '').toUpperCase().trim();
      if (!code) continue;
      if (!dayMap || typeof dayMap !== 'object') continue;

      let sum = 0;
      for (const v of Object.values(dayMap)) {
        const n = Number(v);
        if (Number.isFinite(n) && n > 0) sum += n;
      }
      if (sum > 0) out[code] = sum;
    }

    return out;
  };

  let additionalUnitsWeek = undefined;   // undefined = "no change"
  let additionalUnitsPerDay = undefined; // undefined = "no change"

  // weekly
  if (body && Object.prototype.hasOwnProperty.call(body, 'additional_units_week')) {
    if (body.additional_units_week && typeof body.additional_units_week === 'object') {
      additionalUnitsWeek = normaliseUnitsWeek(body.additional_units_week);
    } else if (body.additional_units_week === null) {
      additionalUnitsWeek = {}; // explicit clear
    } else if (typeof body.additional_units_week === 'string') {
      try {
        const parsed = JSON.parse(body.additional_units_week);
        if (parsed && typeof parsed === 'object') additionalUnitsWeek = normaliseUnitsWeek(parsed);
      } catch {
        additionalUnitsWeek = undefined;
      }
    } else {
      additionalUnitsWeek = undefined;
    }
  }

  // per-day
  if (body && Object.prototype.hasOwnProperty.call(body, 'additional_units_per_day')) {
    if (body.additional_units_per_day && typeof body.additional_units_per_day === 'object') {
      try {
        additionalUnitsPerDay = normaliseUnitsPerDay(body.additional_units_per_day);
      } catch (e) {
        return withCORS(env, req, badRequest(e?.message || 'Invalid additional_units_per_day'));
      }
    } else if (body.additional_units_per_day === null) {
      additionalUnitsPerDay = {}; // explicit clear
    } else if (typeof body.additional_units_per_day === 'string') {
      try {
        const parsed = JSON.parse(body.additional_units_per_day);
        if (parsed && typeof parsed === 'object') {
          try {
            additionalUnitsPerDay = normaliseUnitsPerDay(parsed);
          } catch (e) {
            return withCORS(env, req, badRequest(e?.message || 'Invalid additional_units_per_day'));
          }
        }
      } catch {
        additionalUnitsPerDay = undefined;
      }
    } else {
      additionalUnitsPerDay = undefined;
    }
  }

  // Build patch
  const now = nowIso();

  const existingTotals =
    (cw.totals_json && typeof cw.totals_json === 'object') ? cw.totals_json : {};

  const totals_json = {
    ...existingTotals,
    hours
  };

  // If per-day key is provided, derive weekly totals from per-day to keep coherence.
  if (additionalUnitsPerDay !== undefined) {
    totals_json.additional_units_per_day = additionalUnitsPerDay;
    totals_json.additional_units_week = deriveWeekFromPerDay(additionalUnitsPerDay);
  } else if (additionalUnitsWeek !== undefined) {
    totals_json.additional_units_week = additionalUnitsWeek;
  }

  const patch = {
    totals_json,
    planned_schedule_json: planned_schedule_json, // ALWAYS set (including empty array) so "clear" persists
    updated_at: now
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(patch)
    }
  );

  if (!res.ok) {
    const txt = await res.text().catch(() => '');
    return withCORS(env, req, serverError(txt || 'Failed to patch contract_week'));
  }

  const json = await res.json().catch(() => []);
  const row = Array.isArray(json) ? (json[0] || null) : json;

  return withCORS(env, req, ok(row || { updated: true, week_id: weekId, hours }));
}



async function handleContractWeeksList(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  const url = new URL(req.url);
  const q = (k) => url.searchParams.get(k);
  const filters = [];

  const includePlan = String(q('include_plan')||'').toLowerCase() === 'true';

  // NOTE:
  // - contract_weeks does NOT have an additional_units_week column.
  // - draft extras are stored in contract_weeks.totals_json.additional_units_week (Option A).
  let api = includePlan
    ? `${env.SUPABASE_URL}/rest/v1/contract_weeks?select=` +
      [
        'id',
        'contract_id',
        'week_ending_date',
        'additional_seq',
        'status',
        'submission_mode_snapshot',
        'timesheet_id',
        'uploaded_pdf_r2_key',
        'planned_schedule_json',

        // ✅ required for planned-week repaint after draft save
        'totals_json',
        'day_entries_json',

        'created_at',
        'updated_at'
      ].join(',')
    : `${env.SUPABASE_URL}/rest/v1/v_contract_weeks_enriched?select=*`;

  const add = (cond) => { if (cond) filters.push(cond); };
  add(q('contract_id') ? `contract_id=eq.${enc(q('contract_id'))}` : null);
  add(q('candidate_id') ? `candidate_id=eq.${enc(q('candidate_id'))}` : null);
  add(q('client_id') ? `client_id=eq.${enc(q('client_id'))}` : null);
  add(q('status') ? `status=eq.${enc(q('status'))}` : null);
  add(q('submission_mode_snapshot') ? `submission_mode_snapshot=eq.${enc(q('submission_mode_snapshot'))}` : null);
  add(q('week_ending_from') ? `week_ending_date=gte.${enc(q('week_ending_from'))}` : null);
  add(q('week_ending_to') ? `week_ending_date=lte.${enc(q('week_ending_to'))}` : null);

  if (filters.length) api += `&${filters.join('&')}`;
  api += `&order=week_ending_date.asc,additional_seq.asc`;

  const { rows } = await sbFetch(env, api);
  return withCORS(env, req, ok(rows || []));
}


 async function handleContractWeekUpdate(env, req, weekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  let body; try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const cw = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=contract_id,week_ending_date,timesheet_id,submission_mode_snapshot,planned_schedule_json`);
  if (!cw) return withCORS(env, req, notFound('Week not found'));

  const patch = {};

  // Status guard (unchanged)
  if (body.status) {
    const st = String(body.status).toUpperCase();
    if (!['OPEN','PLANNED','SUBMITTED','AUTHORISED','INVOICED','CANCELLED'].includes(st)) {
      return withCORS(env, req, badRequest('Invalid status'));
    }
    if (st === 'CANCELLED' && cw.timesheet_id) return withCORS(env, req, badRequest('Cannot cancel: timesheet exists'));
    patch.status = st;
  }

  // Submission mode guard (unchanged)
  if (body.submission_mode_snapshot) {
    const sm = String(body.submission_mode_snapshot).toUpperCase();
    if (!['ELECTRONIC','MANUAL'].includes(sm)) return withCORS(env, req, badRequest('Invalid mode'));
    if (cw.timesheet_id) return withCORS(env, req, badRequest('Cannot change mode: timesheet exists'));
    patch.submission_mode_snapshot = sm;
  }

  // plan-only override (normalize, infer overnight from times, recompute expected_minutes)
  if ('planned_schedule_json' in body) {
    try {
      const plan = Array.isArray(body.planned_schedule_json) ? body.planned_schedule_json : [];
      const fixed = plan.map(d => {
        if (!d || !d.date) {
          return { date: d?.date || cw.week_ending_date, start:null, end:null, breaks:[], break_minutes:0, overnight:false, expected_minutes:0 };
        }
        if (!d.start || !d.end) {
          return { ...d, breaks: Array.isArray(d.breaks)? d.breaks : [], break_minutes: Math.max(0, Number(d.break_minutes||0)), overnight:false, expected_minutes:0 };
        }
        const s = parseHHMM(d.start), e = parseHHMM(d.end);
        if (s==null || e==null) throw new Error(`Invalid HH:MM in planned_schedule_json for ${d.date}`);
        const br = Math.max(0, Number(d.break_minutes||0));
        const overnight = (e <= s); // infer only from times
        const mins = Math.max(0, minutesDiff(s, e, overnight) - br);
        return { date:d.date, start:d.start, end:d.end, breaks: Array.isArray(d.breaks)? d.breaks : [], break_minutes: br, overnight, expected_minutes: mins };
      });
      patch.planned_schedule_json = fixed;
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid planned_schedule_json'));
    }
  }

  if (!Object.keys(patch).length) return withCORS(env, req, badRequest('No updatable fields'));

  patch.updated_at = nowIso();

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}`, {
    method: 'PATCH', headers: { ...sbHeaders(env), 'Prefer': 'return=representation' }, body: JSON.stringify(patch)
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const json = await res.json().catch(()=>[]);
  return withCORS(env, req, ok(Array.isArray(json)?json[0]:json));
}


 async function handleContractWeekCreateAdditional(env, req, weekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const base = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=*`);
  if (!base) return withCORS(env, req, notFound('Week not found'));

  const { rows: siblings } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(base.contract_id)}&week_ending_date=eq.${enc(base.week_ending_date)}&select=additional_seq&order=additional_seq.desc&limit=1`
  );
  const nextSeq = ((siblings && siblings[0] && Number(siblings[0].additional_seq)) || 0) + 1;

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify({
      contract_id: base.contract_id,
      week_ending_date: base.week_ending_date,
      additional_seq: nextSeq,
      status: 'OPEN',
      submission_mode_snapshot: base.submission_mode_snapshot,
      created_at: nowIso(), updated_at: nowIso(),
    })
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const row = (await res.json().catch(()=>[]))[0];
  return withCORS(env, req, ok(row));
}

async function handleContractWeekSwitchMode(env, req, weekId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!weekId) return withCORS(env, req, badRequest('contract_week_id is required'));

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=*`
  );
  if (!cw) return withCORS(env, req, notFound('Week not found'));
  if (cw.timesheet_id) return withCORS(env, req, badRequest('Cannot switch mode for a week with a timesheet'));

  // ✅ UPDATED: backend defence-in-depth — block import-authoritative planned weeks using summary view / contract overrides
  try {
    const resolved = await resolveImportAuthoritative(env, {
      contract_week_id: cw.id,
      contract_id: cw.contract_id || null
    });

    if (resolved && resolved.is_import_authoritative) {
      return withCORS(
        env,
        req,
        badRequest('Import-authoritative weeks (NHSP / HealthRoster weekly no-timesheets) cannot switch planned submission mode')
      );
    }
  } catch {
    // fail-open if flags cannot be loaded
  }

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  let newMode = null;
  if (body && typeof body.submission_mode_snapshot === 'string' && body.submission_mode_snapshot.trim()) {
    const m = body.submission_mode_snapshot.trim().toUpperCase();
    if (m === 'MANUAL' || m === 'ELECTRONIC') newMode = m;
  }
  if (!newMode) {
    newMode = (String(cw.submission_mode_snapshot || '').toUpperCase() === 'ELECTRONIC') ? 'MANUAL' : 'ELECTRONIC';
  }

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({ submission_mode_snapshot: newMode, updated_at: nowIso() })
    }
  );
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const row = (await res.json().catch(() => []))[0];
  return withCORS(env, req, ok(row));
}


async function handleContractWeekPresignManualPdf(env, req, weekId) {
  // Admin presign wrapper — MUST align with /api/files/presign-upload + /api/files/upload token/key rules
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=id,week_ending_date,additional_seq,uploaded_pdf_r2_key,timesheet_id`
  );
  if (!cw) return withCORS(env, req, notFound('Week not found'));

  const hasAnySegmentInvoiceLock = (tf) => {
    try {
      const ib = tf?.invoice_breakdown_json;
      if (!ib || typeof ib !== 'object') return false;
      const mode = String(ib?.mode || '').toUpperCase();
      if (mode !== 'SEGMENTS') return false;
      const segs = Array.isArray(ib?.segments) ? ib.segments : [];
      return segs.some(s => {
        const v = s?.invoice_locked_invoice_id;
        return v != null && String(v).trim() !== '';
      });
    } catch {
      return false;
    }
  };


  // If already invoiced, forbid replacement at this path (use unissue flow first)
  if (cw.timesheet_id) {
    const tsfin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?timesheet_id=eq.${enc(cw.timesheet_id)}&is_current=eq.true&select=locked_by_invoice_id,invoice_breakdown_json`
    );
    if (tsfin?.locked_by_invoice_id || hasAnySegmentInvoiceLock(tsfin)) {
      return withCORS(env, req, badRequest('Timesheet invoiced. Unissue invoice before replacing scan.'));
    }
  }

  // Optional hints (backward compatible with callers that POST {})
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const contentTypeRaw =
    (body && (body.content_type || body.contentType)) ||
    'application/pdf';

  const filenameRaw =
    (body && (body.filename || body.name)) ||
    `contract_week_${cw.id}.pdf`;

  const contentType = String(contentTypeRaw || 'application/pdf');
  const filename = String(filenameRaw || '');

  // Derive extension like handleFilePresignUpload (so key matches /api/files/upload regex)
  let ext = '';
  if (filename && filename.includes('.')) {
    ext = filename.substring(filename.lastIndexOf('.'));
  } else {
    const ctMap = {
      'image/png': '.png',
      'image/jpeg': '.jpg',
      'image/gif': '.gif',
      'image/webp': '.webp',
      'image/heic': '.heic',
      'image/heif': '.heif',
      'application/pdf': '.pdf'
    };
    if (contentType in ctMap) ext = ctMap[contentType];
  }

  // MUST match /api/files/upload:
  //   key:  /^\/files\/\d{8}\/file_[0-9a-f]{16}(\.[A-Za-z0-9]{3,10})?$/
  //   token payload: { typ: "file_upload", key, exp } signed with env.UPLOAD_TOKEN_SECRET
  const dateTag = new Date().toISOString().slice(0, 10).replace(/-/g, '');
  const randBytes = crypto.getRandomValues(new Uint8Array(8));
  let randHex = '';
  randBytes.forEach(b => { randHex += b.toString(16).padStart(2, '0'); });

  const key = `/files/${dateTag}/file_${randHex}${ext || ''}`;

  const expiresSec = Math.min(parseInt(env.PRESIGN_EXPIRES_SECONDS || '600', 10) || 600, 900);
  const exp = Math.floor(Date.now() / 1000) + expiresSec;

  const token = await createToken(env.UPLOAD_TOKEN_SECRET, { typ: 'file_upload', key, exp });

  const uploadBase = new URL(req.url);
  uploadBase.pathname = '/api/files/upload';
  uploadBase.search = '';
  uploadBase.searchParams.set('key', key);
  uploadBase.searchParams.set('token', token);
  const upload_url = uploadBase.toString();

  // Persist the key on the week (legacy behaviour)
  await patchContractWeekScan(env, cw.id, key);

  return withCORS(
    env,
    req,
    ok({
      key,
      upload_url,
      token,
      expires_in: expiresSec,
      expires_at: new Date(exp * 1000).toISOString(),
      max_bytes: parseInt(env.FILE_MAX_BYTES || '5000000', 10)
    })
  );
}

// PATCH /api/timesheets/:id/evidence/:evidence_id
// Body: { kind: "Timesheet" | "Mileage" | "Accommodation" | "Expenses" | "<custom>" }

async function handleContractWeekReplaceManualPdf(env, req, weekId) {
 
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=id,timesheet_id,uploaded_pdf_r2_key`
  );
  if (!cw) return withCORS(env, req, notFound('Week not found'));

  const hasAnySegmentInvoiceLock = (tf) => {
    try {
      const ib = tf?.invoice_breakdown_json;
      if (!ib || typeof ib !== 'object') return false;
      const mode = String(ib?.mode || '').toUpperCase();
      if (mode !== 'SEGMENTS') return false;
      const segs = Array.isArray(ib?.segments) ? ib.segments : [];
      return segs.some(s => {
        const v = s?.invoice_locked_invoice_id;
        return v != null && String(v).trim() !== '';
      });
    } catch {
      return false;
    }
  };


  // If already invoiced/paid, forbid replacement at this path
  if (cw.timesheet_id) {
    const tsfin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?timesheet_id=eq.${enc(cw.timesheet_id)}&is_current=eq.true&select=locked_by_invoice_id,paid_at_utc,invoice_breakdown_json`
    );
    if (tsfin?.locked_by_invoice_id || hasAnySegmentInvoiceLock(tsfin) || tsfin?.paid_at_utc) {
      return withCORS(env, req, badRequest('Invoiced/paid; unissue/unpay first to replace PDF'));
    }
  }

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  if (!body?.r2_key) return withCORS(env, req, badRequest('r2_key is required'));
  const newKey = normalizeKey(String(body.r2_key));

  // sanity check new key exists
  const exists = await r2Exists(env, newKey).catch(() => false);
  if (!exists) return withCORS(env, req, badRequest('r2_key does not exist in R2'));

  const oldKey = cw.uploaded_pdf_r2_key ? normalizeKey(String(cw.uploaded_pdf_r2_key)) : null;

  await patchContractWeekScan(env, weekId, newKey);

  // ✅ NEW: delete old scan blob if replaced
  try {
    const bucket = env.R2_BUCKET || env.R2;
    if (bucket && typeof bucket.delete === 'function') {
      const o = String(oldKey || '').replace(/^\/+/, '').trim();
      const n = String(newKey || '').replace(/^\/+/, '').trim();
      if (o && n && o !== n) {
        await bucket.delete(o).catch(() => {});
      }
    }
  } catch {
    // non-fatal
  }

  return withCORS(env, req, ok({ replaced: true, r2_key: newKey }));
}

async function handleContractWeekManualUpsert(env, req, weekId) {

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  // ✅ Guarded write (only enforced when a current timesheet already exists for this week)
  const expectedTimesheetId = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';

  // Additional units keys (weekly/per-day) are still supported
  const hasUnitsWeekKey   = !!(body && Object.prototype.hasOwnProperty.call(body, 'additional_units_week'));
  const hasUnitsPerDayKey = !!(body && Object.prototype.hasOwnProperty.call(body, 'additional_units_per_day'));

  // QR revoke/reissue hints (legacy)
  const rawRevokeQr  = !!body?.revoke_qr;
  const rawReissueQr = !!body?.reissue_qr;

  // preferred enum
  const qrActionEnumRaw = String(body?.qr_action || body?.qrAction || '').trim().toUpperCase();
  const enumOk = (x) => (
    x === 'INVALIDATE' ||
    x === 'REISSUE' ||
    x === 'REVOKE_TO_MANUAL' ||
    x === 'ISSUE' ||
    x === 'SAVE_WITHOUT_ISSUE'
  );

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=*`
  );
  if (!cw) return withCORS(env, req, notFound('Week not found'));

  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(cw.contract_id)}&select=*`
  );
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  // ✅ Compute a timestamp ONCE (and do not shadow the nowIso() helper)
  const nowIso2 = nowIso();

  // ✅ Resolve cw.timesheet_id to the current timesheet id (if one exists)
  let currentTimesheetIdForWeek = cw.timesheet_id || null;
  let wasStaleWeekTs = false;

  if (currentTimesheetIdForWeek) {
    const resTs = await resolveTimesheetToCurrent(env, currentTimesheetIdForWeek);
    if (!resTs) return withCORS(env, req, notFound('Timesheet not found'));

    if (String(resTs.current_timesheet_id) !== String(currentTimesheetIdForWeek)) {
      wasStaleWeekTs = true;
      currentTimesheetIdForWeek = resTs.current_timesheet_id;

      // keep contract_week pointer aligned (best-effort)
      try {
        await fetch(
          `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({ timesheet_id: currentTimesheetIdForWeek, updated_at: nowIso2 })
          }
        ).catch(() => {});
      } catch {}
    }

    // Guard requires expected_timesheet_id when a timesheet exists
    if (!expectedTimesheetId) {
      return withCORS(env, req, badRequest('expected_timesheet_id is required'));
    }

    if (String(expectedTimesheetId) !== String(currentTimesheetIdForWeek)) {
      return withCORS(
        env,
        req,
        new Response(
          JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetIdForWeek }),
          { status: 409, headers: { 'Content-Type': 'application/json' } }
        )
      );
    }
  }

  // Load candidate/client once for use in TS creation + QR reissue
  const candidate = contract.candidate_id
    ? await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(contract.candidate_id)}&select=id,display_name,email`
      )
    : null;

  const client = contract.client_id
    ? await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=eq.${enc(contract.client_id)}&select=id,name`
      )
    : null;

  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);

  // rotation degrees normalisation
  const normaliseRotation = (raw) => {
    if (raw == null) return 0;
    let n = Number(raw);
    if (!Number.isFinite(n)) return 0;
    n = ((n % 360) + 360) % 360;
    if (n >= 315 || n < 45) return 0;
    if (n >= 45 && n < 135) return 90;
    if (n >= 135 && n < 225) return 180;
    return 270;
  };
  const manualPdfRotationDeg = normaliseRotation(
    body?.manual_pdf_rotation_degrees ?? body?.rotation_degrees
  );

  // ─────────────────────────────────────────────────────────────
  // ✅ SCHEDULE-DRIVEN ONLY (weekly manual)
  // Require actual_schedule_json (array; may be empty for "clear schedule")
  // ─────────────────────────────────────────────────────────────
  let actual_schedule_json = null;

  if (Array.isArray(body?.actual_schedule_json)) {
    actual_schedule_json = body.actual_schedule_json;
  } else if (typeof body?.actual_schedule_json === 'string') {
    try {
      const parsed = JSON.parse(body.actual_schedule_json);
      if (Array.isArray(parsed)) actual_schedule_json = parsed;
    } catch {}
  }

  if (!Array.isArray(actual_schedule_json)) {
    return withCORS(env, req, badRequest('actual_schedule_json is required (schedule-driven weekly manual only)'));
  }

  // Normalise: ensure breaks[] exists, and break_mins reflects sum of breaks windows
  const parseHHMM = (s) => {
    const m = String(s || '').trim().match(/^(\d{1,2}):(\d{2})$/);
    if (!m) return null;
    const hh = Number(m[1]), mm = Number(m[2]);
    if (!Number.isFinite(hh) || !Number.isFinite(mm)) return null;
    if (hh < 0 || hh > 23 || mm < 0 || mm > 59) return null;
    return hh * 60 + mm;
  };

  const diffMins = (a, b) => {
    const am = parseHHMM(a);
    const bm = parseHHMM(b);
    if (am == null || bm == null) return null;
    let d = bm - am;
    if (d < 0) d += 1440;
    return d;
  };

  const normaliseSchedule = (arr) => {
    const out = [];
    for (const raw of (arr || [])) {
      const seg = (raw && typeof raw === 'object') ? { ...raw } : null;
      if (!seg) continue;

      // normalise ref key
      if (seg.ref_num == null && seg.reference != null) seg.ref_num = seg.reference;

      // build breaks[]
      let breaks = [];
      if (Array.isArray(seg.breaks)) {
        breaks = seg.breaks
          .map(b => ({
            start: String(b?.start || '').trim(),
            end:   String(b?.end   || '').trim()
          }))
          .filter(b => b.start || b.end);
      }

      // legacy primary break fields -> include as first break if present and not already
      const bs0 = String(seg.break_start || '').trim();
      const be0 = String(seg.break_end   || '').trim();
      if ((bs0 || be0) && !breaks.some(b => (b.start === bs0 && b.end === be0))) {
        breaks.unshift({ start: bs0, end: be0 });
      }

      // compute break minutes from breaks if possible
      let br = Number(seg.break_mins ?? seg.break_minutes ?? 0);
      if ((!Number.isFinite(br) || br <= 0) && breaks.length) {
        let sum = 0;
        for (const b of breaks) {
          const d = diffMins(b.start, b.end);
          if (Number.isFinite(d) && d > 0) sum += d;
        }
        br = sum;
      }
      if (!Number.isFinite(br) || br < 0) br = 0;

      seg.breaks = breaks;

      // ✅ Canonical: never store both
      if (breaks.length) {
        // windows mode
        delete seg.break_mins;
        delete seg.break_minutes;
        delete seg.break_minutes; // (keep once if duplicated)
      } else {
        // minutes mode (only if >0)
        const bm = Number(seg.break_mins ?? seg.break_minutes ?? 0);
        const n = (Number.isFinite(bm) && bm > 0) ? Math.floor(bm) : 0;

        if (n > 0) seg.break_minutes = n;
        else delete seg.break_minutes;

        delete seg.break_mins;
        delete seg.break_start;
        delete seg.break_end;
        delete seg.breaks;
      }

      // keep legacy convenience fields aligned to first break
      const p = breaks[0] || null;
      seg.break_start = p ? p.start : (seg.break_start || '');
      seg.break_end   = p ? p.end   : (seg.break_end   || '');

      out.push(seg);
    }
    return out;
  };

  actual_schedule_json = normaliseSchedule(actual_schedule_json);

  // If we are creating a NEW timesheet (no ts exists), require at least 1 shift segment.
  // Draft/planned saves belong in the draft endpoint.
  if (!currentTimesheetIdForWeek && actual_schedule_json.length === 0) {
    return withCORS(env, req, badRequest('Cannot create a timesheet with an empty schedule. Save as draft or add at least one shift.'));
  }

  try {
    validateScheduleStructure(actual_schedule_json);
  } catch (e) {
    return withCORS(env, req, badRequest(e.message || 'Invalid schedule (overlap/breaks).'));
  }

  // Resolve bucket minutes from schedule (single source of truth)
  let hours = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
  try {
    if (actual_schedule_json.length) {
      const minsByBucket = await resolveBucketsFromSchedule(env, contract, actual_schedule_json);
      hours = {
        day:   +(minsByBucket.day   / 60).toFixed(2),
        night: +(minsByBucket.night / 60).toFixed(2),
        sat:   +(minsByBucket.sat   / 60).toFixed(2),
        sun:   +(minsByBucket.sun   / 60).toFixed(2),
        bh:    +(minsByBucket.bh    / 60).toFixed(2)
      };
    }
  } catch (e) {
    return withCORS(env, req, badRequest(e.message || 'Invalid actual_schedule_json'));
  }

  // Base rates must exist for any positive bucket
  const { pay, charge, method } = payChargeFromContract(contract);
  const anyMissing = (h, P, C) =>
    (h.day   > 0 && (!P.day   && P.day   !== 0 || !C.day   && C.day   !== 0)) ||
    (h.night > 0 && (!P.night && P.night !== 0 || !C.night && C.night !== 0)) ||
    (h.sat   > 0 && (!P.sat   && P.sat   !== 0 || !C.sat   && C.sat   !== 0)) ||
    (h.sun   > 0 && (!P.sun   && P.sun   !== 0 || !C.sun   && C.sun   !== 0)) ||
    (h.bh    > 0 && (!P.bh    && P.bh    !== 0 || !C.bh    && C.bh    !== 0));

  if (anyMissing(hours, pay, charge)) {
    return withCORS(env, req, badRequest('Missing rate(s) in contract for one or more entered hour buckets'));
  }

  // Additional unit buckets – weekly totals (still supported)
  const normaliseUnitsWeek = (obj) => {
    const out = {};
    const src = (obj && typeof obj === 'object') ? obj : {};
    for (const [kRaw, vRaw] of Object.entries(src)) {
      const code = String(kRaw || '').toUpperCase().trim();
      if (!code) continue;

      const n = Number(vRaw);
      // ✅ Only allow positive numbers (reject negatives + NaN + 0)
      if (!Number.isFinite(n) || n <= 0) continue;

      out[code] = n;
    }
    return out;
  };

  const normaliseUnitsPerDay = (obj) => {
    const out = {};
    const src = (obj && typeof obj === 'object') ? obj : {};
    for (const [kRaw, per] of Object.entries(src)) {
      const code = String(kRaw || '').toUpperCase().trim();
      if (!code) continue;
      if (!per || typeof per !== 'object') continue;

      const days = {};
      for (const [dRaw, vRaw] of Object.entries(per)) {
        const ymd = String(dRaw || '').slice(0, 10);
        if (!/^\d{4}-\d{2}-\d{2}$/.test(ymd)) continue;

        const n = Number(vRaw);
        // ✅ Only allow positive numbers (reject negatives + NaN + 0)
        if (!Number.isFinite(n) || n <= 0) continue;

        days[ymd] = n;
      }

      if (Object.keys(days).length) out[code] = days;
    }
    return out;
  };

  const parseMaybeJsonObj = (v) => {
    if (v == null) return null;
    if (typeof v === 'object') return v;
    if (typeof v === 'string') {
      try {
        const p = JSON.parse(v);
        return (p && typeof p === 'object') ? p : null;
      } catch {
        return null;
      }
    }
    return null;
  };

  // ✅ Accept object or JSON string; allow null to mean "clear"
  let unitsWeek = null;
  if (hasUnitsWeekKey) {
    if (body.additional_units_week === null) unitsWeek = {};
    else {
      const src = parseMaybeJsonObj(body.additional_units_week);
      unitsWeek = src ? normaliseUnitsWeek(src) : {};
    }
  }

  let unitsPerDay = null;
  if (hasUnitsPerDayKey) {
    if (body.additional_units_per_day === null) unitsPerDay = {};
    else {
      const src = parseMaybeJsonObj(body.additional_units_per_day);
      unitsPerDay = src ? normaliseUnitsPerDay(src) : {};
    }
  }

  // If missing, reuse from the current timesheet (if any)
  if ((!hasUnitsWeekKey || !hasUnitsPerDayKey) && currentTimesheetIdForWeek) {
    const tsExistingUnits = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetIdForWeek)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,additional_units_week,additional_units_per_day`
    );

    if (!hasUnitsWeekKey) {
      const u = tsExistingUnits?.additional_units_week;
      unitsWeek = (u && typeof u === 'object') ? normaliseUnitsWeek(u) : {};
    }
    if (!hasUnitsPerDayKey) {
      const u = tsExistingUnits?.additional_units_per_day;
      unitsPerDay = (u && typeof u === 'object') ? normaliseUnitsPerDay(u) : {};
    }
  }

  if (unitsWeek == null) unitsWeek = {};
  if (unitsPerDay == null) unitsPerDay = {};

  const addlConfig = Array.isArray(contract.additional_rates_json) ? contract.additional_rates_json : [];

  // Derive week dates (for per-day units)
  const weekDates = [];
  try {
    const base = new Date(String(cw.week_ending_date) + 'T00:00:00Z');
    for (let offset = 6; offset >= 0; offset--) {
      const d = new Date(base);
      d.setUTCDate(base.getUTCDate() - offset);
      const yyyy = d.getUTCFullYear();
      const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
      const dd   = String(d.getUTCDate()).toString().padStart(2, '0');
      const ymd  = `${yyyy}-${mm}-${dd}`;
      const dow  = d.getUTCDay();
      weekDates.push({ ymd, dow });
    }
  } catch {}

  let bhSet = new Set();
  try {
    const pol = await loadPolicy(env, contract.client_id || null, cw.week_ending_date);
    const bhList = Array.isArray(pol?.bh_list) ? pol.bh_list : [];
    bhSet = new Set(bhList.map(String));
  } catch {
    bhSet = new Set();
  }

  const isBH = (ymd) => bhSet.has(ymd);

  const normaliseFreq = (raw) => {
    const s = String(raw || '').toUpperCase();
    if (s === 'ONE_PER_WEEK')          return 'ONE_PER_WEEK';
    if (s === 'ONE_PER_DAY')           return 'ONE_PER_DAY';
    if (s === 'WEEKENDS_AND_BH_ONLY')  return 'WEEKENDS_AND_BH_ONLY';
    if (s === 'WEEKDAYS_EXCL_BH_ONLY') return 'WEEKDAYS_EXCL_BH_ONLY';
    return 'ONE_PER_WEEK';
  };

  const shouldIncludeDay = (freq, meta) => {
    const { ymd, dow } = meta;
    const bh = isBH(ymd);
    if (freq === 'ONE_PER_DAY')           return true;
    if (freq === 'WEEKENDS_AND_BH_ONLY')  return bh || dow === 0 || dow === 6;
    if (freq === 'WEEKDAYS_EXCL_BH_ONLY') return !bh && dow >= 1 && dow <= 5;
    return false;
  };

  // ✅ If per-day units were provided, restrict them to the 7 days of this week
  //    and derive coherent weekly totals when weekly wasn't provided.
  try {
    const weekDateSet = new Set((weekDates || []).map(x => String(x.ymd || '').slice(0, 10)));

    if (unitsPerDay && typeof unitsPerDay === 'object') {
      const cleaned = {};
      for (const [codeRaw, per] of Object.entries(unitsPerDay)) {
        const code = String(codeRaw || '').toUpperCase().trim();
        if (!code) continue;
        if (!per || typeof per !== 'object') continue;

        const days = {};
        for (const [dRaw, vRaw] of Object.entries(per)) {
          const ymd = String(dRaw || '').slice(0, 10);
          if (!weekDateSet.has(ymd)) continue;

          const n = Number(vRaw);
          if (!Number.isFinite(n) || n <= 0) continue;

          days[ymd] = n;
        }

        if (Object.keys(days).length) cleaned[code] = days;
      }

      unitsPerDay = cleaned;
    }

    // Derive weekly totals from per-day if weekly wasn't provided in this request
    if (hasUnitsPerDayKey && !hasUnitsWeekKey) {
      const derived = {};
      for (const cfgRaw of (addlConfig || [])) {
        if (!cfgRaw || typeof cfgRaw !== 'object') continue;
        const code = String(cfgRaw.code || '').toUpperCase() || 'EX1';
        const freq = normaliseFreq(cfgRaw.frequency);

        if (freq === 'ONE_PER_WEEK') continue;

        const perRaw = (unitsPerDay && unitsPerDay[code] && typeof unitsPerDay[code] === 'object') ? unitsPerDay[code] : {};
        let sum = 0;

        for (const meta of (weekDates || [])) {
          if (!shouldIncludeDay(freq, meta)) continue;
          const v = Number(perRaw[meta.ymd]);
          if (!Number.isFinite(v) || v <= 0) continue;
          sum += v;
        }

        if (sum > 0) derived[code] = sum;
      }

      unitsWeek = derived;
    }
  } catch {}

  let additional_units_json = {};
  let additional_pay_ex_vat = 0;
  let additional_charge_ex_vat = 0;
  const badBuckets = [];

  for (const cfgRaw of addlConfig) {
    if (!cfgRaw || typeof cfgRaw !== 'object') continue;
    const code = String(cfgRaw.code || '').toUpperCase() || 'EX1';
    const freq = normaliseFreq(cfgRaw.frequency);
    let unitCount = 0;
    const daysUsed = {};

    if (freq === 'ONE_PER_WEEK') {
      const u = Number(unitsWeek[code] || 0);
      if (u && Number.isFinite(u)) unitCount = u;
    } else {
      const perRaw = (unitsPerDay[code] && typeof unitsPerDay[code] === 'object') ? unitsPerDay[code] : {};
      for (const meta of weekDates) {
        const raw = perRaw[meta.ymd];
        if (raw == null || raw === '') continue;
        const v = Number(raw);
        if (!Number.isFinite(v) || !v) continue;
        if (!shouldIncludeDay(freq, meta)) continue;
        unitCount += v;
        daysUsed[meta.ymd] = v;
      }
    }

    if (!unitCount || !Number.isFinite(unitCount)) continue;

    const payRate    = (cfgRaw.pay_rate    != null) ? Number(cfgRaw.pay_rate)    : NaN;
    const chargeRate = (cfgRaw.charge_rate != null) ? Number(cfgRaw.charge_rate) : NaN;
    if (!Number.isFinite(payRate) || !Number.isFinite(chargeRate)) {
      badBuckets.push(cfgRaw.bucket_name || code);
      continue;
    }

    const payEx = +Number(unitCount * payRate).toFixed(2);
    const chgEx = +Number(unitCount * chargeRate).toFixed(2);

    additional_units_json[code] = {
      bucket_name: cfgRaw.bucket_name || null,
      unit_name:   cfgRaw.unit_name   || null,
      frequency:   freq,
      unit_count:  unitCount,
      pay_rate:    payRate,
      charge_rate: chargeRate,
      pay_ex_vat:  payEx,
      charge_ex_vat: chgEx,
      days: Object.keys(daysUsed).length ? daysUsed : undefined
    };

    additional_pay_ex_vat += payEx;
    additional_charge_ex_vat += chgEx;
  }

  if (badBuckets.length) {
    return withCORS(env, req, badRequest(`Missing additional rate(s) in contract for bucket(s): ${badBuckets.join(', ')}`));
  }

  additional_pay_ex_vat = +Number(additional_pay_ex_vat).toFixed(2);
  additional_charge_ex_vat = +Number(additional_charge_ex_vat).toFixed(2);
  const additional_margin_ex_vat = +Number(additional_charge_ex_vat - additional_pay_ex_vat).toFixed(2);

  // Load current timesheet row (if exists)
  let ts = currentTimesheetIdForWeek
    ? await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(currentTimesheetIdForWeek)}` +
          `&is_current=eq.true` +
          `&select=*`
      )
    : null;



  const hasAnySegmentInvoiceLock = (tf) => {
    try {
      const ib = tf?.invoice_breakdown_json;
      if (!ib || typeof ib !== 'object') return false;
      const mode = String(ib?.mode || '').toUpperCase();
      if (mode !== 'SEGMENTS') return false;
      const segs = Array.isArray(ib?.segments) ? ib.segments : [];
      return segs.some(s => {
        const v = s?.invoice_locked_invoice_id;
        return v != null && String(v).trim() !== '';
      });
    } catch {
      return false;
    }
  };

  // Lock enforcement: block changes if invoiced or paid
  let finLock = null;
  if (ts && ts.timesheet_id) {
    finLock = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
        `&is_current=eq.true&select=*`
    );
    if (finLock && (finLock.locked_by_invoice_id || hasAnySegmentInvoiceLock(finLock) || finLock.paid_at_utc)) {
      return withCORS(env, req, badRequest('Timesheet already invoiced or paid; changes are blocked'));
    }
  }

  // ✅ Preserve financial adjustments across recompute (even when schedule changes)
  // Use the current TSFIN snapshot (if present) as the source of truth.
  const preservedFin = finLock || null;

  // Helper: rotate the current timesheet version (preserve old QR/signed evidence by revoking old current)
  const rotateTimesheetVersion = async (currentTs, revokeReason, qrActionForNew) => {
    if (!currentTs || !currentTs.timesheet_id) return currentTs;

    const bookingId = currentTs.booking_id || null;
    if (!bookingId) throw new Error('Cannot rotate: booking_id missing on current timesheet');

    // Determine next version by booking_id
    let nextVersion = Number(currentTs.version || 1) + 1;
    try {
      const { rows: vRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?booking_id=eq.${enc(bookingId)}` +
          `&select=version` +
          `&order=version.desc` +
          `&limit=1`
      );
      const maxV = vRows?.[0]?.version != null ? Number(vRows[0].version) : Number(currentTs.version || 1);
      nextVersion = Number.isFinite(maxV) ? maxV + 1 : (Number(currentTs.version || 1) + 1);
    } catch {}

    const now2 = nowIso();

    // Demote any current row for this booking_id
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          is_current: false,
          status: 'REVOKED',
          revoked_reason: revokeReason || null,
          revoked_by: user?.id || null,
          updated_at: now2
        })
      }
    ).catch(() => {});

    const newRow = { ...currentTs };
    delete newRow.id;
    delete newRow.timesheet_id;

    const act = String(qrActionForNew || '').toUpperCase();

    const newIsQrPending =
      (act === 'INVALIDATE' || act === 'REISSUE' || act === 'ISSUE');

    const newIsManualOnly =
      (act === 'REVOKE_TO_MANUAL');

    Object.assign(newRow, {
      booking_id: bookingId,
      version: nextVersion,
      is_current: true,
      status: 'RECEIVED',
      revoked_reason: null,
      revoked_by: null,

      // ✅ New truth model:
      // INVALIDATE/REISSUE/ISSUE => QR enabled but not issued (token/gen cleared, qr_status=PENDING)
      // REVOKE_TO_MANUAL        => manual-only (qr fields cleared so QR UI won't show)
      qr_token: null,
      qr_status: newIsQrPending ? 'PENDING' : null,
      qr_payload_json: {},
      qr_generated_at: null,
      qr_scanned_at: null,
      qr_scan_info_json: null,
      qr_r2_key: null,

      // ✅ Hash-truth fields (must exist in DB)
      qr_last_sent_hash: null,
      qr_last_sent_at_utc: null,
      qr_signed_hash: null,
      qr_signed_at_utc: null,

      // ✅ Critical: a rotated "new current" must NOT keep any signed/manual evidence or authorisation.
      // The old signed copy remains on the revoked version for audit/history.
      manual_pdf_r2_key: null,
      authorised_at_server: null,

      updated_at: now2,
      created_at: now2
    });

    const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify([newRow])
    });

    if (!ins.ok) {
      const t = await ins.text().catch(() => '');
      throw new Error(`Failed to rotate timesheet version: ${t}`);
    }

    const created = (await ins.json().catch(() => []))[0] || null;

    // ✅ NEW: Purge superseded versions immediately (best-effort; never blocks caller)
    try {
      await purgeSupersededTimesheetArtifactsForBooking(env, bookingId);
    } catch (e) {
      try {
        console.warn('[ROTATE_TIMESHEET_VERSION] purge failed (non-fatal)', {
          booking_id: bookingId,
          err: e?.message || String(e)
        });
      } catch {}
    }

    return created || null;
  };

  // Determine QR action (enum preferred, legacy booleans fallback)
  let qrAction = null; // 'INVALIDATE' | 'REISSUE' | 'REVOKE_TO_MANUAL' | 'ISSUE' | null
  if (enumOk(qrActionEnumRaw)) {
    qrAction = qrActionEnumRaw;
  } else {
    if (rawReissueQr) qrAction = 'REISSUE';
    else if (rawRevokeQr) qrAction = 'REVOKE_TO_MANUAL';
  }

  // If QR action on existing QR timesheet, rotate FIRST so:
  // - the old signed/issued QR evidence stays on the revoked version for audit
  // - the new current version is clean / truthy for hashes + UI rules
  const hadQrBefore = !!(ts && (ts.qr_status || ts.qr_token || ts.qr_generated_at || ts.qr_scanned_at));

  if (
    ts && ts.timesheet_id &&
    hadQrBefore &&
    (qrAction === 'INVALIDATE' || qrAction === 'REISSUE' || qrAction === 'REVOKE_TO_MANUAL')
  ) {
    const why =
      (qrAction === 'INVALIDATE' || qrAction === 'REISSUE')
        ? 'QR_INVALIDATED_AFTER_CONTENT_CHANGE'
        : 'QR_REVOKED_TO_MANUAL';

    const rotated = await rotateTimesheetVersion(ts, why, qrAction);
    if (!rotated || !rotated.timesheet_id) {
      return withCORS(env, req, serverError('Failed to rotate timesheet version'));
    }
    ts = rotated;

    // Move contract_week pointer to the new current timesheet id
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({ timesheet_id: ts.timesheet_id, updated_at: nowIso2 })
      }
    ).catch(() => {});
  }

  // processing status:
  // - INVALIDATE/REISSUE/ISSUE => QR-enabled but not issued (awaiting signature evidence once sent)
  // - REVOKE_TO_MANUAL         => manual-only (admin will upload signature evidence manually)
  // In both cases we are still awaiting signature evidence, so keep AWAITING_MANUAL_SIGNATURE.
  const processingStatus =
    (qrAction === 'INVALIDATE' || qrAction === 'REISSUE' || qrAction === 'ISSUE' || qrAction === 'REVOKE_TO_MANUAL')
      ? 'AWAITING_MANUAL_SIGNATURE'
      : 'PENDING_AUTH';

  let createdNow = false;

  if (!ts) {
    // create new timesheet for this contract_week
    const occupant_norm = (candidate?.display_name || String(candidate?.id || 'worker')).toLowerCase();
    const hospital_norm = (contract.display_site || client?.name || String(contract.client_id)).toLowerCase();
    const ward_norm     = (contract.ward_hint || 'contract').toLowerCase();
    const job_title_norm= (contract.role || 'weekly').toLowerCase();

    const booking_id = await makeWeeklyBookingId(contract?.candidate_id || null, contract, cw);
    if (!booking_id || booking_id === '{}' || booking_id === 'null' || booking_id === 'undefined') {
      return withCORS(env, req, badRequest(`Invalid booking_id produced: "${booking_id}"`));
    }

    const payload = [{
      booking_id,
      version: 1,
      is_current: true,
      status: 'RECEIVED',
      occupant_key_norm: occupant_norm,
      hospital_norm, ward_norm, job_title_norm,
      shift_label_norm: 'weekly',
      week_ending_date: cw.week_ending_date,
      r2_nurse_key: null, r2_auth_key: null,
      contract_id: contract.id,
      sheet_scope: 'WEEKLY',
      submission_mode: 'MANUAL',

      manual_pdf_r2_key: cw.uploaded_pdf_r2_key || null,
      manual_pdf_rotation_degrees: manualPdfRotationDeg,
      line_type: 'HOURS',

      // ✅ schedule-driven truth
      actual_schedule_json,

      additional_units_week: unitsWeek || {},
      additional_units_per_day: unitsPerDay || {},

      // per-day refs are obsolete in this flow (per-shift ref_num lives inside schedule)
      day_references_json: null,

      authorised_at_server: null,
      created_at: nowIso2, updated_at: nowIso2,

      qr_payload_json: {},
      qr_status: null,
      qr_token: null,
      qr_generated_at: null,
      qr_scanned_at: null,
      qr_scan_info_json: null,
      qr_r2_key: null
    }];

    const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload)
    });
    if (!ins.ok) return withCORS(env, req, serverError(await ins.text()));

    ts = (await ins.json().catch(() => []))[0];
    createdNow = true;

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          timesheet_id: ts.timesheet_id,
          status: 'SUBMITTED',
          updated_at: nowIso2
        })
      }
    ).catch(() => {});

    try {
      await writeAudit(
        env,
        user,
        'TIMESHEET_CREATED',
        {
          timesheet_id: ts.timesheet_id,
          contract_week_id: cw.id,
          contract_id: contract.id,
          sheet_scope: 'WEEKLY',
          submission_mode: 'MANUAL',
          source: 'contract_week_manual_upsert',
          week_ending_date: cw.week_ending_date
        },
        { entity: 'timesheets', subject_id: ts.timesheet_id, req }
      );
    } catch {}
  } else {
    // Patch existing current timesheet for this week (always schedule-driven)
    const patchBody = { updated_at: nowIso2 };

    patchBody.actual_schedule_json = actual_schedule_json;

    if (body?.manual_pdf_rotation_degrees != null || body?.rotation_degrees != null) {
      patchBody.manual_pdf_rotation_degrees = manualPdfRotationDeg;
    }

    if (hasUnitsWeekKey) patchBody.additional_units_week = unitsWeek || {};
    if (hasUnitsPerDayKey) patchBody.additional_units_per_day = unitsPerDay || {};

    // ✅ Keep stored weekly totals coherent when per-day was provided
    if (hasUnitsPerDayKey && !hasUnitsWeekKey) patchBody.additional_units_week = unitsWeek || {};

    // do NOT set day_references_json here (obsolete)

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
      { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify(patchBody) }
    ).catch(() => {});
  }

  // policy snapshot (for holiday, etc.)
  let policySnapshot = {};
  try {
    policySnapshot = await loadPolicy(env, contract.client_id || null, cw.week_ending_date);
    if (!policySnapshot || typeof policySnapshot !== 'object') policySnapshot = {};
  } catch {
    policySnapshot = {};
  }

  const pay_wtr_rate_pct_snapshot =
    (String(method || '').toUpperCase() === 'PAYE' && policySnapshot && policySnapshot.holiday_pay_pct != null)
      ? Number(policySnapshot.holiday_pay_pct)
      : null;

  // ─────────────────────────────────────────────────────────────
  // TSFIN snapshot: ALWAYS SEGMENTS for schedule-driven weekly manual
  // (supports multiple shifts per day + per-shift ref_num)
  // ─────────────────────────────────────────────────────────────
  const segments = [];

  if (typeof ukLocalToUtcISO !== 'function') {
    throw new Error('ukLocalToUtcISO helper is missing (required for weekly conversion).');
  }

  const _addDaysYmd = (ymd, days) => {
    const d = new Date(`${String(ymd)}T00:00:00Z`);
    if (!Number.isFinite(d.getTime())) return String(ymd || '');
    d.setUTCDate(d.getUTCDate() + Number(days || 0));
    const yyyy = d.getUTCFullYear();
    const mm = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const _isIsoLike = (s) => {
    const x = String(s || '');
    return x.includes('T') && (x.endsWith('Z') || /[+\-]\d{2}:\d{2}$/.test(x));
  };

  const scheduleEntryToUtcRange = (seg) => {
    const date = String(seg?.date || '').trim();
    if (!date) return { startUtcIso: null, endUtcIso: null };

    const startIsoRaw = seg?.start_utc || seg?.start_iso || null;
    const endIsoRaw   = seg?.end_utc   || seg?.end_iso   || null;
    if (startIsoRaw && endIsoRaw && _isIsoLike(startIsoRaw) && _isIsoLike(endIsoRaw)) {
      return { startUtcIso: String(startIsoRaw), endUtcIso: String(endIsoRaw) };
    }

    const startHH = String(seg?.start || '').trim();
    const endHH   = String(seg?.end   || '').trim();
    if (!startHH || !endHH) return { startUtcIso: null, endUtcIso: null };

    const sMin = parseHHMM(startHH);
    const eMin = parseHHMM(endHH);
    if (sMin == null || eMin == null) return { startUtcIso: null, endUtcIso: null };

    const overnight = (eMin <= sMin);
    const endYmd = overnight ? _addDaysYmd(date, 1) : date;

    return {
      startUtcIso: ukLocalToUtcISO(date, startHH),
      endUtcIso:   ukLocalToUtcISO(endYmd, endHH)
    };
  };

  // Per-segment bucket calc (consistent w/ resolveBucketsFromSchedule)
  let segPayTotal = 0;
  let segChgTotal = 0;

  for (let i = 0; i < actual_schedule_json.length; i++) {
    const seg = actual_schedule_json[i] || {};
    const date = String(seg.date || '').trim();
    if (!date) continue;

    const { startUtcIso, endUtcIso } = scheduleEntryToUtcRange(seg);
    if (!startUtcIso || !endUtcIso) continue;

    // bucket mins for THIS segment using the same resolver
    let minsByBucketSeg = null;
    try {
      minsByBucketSeg = await resolveBucketsFromSchedule(env, contract, [seg]);
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid schedule segment'));
    }

    const h = {
      hours_day:   +(minsByBucketSeg.day   / 60).toFixed(2),
      hours_night: +(minsByBucketSeg.night / 60).toFixed(2),
      hours_sat:   +(minsByBucketSeg.sat   / 60).toFixed(2),
      hours_sun:   +(minsByBucketSeg.sun   / 60).toFixed(2),
      hours_bh:    +(minsByBucketSeg.bh    / 60).toFixed(2)
    };

    const p = pay || {};
    const c = charge || {};

    const segPay = round2(
      (h.hours_day   || 0) * asNumberLocal(p.day)   +
      (h.hours_night || 0) * asNumberLocal(p.night) +
      (h.hours_sat   || 0) * asNumberLocal(p.sat)   +
      (h.hours_sun   || 0) * asNumberLocal(p.sun)   +
      (h.hours_bh    || 0) * asNumberLocal(p.bh)
    );

    const segChg = round2(
      (h.hours_day   || 0) * asNumberLocal(c.day)   +
      (h.hours_night || 0) * asNumberLocal(c.night) +
      (h.hours_sat   || 0) * asNumberLocal(c.sat)   +
      (h.hours_sun   || 0) * asNumberLocal(c.sun)   +
      (h.hours_bh    || 0) * asNumberLocal(c.bh)
    );

    segPayTotal += segPay;
    segChgTotal += segChg;

    const br = Number(seg.break_mins ?? seg.break_minutes ?? 0);

    segments.push({
      segment_id: `ts:${ts.timesheet_id}:${i}`,
      date,
      start_utc: startUtcIso,
      end_utc: endUtcIso,
      break_mins: Number.isFinite(br) ? br : 0,

      // ✅ per-shift reference number (supports multiple refs per day)
      ref_num: (seg.ref_num != null && String(seg.ref_num).trim()) ? String(seg.ref_num).trim() : null,

      // optional: keep breaks array for audit/debug
      breaks: Array.isArray(seg.breaks) ? seg.breaks : [],

      hours_day:   h.hours_day   || 0,
      hours_night: h.hours_night || 0,
      hours_sat:   h.hours_sat   || 0,
      hours_sun:   h.hours_sun   || 0,
      hours_bh:    h.hours_bh    || 0,

      pay_amount: segPay,
      charge_amount: segChg,
      exclude_from_pay: false
    });
  }

  const basePay = round2(segPayTotal);
  const baseCharge = round2(segChgTotal);

  // ✅ Preserve expenses + mileage values (and include in totals)
  const expPay   = round2(asNumberLocal(preservedFin?.expenses_pay_ex_vat ?? 0));
  const expChg   = round2(asNumberLocal(preservedFin?.expenses_charge_ex_vat ?? 0));
  const milPay   = round2(asNumberLocal(preservedFin?.mileage_pay_ex_vat ?? 0));
  const milChg   = round2(asNumberLocal(preservedFin?.mileage_charge_ex_vat ?? 0));
  const milUnits = round2(asNumberLocal(preservedFin?.mileage_units ?? 0));

  // ✅ Negative margin check applies ONLY to base+additional (expenses/mileage may be negative margin)
  const corePay = round2(basePay + additional_pay_ex_vat);
  const coreChg = round2(baseCharge + additional_charge_ex_vat);
  const coreMargin = round2(coreChg - corePay);
  if (coreMargin < 0) {
    return withCORS(env, req, badRequest('Negative margin: total charge is less than total pay.'));
  }

  const total_pay = round2(corePay + expPay + milPay);
  const total_chg = round2(coreChg + expChg + milChg);
  const margin = round2(total_chg - total_pay);

  const snap = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,
    basis: 'CONTRACT_WEEKLY',
    candidate_id: contract.candidate_id,
    client_id: contract.client_id,
    role: contract.role || null,
    band: contract.band || null,
    candidate_assignment: contract.candidate_id ? 'ASSIGNED' : 'UNASSIGNED',
    processing_status: processingStatus,
    pay_method: method,

    // hours buckets derived from schedule (authoritative)
    hours_day: Number(hours.day || 0),
    hours_night: Number(hours.night || 0),
    hours_sat: Number(hours.sat || 0),
    hours_sun: Number(hours.sun || 0),
    hours_bh: Number(hours.bh || 0),
    total_hours: round2(
      Number(hours.day || 0) +
      Number(hours.night || 0) +
      Number(hours.sat || 0) +
      Number(hours.sun || 0) +
      Number(hours.bh || 0)
    ),

    pay_day: pay.day, pay_night: pay.night, pay_sat: pay.sat, pay_sun: pay.sun, pay_bh: pay.bh,
    charge_day: charge.day, charge_night: charge.night, charge_sat: charge.sat, charge_sun: charge.sun, charge_bh: charge.bh,

    total_pay_ex_vat: total_pay,
    total_charge_ex_vat: total_chg,
    margin_ex_vat: margin,

    additional_units_json,
    additional_pay_ex_vat,
    additional_charge_ex_vat,
    additional_margin_ex_vat,

    // ✅ PRESERVE expenses fields
    expenses_pay_ex_vat: expPay,
    expenses_charge_ex_vat: expChg,
    expenses_description: preservedFin?.expenses_description ?? null,
    expenses_evidence_r2_key: preservedFin?.expenses_evidence_r2_key ?? null,
    expenses_evidence_manifest: preservedFin?.expenses_evidence_manifest ?? null,

    // ✅ PRESERVE mileage fields (+ units)
    mileage_units: milUnits,
    mileage_pay_ex_vat: milPay,
    mileage_charge_ex_vat: milChg,
    mileage_evidence_r2_key: preservedFin?.mileage_evidence_r2_key ?? null,
    mileage_evidence_manifest: preservedFin?.mileage_evidence_manifest ?? null,
    mileage_pay_rate: preservedFin?.mileage_pay_rate ?? null,
    mileage_charge_rate: preservedFin?.mileage_charge_rate ?? null,

    pay_on_hold: false,
    pay_on_hold_reason: null,
    pay_on_hold_since_utc: null,

    paid_at_utc: null,
    paid_by_user_id: null,
    payment_reference: null,

    policy_snapshot_json: policySnapshot,
    rate_source_refs_json: { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null },
    pay_wtr_rate_pct_snapshot,

    created_at: nowIso2,
    invoice_breakdown_json: {
      mode: 'SEGMENTS',
      segments,
      additional: {
        units: additional_units_json,
        pay_ex_vat: additional_pay_ex_vat,
        charge_ex_vat: additional_charge_ex_vat,
        margin_ex_vat: additional_margin_ex_vat
      },
      totals: {
        total_pay_ex_vat: total_pay,
        total_charge_ex_vat: total_chg,
        margin_ex_vat: margin
      }
    }
  };

  // ✅ Write TSFIN using SQL-backed outbox + batch writer.
  // Uses your new RPCs:
  // - enqueue_ts_financials_priority
  // - tsfin_dequeue_specific
  // - tsfin_write_snapshots_and_complete
  let outboxId = null;
  let wroteViaSql = false;

  try {
    // 1) Ensure a single outbox row exists for this timesheet (unique constraint dedupes)
    await sbRpc(env, 'enqueue_ts_financials_priority', {
      _timesheet_ids: [ts.timesheet_id],
      _reason: 'CONTEXT_CHANGED'
    });

    // ✅ FIX (C): RPC-only deterministic lease (no REST lookup of ts_financials_outbox)
    const leased = await sbRpc(env, 'tsfin_dequeue_specific', {
      p_timesheet_ids: [ts.timesheet_id],
      p_limit: 1
    });
    const row = Array.isArray(leased) ? leased[0] : null;
    outboxId = row?.id || row?.outbox_id || null;

    // 3) Write snapshot + complete outbox in one RPC
    if (outboxId) {
      const wr = await rpcTsfinWriteSnapshotsAndComplete(env, {
        rows: [{
          outbox_id: outboxId,
          timesheet_id: ts.timesheet_id,
          snapshot: snap
        }]
      });

      wroteViaSql = (Number(wr?.ok_count || 0) > 0);
    }
  } catch (e) {
    try {
      console.warn('[CONTRACT_WEEK_MANUAL_UPSERT] SQL TSFIN write failed (fallback)', {
        timesheet_id: ts?.timesheet_id,
        err: e?.message || String(e)
      });
    } catch {}
  }

  // Fallback: preserve legacy behaviour if SQL path fails (rare)
  if (!wroteViaSql) {
    await writeSnapshot(env, snap);

    // ✅ best-effort: clear the outbox row we created so it doesn't churn later
    if (outboxId) {
      try { await sbRpc(env, 'tsfin_work_success', { p_id: outboxId }); } catch {}
    }
  }

  // Persist week totals + schedule + weekly extras (draft-per-day refs removed)
  const existingWeekTotals = (cw.totals_json && typeof cw.totals_json === 'object') ? cw.totals_json : {};
  const mergedWeekTotals = { ...existingWeekTotals, hours };

  // ✅ Persist weekly totals if provided OR derived from per-day
  if (hasUnitsWeekKey) mergedWeekTotals.additional_units_week = unitsWeek || {};
  if (hasUnitsPerDayKey && !hasUnitsWeekKey) mergedWeekTotals.additional_units_week = unitsWeek || {};

  // ✅ Persist per-day units when provided
  if (hasUnitsPerDayKey) mergedWeekTotals.additional_units_per_day = unitsPerDay || {};

  const weekPatch = {
    totals_json: mergedWeekTotals,
    planned_schedule_json: actual_schedule_json, // keep week schedule aligned for future view/processing
    updated_at: nowIso2
  };

  await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
    { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify(weekPatch) }
  ).catch(() => {});

  return withCORS(env, req, ok({
    timesheet_id: ts.timesheet_id,
    current_timesheet_id: ts.timesheet_id,
    was_stale: !!wasStaleWeekTs,
    processing_status: processingStatus,
    hours,
    used_schedule: true,
    created_now: !!createdNow
  }));
}



 async function handleManualTimesheetQueueEnqueue(env, req) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const files = Array.isArray(body?.files) ? body.files : [];
  if (!files.length) {
    return withCORS(env, req, badRequest('files[] is required and must be a non-empty array'));
  }

  // Normalise rotation to 0/90/180/270 – optional for queue viewer
  const normaliseRotation = (raw) => {
    if (raw == null) return 0;
    let n = Number(raw);
    if (!Number.isFinite(n)) return 0;
    n = ((n % 360) + 360) % 360;
    if (n >= 315 || n < 45) return 0;
    if (n >= 45 && n < 135) return 90;
    if (n >= 135 && n < 225) return 180;
    return 270;
  };

  // Collect distinct, non-empty hashes from this batch
  const batchHashes = Array.from(
    new Set(
      files
        .map(f => String(f?.content_hash || '').trim())
        .filter(Boolean)
    )
  );

  // 1) Load existing active queue items for these hashes to avoid duplicates
  const existingByHash = new Map();
  if (batchHashes.length) {
    const hashParam = batchHashes.map(h => enc(h)).join(',');
    const { rows: existingRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue` +
        `?content_hash=in.(${hashParam})` +
        `&status=in.(QUEUED,IN_PROGRESS)` +
        `&select=id,content_hash`
    );
    for (const r of existingRows || []) {
      if (r.content_hash) {
        existingByHash.set(String(r.content_hash), r);
      }
    }
  }

  const seenInRequest = new Set();
  const enqueued = [];
  const duplicates = [];
  const errors = [];

  for (const f of files) {
    const r2Key  = String(f?.r2_key || '').trim();
    const fname  = String(f?.original_filename || '').trim();
    const mime   = f?.mime_type ? String(f.mime_type) : null;
    const hash   = String(f?.content_hash || '').trim();
    const rotDeg = normaliseRotation(f?.rotation_degrees);

    if (!r2Key || !fname || !hash) {
      errors.push({
        r2_key: r2Key || null,
        original_filename: fname || null,
        reason: 'MISSING_FIELDS'
      });
      continue;
    }

    // Deduplicate within the same request
    if (seenInRequest.has(hash)) {
      duplicates.push({
        r2_key: r2Key,
        original_filename: fname,
        reason: 'DUPLICATE_IN_REQUEST'
      });
      continue;
    }
    seenInRequest.add(hash);

    // Deduplicate against existing active queue rows
    if (existingByHash.has(hash)) {
      duplicates.push({
        r2_key: r2Key,
        original_filename: fname,
        existing_queue_id: existingByHash.get(hash).id,
        reason: 'ALREADY_IN_QUEUE'
      });
      continue;
    }

    // Insert into manual_timesheet_queue
    const payload = {
      r2_key: r2Key,
      original_filename: fname,
      mime_type: mime,
      content_hash: hash,
      uploaded_by_user_id: user.id,
      last_rotation_deg: rotDeg
    };

    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify(payload)
      }
    );

    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      // If we hit the partial unique index because of a race, treat as duplicate
      if (/duplicate key value/i.test(txt) || res.status === 409) {
        duplicates.push({
          r2_key: r2Key,
          original_filename: fname,
          reason: 'ALREADY_IN_QUEUE_RACE'
        });
        continue;
      }

      errors.push({
        r2_key: r2Key,
        original_filename: fname,
        reason: 'INSERT_FAILED',
        detail: txt || null
      });
      continue;
    }

    const json = await res.json().catch(() => []);
    const rec = Array.isArray(json) ? json[0] : json;
    if (!rec?.id) {
      errors.push({
        r2_key: r2Key,
        original_filename: fname,
        reason: 'NO_ID_RETURNED'
      });
      continue;
    }
    enqueued.push(rec);
    existingByHash.set(hash, rec);
  }

  return withCORS(env, req, ok({
    enqueued,
    duplicates,
    errors
  }));
}

 async function handleManualTimesheetQueueList(env, req) {
  const enc = encodeURIComponent;
  const url = new URL(req.url);
  const q = (k) => url.searchParams.get(k);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const statusParam = (q('status') || 'QUEUED').trim();
  const uploadedBy  = (q('uploaded_by') || '').trim();
  const limitParam  = q('limit');
  const limit       = limitParam ? Math.min(Math.max(Number(limitParam) || 0, 1), 500) : 100;

  const fromDate    = (q('uploaded_from') || '').trim();
  const toDate      = (q('uploaded_to') || '').trim();

  const statuses = statusParam
    .split(',')
    .map(s => s.trim().toUpperCase())
    .filter(Boolean);

  let urlStr =
    `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue` +
    `?select=*` +
    `&order=uploaded_at_utc.desc`;

  if (statuses.length === 1) {
    urlStr += `&status=eq.${enc(statuses[0])}`;
  } else if (statuses.length > 1) {
    urlStr += `&status=in.(${statuses.map(enc).join(',')})`;
  }

  if (uploadedBy) {
    urlStr += `&uploaded_by_user_id=eq.${enc(uploadedBy)}`;
  }

  if (fromDate) {
    urlStr += `&uploaded_at_utc=gte.${enc(fromDate)}`;
  }
  if (toDate) {
    urlStr += `&uploaded_at_utc=lte.${enc(toDate)}`;
  }

  urlStr += `&limit=${limit}`;

  try {
    const { rows } = await sbFetch(env, urlStr);
    return withCORS(env, req, ok({
      items: rows || []
    }));
  } catch (e) {
    console.error('[MT_QUEUE_LIST] error', {
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to list manual timesheet queue'));
  }
}


 async function handleManualTimesheetQueueGet(env, req, queueId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!queueId) {
    return withCORS(env, req, badRequest('queue_id is required'));
  }

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue` +
      `?id=eq.${enc(queueId)}` +
      `&select=*` +
      `&limit=1`
    );
    const item = rows?.[0] || null;
    if (!item) {
      return withCORS(env, req, notFound('Queue item not found'));
    }

    return withCORS(env, req, ok({ item }));
  } catch (e) {
    console.error('[MT_QUEUE_GET] error', {
      queue_id: queueId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to load manual timesheet queue item'));
  }
}
 async function handleManualTimesheetQueueDelete(env, req, queueId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!queueId) {
    return withCORS(env, req, badRequest('queue_id is required'));
  }

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue` +
      `?id=eq.${enc(queueId)}` +
      `&select=id,status,timesheet_id,r2_key,original_filename` +
      `&limit=1`
    );
    const item = rows?.[0] || null;
    if (!item) {
      return withCORS(env, req, notFound('Queue item not found'));
    }

    const status = String(item.status || '').toUpperCase();
    if (status === 'ATTACHED') {
      return withCORS(env, req, badRequest('Cannot delete: item is already attached to a timesheet'));
    }

    const patchRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue?id=eq.${enc(queueId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({ status: 'DISCARDED' })
      }
    );

    if (!patchRes.ok) {
      const txt = await patchRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to discard queue item: ${txt}`));
    }

    try {
      await writeAudit(
        env,
        user,
        'MANUAL_TIMESHEET_QUEUE_DISCARDED',
        {
          queue_id: item.id,
          r2_key: item.r2_key,
          original_filename: item.original_filename
        },
        { entity: 'manual_timesheet_queue', subject_id: item.id, req }
      );
    } catch {
      // best-effort
    }

    return withCORS(env, req, ok({ discarded: true, id: item.id }));
  } catch (e) {
    console.error('[MT_QUEUE_DELETE] error', {
      queue_id: queueId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to discard manual timesheet queue item'));
  }
}

// BE FIX: require expected_timesheet_id + resolve to CURRENT; strict 409 payload; patch queue + timesheet using CURRENT id only
async function handleManualTimesheetQueueAttach(env, req, queueId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!queueId) return withCORS(env, req, badRequest('queue_id is required'));

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const requestedTimesheetId = String(body?.timesheet_id || '').trim();
  if (!requestedTimesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // ✅ resolve + guard
  const resolved = await resolveTimesheetToCurrent(env, requestedTimesheetId);
  const currentTimesheetId = resolved?.current_timesheet_id ? String(resolved.current_timesheet_id) : '';
  if (!currentTimesheetId) return withCORS(env, req, badRequest('Timesheet not found for timesheet_id'));

  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }), {
        status: 409,
        headers: { 'Content-Type': 'application/json' }
      })
    );
  }

  try {
    const { rows: qRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue` +
        `?id=eq.${enc(queueId)}` +
        `&select=id,status,timesheet_id,content_hash,r2_key,last_rotation_deg,meta_json` +
        `&limit=1`
    );
    const item = qRows?.[0] || null;
    if (!item) return withCORS(env, req, notFound('Queue item not found'));

    const status = String(item.status || '').toUpperCase();

    if (status === 'ATTACHED') {
      const attachedId = String(item.timesheet_id || '').trim();
      if (!attachedId) return withCORS(env, req, badRequest('Queue item is marked ATTACHED but has no timesheet_id'));

      const attachedResolved = await resolveTimesheetToCurrent(env, attachedId).catch(() => null);
      const attachedCurrent = attachedResolved?.current_timesheet_id ? String(attachedResolved.current_timesheet_id) : attachedId;

      if (String(attachedCurrent) === String(currentTimesheetId)) {
        // Best-effort: normalise queue row to current id
        if (String(attachedId) !== String(currentTimesheetId)) {
          await fetch(`${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue?id=eq.${enc(queueId)}`, {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({ timesheet_id: currentTimesheetId })
          }).catch(() => {});
        }

        return withCORS(env, req, ok({ attached: true, id: item.id, timesheet_id: currentTimesheetId, current_timesheet_id: currentTimesheetId }));
      }

      return withCORS(env, req, badRequest('Queue item already attached to a different timesheet'));
    }

    if (status === 'DISCARDED') return withCORS(env, req, badRequest('Cannot attach a discarded queue item'));

    // Validate CURRENT timesheet exists
    const ts = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}&select=timesheet_id&limit=1`
    );
    if (!ts) return withCORS(env, req, badRequest('Timesheet not found for timesheet_id'));

    // 1) Patch queue: ATTACHED + CURRENT id
    const patchQueueRes = await fetch(`${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue?id=eq.${enc(queueId)}`, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({ status: 'ATTACHED', timesheet_id: currentTimesheetId })
    });

    if (!patchQueueRes.ok) {
      const txt = await patchQueueRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to attach queue item: ${txt}`));
    }

    // 2) Patch CURRENT timesheet to use PDF
    if (item.r2_key) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            manual_pdf_r2_key: item.r2_key,
            manual_pdf_rotation_degrees: (item.last_rotation_deg != null ? Number(item.last_rotation_deg) : 0)
          })
        }
      ).catch(() => {});
    }

    try {
      await writeAudit(
        env,
        user,
        'MANUAL_TIMESHEET_QUEUE_ATTACHED',
        {
          queue_id: item.id,
          requested_timesheet_id: requestedTimesheetId,
          current_timesheet_id: currentTimesheetId,
          content_hash: item.content_hash || null,
          r2_key: item.r2_key || null
        },
        { entity: 'manual_timesheet_queue', subject_id: item.id, req }
      );
    } catch {}

    return withCORS(env, req, ok({ attached: true, id: item.id, timesheet_id: currentTimesheetId, current_timesheet_id: currentTimesheetId }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to attach manual timesheet queue item'));
  }
}





 async function handleManualTimesheetQueueRotate(env, req, queueId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!queueId) {
    return withCORS(env, req, badRequest('queue_id is required'));
  }

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const rawRot = body?.rotation_degrees;
  if (rawRot == null) {
    return withCORS(env, req, badRequest('rotation_degrees is required'));
  }

  const normaliseRotation = (raw) => {
    let n = Number(raw);
    if (!Number.isFinite(n)) return 0;
    n = ((n % 360) + 360) % 360;
    if (n >= 315 || n < 45) return 0;
    if (n >= 45 && n < 135) return 90;
    if (n >= 135 && n < 225) return 180;
    return 270;
  };

  const deg = normaliseRotation(rawRot);

  try {
    // Ensure queue item exists
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue` +
      `?id=eq.${enc(queueId)}` +
      `&select=id,last_rotation_deg` +
      `&limit=1`
    );
    const item = rows?.[0] || null;
    if (!item) {
      return withCORS(env, req, notFound('Queue item not found'));
    }

    const patchRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/manual_timesheet_queue?id=eq.${enc(queueId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify({ last_rotation_deg: deg })
      }
    );

    if (!patchRes.ok) {
      const txt = await patchRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to update rotation: ${txt}`));
    }

    const updated = (await patchRes.json().catch(() => []))[0] || { id: queueId, last_rotation_deg: deg };

    try {
      await writeAudit(
        env,
        user,
        'MANUAL_TIMESHEET_QUEUE_ROTATED',
        {
          queue_id: updated.id,
          last_rotation_deg: updated.last_rotation_deg
        },
        { entity: 'manual_timesheet_queue', subject_id: updated.id, req }
      );
    } catch {
      // best-effort
    }

    return withCORS(env, req, ok({
      id: updated.id,
      last_rotation_deg: updated.last_rotation_deg
    }));
  } catch (e) {
    console.error('[MT_QUEUE_ROTATE] error', {
      queue_id: queueId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to update manual timesheet queue rotation'));
  }
}

async function handleTimesheetPdf(env, req, timesheetId) {
  const enc = encodeURIComponent;

  // Admin auth
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!timesheetId) {
    return withCORS(env, req, badRequest('timesheet_id is required'));
  }

  try {
    // ✅ Stale-safe resolve (read path)
    const resolved = await resolveTimesheetToCurrent(env, timesheetId);
    if (!resolved?.current_timesheet_id) {
      return withCORS(env, req, notFound('Timesheet not found'));
    }

    const currentTimesheetId = String(resolved.current_timesheet_id);

    // ensureTimesheetPdf will either:
    // - return manual scanned evidence key (manual_pdf_r2_key) if present and allowed, OR
    // - return the generated/system PDF key
    const r2Key = await ensureTimesheetPdf(env, currentTimesheetId);
    if (!r2Key) {
      return withCORS(env, req, serverError('Failed to ensure timesheet PDF'));
    }

    // ✅ Rotation: only apply to scanned/manual evidence PDFs
    // (Generated/system PDFs should always be 0 rotation.)
    let rotationDeg = 0;
    try {
      const { rows: tsRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&is_current=eq.true` +
          `&select=manual_pdf_r2_key,manual_pdf_rotation_degrees` +
          `&limit=1`
      );
      const ts = tsRows?.[0] || null;

      const manualKey = ts?.manual_pdf_r2_key ? normalizeKey(ts.manual_pdf_r2_key) : null;
      const usedKey = r2Key ? normalizeKey(r2Key) : null;

      // Only rotate if we're actually returning the manual scanned PDF
      if (manualKey && usedKey && manualKey === usedKey) {
        const n = Number(ts.manual_pdf_rotation_degrees);
        if (Number.isFinite(n)) rotationDeg = n;
      }
    } catch {
      rotationDeg = 0;
    }

    return withCORS(env, req, ok({
      requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
      current_timesheet_id: currentTimesheetId,
      was_stale: !!resolved.was_stale,

      r2_key: r2Key,
      rotation_degrees: rotationDeg
    }));
  } catch (e) {
    console.error('[TIMESHEET_PDF] error', {
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to generate or locate timesheet PDF'));
  }
}

// BE FIX: expected guard + resolve CW-linked timesheet to CURRENT before mutating TS/TSFIN; strict 409 payload


async function handleContractWeekManualAuthorise(env, req, weekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const boolish = (v) => {
    if (v === true) return true;
    if (v === false) return false;
    if (v == null) return false;
    const s = String(v).trim().toLowerCase();
    return (s === 'true' || s === '1' || s === 'yes' || s === 'y' || s === 'on');
  };

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=id,contract_id,timesheet_id`
  );
  if (!cw?.timesheet_id) return withCORS(env, req, badRequest('No timesheet linked to this week'));

  // Resolve + guard
  const resolved = await resolveTimesheetToCurrent(env, cw.timesheet_id);
  const currentTimesheetId = resolved?.current_timesheet_id ? String(resolved.current_timesheet_id) : '';
  if (!currentTimesheetId) return withCORS(env, req, notFound('Timesheet not found'));

  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }), {
        status: 409,
        headers: { 'Content-Type': 'application/json' }
      })
    );
  }

  const now = nowIso();

  // Load CURRENT TS + TSFIN (include basis)
  const tsBefore = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=timesheet_id,contract_id,authorised_at_server,submission_mode,sheet_scope,version,status`
  ).catch(() => null);

  const { rows: finRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=id,client_id,basis,processing_status,locked_by_invoice_id,paid_at_utc`
  );
  const fin = finRows?.[0] || null;

  const finBeforeStatus = String(fin?.processing_status || '').toUpperCase();
  let finAfterStatus = fin?.processing_status || null;

  if (fin) {
    const ps = finBeforeStatus;

    // Guard for QR print/sign flow
    if (ps === 'QR_PENDING_SIGNATURE' || ps === 'AWAITING_QR_SIGNATURE') {
      return withCORS(env, req, badRequest('Timesheet is awaiting QR/manual signature; cannot authorise yet'));
    }

    if (fin.locked_by_invoice_id || fin.paid_at_utc) {
      return withCORS(env, req, badRequest('Cannot authorise: timesheet is locked or paid'));
    }

    // Policy B bases: authorise must unlock invoicing directly
    const basisU = String(fin?.basis || '').toUpperCase();
    const forceReadyForInvoice =
      (basisU === 'NHSP' ||
       basisU === 'NHSP_ADJUSTMENT' ||
       basisU === 'HEALTHROSTER_SELF_BILL' ||
       basisU === 'HEALTHROSTER_ADJUSTMENT');

    let requiresHr = false;

    if (!forceReadyForInvoice) {
      // Prefer v_timesheets_summary effective flag
      let eff = null;
      try {
        const { rows: eRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
            `?timesheet_id=eq.${enc(currentTimesheetId)}` +
            `&select=client_requires_hr` +
            `&limit=1`
        );
        eff = eRows?.[0] || null;
      } catch {}

      if (eff && Object.prototype.hasOwnProperty.call(eff, 'client_requires_hr')) {
        requiresHr = boolish(eff.client_requires_hr);
      } else {
        // Fallback: contract column if non-null; else client_settings
        let contractRequires = null;
        try {
          const contractId = (cw.contract_id || tsBefore?.contract_id) ? String(cw.contract_id || tsBefore.contract_id) : '';
          if (contractId) {
            const c = await sbGetOne(
              env,
              `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=requires_hr&limit=1`
            );
            if (c && Object.prototype.hasOwnProperty.call(c, 'requires_hr') && c.requires_hr !== null) {
              contractRequires = !!c.requires_hr;
            }
          }
        } catch {}

        if (contractRequires != null) {
          requiresHr = !!contractRequires;
        } else if (fin.client_id) {
          const { rows: csRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/client_settings` +
              `?client_id=eq.${enc(fin.client_id)}` +
              `&select=requires_hr` +
              `&order=effective_from.desc&limit=1`
          );
          requiresHr = !!csRows?.[0]?.requires_hr;
        }
      }
    }

    let newStatus = fin.processing_status;
    if (ps === 'PENDING_AUTH' || ps === 'READY_FOR_HR') {
      newStatus = forceReadyForInvoice
        ? 'READY_FOR_INVOICE'
        : (requiresHr ? 'READY_FOR_HR' : 'READY_FOR_INVOICE');
    }
    finAfterStatus = newStatus;

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          processing_status: newStatus,
          authorised_by_user_id: user.id,
          authorised_at_utc: now,
          updated_at: now
        })
      }
    ).catch(() => {});
  }

  // Stamp timesheet as authorised (CURRENT only)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({ authorised_at_server: now, updated_at: now })
    }
  ).catch(() => {});

  // Update week status → AUTHORISED
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({ status: 'AUTHORISED', updated_at: now })
    }
  ).catch(() => {});

  // Audit
  try {
    const wasAlreadyAuthorised = !!(tsBefore && tsBefore.authorised_at_server);
    const didPromoteStatus = !!(finAfterStatus && String(finBeforeStatus || '') !== String(finAfterStatus || ''));

    if (!wasAlreadyAuthorised || didPromoteStatus) {
      await writeAudit(
        env,
        user,
        'TIMESHEET_AUTHORISED',
        {
          timesheet_id: currentTimesheetId,
          contract_week_id: weekId,
          authorised_at_utc: now,
          tsfin_processing_status_before: finBeforeStatus || null,
          tsfin_processing_status_after: finAfterStatus ? String(finAfterStatus).toUpperCase() : null
        },
        {
          entity: 'timesheets',
          subject_id: currentTimesheetId,
          req,
          before: {
            authorised_at_server: tsBefore?.authorised_at_server || null,
            tsfin_processing_status: finBeforeStatus || null
          },
          reason: didPromoteStatus ? 'PROMOTED_TSFIN_STATUS' : 'STAMPED_AUTHORISE'
        }
      );
    }
  } catch {}

  return withCORS(env, req, ok({ authorised: true, timesheet_id: currentTimesheetId }));
}










async function handleTimesheetUpdateReference(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  // NEW: guarded write (optimistic concurrency)
  const expectedTimesheetId = body?.expected_timesheet_id || null;
  const guard = await guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId);
  if (!guard.ok) return guard.res;

  const currentTimesheetId = guard.resolved.current_timesheet_id;

  const reference_number = (body?.reference_number || '').trim();

  // NEW: patch only the CURRENT timesheet row
  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({ reference_number, updated_at: nowIso() })
    }
  );

  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const row = (await res.json().catch(() => []))[0];

  return withCORS(env, req, ok({
    ...row,
    booking_id: guard.resolved.booking_id || null,
    requested_timesheet_id: guard.resolved.requested_timesheet_id || timesheetId,
    current_timesheet_id: currentTimesheetId,
    current_version: guard.resolved.current_version ?? null,
    was_stale: !!guard.resolved.was_stale
  }));
}

async function handleTimesheetDetails(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!timesheetId) {
    return withCORS(env, req, badRequest('timesheet_id is required'));
  }

  try {
    // ─────────────────────────────────────────────────────────────
    // Resolve stale/historical timesheet_id -> current by booking_id
    // ─────────────────────────────────────────────────────────────
    const resolved = await resolveTimesheetToCurrent(env, timesheetId);
    if (!resolved) {
      return withCORS(env, req, notFound('Timesheet not found'));
    }

    const bookingId = resolved.booking_id || null;
    const currentTimesheetId = resolved.current_timesheet_id || timesheetId;

    // Current timesheet record (ALWAYS load by current_timesheet_id)
    let ts = null;
    {
      const { rows: tsRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&select=*` +
          `&limit=1`
      );
      ts = tsRows?.[0] || null;
    }
    if (!ts) {
      return withCORS(env, req, notFound('Timesheet not found'));
    }

    // Linked contract_week (if any) - points at CURRENT row id
    let contractWeekId = null;
    let contractWeek = null;
    try {
      const { rows: cwRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&select=*` +
          `&limit=1`
      );
      contractWeek = cwRows?.[0] || null;
      contractWeekId = contractWeek?.id || null;
    } catch {
      contractWeekId = null;
      contractWeek = null;
    }

    // ✅ NEW: adjustment detection used to hard-block convert actions
    const isAdjustment = !!(ts?.is_adjustment || contractWeek?.is_adjustment);

    // Current TSFIN snapshot (current TSFIN row keyed to current timesheet_id)
    let tsfinRaw = null;
    {
      const { rows: finRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&is_current=eq.true` +
          `&select=*` +
          `&limit=1`
      );
      tsfinRaw = finRows?.[0] || null;
    }

    // ─────────────────────────────────────────────────────────────
    // ✅ NEW: Repair-on-open for corrupt SEGMENTS snapshots
    // If TSFIN has invalid segment elements, enqueue priority + run worker once for this timesheet,
    // then re-fetch TSFIN before returning details.
    // ─────────────────────────────────────────────────────────────
    try {
      const ib0 = tsfinRaw?.invoice_breakdown_json;
      const segs0 =
        (ib0 && typeof ib0 === 'object' && String(ib0.mode || '').toUpperCase() === 'SEGMENTS' && Array.isArray(ib0.segments))
          ? ib0.segments
          : null;

      if (segs0 && segs0.length) {
        let invalidCount0 = 0;
        for (const s0 of segs0) {
          const isObj0 = !!(s0 && typeof s0 === 'object' && !Array.isArray(s0));
          const sid0 = isObj0 ? String(s0.segment_id || '').trim() : '';
          if (!isObj0 || !sid0) invalidCount0++;
        }

        if (invalidCount0 > 0) {
          // Enqueue TSFIN recompute with priority and run the worker once for this id
          try {
            await sbRpc(env, 'enqueue_ts_financials_priority', {
              _timesheet_ids: [currentTimesheetId],
              _reason: 'CONTEXT_CHANGED'
            });
          } catch {}

          try {
            await runTsfinWorkerOnce(env, { limit: 50, onlyTimesheetIds: [currentTimesheetId] });
          } catch {}

          // Re-fetch TSFIN after worker attempt
          try {
            const { rows: finRows2 } = await sbFetch(
              env,
              `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
                `?timesheet_id=eq.${enc(currentTimesheetId)}` +
                `&is_current=eq.true` +
                `&select=*` +
                `&limit=1`
            );
            tsfinRaw = finRows2?.[0] || tsfinRaw;
          } catch {}
        }
      }
    } catch {}

    // ─────────────────────────────────────────────────────────────
    // Contract-resolved EFFECTIVE flags (source of truth = v_timesheets_summary)
    // ─────────────────────────────────────────────────────────────
    let summaryRow = null;
    try {
      const { rows: sRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&select=*` +
          `&limit=1`
      );
      summaryRow = sRows?.[0] || null;
    } catch {
      summaryRow = null;
    }

    const effective = summaryRow ? {
      route_type: summaryRow.route_type ?? null,
      summary_stage: summaryRow.summary_stage ?? null,

      client_requires_hr: summaryRow.client_requires_hr,
      client_autoprocess_hr: summaryRow.client_autoprocess_hr,
      client_no_timesheet_required: summaryRow.client_no_timesheet_required,
      client_is_nhsp: summaryRow.client_is_nhsp,

      contract_id: summaryRow.contract_id ?? contractWeek?.contract_id ?? ts.contract_id ?? null,
      require_reference_to_pay: summaryRow.require_reference_to_pay,
      require_reference_to_invoice: summaryRow.require_reference_to_invoice,

      ready_to_pay: summaryRow.ready_to_pay,
      issue_codes: summaryRow.issue_codes
    } : {
      route_type: null,
      summary_stage: null,

      client_requires_hr: undefined,
      client_autoprocess_hr: undefined,
      client_no_timesheet_required: undefined,
      client_is_nhsp: undefined,

      contract_id: contractWeek?.contract_id ?? ts.contract_id ?? null,
      require_reference_to_pay: undefined,
      require_reference_to_invoice: undefined,

      ready_to_pay: undefined,
      issue_codes: undefined
    };

    // Validation rows (most recent first)
    const { rows: valRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheet_validations` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=*` +
        `&order=validated_at_utc.desc,created_at.desc`
    );
    const validations = valRows || [];

    // Linked nhsp_shifts (if any)
    const { rows: shiftRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=*` +
        `&order=work_date.asc,start_utc.asc`
    );
    const shifts = shiftRows || [];

    // ───────────────────── Policy snapshot (SQL-first; avoids broken loadPolicy) ─────────────────────
    let policy = null;
    let supportsElectronicSubmission = false;

    try {
      const fromFin = tsfinRaw?.policy_snapshot_json;
      if (fromFin && typeof fromFin === 'object') {
        policy = fromFin;
      } else if (typeof fromFin === 'string') {
        try {
          const parsed = JSON.parse(fromFin);
          if (parsed && typeof parsed === 'object') policy = parsed;
        } catch {}
      }

      if (!policy) {
        const ctxRows = await sbRpc(env, 'tsfin_load_context_batch', { p_timesheet_ids: [currentTimesheetId] });
        const ctx = Array.isArray(ctxRows) ? ctxRows[0] : (ctxRows || null);

        let pol = ctx?.out_policy ?? null;
        if (typeof pol === 'string') {
          try { pol = JSON.parse(pol); } catch { pol = null; }
        }
        policy = (pol && typeof pol === 'object') ? pol : null;
      }

      const dsm = String(policy?.default_submission_mode || '').toUpperCase();
      supportsElectronicSubmission = (dsm === 'ELECTRONIC');
    } catch (e) {
      console.warn('[TIMESHEET_DETAILS] policy resolution failed (non-fatal)', {
        timesheet_id: currentTimesheetId,
        err: e?.message || String(e)
      });
      policy = null;
      supportsElectronicSubmission = false;
    }

    // ───────────────────── Derived route/scenario helpers ─────────────────────
    const subMode = String(ts.submission_mode || '').toUpperCase();
    const qrStatus = String(ts.qr_status || '').toUpperCase() || null;

    const hasQrToken = !!(ts.qr_token && String(ts.qr_token).trim());
    const hasQrGenerated = !!ts.qr_generated_at;
    const hasQrScanned = !!ts.qr_scanned_at;

    const isManualOnly =
      (subMode === 'MANUAL') &&
      !qrStatus &&
      !hasQrToken &&
      !hasQrGenerated &&
      !hasQrScanned;

    let qrScenario = null;

    if (qrStatus === 'CANCELLED') {
      qrScenario = 'CANCELLED';
    } else if (qrStatus === 'EXPIRED') {
      qrScenario = 'EXPIRED';
    } else if (qrStatus === 'PENDING') {
      if (!hasQrToken && !hasQrGenerated) qrScenario = 'SCENARIO_1';
      else if (hasQrToken && hasQrGenerated && !hasQrScanned) qrScenario = 'SCENARIO_2';
      else qrScenario = 'SCENARIO_2';
    } else if (qrStatus === 'USED') {
      qrScenario = hasQrScanned ? 'SCENARIO_3' : 'SCENARIO_3';
    } else {
      qrScenario = null;
    }

    // Locks
    const isLockedByInvoice = !!(tsfinRaw?.locked_by_invoice_id);
    const isPaid = !!(tsfinRaw?.paid_at_utc);
    const isHardLocked = isLockedByInvoice || isPaid;

    // Action availability flags (history by booking_id)
    let canRestoreQrPending = false;
    let canRestoreQrSigned = false;
    let canRevertToElectronic = false;

    if (bookingId) {
      try {
        const { rows: pendingRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?booking_id=eq.${enc(bookingId)}` +
            `&is_current=eq.false` +
            `&qr_status=eq.PENDING` +
            `&qr_generated_at=is.not.null` +
            `&qr_scanned_at=is.null` +
            `&qr_token=is.not.null` +
            `&select=timesheet_id,version` +
            `&order=version.desc` +
            `&limit=1`
        );
        canRestoreQrPending = !!(pendingRows && pendingRows.length);
      } catch {}

      try {
        const { rows: signedRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?booking_id=eq.${enc(bookingId)}` +
            `&is_current=eq.false` +
            `&qr_status=eq.USED` +
            `&qr_scanned_at=is.not.null` +
            `&manual_pdf_r2_key=is.not.null` +
            `&select=timesheet_id,version` +
            `&order=version.desc` +
            `&limit=1`
        );
        canRestoreQrSigned = !!(signedRows && signedRows.length);
      } catch {}

      try {
        const { rows: elecRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?booking_id=eq.${enc(bookingId)}` +
            `&is_current=eq.false` +
            `&submission_mode=eq.ELECTRONIC` +
            `&select=timesheet_id,version` +
            `&order=version.desc` +
            `&limit=1`
        );
        canRevertToElectronic = !!(elecRows && elecRows.length);
      } catch {}
    }

    // ✅ UPDATED: adjustment sheets cannot be converted/restored to QR/Electronic
    if (isAdjustment) {
      canRestoreQrPending = false;
      canRestoreQrSigned = false;
      canRevertToElectronic = false;
    }

    const canAllowQrAgain = (!isHardLocked) && isManualOnly && !isAdjustment;
    const canAllowElectronicAgain = (!isHardLocked) && isManualOnly && supportsElectronicSubmission && !isAdjustment;

    // Shape TS + TSFIN for FE
    const timesheetOut = {
      ...ts,
      day_references_json: Object.prototype.hasOwnProperty.call(ts, 'day_references_json')
        ? ts.day_references_json
        : null
    };

    const tsfinOut = tsfinRaw
      ? {
          ...tsfinRaw,
          hr_crosscheck_status: Object.prototype.hasOwnProperty.call(tsfinRaw, 'hr_crosscheck_status')
            ? tsfinRaw.hr_crosscheck_status
            : null,
          hr_crosscheck_issues: Object.prototype.hasOwnProperty.call(tsfinRaw, 'hr_crosscheck_issues')
            ? tsfinRaw.hr_crosscheck_issues
            : null,
          external_source_rows_json: Object.prototype.hasOwnProperty.call(tsfinRaw, 'external_source_rows_json')
            ? tsfinRaw.external_source_rows_json
            : null
        }
      : null;

    const invoiceBreakdown =
      (tsfinOut && tsfinOut.invoice_breakdown_json && typeof tsfinOut.invoice_breakdown_json === 'object')
        ? tsfinOut.invoice_breakdown_json
        : null;

    const isSegmentsMode =
      !!(invoiceBreakdown && String(invoiceBreakdown.mode || '').toUpperCase() === 'SEGMENTS');

    const segments =
      (isSegmentsMode && invoiceBreakdown && Array.isArray(invoiceBreakdown.segments))
        ? invoiceBreakdown.segments
        : [];

    // ✅ NEW: invoice_no_by_invoice_id (segment-aware)
    // - includes whole-timesheet locked_by_invoice_id
    // - plus any segment.invoice_locked_invoice_id
    const invoice_no_by_invoice_id = (() => Object.create(null))();
    try {
      const isUuid = (s) => /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i.test(String(s || '').trim());

      const invIdSet = new Set();

      const wholeInvId = tsfinOut?.locked_by_invoice_id != null ? String(tsfinOut.locked_by_invoice_id).trim() : '';
      if (wholeInvId && isUuid(wholeInvId)) invIdSet.add(wholeInvId);

      for (const seg of (Array.isArray(segments) ? segments : [])) {
        if (!seg || typeof seg !== 'object') continue;
        const segInvId = seg.invoice_locked_invoice_id != null ? String(seg.invoice_locked_invoice_id).trim() : '';
        if (segInvId && isUuid(segInvId)) invIdSet.add(segInvId);
      }

      const allIds = Array.from(invIdSet);
      if (allIds.length) {
        const chunkSize = 200;

        // Primary: invoices table (expects id + invoice_no)
        let lookedUp = false;
        try {
          for (let i = 0; i < allIds.length; i += chunkSize) {
            const chunk = allIds.slice(i, i + chunkSize);
            const { rows: invRows } = await sbFetch(
              env,
              `${env.SUPABASE_URL}/rest/v1/invoices` +
                `?select=id,invoice_no` +
                `&id=in.(${chunk.map(encodeURIComponent).join(',')})`
            );

            for (const r of (invRows || [])) {
              const id = r?.id != null ? String(r.id).trim() : '';
              const no = (r?.invoice_no != null) ? String(r.invoice_no).trim() : '';
              if (id && no) invoice_no_by_invoice_id[id] = no;
            }
          }
          lookedUp = true;
        } catch {
          lookedUp = false;
        }

        // Fallback: try v_invoices_summary (if invoices table select fails)
        if (!lookedUp) {
          try {
            for (let i = 0; i < allIds.length; i += chunkSize) {
              const chunk = allIds.slice(i, i + chunkSize);
              const { rows: invRows2 } = await sbFetch(
                env,
                `${env.SUPABASE_URL}/rest/v1/v_invoices_summary` +
                  `?select=id,invoice_no` +
                  `&id=in.(${chunk.map(encodeURIComponent).join(',')})`
              );

              for (const r of (invRows2 || [])) {
                const id = r?.id != null ? String(r.id).trim() : '';
                const no = (r?.invoice_no != null) ? String(r.invoice_no).trim() : '';
                if (id && no) invoice_no_by_invoice_id[id] = no;
              }
            }
          } catch {
            // final fallback: leave map empty (do not fail timesheet details)
          }
        }
      }
    } catch {
      // leave empty
    }

    const action_flags = {
      can_restore_qr_pending: (!isHardLocked) && canRestoreQrPending,
      can_restore_qr_signed: (!isHardLocked) && canRestoreQrSigned,
      can_revert_to_electronic: (!isHardLocked) && canRevertToElectronic,

      can_allow_qr_again: canAllowQrAgain,
      can_allow_electronic_again: canAllowElectronicAgain,

      supports_electronic_submission: supportsElectronicSubmission,
      is_manual_only: isManualOnly,
      qr_scenario: qrScenario,

      // ✅ include so FE can hide conversion actions decisively
      is_adjustment: isAdjustment,

      locked_by_invoice: isLockedByInvoice,
      paid: isPaid
    };

    return withCORS(env, req, ok({
      booking_id: bookingId,
      requested_timesheet_id: resolved.requested_timesheet_id,
      current_timesheet_id: resolved.current_timesheet_id,
      current_version: resolved.current_version,
      was_stale: resolved.was_stale,

      timesheet: timesheetOut,
      tsfin: tsfinOut,

      invoiceBreakdown,
      isSegmentsMode,
      segments,

      // ✅ NEW (for FE “Invoiced – <invoice_no>” rendering)
      invoice_no_by_invoice_id,

      validations,
      shifts,

      effective, // ✅ contract-resolved effective flags

      // backwards-compatible echoes
      ready_to_pay: !!effective.ready_to_pay,
      summary_stage: effective.summary_stage || null,
      route_type: effective.route_type || null,
      issue_codes: Array.isArray(effective.issue_codes) ? effective.issue_codes : [],

      sheet_scope: ts.sheet_scope || null,
      qr_status: ts.qr_status || null,
      qr_generated_at: ts.qr_generated_at || null,
      qr_scanned_at: ts.qr_scanned_at || null,
      manual_pdf_r2_key: ts.manual_pdf_r2_key || null,

      contract_week_id: contractWeekId,
      contract_week: contractWeek,

      policy,
      evidence: [],
      action_flags
    }));
  } catch (e) {
    console.error('[TIMESHEET_DETAILS] error', {
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to load timesheet details'));
  }
}



async function handleTimesheetUnauthorise(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  // NEW: require expected_timesheet_id for guarded write
  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const expectedTimesheetId = body?.expected_timesheet_id || null;
  const guard = await guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId);
  if (!guard.ok) return guard.res;

  const currentTimesheetId = guard.resolved.current_timesheet_id;

  const now = nowIso();

  const { rows: finRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=id,locked_by_invoice_id,paid_at_utc,processing_status`
  );
  const fin = finRows?.[0] || null;
  if (!fin) {
    return withCORS(env, req, badRequest('No financial snapshot to unauthorise'));
  }

  if (fin.locked_by_invoice_id || fin.paid_at_utc) {
    return withCORS(env, req, badRequest('Cannot unauthorise: timesheet is locked or paid'));
  }

  // Clear authorised_at_server on the timesheet
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({ authorised_at_server: null, updated_at: now })
    }
  ).catch(() => {});

  // Set status back to PENDING_AUTH
  const prevStatus = String(fin.processing_status || '').toUpperCase();
  const newStatus = 'PENDING_AUTH';

  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({
        processing_status: newStatus,
        authorised_by_user_id: null,
        authorised_at_utc: null,
        updated_at: now
      })
    }
  ).catch(() => {});

  return withCORS(env, req, ok({
    unauthorised: true,
    processing_status: newStatus,
    previous_status: prevStatus,
    booking_id: guard.resolved.booking_id || null,
    requested_timesheet_id: guard.resolved.requested_timesheet_id || timesheetId,
    current_timesheet_id: currentTimesheetId,
    current_version: guard.resolved.current_version ?? null,
    was_stale: !!guard.resolved.was_stale
  }));
}

async function handleTimesheetDailyManualUpsert(env, req, timesheetId) {
  const enc = encodeURIComponent;

  // 1) Auth
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!timesheetId) {
    return withCORS(env, req, badRequest('timesheet_id is required'));
  }

  // 2) Parse body
  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  // NEW: guarded write (optimistic concurrency)
  const expectedTimesheetId = body?.expected_timesheet_id || null;
  const guard = await guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId);
  if (!guard.ok) return guard.res;

  // From here on, always act on the CURRENT timesheet row.
  let currentTimesheetId = guard.resolved.current_timesheet_id;

  const has = (k) => Object.prototype.hasOwnProperty.call(body || {}, k);

  // Optional helper input (do NOT patch to DB unless you actually have this column)
  let worked_date_ymd = body?.worked_date_ymd ? String(body.worked_date_ymd) : null;

  // Worked/break inputs (only patch if provided)
  const worked_start_iso_in = has('worked_start_iso') ? body.worked_start_iso : undefined;
  const worked_end_iso_in   = has('worked_end_iso')   ? body.worked_end_iso   : undefined;
  const break_start_iso_in  = has('break_start_iso')  ? body.break_start_iso  : undefined;
  const break_end_iso_in    = has('break_end_iso')    ? body.break_end_iso    : undefined;
  const break_minutes_in    = has('break_minutes')    ? body.break_minutes    : undefined;

  // NEW: schedule_json payload (preferred FE shape for daily upsert)
  const schedule_json_in    = has('schedule_json')    ? body.schedule_json    : undefined;

  // QR action hints from FE decision modal (legacy booleans still supported)
  const rawIssueQr        = body?.issue_qr === true;
  const rawDisableQr      = body?.disable_qr === true;
  const rawRevokeToManual = body?.revoke_to_manual === true;
  const rawRevokeQr       = body?.revoke_qr === true;   // legacy
  const rawReissueQr      = body?.reissue_qr === true;  // legacy

  // ✅ NEW: preferred enum (from After-save decision modal)
  const qrActionEnumRaw = String(body?.qr_action || body?.qrAction || '').trim().toUpperCase();
  const enumOk = (x) => (
    x === 'INVALIDATE' ||
    x === 'REVOKE_TO_MANUAL' ||
    x === 'REISSUE' ||
    x === 'ISSUE' ||
    x === 'DISABLE' ||
    x === 'SAVE_WITHOUT_ISSUE'
  );

  const now = nowIso();

  // ✅ FIX: daily-manual-upsert no longer issues/resends QR.
  // These legacy variables must exist so the function does not throw ReferenceError.
  const qrIssued   = false;
  const qrReissued = false;
  const qrToken    = null;
  const qr_r2_key  = null;
  const pdfKey     = null;

  // Helpers
  const normIso = (v) => {
    if (v === undefined) return undefined;
    if (v === null) return null;
    const s = String(v).trim();
    return s ? s : null; // treat '' as null (clear)
  };

  const hasIso = (v) => (v != null && String(v).trim() !== '');

  const isoToMs = (iso) => {
    if (!hasIso(iso)) return null;
    const t = new Date(String(iso)).getTime();
    return Number.isFinite(t) ? t : null;
  };

  const bad = (msg) => withCORS(env, req, badRequest(msg));

  const parseYmd = (ymdStr) => {
    if (!ymdStr || typeof ymdStr !== 'string') return null;
    const m = ymdStr.trim().match(/^(\d{4})-(\d{2})-(\d{2})$/);
    if (!m) return null;
    const y = Number(m[1]), mo = Number(m[2]), d = Number(m[3]);
    if (!Number.isFinite(y) || !Number.isFinite(mo) || !Number.isFinite(d)) return null;
    if (mo < 1 || mo > 12 || d < 1 || d > 31) return null;
    return { y, mo, d };
  };

  const addDaysYmd = (ymdStr, days) => {
    const p = parseYmd(ymdStr);
    if (!p) return null;
    const dt = new Date(Date.UTC(p.y, p.mo - 1, p.d, 0, 0, 0, 0));
    dt.setUTCDate(dt.getUTCDate() + Number(days || 0));
    const y = dt.getUTCFullYear();
    const m = String(dt.getUTCMonth() + 1).padStart(2, '0');
    const d = String(dt.getUTCDate()).padStart(2, '0');
    return `${y}-${m}-${d}`;
  };

  const normaliseHHMM = (raw) => {
    let s = String(raw || '').trim();
    if (!s) return '';
    if (/^\d{1,2}:\d{2}$/.test(s)) {
      const [h, m] = s.split(':');
      const hh = String(Number(h) || 0).padStart(2, '0');
      const mm = String(Number(m) || 0).padStart(2, '0');
      return `${hh}:${mm}`;
    }
    s = s.replace(':', '');
    if (!/^\d{1,4}$/.test(s)) return '';
    if (s.length <= 2) {
      const h = Number(s);
      if (!Number.isFinite(h)) return '';
      return `${String(h).padStart(2, '0')}:00`;
    }
    const mm = s.slice(-2);
    const h  = s.slice(0, -2);
    const hh = String(Number(h) || 0).padStart(2, '0');
    const mm2 = String(Number(mm) || 0).padStart(2, '0');
    return `${hh}:${mm2}`;
  };

  const hhmmToMinutes = (hhmm) => {
    if (!hhmm || typeof hhmm !== 'string') return null;
    const m = hhmm.trim().match(/^(\d{2}):(\d{2})$/);
    if (!m) return null;
    const h = Number(m[1]);
    const mi = Number(m[2]);
    if (!Number.isFinite(h) || !Number.isFinite(mi)) return null;
    if (h < 0 || h > 23 || mi < 0 || mi > 59) return null;
    return h * 60 + mi;
  };

  const getLondonOffsetHours = (ymdStr) => {
    try {
      if (typeof isBSTLocal === 'function') return isBSTLocal(ymdStr) ? 1 : 0;
    } catch {}
    return 0;
  };

  const localYmdHhmmToIsoUtc = (ymdStr, hhmmStr) => {
    const p = parseYmd(ymdStr);
    if (!p) return null;
    const normT = normaliseHHMM(hhmmStr);
    const mins = hhmmToMinutes(normT);
    if (mins == null) return null;
    const hh = Math.floor(mins / 60);
    const mm = mins % 60;
    const off = getLondonOffsetHours(ymdStr);
    const ms = Date.UTC(p.y, p.mo - 1, p.d, hh - off, mm, 0, 0);
    return new Date(ms).toISOString();
  };

  // Map schedule_json -> ISO fields (Europe/London local HH:MM + YMD -> UTC ISO)
  const mapScheduleJsonToIso = (scheduleJson) => {
    let seg = null;

    if (Array.isArray(scheduleJson)) {
      const nonNull = scheduleJson.filter(x => x && typeof x === 'object');
      if (!nonNull.length) return { error: 'schedule_json must contain at least one day entry.' };
      if (nonNull.length > 1) {
        const dates = new Set(nonNull.map(x => String(x.date || x.work_date || x.ymd || '').trim()).filter(Boolean));
        if (dates.size > 1) return { error: 'DAILY schedule_json must contain exactly one date entry.' };
      }
      seg = nonNull[0];
    } else if (scheduleJson && typeof scheduleJson === 'object') {
      seg = scheduleJson;
    } else {
      return { error: 'schedule_json must be an object or array.' };
    }

    const ymdStrRaw = String(seg.date || seg.work_date || seg.ymd || '').trim();
    const ymdStr = ymdStrRaw || null;
    if (!ymdStr || !parseYmd(ymdStr)) return { error: 'schedule_json.date must be a valid YYYY-MM-DD.' };

    const startHHMM = normaliseHHMM(seg.start || seg.worked_start || '');
    const endHHMM   = normaliseHHMM(seg.end   || seg.worked_end   || '');

    const hasStart = !!startHHMM;
    const hasEnd   = !!endHHMM;

    if (hasStart !== hasEnd) return { error: 'schedule_json.start and schedule_json.end must both be present (or both blank).' };

    let worked_start_iso = null;
    let worked_end_iso   = null;

    let shiftStartMin0 = null;
    let shiftEndMin0   = null;
    let shiftStartAdj  = null;
    let shiftEndAdj    = null;

    if (hasStart && hasEnd) {
      shiftStartMin0 = hhmmToMinutes(startHHMM);
      shiftEndMin0   = hhmmToMinutes(endHHMM);
      if (shiftStartMin0 == null || shiftEndMin0 == null) return { error: 'schedule_json.start/end must be valid HH:MM.' };
      if (shiftStartMin0 === shiftEndMin0) return { error: 'schedule_json.start cannot equal schedule_json.end.' };

      shiftStartAdj = shiftStartMin0;
      shiftEndAdj   = (shiftEndMin0 > shiftStartMin0) ? shiftEndMin0 : (shiftEndMin0 + 1440);

      const endDayAdd = Math.floor(shiftEndAdj / 1440);
      const endYmd = addDaysYmd(ymdStr, endDayAdd);
      if (!endYmd) return { error: 'Failed to compute overnight end date.' };

      worked_start_iso = localYmdHhmmToIsoUtc(ymdStr, startHHMM);
      worked_end_iso   = localYmdHhmmToIsoUtc(
        endYmd,
        normaliseHHMM(`${Math.floor((shiftEndAdj % 1440) / 60)}:${String((shiftEndAdj % 1440) % 60).padStart(2,'0')}`)
      );

      if (!worked_start_iso || !worked_end_iso) return { error: 'Failed to convert schedule_json.start/end to ISO.' };
    }

    // Break source: prefer explicit fields; else breaks[0]
    let brStartHHMM = normaliseHHMM(seg.break_start || '');
    let brEndHHMM   = normaliseHHMM(seg.break_end   || '');

    const breaksArr = Array.isArray(seg.breaks) ? seg.breaks : [];
    const meaningfulBreaks = breaksArr.filter(b => b && typeof b === 'object' && (String(b.start || '').trim() || String(b.end || '').trim()));

    if ((!brStartHHMM && !brEndHHMM) && meaningfulBreaks.length) {
      brStartHHMM = normaliseHHMM(meaningfulBreaks[0].start || '');
      brEndHHMM   = normaliseHHMM(meaningfulBreaks[0].end   || '');
    }

    if (meaningfulBreaks.length > 1) {
      return { error: 'DAILY schedule_json supports only one break window. Remove extra breaks or use break_minutes only.' };
    }

    const hasBrStart = !!brStartHHMM;
    const hasBrEnd   = !!brEndHHMM;

    if (hasBrStart !== hasBrEnd) return { error: 'schedule_json.break_start and schedule_json.break_end must both be present (or both blank).' };

    let break_start_iso = null;
    let break_end_iso   = null;
    let break_minutes   = null;

    // If break times are provided: compute ISO + minutes (overnight-aware using shift timeline)
    if (hasBrStart && hasBrEnd) {
      if (!(hasStart && hasEnd)) return { error: 'Cannot set a break window without a worked start/end.' };

      const bs0 = hhmmToMinutes(brStartHHMM);
      const be0 = hhmmToMinutes(brEndHHMM);
      if (bs0 == null || be0 == null) return { error: 'schedule_json.break_start/end must be valid HH:MM.' };
      if (bs0 === be0) return { error: 'schedule_json.break_start cannot equal schedule_json.break_end.' };

      // Place break on the same adjusted timeline as the shift
      let bsAdj = bs0;
      if (bsAdj < shiftStartAdj) bsAdj += 1440;

      let beAdj = be0;
      if (beAdj < bsAdj) beAdj += 1440;

      if (bsAdj < shiftStartAdj || beAdj > shiftEndAdj || beAdj <= bsAdj) {
        return { error: 'Break window must be within the worked shift span (overnight-aware).' };
      }

      const bsDayAdd = Math.floor(bsAdj / 1440);
      const beDayAdd = Math.floor(beAdj / 1440);

      const bsYmd = addDaysYmd(ymdStr, bsDayAdd);
      const beYmd = addDaysYmd(ymdStr, beDayAdd);
      if (!bsYmd || !beYmd) return { error: 'Failed to compute break dates.' };

      const bsM = bsAdj % 1440;
      const beM = beAdj % 1440;

      const bsHH = String(Math.floor(bsM / 60)).padStart(2, '0');
      const bsMM = String(bsM % 60).padStart(2, '0');

      const beHH = String(Math.floor(beM / 60)).padStart(2, '0');
      const beMM = String(beM % 60).padStart(2, '0');

      break_start_iso = localYmdHhmmToIsoUtc(bsYmd, `${bsHH}:${bsMM}`);
      break_end_iso   = localYmdHhmmToIsoUtc(beYmd, `${beHH}:${beMM}`);

      if (!break_start_iso || !break_end_iso) return { error: 'Failed to convert break window to ISO.' };

      break_minutes = Math.round((beAdj - bsAdj));
      if (!(break_minutes > 0)) return { error: 'Break duration must be > 0 minutes.' };
    } else {
      // No break window: accept numeric break minutes if present
      let bm =
        (seg.break_minutes != null) ? Number(seg.break_minutes) :
        (seg.break_mins    != null) ? Number(seg.break_mins) :
        null;

      if (bm != null && !Number.isFinite(bm)) bm = null;

      if (bm != null) {
        if (!(hasStart && hasEnd)) return { error: 'Cannot set break_minutes without a worked start/end.' };
        bm = Math.round(bm);
        if (bm < 0) return { error: 'break_minutes must be a non-negative number.' };
        const shiftLen = shiftEndAdj - shiftStartAdj;
        if (bm > shiftLen) return { error: 'break_minutes cannot exceed the worked shift duration.' };
        break_minutes = bm;
      }
    }

    return {
      ymd: ymdStr,
      worked_start_iso,
      worked_end_iso,
      break_start_iso,
      break_end_iso,
      break_minutes
    };
  };

  // Helper: rotate current TS -> history, insert new current version (restorable)
  const rotateTimesheetVersion = async (currentTs, revokeReason, qrActionForNew) => {
    if (!currentTs || !currentTs.timesheet_id) return currentTs;

    const oldVersion = Number(currentTs.version || 1);
    const newVersion = oldVersion + 1;
    const now2 = nowIso();

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTs.timesheet_id)}` +
        `&version=eq.${enc(oldVersion)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          is_current: false,
          status: 'REVOKED',
          revoked_reason: revokeReason || null,
          revoked_by: user?.id || null,
          updated_at: now2
        })
      }
    );

    const act = String(qrActionForNew || '').toUpperCase();
    const newIsQrPending = (act === 'INVALIDATE' || act === 'REISSUE' || act === 'ISSUE');
    const newIsManualOnly = (act === 'REVOKE_TO_MANUAL' || act === 'DISABLE');

    const newRow = {
      ...currentTs,
      version: newVersion,
      is_current: true,

      status: currentTs.status || 'RECEIVED',

      revoked_reason: null,
      revoked_by: null,

      // ✅ Recommended: new current should not inherit signed/manual evidence or authorisation after QR invalidate/reissue
      manual_pdf_r2_key: (newIsQrPending ? null : null),
      authorised_at_server: (newIsQrPending ? null : null),

      // ✅ QR state:
      // INVALIDATE/REISSUE/ISSUE => QR enabled but not issued (token/gen cleared, qr_status=PENDING)
      // REVOKE_TO_MANUAL/DISABLE => manual-only (clear QR state so UI doesn't show QR)
      qr_token: null,
      qr_status: newIsQrPending ? 'PENDING' : null,
      qr_payload_json: {},     // never null
      qr_generated_at: null,
      qr_scanned_at: null,
      qr_scan_info_json: null,
      qr_r2_key: null,

      // ✅ Hash truth fields (must exist in DB)
      qr_last_sent_hash: null,
      qr_last_sent_at_utc: null,
      qr_signed_hash: null,
      qr_signed_at_utc: null,

      updated_at: now2,
      created_at: now2
    };

    delete newRow.id;
    delete newRow.timesheet_id;

    const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify([newRow])
    });

    if (!ins.ok) {
      const t = await ins.text().catch(() => '');
      throw new Error(`Failed to rotate daily timesheet version: ${t}`);
    }

    const created = (await ins.json().catch(() => []))[0] || null;

    // ✅ NEW: purge superseded versions immediately (best-effort; never blocks caller)
    // ✅ FIX: do NOT reference bookingId here (it is not in scope); only use values available here.
    try {
      const bid = (created?.booking_id || currentTs?.booking_id || null);
      if (bid) {
        await purgeSupersededTimesheetArtifactsForBooking(env, bid);
      }
    } catch (e) {
      try {
        console.warn('[DAILY_MANUAL_UPSERT][ROTATE] purge failed (non-fatal)', {
          booking_id: (created?.booking_id || currentTs?.booking_id || null),
          err: e?.message || String(e)
        });
      } catch {}
    }

    return created || { ...currentTs, version: newVersion, is_current: true };
  };

  // 3) Load DAILY timesheet (current version) — use currentTimesheetId
  let ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  const sheetScope = String(ts.sheet_scope || '').toUpperCase();
  if (sheetScope !== 'DAILY') {
    return bad('Timesheet is not DAILY; daily-manual-upsert only applies to DAILY sheets');
  }

  const subMode = String(ts.submission_mode || '').toUpperCase();
  if (subMode !== 'MANUAL') {
    return bad('Timesheet must be MANUAL before editing hours. Use switch-daily-to-manual first.');
  }

  // 4) Load TSFIN – must not be locked/paid — use currentTimesheetId
  const tsfin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );
  if (!tsfin) return withCORS(env, req, serverError('No TSFIN snapshot found'));

  if (tsfin.locked_by_invoice_id || tsfin.paid_at_utc) {
    return bad('Timesheet already invoiced or paid; cannot edit');
  }

  // ─────────────────────────────────────────────────────────────
  // NEW: schedule_json -> ISO mapping (runs BEFORE validation)
  // ─────────────────────────────────────────────────────────────
  const scheduleProvided = (schedule_json_in !== undefined);
  let mappedWorkedStartIso = worked_start_iso_in;
  let mappedWorkedEndIso   = worked_end_iso_in;
  let mappedBreakStartIso  = break_start_iso_in;
  let mappedBreakEndIso    = break_end_iso_in;
  let mappedBreakMinutesIn = break_minutes_in;

  if (scheduleProvided) {
    if (schedule_json_in == null) return bad('schedule_json must not be null.');
    const mapped = mapScheduleJsonToIso(schedule_json_in);
    if (mapped && mapped.error) return bad(mapped.error);

    worked_date_ymd = mapped.ymd || worked_date_ymd;

    mappedWorkedStartIso = mapped.worked_start_iso;
    mappedWorkedEndIso   = mapped.worked_end_iso;
    mappedBreakStartIso  = mapped.break_start_iso;
    mappedBreakEndIso    = mapped.break_end_iso;
    mappedBreakMinutesIn = (mapped.break_minutes != null) ? mapped.break_minutes : null;
  }

  // ─────────────────────────────────────────────────────────────
  // ✅ Pre-validate worked/break ordering + partials BEFORE rotate/patch/rebuild
  // ─────────────────────────────────────────────────────────────
  const nextWorkedStartIso = (mappedWorkedStartIso !== undefined) ? normIso(mappedWorkedStartIso) : normIso(ts.worked_start_iso);
  const nextWorkedEndIso   = (mappedWorkedEndIso   !== undefined) ? normIso(mappedWorkedEndIso)   : normIso(ts.worked_end_iso);

  const nextBreakStartIso  = (mappedBreakStartIso  !== undefined) ? normIso(mappedBreakStartIso)  : normIso(ts.break_start_iso);
  const nextBreakEndIso    = (mappedBreakEndIso    !== undefined) ? normIso(mappedBreakEndIso)    : normIso(ts.break_end_iso);

  let nextBreakMinutesNum =
    (mappedBreakMinutesIn !== undefined)
      ? Number(mappedBreakMinutesIn == null ? NaN : mappedBreakMinutesIn)
      : (ts.break_minutes != null ? Number(ts.break_minutes) : null);

  const hasShiftStart = hasIso(nextWorkedStartIso);
  const hasShiftEnd   = hasIso(nextWorkedEndIso);

  if (hasShiftStart !== hasShiftEnd) {
    return bad('worked_start_iso and worked_end_iso must both be provided (or both cleared).');
  }

  let shiftStartMs = null;
  let shiftEndMs   = null;
  let shiftMinutes = null;

  if (hasShiftStart && hasShiftEnd) {
    shiftStartMs = isoToMs(nextWorkedStartIso);
    shiftEndMs   = isoToMs(nextWorkedEndIso);

    if (shiftStartMs == null || shiftEndMs == null) {
      return bad('worked_start_iso/worked_end_iso must be valid ISO timestamps.');
    }

    const diffMs = shiftEndMs - shiftStartMs;
    if (diffMs <= 0) {
      return bad('worked_end_iso must be after worked_start_iso (overnight shifts must use next-day end ISO).');
    }

    const diffMin = diffMs / 60000;
    if (!(diffMin > 0)) {
      return bad('Worked shift duration must be > 0 minutes.');
    }

    if (diffMs === 0) {
      return bad('worked_start_iso cannot equal worked_end_iso.');
    }

    shiftMinutes = Math.round(diffMin);
    if (shiftMinutes <= 0) {
      return bad('Worked shift duration must be at least 1 minute.');
    }
  }

  const hasBrStart = hasIso(nextBreakStartIso);
  const hasBrEnd   = hasIso(nextBreakEndIso);

  if (hasBrStart !== hasBrEnd) {
    return bad('break_start_iso and break_end_iso must both be provided (or both cleared).');
  }

  const anyBreakInfo =
    (hasBrStart && hasBrEnd) ||
    (mappedBreakMinutesIn !== undefined && Number.isFinite(nextBreakMinutesNum));

  if (anyBreakInfo && !(hasShiftStart && hasShiftEnd)) {
    return bad('You cannot set break times/minutes without worked_start_iso and worked_end_iso.');
  }

  let computedBreakMinutes = null;

  if (hasBrStart && hasBrEnd) {
    const brStartMs = isoToMs(nextBreakStartIso);
    const brEndMs   = isoToMs(nextBreakEndIso);

    if (brStartMs == null || brEndMs == null) {
      return bad('break_start_iso/break_end_iso must be valid ISO timestamps.');
    }

    const brDiffMs = brEndMs - brStartMs;
    if (brDiffMs <= 0) {
      return bad('break_end_iso must be after break_start_iso (overnight breaks must use next-day end ISO).');
    }

    if (brDiffMs === 0) {
      return bad('break_start_iso cannot equal break_end_iso.');
    }

    if (brStartMs < shiftStartMs || brEndMs > shiftEndMs) {
      return bad('Break window must be fully within the worked shift span.');
    }

    computedBreakMinutes = Math.round(brDiffMs / 60000);
    if (!(computedBreakMinutes > 0)) {
      return bad('Break duration must be > 0 minutes.');
    }

    if (shiftMinutes != null && computedBreakMinutes > shiftMinutes) {
      return bad('Break duration cannot exceed the worked shift duration.');
    }

    nextBreakMinutesNum = computedBreakMinutes;
  } else {
    if (mappedBreakMinutesIn !== undefined) {
      if (!Number.isFinite(nextBreakMinutesNum) || nextBreakMinutesNum < 0) {
        return bad('break_minutes must be a non-negative number.');
      }
      nextBreakMinutesNum = Math.round(nextBreakMinutesNum);
      if (shiftMinutes != null && nextBreakMinutesNum > shiftMinutes) {
        return bad('break_minutes cannot exceed the worked shift duration.');
      }
    } else {
      if (Number.isFinite(nextBreakMinutesNum) && shiftMinutes != null && nextBreakMinutesNum > shiftMinutes) {
        return bad('Existing break_minutes exceeds the worked shift duration. Please reduce break_minutes or set break_start_iso/break_end_iso.');
      }
    }
  }

  // ─────────────────────────────────────────────────────────────
  // MINIMAL TIMESHEET AUDIT: capture BEFORE for diffing
  // ─────────────────────────────────────────────────────────────
  const tsBefore = { ...ts };
  const finBefore = { ...tsfin };

  const hadQrBefore = !!(
    ts.qr_status ||
    ts.qr_token ||
    ts.qr_generated_at ||
    ts.qr_scanned_at
  );

  // ✅ Decide requested QR action (enum preferred)
  let qrAction = null; // 'INVALIDATE' | 'REVOKE_TO_MANUAL' | 'REISSUE' | 'ISSUE' | 'DISABLE' | null

  if (enumOk(qrActionEnumRaw)) {
    // SAVE_WITHOUT_ISSUE means "no QR side-effects here"
    qrAction = (qrActionEnumRaw === 'SAVE_WITHOUT_ISSUE') ? null : qrActionEnumRaw;
  } else if (hadQrBefore) {
    // Legacy fallback (only meaningful if the sheet already had QR activity)
    if (rawReissueQr) qrAction = 'REISSUE';
    else if (rawRevokeToManual || rawRevokeQr) qrAction = 'REVOKE_TO_MANUAL';
    else if (rawDisableQr) qrAction = 'DISABLE';
    else if (rawIssueQr) qrAction = 'ISSUE';
  }

  const preRotateVersion = Number(ts.version || 1);
  let rotated = false;
  let rotateReason = null;

  // Rotate for invalidate/revoke/disable/reissue so restore is possible and old evidence remains in history.
  if (hadQrBefore && (qrAction === 'INVALIDATE' || qrAction === 'REISSUE' || qrAction === 'REVOKE_TO_MANUAL' || qrAction === 'DISABLE')) {
    const why =
      (qrAction === 'INVALIDATE' || qrAction === 'REISSUE') ? 'QR_INVALIDATED_AFTER_CONTENT_CHANGE' :
      (qrAction === 'REVOKE_TO_MANUAL') ? 'QR_REVOKED_TO_MANUAL' :
      'QR_DISABLED_TO_MANUAL';

    rotateReason = why;
    ts = await rotateTimesheetVersion(ts, why, qrAction);
    rotated = true;

    // After rotation we are now operating on the new timesheet_id
    currentTimesheetId = ts?.timesheet_id || currentTimesheetId;
  }

  // 5) Patch worked/break fields (on CURRENT timesheet id)
  const patchBody = { updated_at: now };

  const shouldPatchWorked = scheduleProvided || worked_start_iso_in !== undefined || worked_end_iso_in !== undefined;
  const shouldPatchBreakTimes = scheduleProvided || break_start_iso_in !== undefined || break_end_iso_in !== undefined;
  const shouldPatchBreakMinutes = scheduleProvided || break_minutes_in !== undefined || (hasBrStart && hasBrEnd);

  if (shouldPatchWorked) {
    patchBody.worked_start_iso = normIso(nextWorkedStartIso);
    patchBody.worked_end_iso   = normIso(nextWorkedEndIso);
  }

  if (shouldPatchBreakTimes) {
    patchBody.break_start_iso = normIso(nextBreakStartIso);
    patchBody.break_end_iso   = normIso(nextBreakEndIso);
  }

  if (shouldPatchBreakMinutes) {
    patchBody.break_minutes = (Number.isFinite(nextBreakMinutesNum) ? nextBreakMinutesNum : null);
  }

  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify(patchBody)
    }
  ).catch(() => {});

  // 6) Reload updated TS for snapshot + QR (CURRENT timesheet id)
  const updatedTs = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );

   // 7) Rebuild DAILY snapshot (TSFIN) — SQL-first (band no-guess enforced)
  try {
    // Priority enqueue JUST this timesheet
    await sbRpc(env, 'enqueue_ts_financials_priority', {
      _timesheet_ids: [currentTimesheetId],
      _reason: 'CONTEXT_CHANGED'
    });

    // Deterministic drain ONLY this timesheet
    await runTsfinWorkerOnce(env, {
      limit: 1,
      onlyTimesheetIds: [currentTimesheetId]
    });

    // NOTE: we intentionally do NOT hard-fail if picked=0 (rare race if leased elsewhere);
    // it's still queued and will update shortly via the normal drain.
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to rebuild daily snapshot: ${e?.message || e}`));
  }


  // Reload TSFIN after recompute (CURRENT timesheet id)
  const finAfter = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  ).catch(() => null);

  // ─────────────────────────────────────────────────────────────
  // MINIMAL TIMESHEET AUDIT: log HOURS_CHANGED only when meaningful
  // ─────────────────────────────────────────────────────────────
  const changedFields = [];
  const same = (a, b) => String(a ?? '') === String(b ?? '');

  if ((scheduleProvided || worked_start_iso_in !== undefined) && !same(tsBefore.worked_start_iso, updatedTs?.worked_start_iso)) changedFields.push('worked_start_iso');
  if ((scheduleProvided || worked_end_iso_in   !== undefined) && !same(tsBefore.worked_end_iso,   updatedTs?.worked_end_iso))   changedFields.push('worked_end_iso');
  if ((scheduleProvided || break_start_iso_in  !== undefined) && !same(tsBefore.break_start_iso,  updatedTs?.break_start_iso))  changedFields.push('break_start_iso');
  if ((scheduleProvided || break_end_iso_in    !== undefined) && !same(tsBefore.break_end_iso,    updatedTs?.break_end_iso))    changedFields.push('break_end_iso');
  if ((scheduleProvided || break_minutes_in !== undefined || (hasBrStart && hasBrEnd)) && !same(tsBefore.break_minutes, updatedTs?.break_minutes)) changedFields.push('break_minutes');

  const hoursChangedBuckets = !!(finAfter && (
    Number(finBefore.hours_day   ?? 0) !== Number(finAfter.hours_day   ?? 0) ||
    Number(finBefore.hours_night ?? 0) !== Number(finAfter.hours_night ?? 0) ||
    Number(finBefore.hours_sat   ?? 0) !== Number(finAfter.hours_sat   ?? 0) ||
    Number(finBefore.hours_sun   ?? 0) !== Number(finAfter.hours_sun   ?? 0) ||
    Number(finBefore.hours_bh    ?? 0) !== Number(finAfter.hours_bh    ?? 0) ||
    Number(finBefore.total_hours ?? 0) !== Number(finAfter.total_hours ?? 0)
  ));

  if (changedFields.length || hoursChangedBuckets) {
    try {
      await writeAudit(
        env,
        user,
        'TIMESHEET_HOURS_CHANGED',
        {
          timesheet_id: currentTimesheetId,
          sheet_scope: 'DAILY',
          submission_mode: 'MANUAL',
          changed_fields: changedFields,
          rotated_for_qr: rotated,
          rotate_reason: rotateReason,
          before: {
            worked_start_iso: tsBefore.worked_start_iso ?? null,
            worked_end_iso:   tsBefore.worked_end_iso   ?? null,
            break_start_iso:  tsBefore.break_start_iso  ?? null,
            break_end_iso:    tsBefore.break_end_iso    ?? null,
            break_minutes:    tsBefore.break_minutes    ?? null,
            bucket_hours: {
              day:   Number(finBefore.hours_day   ?? 0),
              night: Number(finBefore.hours_night ?? 0),
              sat:   Number(finBefore.hours_sat   ?? 0),
              sun:   Number(finBefore.hours_sun   ?? 0),
              bh:    Number(finBefore.hours_bh    ?? 0),
              total: Number(finBefore.total_hours ?? 0)
            }
          },
          after: {
            worked_start_iso: updatedTs?.worked_start_iso ?? null,
            worked_end_iso:   updatedTs?.worked_end_iso   ?? null,
            break_start_iso:  updatedTs?.break_start_iso  ?? null,
            break_end_iso:    updatedTs?.break_end_iso    ?? null,
            break_minutes:    updatedTs?.break_minutes    ?? null,
            bucket_hours: finAfter ? {
              day:   Number(finAfter.hours_day   ?? 0),
              night: Number(finAfter.hours_night ?? 0),
              sat:   Number(finAfter.hours_sat   ?? 0),
              sun:   Number(finAfter.hours_sun   ?? 0),
              bh:    Number(finAfter.hours_bh    ?? 0),
              total: Number(finAfter.total_hours ?? 0)
            } : null
          }
        },
        { entity: 'timesheets', subject_id: currentTimesheetId, req }
      );
    } catch {}
  }

  // 8) QR state change for after-save actions (NEW)
  // - INVALIDATE / REISSUE: clear token/payload/scanned + clear hashes, keep qr_status='PENDING' (QR-enabled, not issued)
  // - REVOKE_TO_MANUAL / DISABLE: clear QR fields and hashes so QR UI does not show
  if (qrAction && finAfter && !finAfter.locked_by_invoice_id && !finAfter.paid_at_utc) {
    const now2 = nowIso();

    const act = String(qrAction || '').toUpperCase();
    const qrEnablePending = (act === 'INVALIDATE' || act === 'REISSUE' || act === 'ISSUE');
    const qrClearAll = (act === 'REVOKE_TO_MANUAL' || act === 'DISABLE');

    const tsPatch = {
      updated_at: now2,

      qr_token: null,
      qr_generated_at: null,
      qr_scanned_at: null,
      qr_scan_info_json: null,
      qr_r2_key: null,
      qr_payload_json: {},

      qr_last_sent_hash: null,
      qr_last_sent_at_utc: null,
      qr_signed_hash: null,
      qr_signed_at_utc: null,

      manual_pdf_r2_key: null,
      authorised_at_server: null
    };

    if (qrEnablePending) {
      tsPatch.qr_status = 'PENDING';
    } else if (qrClearAll) {
      tsPatch.qr_status = null;
    }

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(tsPatch)
      }
    ).catch(() => {});

    const desired = 'AWAITING_MANUAL_SIGNATURE';
    if (String(finAfter.processing_status || '').toUpperCase() !== desired) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(finAfter.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({ processing_status: desired, updated_at: now2 })
        }
      ).catch(() => {});
    }
  }

  // NOTE: We do NOT issue/send a QR from daily-manual-upsert anymore.
  // Sending happens via /api/timesheets/:id/qr-resend after save when the FE chooses “Send new now”.

  // ─────────────────────────────────────────────────────────────
  // MINIMAL TIMESHEET AUDIT: QR events (only meaningful ones)
  // ─────────────────────────────────────────────────────────────
  try {
    if (qrAction === 'DISABLE' && rotated) {
      await writeAudit(
        env,
        user,
        'TIMESHEET_QR_DISABLED',
        {
          timesheet_id: currentTimesheetId,
          sheet_scope: 'DAILY',
          rotated: true,
          from_version: preRotateVersion,
          to_version: Number(ts?.version || preRotateVersion),
          reason: rotateReason
        },
        { entity: 'timesheets', subject_id: currentTimesheetId, req }
      );
    }

    if (qrAction === 'REVOKE_TO_MANUAL' && rotated) {
      await writeAudit(
        env,
        user,
        'TIMESHEET_QR_REVOKED_TO_MANUAL',
        {
          timesheet_id: currentTimesheetId,
          sheet_scope: 'DAILY',
          rotated: true,
          from_version: preRotateVersion,
          to_version: Number(ts?.version || preRotateVersion),
          reason: rotateReason
        },
        { entity: 'timesheets', subject_id: currentTimesheetId, req }
      );
    }

    // ✅ FIX: Remove issuance/reissue audit blocks — daily-manual-upsert does not issue QR now.
    // if (qrIssued && qrToken) { ... }
    // if (qrReissued && qrToken) { ... }

  } catch {}

  // ─────────────────────────────────────────────────────────────
  // MINIMAL TIMESHEET AUDIT: PROCESSED (always after rebuild)
  // ─────────────────────────────────────────────────────────────
  try {
    await writeAudit(
      env,
      user,
      'TIMESHEET_PROCESSED',
      {
        timesheet_id: currentTimesheetId,
        sheet_scope: 'DAILY',
        submission_mode: 'MANUAL',
        source: 'timesheet_daily_manual_upsert',
        qr_action: qrAction,
        processing_status: finAfter?.processing_status ?? null,
        bucket_hours: finAfter ? {
          day:   Number(finAfter.hours_day   ?? 0),
          night: Number(finAfter.hours_night ?? 0),
          sat:   Number(finAfter.hours_sat   ?? 0),
          sun:   Number(finAfter.hours_sun   ?? 0),
          bh:    Number(finAfter.hours_bh    ?? 0),
          total: Number(finAfter.total_hours ?? 0)
        } : null
      },
      { entity: 'timesheets', subject_id: currentTimesheetId, req }
    );
  } catch {}

  return withCORS(env, req, ok({
    timesheet_id: currentTimesheetId,
    booking_id: guard.resolved.booking_id || null,
    requested_timesheet_id: guard.resolved.requested_timesheet_id || timesheetId,
    current_timesheet_id: currentTimesheetId,
    current_version: ts?.version ?? guard.resolved.current_version ?? null,
    was_stale: !!guard.resolved.was_stale,

    qr_action: qrAction,
    qr_issued: qrIssued,
    qr_reissued: qrReissued,
    qr_pdf_key: pdfKey,
    qr_r2_key,
    qr_token: qrToken || null
  }));
}


async function handleContractWeekDeleteTimesheet(env, req, weekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!weekId) return withCORS(env, req, badRequest('contract_week_id is required'));

  const enc = encodeURIComponent;

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=*`
  );
  if (!cw) {
    return withCORS(env, req, notFound('Week not found'));
  }

  // ✅ planned-only delete (no timesheet_id) → SQL RPC contract_week_delete_planned(...)
  // (No expected_timesheet_id required here; if the week has gained a timesheet_id, it will go down the guarded branch below.)
  if (!cw.timesheet_id) {
    try {
      const rpcRes = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/contract_week_delete_planned`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
          body: JSON.stringify({
            p_contract_week_id: weekId,
            p_actor_user_id: user?.id || null
          })
        }
      );

      if (!rpcRes.ok) {
        const t = await rpcRes.text().catch(() => '');
        return withCORS(env, req, serverError(`Planned delete failed: ${t}`));
      }

      return withCORS(env, req, ok({ deleted: true, planned: true }));
    } catch (e) {
      return withCORS(env, req, serverError(`Planned delete failed: ${e?.message || String(e)}`));
    }
  }

  // ✅ Guarded delete for a week that currently has a timesheet
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // Resolve CW-linked timesheet to CURRENT
  const resolved = await resolveTimesheetToCurrent(env, cw.timesheet_id);
  if (!resolved?.current_timesheet_id) {
    return withCORS(env, req, serverError('Failed to resolve current timesheet for contract week'));
  }
  const currentTimesheetId = String(resolved.current_timesheet_id);

  // Guard mismatch → 409 moved
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  // booking_id is required to delete the whole rotation series safely
  if (!resolved.booking_id) {
    return withCORS(env, req, serverError('Failed to resolve booking_id for contract week timesheet'));
  }
  const bookingId = String(resolved.booking_id);

  // Fetch all timesheet_ids in this booking_id series
  const { rows: tsRowsAll } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&select=timesheet_id`
  );
  const allIds = (tsRowsAll || []).map(r => r.timesheet_id).filter(Boolean);

  // Guard: no current TSFIN in this series may be paid or invoiced
  if (allIds.length) {
    const inList = allIds.map(x => `"${String(x).replace(/"/g, '')}"`).join(',');
    const { rows: finRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?is_current=eq.true&timesheet_id=in.(${inList})` +
        `&select=timesheet_id,paid_at_utc,locked_by_invoice_id`
    );

    for (const f of (finRows || [])) {
      if (f?.paid_at_utc) {
        return withCORS(env, req, badRequest('Cannot delete: already paid'));
      }
      if (f?.locked_by_invoice_id) {
        return withCORS(env, req, badRequest('Cannot delete: invoiced'));
      }
    }
  }

  // Delete all timesheet rows in the series
  const delTs = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=eq.${enc(bookingId)}`,
    { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return-minimal' } }
  );
  if (!delTs.ok) {
    return withCORS(env, req, serverError(await delTs.text()));
  }

  // Delete TSFIN rows for those timesheet_ids (avoid orphan snapshots)
  if (allIds.length) {
    const inList = allIds.map(x => `"${String(x).replace(/"/g, '')}"`).join(',');
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?timesheet_id=in.(${inList})`,
      { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return-minimal' } }
    ).catch(() => {});
  }

  // Reset week to OPEN
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        timesheet_id: null,
        status: 'OPEN',
        updated_at: nowIso()
      })
    }
  ).catch(() => {});

  // Audit
  try {
    await writeAudit(
      env,
      user,
      'CONTRACT_WEEK_TIMESHEET_DELETED',
      { contract_week_id: weekId, booking_id: bookingId, timesheet_id: currentTimesheetId },
      { entity: 'contract_weeks', subject_id: weekId, req }
    );
  } catch {}

  return withCORS(env, req, ok({
    deleted: true,
    planned: false,
    booking_id: bookingId,
    requested_timesheet_id: cw.timesheet_id,
    current_timesheet_id: currentTimesheetId,
    was_stale: !!resolved?.was_stale
  }));
}


async function handleContractWeekCreateExpenseSheet(env, req, weekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  const cw = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=*`);
  if (!cw) return withCORS(env, req, notFound('Week not found'));
  const contract = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(cw.contract_id)}&select=*`);
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  const candidate = contract.candidate_id
    ? await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(contract.candidate_id)}&select=id,display_name`)
    : null;

  const client = contract.client_id
    ? await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${enc(contract.client_id)}&select=id,name`)
    : null;

  const booking_id = await makeWeeklyBookingId(contract?.candidate_id || null, contract, cw);

  const now = nowIso();

  const payload = [{
    booking_id, version: 1, is_current: true, status: 'SUBMITTED',
    occupant_key_norm: (candidate?.display_name || String(candidate?.id || 'worker')).toLowerCase(),
    hospital_norm: (contract.display_site || client?.name || String(contract.client_id)).toLowerCase(),
    ward_norm: (contract.ward_hint || 'contract').toLowerCase(),
    job_title_norm: (contract.role || 'weekly').toLowerCase(),
    shift_label_norm: 'weekly-expenses',
    week_ending_date: cw.week_ending_date,
    contract_id: contract.id,

    submission_mode: 'MANUAL',
    sheet_scope: 'WEEKLY',

    manual_pdf_r2_key: null,
    line_type: 'EXPENSES',
    created_at: now, updated_at: now
  }];

  const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(payload)
  });
  if (!ins.ok) return withCORS(env, req, serverError(await ins.text()));
  const ts = (await ins.json().catch(()=>[]))[0];

  if (!cw.timesheet_id) {
    await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), 'Prefer': 'return=minimal' },
      body: JSON.stringify({ timesheet_id: ts.timesheet_id, updated_at: nowIso() })
    });
  }

  const snap = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,
    basis: 'CONTRACT_WEEKLY',
    candidate_id: contract.candidate_id,
    client_id: contract.client_id,
    candidate_assignment: 'ASSIGNED',
    processing_status: 'PENDING_AUTH',
    pay_method: contract.pay_method_snapshot,

    policy_snapshot_json: {},
    rate_source_refs_json: {},

    hours_day: 0, hours_night: 0, hours_sat: 0, hours_sun: 0, hours_bh: 0,
    total_hours: 0,

    total_pay_ex_vat: 0, total_charge_ex_vat: 0, margin_ex_vat: 0,

    additional_units_json: {},
    additional_pay_ex_vat: 0,
    additional_charge_ex_vat: 0,
    additional_margin_ex_vat: 0,

    invoice_breakdown_json: {
      mode: 'EXPENSES_ONLY',
      totals: { total_pay_ex_vat: 0, total_charge_ex_vat: 0, margin_ex_vat: 0 }
    },

    created_at: nowIso(),
  };

  await writeSnapshot(env, snap);

  // ✅ 3.11: always return created timesheet_id
  return withCORS(env, req, ok({ timesheet_id: ts.timesheet_id }));
}


// ----------------------------------------------------------------------------
// C) WEEKLY (ELECTRONIC) – public broker endpoints
// ----------------------------------------------------------------------------

async function handleTimesheetsPresignWeekly(env, req) {
  // Public: presign nurse/authoriser signature uploads for a weekly slot + return bucket labels for UI
  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  let cw = null;
  if (body.contract_week_id) {
    cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(body.contract_week_id)}&select=*`
    );
  } else if (body.contract_id && body.week_ending_date) {
    const addSeq = Number(body.additional_seq || 0);
    cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(body.contract_id)}` +
        `&week_ending_date=eq.${enc(body.week_ending_date)}` +
        `&additional_seq=eq.${enc(addSeq)}` +
        `&select=*`
    );
  }
  if (!cw) return withCORS(env, req, notFound('Weekly slot not found'));

  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(cw.contract_id)}` +
      `&select=id,candidate_id,client_id,bucket_labels_json,additional_rates_json`
  );
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  const candidateId = contract.candidate_id;
  const clientId = contract.client_id;

  const hasAnySegmentInvoiceLock = (tf) => {
    try {
      const ib = tf?.invoice_breakdown_json;
      if (!ib || typeof ib !== 'object') return false;
      const mode = String(ib?.mode || '').toUpperCase();
      if (mode !== 'SEGMENTS') return false;
      const segs = Array.isArray(ib?.segments) ? ib.segments : [];
      return segs.some(s => {
        const v = s?.invoice_locked_invoice_id;
        return v != null && String(v).trim() !== '';
      });
    } catch {
      return false;
    }
  };

  // Authoritative: client_settings.default_submission_mode must be ELECTRONIC for electronic presign
  let supportsElectronic = false;
  try {
    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
        `?client_id=eq.${enc(clientId)}` +
        `&select=default_submission_mode,updated_at,created_at` +
        `&order=updated_at.desc.nullslast,created_at.desc.nullslast` +
        `&limit=1`
    );
    const cs = csRows?.[0] || null;
    const dsm = String(cs?.default_submission_mode || '').toUpperCase();
    supportsElectronic = (dsm === 'ELECTRONIC');
  } catch {
    supportsElectronic = false;
  }

  if (!supportsElectronic) {
    return withCORS(env, req, badRequest('Electronic submission is not enabled for this client'));
  }

  // If there is an existing timesheet, enforce resubmission rules:
  // block presign when manual-only or locked (paid/invoiced)
  let nextVersion = 1;
  if (cw.timesheet_id) {
    const tsid = cw.timesheet_id;

    const tsCur = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(tsid)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,submission_mode,qr_status,qr_token,qr_generated_at,qr_scanned_at`
    );

    const finCur = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(tsid)}` +
        `&is_current=eq.true` +
        `&select=paid_at_utc,locked_by_invoice_id,invoice_breakdown_json`
    );

    if (finCur?.paid_at_utc) {
      return withCORS(env, req, badRequest('Cannot presign: already paid'));
    }
    if (finCur?.locked_by_invoice_id || hasAnySegmentInvoiceLock(finCur)) {
      return withCORS(env, req, badRequest('Cannot presign: invoiced'));
    }

    // manual-only derivation
    const sm = String(tsCur?.submission_mode || '').toUpperCase();
    const qrStatus = String(tsCur?.qr_status || '').toUpperCase() || '';
    const hasQrToken = !!(tsCur?.qr_token && String(tsCur.qr_token).trim());
    const hasQrGen = !!tsCur?.qr_generated_at;
    const hasQrScan = !!tsCur?.qr_scanned_at;

    const isManualOnly = (sm === 'MANUAL') && !qrStatus && !hasQrToken && !hasQrGen && !hasQrScan;
    if (isManualOnly) {
      return withCORS(env, req, badRequest('Cannot presign: manual-only (candidate submission disabled)'));
    }

    // next version for signatures = max(version)+1
    try {
      const { rows: vRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(tsid)}` +
          `&select=version` +
          `&order=version.desc` +
          `&limit=1`
      );
      const maxV = Number(vRows?.[0]?.version || 1);
      nextVersion = (Number.isFinite(maxV) ? maxV : 1) + 1;
    } catch {
      nextVersion = 2;
    }
  }

  const DEFAULT_LABELS = { day: 'Day', night: 'Night', sat: 'Sat', sun: 'Sun', bh: 'BH' };
  const bucketLabels = (contract.bucket_labels_json && typeof contract.bucket_labels_json === 'object')
    ? contract.bucket_labels_json
    : DEFAULT_LABELS;

  const additional_rates = Array.isArray(contract.additional_rates_json)
    ? contract.additional_rates_json
    : [];

  const bookingId = makeWeeklyBookingId(candidateId, contract, cw);
  const weC = ymdCompact(cw.week_ending_date);

  // IMPORTANT: use nextVersion so resubmissions don't overwrite prior signatures
  const base = `Signatures/we=${weC}/${bookingId}/v${nextVersion}`;
  const nurseKey = `${base}/nurse.png`;
  const authKey  = `${base}/authoriser.png`;

  // Tokens – 10MB each
  const nurseToken = await createToken(env, 'UPLOAD', {
    key: nurseKey,
    c: 'sign',
    ttlSec: 3600,
    maxBytes: 10 * 1024 * 1024,
    contentTypes: ['image/png', 'image/jpeg']
  });
  const authToken  = await createToken(env, 'UPLOAD', {
    key: authKey,
    c: 'sign',
    ttlSec: 3600,
    maxBytes: 10 * 1024 * 1024,
    contentTypes: ['image/png', 'image/jpeg']
  });

  const origin = new URL(req.url).origin;
  return withCORS(env, req, ok({
    booking_id: bookingId,
    week_ending_date: cw.week_ending_date,
    bucket_labels: bucketLabels,
    additional_rates,
    next_version: nextVersion,
    keys: {
      nurse: {
        key: nurseKey,
        token: nurseToken,
        upload_url: `${origin}/api/signatures/upload?key=${enc(nurseKey)}&token=${enc(nurseToken)}`
      },
      authoriser: {
        key: authKey,
        token: authToken,
        upload_url: `${origin}/api/signatures/upload?key=${enc(authKey)}&token=${enc(authToken)}`
      }
    }
  }));
}
async function handleTimesheetsEligibilityWeekly(env, req) {
  const enc = encodeURIComponent;

  // Public: app supplies candidate_id, optional client_id; return eligible weeks + per-contract bucket labels
  let body; try { body = await parseJSONBody(req); } catch { body = {}; }
  const candidateId = body.candidate_id || null;
  if (!candidateId) return withCORS(env, req, badRequest('candidate_id required'));

  // We now include more statuses because resubmission is allowed when not locked/paid and not manual-only.
  // (OPEN/PLANNED are "no timesheet yet", SUBMITTED/AUTHORISED are "timesheet exists; may be resubmittable".)
  const statuses = ['OPEN', 'PLANNED', 'SUBMITTED', 'AUTHORISED'];

  let url =
    `${env.SUPABASE_URL}/rest/v1/v_contract_weeks_enriched?select=*` +
    `&candidate_id=eq.${enc(candidateId)}` +
    `&status=in.(${statuses.map(s => enc(s)).join(',')})`;

  if (body.client_id) url += `&client_id=eq.${enc(body.client_id)}`;

  const { rows } = await sbFetch(env, url);
  const list = rows || [];

  // Attach bucket labels per contract for the app UI
  const DEFAULT_LABELS = { day: 'Day', night: 'Night', sat: 'Sat', sun: 'Sun', bh: 'BH' };
  const contractIds = [...new Set(list.map(r => r.contract_id).filter(Boolean))];
  let mapLabels = {};
  if (contractIds.length) {
    const { rows: cons } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts?id=in.(${contractIds.map(enc).join(',')})&select=id,bucket_labels_json`
    );
    mapLabels = Object.fromEntries(
      (cons || []).map(c => [
        c.id,
        (c.bucket_labels_json && typeof c.bucket_labels_json === 'object')
          ? c.bucket_labels_json
          : DEFAULT_LABELS
      ])
    );
  }

  // Batch: client_settings (authoritative electronic capability)
  const clientIds = [...new Set(list.map(r => r.client_id).filter(Boolean))];
  const clientSupportsElectronic = {};
  if (clientIds.length) {
    try {
      const { rows: csRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_settings` +
          `?client_id=in.(${clientIds.map(enc).join(',')})` +
          `&select=client_id,default_submission_mode,updated_at,created_at` +
          `&order=client_id.asc,updated_at.desc.nullslast,created_at.desc.nullslast`
      );

      // take first row per client_id (because sorted desc within each client_id)
      for (const row of (csRows || [])) {
        const cid = row?.client_id;
        if (!cid) continue;
        if (Object.prototype.hasOwnProperty.call(clientSupportsElectronic, cid)) continue;
        const dsm = String(row?.default_submission_mode || '').toUpperCase();
        clientSupportsElectronic[cid] = (dsm === 'ELECTRONIC');
      }
    } catch {
      // default: false if missing
    }
  }

  // Batch: timesheets current + tsfin current for rows that already have a timesheet_id
  const timesheetIds = [...new Set(list.map(r => r.timesheet_id).filter(Boolean))];

  const mapTsCurrent = {};   // timesheet_id -> ts row
  const mapFinCurrent = {};  // timesheet_id -> fin row

  if (timesheetIds.length) {
    try {
      const { rows: tsRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=in.(${timesheetIds.map(enc).join(',')})` +
          `&is_current=eq.true` +
          `&select=timesheet_id,submission_mode,qr_status,qr_token,qr_generated_at,qr_scanned_at`
      );
      for (const t of (tsRows || [])) {
        if (t?.timesheet_id) mapTsCurrent[t.timesheet_id] = t;
      }
    } catch {}

    try {
      const { rows: finRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=in.(${timesheetIds.map(enc).join(',')})` +
          `&is_current=eq.true` +
          `&select=timesheet_id,paid_at_utc,locked_by_invoice_id,processing_status`
      );
      for (const f of (finRows || [])) {
        if (f?.timesheet_id) mapFinCurrent[f.timesheet_id] = f;
      }
    } catch {}
  }

  const deriveIsManualOnly = (ts) => {
    if (!ts || typeof ts !== 'object') return false;
    const sm = String(ts.submission_mode || '').toUpperCase();
    if (sm !== 'MANUAL') return false;

    const qrStatus = String(ts.qr_status || '').toUpperCase() || '';
    const hasQrToken = !!(ts.qr_token && String(ts.qr_token).trim());
    const hasQrGen = !!ts.qr_generated_at;
    const hasQrScan = !!ts.qr_scanned_at;

    return !qrStatus && !hasQrToken && !hasQrGen && !hasQrScan;
  };

  const deriveLocked = (fin) => {
    if (!fin || typeof fin !== 'object') return { locked: false, reason: null };
    if (fin.paid_at_utc) return { locked: true, reason: 'PAID' };
    if (fin.locked_by_invoice_id) return { locked: true, reason: 'INVOICED' };
    return { locked: false, reason: null };
  };

  const withLabels = list.map(r => {
    const clientId = r.client_id || null;
    const supportsElectronic = !!(clientId && clientSupportsElectronic[clientId] === true);

    const tsid = r.timesheet_id || null;
    const tsCur = tsid ? (mapTsCurrent[tsid] || null) : null;
    const finCur = tsid ? (mapFinCurrent[tsid] || null) : null;

    const isManualOnly = deriveIsManualOnly(tsCur);
    const lockInfo = deriveLocked(finCur);

    // Eligibility rules (candidate pipeline):
    // - If no timesheet yet: can always choose QR; electronic only if supportsElectronic
    // - If timesheet exists: can resubmit if not locked/paid and not manual-only
    // - manual-only hard stop blocks both QR and electronic from candidate
    const hasExistingTs = !!tsid;

    const canSubmitQr =
      !lockInfo.locked &&
      !isManualOnly;

    const canSubmitElectronic =
      supportsElectronic &&
      !lockInfo.locked &&
      !isManualOnly;

    const canProceed = canSubmitQr || canSubmitElectronic;

    let blockedReason = null;
    if (!canProceed) {
      if (lockInfo.locked) blockedReason = lockInfo.reason || 'LOCKED';
      else if (isManualOnly) blockedReason = 'MANUAL_ONLY';
      else if (!supportsElectronic) blockedReason = 'ELECTRONIC_DISABLED';
      else blockedReason = 'BLOCKED';
    }

    const isResubmission = hasExistingTs && !lockInfo.locked && !isManualOnly;

    return {
      ...r,
      bucket_labels: mapLabels[r.contract_id] || DEFAULT_LABELS,

      supports_electronic_submission: supportsElectronic,
      has_existing_timesheet: hasExistingTs,
      is_resubmission: isResubmission,
      is_manual_only: isManualOnly,
      locked: lockInfo.locked,
      locked_reason: lockInfo.reason,
      can_submit_qr: canSubmitQr,
      can_submit_electronic: canSubmitElectronic,
      can_proceed: canProceed,
      blocked_reason: blockedReason
    };
  });

  return withCORS(env, req, ok(withLabels));
}


// GET /api/timesheets/:id/evidence
// GET /api/timesheets/:id/evidence
async function handleTimesheetEvidenceList(env, req, tsId) {
  const enc = encodeURIComponent;

  // Auth: admin only
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!tsId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // ✅ Rotation-safe: resolve requested -> current
  const resolved = await resolveTimesheetToCurrent(env, tsId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTsId = resolved.current_timesheet_id;

  // Optional: meta=1 returns wrapper object; default keeps legacy array response
  let wantMeta = false;
  try {
    const u = new URL(req.url);
    wantMeta = (u.searchParams.get('meta') === '1');
  } catch {
    wantMeta = false;
  }

  try {
    // ─────────────────────────────────────────────────────────────
    // 0) Load timesheet row (QR evidence + electronic signature evidence)
    // ─────────────────────────────────────────────────────────────
    const ts = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTsId)}` +
        `&is_current=eq.true` +
        `&select=` +
          [
            'timesheet_id',
            'booking_id',
            'version',
            'sheet_scope',
            'week_ending_date',

            // DAILY shift fields
            'worked_start_iso',
            'worked_end_iso',
            'break_start_iso',
            'break_end_iso',
            'break_minutes',

            // WEEKLY fields used for hashing + summary
            'reference_number',
            'day_references_json',
            'actual_schedule_json',

            // PDF pointer (manual + QR)
            'manual_pdf_r2_key',

            // QR state
            'qr_status',
            'qr_token',
            'qr_generated_at',
            'qr_scanned_at',
            'qr_last_sent_hash',
            'qr_last_sent_at_utc',
            'qr_signed_hash',

            // additional units (hashing)
            'additional_units_week',
            'additional_units_per_day',

            // electronic signatures (no new storage)
            'r2_nurse_key',
            'r2_auth_key',
            'auth_name',
            'auth_job_title',
            'authorised_at_server',

            // ✅ NEW: PDF generation flag (system-generated)
            'generated_pdf_at_utc',

            // ✅ NEW: used to decide whether to show generated PDF item
            'submission_mode'
          ].join(',') +
        `&limit=1`
    );

    const scope    = String(ts?.sheet_scope || '').toUpperCase();
    const qrStatus = String(ts?.qr_status || '').toUpperCase();

    const hasToken = !!(ts?.qr_token && String(ts.qr_token).trim());
    const hasGen   = !!ts?.qr_generated_at;
    const hasScan  = !!ts?.qr_scanned_at;

    const lastSentHash = (ts?.qr_last_sent_hash != null) ? String(ts.qr_last_sent_hash) : '';
    const signedHash   = (ts?.qr_signed_hash != null) ? String(ts.qr_signed_hash) : '';

    // ✅ IMPORTANT: match frontend “issued proof” logic:
    // issued proof is (token+generated_at) OR qr_last_sent_hash
    const hasIssuedProof = ((hasToken && hasGen) || !!(lastSentHash && String(lastSentHash).trim()));

    // Awaiting signature upload = pending + issued proof + not scanned
    const awaitingSignatureUpload = (qrStatus === 'PENDING') && hasIssuedProof && !hasScan;

    // Signed received = used + scanned timestamp
    const signedReceived = (qrStatus === 'USED') && hasScan;

    // Stable hashing helper (used only to compute "matches_current" flags; we DO NOT hide evidence on mismatch)
    const stableClone = (v) => {
      if (Array.isArray(v)) return v.map(stableClone);
      if (v && typeof v === 'object') {
        const out = {};
        for (const k of Object.keys(v).sort()) out[k] = stableClone(v[k]);
        return out;
      }
      return v;
    };

    const computeCurrentHash = async () => {
      if (!ts) return null;

      if (scope === 'WEEKLY') {
        const obj = {
          sheet_scope: 'WEEKLY',
          week_ending_date: ts.week_ending_date || null,
          actual_schedule_json: ts.actual_schedule_json || null,
          reference_number: ts.reference_number || null,
          day_references_json: ts.day_references_json || null,
          additional_units_week: ts.additional_units_week || {},
          additional_units_per_day: ts.additional_units_per_day || {}
        };
        return await sha256Hex(JSON.stringify(stableClone(obj)));
      }

      // DAILY
      const obj = {
        sheet_scope: 'DAILY',
        worked_start_iso: ts.worked_start_iso || null,
        worked_end_iso: ts.worked_end_iso || null,
        break_start_iso: ts.break_start_iso || null,
        break_end_iso: ts.break_end_iso || null,
        break_minutes: (ts.break_minutes != null ? ts.break_minutes : null),
        reference_number: ts.reference_number || null,
        day_references_json: ts.day_references_json || null
      };
      return await sha256Hex(JSON.stringify(stableClone(obj)));
    };

    let current_hash = null;
    try {
      current_hash = ts ? await computeCurrentHash() : null;
    } catch (e) {
      current_hash = null;
      console.warn('[handleTimesheetEvidenceList] current hash compute failed (non-fatal)', {
        timesheet_id: currentTsId,
        err: e?.message || String(e)
      });
    }

    const issuedStillMatches =
      !!current_hash && !!lastSentHash && (String(current_hash) === String(lastSentHash));

    const signedStillMatches =
      !!current_hash && !!signedHash && (String(current_hash) === String(signedHash));

    // ─────────────────────────────────────────────────────────────
    // 0b) Load TSFIN lock state (so we can set can_delete correctly)
    // ─────────────────────────────────────────────────────────────
    let isLockedOrPaid = false;
    try {
      const fin = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(currentTsId)}` +
          `&is_current=eq.true` +
          `&select=locked_by_invoice_id,paid_at_utc` +
          `&limit=1`
      );
      isLockedOrPaid = !!(fin && (fin.locked_by_invoice_id || fin.paid_at_utc));
    } catch {
      isLockedOrPaid = false;
    }

    // ─────────────────────────────────────────────────────────────
    // 1) User evidence rows (timesheet_evidence)
    // ─────────────────────────────────────────────────────────────
    const { rows: evRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence` +
        `?timesheet_id=eq.${enc(currentTsId)}` +
        `&select=id,kind,display_name,storage_key,created_at,created_by` +
        `&order=created_at.asc`
    );

    const userEvidenceRaw = (evRows || []).map(ev => {
      const out = { ...(ev || {}) };
      out.timesheet_id = currentTsId;
      out.system = false;
      out.can_delete = !isLockedOrPaid;
      if (!out.uploaded_at_utc && out.created_at) out.uploaded_at_utc = out.created_at;
      return out;
    });

    // ─────────────────────────────────────────────────────────────
    // 1b) Enrich user evidence with uploader display name
    // ─────────────────────────────────────────────────────────────
    const uploaderIds = new Set();
    for (const ev of userEvidenceRaw) {
      const uid = ev && ev.created_by ? String(ev.created_by).trim() : '';
      if (uid) uploaderIds.add(uid);
    }

    const uploaderMap = {}; // id -> display_name
    if (uploaderIds.size) {
      try {
        const idParam = Array.from(uploaderIds).map(enc).join(',');
        const { rows: uRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/tms_users` +
            `?id=in.(${idParam})` +
            `&select=id,display_name` +
            `&limit=1000`
        );

        for (const u of (uRows || [])) {
          const id = u && u.id ? String(u.id) : '';
          if (!id) continue;
          uploaderMap[id] = (u && u.display_name != null) ? String(u.display_name) : '';
        }
      } catch (e) {
        console.warn('[handleTimesheetEvidenceList] uploader enrich failed (non-fatal)', {
          err: e?.message || String(e)
        });
      }
    }

    const userEvidence = userEvidenceRaw.map(ev => {
      const out = { ...(ev || {}) };
      const uid = out.created_by ? String(out.created_by).trim() : '';
      const dn  = uid && Object.prototype.hasOwnProperty.call(uploaderMap, uid) ? uploaderMap[uid] : '';
      out.uploaded_by_display = dn || null;
      out.created_by_display  = dn || null;
      return out;
    });

    // ─────────────────────────────────────────────────────────────
    // 2) System evidence rows (QR + Imports + Electronic signatures + Generated PDF)
    // ─────────────────────────────────────────────────────────────
    const systemEvidence = [];

    // 2A) QR system evidence
    const docsPdfKey = `docs-pdf/timesheets/ts_${currentTsId}.pdf`;

    if (signedReceived) {
      const storageKey = (ts?.manual_pdf_r2_key && String(ts.manual_pdf_r2_key).trim())
        ? String(ts.manual_pdf_r2_key).trim()
        : docsPdfKey;

      if (storageKey) {
        systemEvidence.push({
          id: `SYS:QR:SIGNED:${currentTsId}`,
          timesheet_id: currentTsId,
          kind: 'QR',
          display_name: 'QR Timesheet (Signed)',
          storage_key: storageKey,
          created_at: ts?.qr_scanned_at || null,
          uploaded_at_utc: ts?.qr_scanned_at || null,
          system: true,
          can_delete: false,
          preview_mode: 'PDF',
          is_primary: true,
          meta_json: {
            qr_status: qrStatus || null,
            matches_current: (signedStillMatches || null)
          }
        });
      }
    } else if (awaitingSignatureUpload) {
      const storageKey = (ts?.manual_pdf_r2_key && String(ts.manual_pdf_r2_key).trim())
        ? String(ts.manual_pdf_r2_key).trim()
        : docsPdfKey;

      const issuedAt = ts?.qr_last_sent_at_utc || ts?.qr_generated_at || null;

      systemEvidence.push({
        id: `SYS:QR:UNSIGNED:${currentTsId}`,
        timesheet_id: currentTsId,
        kind: 'QR',
        display_name: 'QR Timesheet (Unsigned)',
        storage_key: storageKey,
        created_at: issuedAt,
        uploaded_at_utc: issuedAt,
        system: true,
        can_delete: false,
        preview_mode: 'PDF',
        is_primary: false,
        meta_json: {
          qr_status: qrStatus || null,
          matches_current: (issuedStillMatches || null)
        }
      });
    }

    // 2A.2) ✅ Generated system PDF evidence (ELECTRONIC + generated_pdf_at_utc, but avoid duplicating QR entry)
    const submissionMode = String(ts?.submission_mode || '').toUpperCase();
    const hasGeneratedPdf = !!ts?.generated_pdf_at_utc;

    // If QR evidence already shown, don't add a duplicate generated-PDF row (same docsPdfKey).
    const qrEvidenceAlreadyShown = signedReceived || awaitingSignatureUpload;

    if (!qrEvidenceAlreadyShown && submissionMode === 'ELECTRONIC' && hasGeneratedPdf) {
      systemEvidence.push({
        id: `SYS:PDF:GENERATED:${currentTsId}`,
        timesheet_id: currentTsId,
        kind: 'PDF',
        display_name: 'Timesheet (Generated PDF)',
        storage_key: docsPdfKey,
        created_at: ts.generated_pdf_at_utc,
        uploaded_at_utc: ts.generated_pdf_at_utc,
        system: true,
        can_delete: false,
        preview_mode: 'PDF',
        is_primary: true,
        meta_json: {
          generated_pdf_at_utc: ts.generated_pdf_at_utc,
          submission_mode: submissionMode
        }
      });
    }

    // 2B) Electronic signatures system evidence (no new storage)
    const hasSig =
      !!(ts && (
        (ts.authorised_at_server) ||
        (ts.r2_nurse_key && String(ts.r2_nurse_key).trim()) ||
        (ts.r2_auth_key  && String(ts.r2_auth_key).trim())
      ));

    if (hasSig) {
      const sigAt = ts?.authorised_at_server || null;

      systemEvidence.push({
        id: `SYS:ELECTRONIC_SIGNATURES:${currentTsId}`,
        timesheet_id: currentTsId,
        kind: 'ELECTRONIC_SIGNATURES',
        display_name: 'Electronic submission evidence',
        storage_key: null,
        created_at: sigAt,
        uploaded_at_utc: sigAt,
        system: true,
        can_delete: false,
        preview_mode: 'SIGNATURES',
        is_primary: true,
        meta_json: {
          booking_id: ts?.booking_id || null,
          version: (ts?.version != null ? Number(ts.version) : null),

          authorised_at_server: ts?.authorised_at_server || null,
          auth_name: ts?.auth_name || null,
          auth_job_title: ts?.auth_job_title || null,

          r2_nurse_key: (ts?.r2_nurse_key && String(ts.r2_nurse_key).trim()) ? String(ts.r2_nurse_key).trim() : null,
          r2_auth_key:  (ts?.r2_auth_key  && String(ts.r2_auth_key).trim())  ? String(ts.r2_auth_key).trim()  : null,

          sheet_scope: ts?.sheet_scope || null,
          week_ending_date: ts?.week_ending_date || null,
          reference_number: ts?.reference_number || null,

          worked_start_iso: ts?.worked_start_iso || null,
          worked_end_iso: ts?.worked_end_iso || null,
          break_start_iso: ts?.break_start_iso || null,
          break_end_iso: ts?.break_end_iso || null,
          break_minutes: (ts?.break_minutes != null ? ts.break_minutes : null),

          actual_schedule_json: (ts?.actual_schedule_json != null ? ts.actual_schedule_json : null)
        }
      });
    }

    // 2C) NHSP / HealthRoster imports (unchanged logic; already working)
    const importIds = new Set();

    try {
      const { rows: shiftRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
          `?timesheet_id=eq.${enc(currentTsId)}` +
          `&select=latest_import_id,source_system` +
          `&limit=10000`
      );
      for (const sh of shiftRows || []) {
        const iid = sh && sh.latest_import_id ? String(sh.latest_import_id).trim() : '';
        if (iid) importIds.add(iid);
      }
    } catch {}

    try {
      const { rows: valRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheet_validations` +
          `?timesheet_id=eq.${enc(currentTsId)}` +
          `&select=last_source,updated_at` +
          `&order=updated_at.desc` +
          `&limit=1`
      );
      const lastSource = valRows?.[0]?.last_source || null;
      if (lastSource) {
        const iid = String(lastSource).trim();
        if (iid) importIds.add(iid);
      }
    } catch {}

    if (importIds.size) {
      try {
        const idParam = Array.from(importIds).map(enc).join(',');
        const { rows: impRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/hr_imports` +
            `?id=in.(${idParam})` +
            `&select=id,source_system,filename,uploaded_at_utc,file_r2_key` +
            `&limit=1000`
        );

        for (const r of (impRows || [])) {
          if (!r || !r.file_r2_key) continue;

          const sys = String(r.source_system || '').toUpperCase();
          const importId = r.id ? String(r.id) : '';

          let kindLabel = sys || 'SYSTEM';
          if (sys.includes('NHSP')) kindLabel = 'NHSP';
          else if (sys.includes('HEALTHROSTER')) kindLabel = 'HealthRoster';

          const uploadedAt = r.uploaded_at_utc || null;

          systemEvidence.push({
            id: `SYS:${kindLabel}:${importId || 'UNKNOWN'}`,
            timesheet_id: currentTsId,
            kind: kindLabel,
            display_name: r.filename || kindLabel,
            storage_key: r.file_r2_key,
            download_storage_key: r.file_r2_key,
            created_at: uploadedAt,
            uploaded_at_utc: uploadedAt,
            system: true,
            can_delete: false,
            uploaded_by_display: 'System',
            created_by_display: 'System',
            preview_mode: 'IMPORT_TABLE'
          });
        }
      } catch {
        // non-fatal
      }
    }

    const all = [...userEvidence, ...systemEvidence];

    const toTs = (x) => {
      const s = x && (x.uploaded_at_utc || x.created_at);
      if (!s) return 0;
      const t = new Date(s).getTime();
      return Number.isFinite(t) ? t : 0;
    };
    all.sort((a, b) => toTs(a) - toTs(b));

    if (wantMeta) {
      return withCORS(env, req, ok({
        requested_timesheet_id: resolved.requested_timesheet_id || tsId,
        current_timesheet_id: currentTsId,
        was_stale: !!resolved.was_stale,
        evidence: all
      }));
    }

    return withCORS(env, req, ok(all));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to list timesheet evidence: ${e?.message || e}`));
  }
}



// POST /api/timesheets/:id/evidence
// POST /api/timesheets/:id/evidence


// DELETE /api/timesheets/:id/evidence/:evidence_id



// DELETE /api/timesheets/:id/evidence/:evidence_id
async function handleTimesheetEvidenceDelete(env, req, tsId, evidenceId) {
  const enc = encodeURIComponent;

  // Auth: admin only
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!tsId) return withCORS(env, req, badRequest('timesheet_id is required'));
  if (!evidenceId) return withCORS(env, req, badRequest('evidence_id is required'));

  // ✅ Guarded write (DELETE with JSON body)
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // ✅ Rotation-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, tsId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTsId = resolved.current_timesheet_id;

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTsId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTsId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  // Local R2 delete helper (so deletion actually cleans up storage even if global r2Delete is absent)
  const r2DeleteLocal = async (key) => {
    const bucket = env.R2_BUCKET || env.R2;
    if (!bucket || typeof bucket.delete !== 'function') {
      throw new Error('Storage not configured (expected env.R2 or env.R2_BUCKET with delete())');
    }
    const k = String(key || '').replace(/^\/+/, '').trim();
    if (!k) return false;
    await bucket.delete(k);
    return true;
  };

  try {
    // ✅ Block evidence delete if invoiced/paid (match QR scan rule)
    try {
      const fin = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(currentTsId)}` +
          `&is_current=eq.true` +
          `&select=locked_by_invoice_id,paid_at_utc` +
          `&limit=1`
      );
      if (fin && (fin.locked_by_invoice_id || fin.paid_at_utc)) {
        return withCORS(env, req, badRequest('Timesheet already invoiced or paid; cannot delete evidence'));
      }
    } catch (e) {
      return withCORS(env, req, serverError(`Failed to validate timesheet financial lock state: ${e?.message || e}`));
    }

    // Ensure evidence row exists and belongs to this timesheet
    const { rows: evRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence` +
        `?id=eq.${enc(evidenceId)}` +
        `&timesheet_id=eq.${enc(currentTsId)}` +
        `&select=id,storage_key,kind,display_name` +
        `&limit=1`
    );
    const ev = evRows?.[0] || null;
    if (!ev) return withCORS(env, req, notFound('Evidence not found for this timesheet'));

    // Load minimal TS context for audit + optional cleanup of pointers
    let tsMeta = null;
    try {
      const { rows: tsRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(currentTsId)}` +
          `&is_current=eq.true` +
          `&select=timesheet_id,contract_id,week_ending_date,sheet_scope,submission_mode,manual_pdf_r2_key,manual_pdf_rotation_degrees,generated_pdf_at_utc` +
          `&limit=1`
      );
      tsMeta = tsRows?.[0] || null;
    } catch {}

    const storageKeyRaw = ev.storage_key || null;
    const storageKeyForR2 = storageKeyRaw ? String(storageKeyRaw).trim().replace(/^\/+/, '') : null;

    // 1) Best-effort delete from R2 (this deletes the actual file object)
    try {
      if (storageKeyForR2) {
        await r2DeleteLocal(storageKeyForR2);
      }
    } catch (e) {
      console.warn('[handleTimesheetEvidenceDelete] R2 delete failed (non-fatal)', {
        storage_key: storageKeyForR2,
        err: e?.message || String(e)
      });
    }

    // 2) Delete DB evidence row (timesheet_evidence)
    const delRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence?id=eq.${enc(evidenceId)}`,
      { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return-minimal' } }
    );

    if (!delRes.ok) {
      const t = await delRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to delete timesheet evidence: ${t}`));
    }

    // 3) Optional: also clear any timesheet pointer fields that reference the same key
    //    (prevents the timesheet record pointing at a deleted object).
    //    This is still a single REST call, not a loop.
    try {
      const patches = {};

      const mk = tsMeta?.manual_pdf_r2_key ? String(tsMeta.manual_pdf_r2_key).replace(/^\/+/, '').trim() : '';
      const sk = storageKeyForR2 ? String(storageKeyForR2).trim() : '';

      // If the deleted file was also the manual scan pointer, clear it
      if (mk && sk && mk === sk) {
        patches.manual_pdf_r2_key = null;
        patches.manual_pdf_rotation_degrees = 0;
      }

      // If the deleted file was the system-generated PDF key, clear the generated flag
      const generatedKey = `docs-pdf/timesheets/ts_${currentTsId}.pdf`;
      if (sk && sk === generatedKey) {
        patches.generated_pdf_at_utc = null;
      }

      if (Object.keys(patches).length) {
        const updRes = await fetch(
          `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTsId)}&is_current=eq.true`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
            body: JSON.stringify(patches)
          }
        );

        if (!updRes.ok) {
          const txt = await updRes.text().catch(() => '');
          console.warn('[handleTimesheetEvidenceDelete] timesheets pointer cleanup failed (non-fatal)', {
            timesheet_id: currentTsId,
            patches,
            err: txt
          });
        }
      }
    } catch (e) {
      console.warn('[handleTimesheetEvidenceDelete] pointer cleanup failed (non-fatal)', {
        timesheet_id: currentTsId,
        err: e?.message || String(e)
      });
    }

    // Audit
    try {
      await writeAudit(
        env,
        user,
        'TIMESHEET_EVIDENCE_REMOVED',
        {
          timesheet_id: currentTsId,
          evidence_id: evidenceId,
          kind: ev.kind || null,
          display_name: ev.display_name || null,
          storage_key: storageKeyRaw,
          contract_id: tsMeta?.contract_id || null,
          week_ending_date: tsMeta?.week_ending_date || null,
          sheet_scope: tsMeta?.sheet_scope || null,
          submission_mode: tsMeta?.submission_mode || null
        },
        { entity: 'timesheets', subject_id: currentTsId, req }
      );
    } catch {}

    return withCORS(env, req, ok({
      ok: true,
      requested_timesheet_id: resolved.requested_timesheet_id || tsId,
      current_timesheet_id: currentTsId,
      was_stale: !!resolved.was_stale
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to delete timesheet evidence: ${e?.message || e}`));
  }
}

async function handleTimesheetReplaceManualPdf(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  const body = await parseJSONBody(req).catch(() => null);

  // ✅ Guarded write
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // ✅ stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = resolved.current_timesheet_id;

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  const normalize = (k) => normalizeKey(String(k || '')); // uses your existing helper
  const cleanKey = (k) => String(k || '').replace(/^\/+/, '').trim();

  const newKeyRaw = body?.manual_pdf_r2_key ?? null;
  const newKey = newKeyRaw ? normalize(String(newKeyRaw)) : null;

  // ✅ Lock/paid enforcement (same rule as evidence add/delete + QR scan)
  try {
    const fin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=locked_by_invoice_id,paid_at_utc` +
        `&limit=1`
    );
    if (fin && (fin.locked_by_invoice_id || fin.paid_at_utc)) {
      return withCORS(env, req, badRequest('Timesheet already invoiced or paid; cannot replace manual PDF'));
    }
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to validate timesheet lock state: ${e?.message || e}`));
  }

  // Load current timesheet row to know the old pointer (so we can delete it)
  const tsBefore = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=timesheet_id,manual_pdf_r2_key` +
      `&limit=1`
  );
  if (!tsBefore) return withCORS(env, req, notFound('Timesheet not found'));

  const oldKey = tsBefore?.manual_pdf_r2_key ? normalize(tsBefore.manual_pdf_r2_key) : null;

  // Canonical deterministic key for this timesheet version
  const canonicalPdfKey = cleanKey(`docs-pdf/timesheets/ts_${currentTimesheetId}.pdf`);

  // If a key is provided, sanity check it exists in R2
  if (newKey) {
    const exists = await r2Exists(env, newKey).catch(() => false);
    if (!exists) return withCORS(env, req, badRequest('manual_pdf_r2_key does not exist in R2'));
  }

  // R2 helpers (inline so this function is paste-ready)
  const bucket = env.R2_BUCKET || env.R2;
  const canGetPut = !!(bucket && typeof bucket.get === 'function' && typeof bucket.put === 'function');
  const canDelete = !!(bucket && typeof bucket.delete === 'function');

  const r2CopyOverwriteLocal = async (fromKey, toKey) => {
    if (!canGetPut) throw new Error('Storage not configured for copy (need env.R2 or env.R2_BUCKET with get/put)');
    const src = cleanKey(fromKey);
    const dst = cleanKey(toKey);
    const obj = await bucket.get(src);
    if (!obj) throw new Error(`Source not found in R2: ${src}`);
    const putOpts = {};
    if (obj.httpMetadata) putOpts.httpMetadata = obj.httpMetadata;
    if (obj.customMetadata) putOpts.customMetadata = obj.customMetadata;
    await bucket.put(dst, obj.body, putOpts);
    return true;
  };

  const r2DeleteBestEffort = async (k) => {
    if (!canDelete) return false;
    const kk = cleanKey(k);
    if (!kk) return false;
    try { await bucket.delete(kk); return true; } catch { return false; }
  };

  // Compute target key we will store on the timesheet:
  // - If setting a new manual PDF: copy it into canonical key and point manual_pdf_r2_key to canonical.
  // - If clearing: set manual_pdf_r2_key null.
  let targetKey = null;

  try {
    if (newKey) {
      // Copy uploaded scan to canonical key (overwrite canonical)
      await r2CopyOverwriteLocal(newKey, canonicalPdfKey);

      // Delete the uploaded scan key after copy (best-effort)
      await r2DeleteBestEffort(newKey);

      targetKey = canonicalPdfKey;
    } else {
      targetKey = null;
    }
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to store manual PDF: ${e?.message || e}`));
  }

  // Patch the CURRENT timesheet row's manual_pdf_r2_key
  const tsRes = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({
        manual_pdf_r2_key: targetKey,
        updated_at: new Date().toISOString()
      })
    }
  );

  if (!tsRes.ok) return withCORS(env, req, serverError(await tsRes.text()));

  const tsJson = await tsRes.json().catch(() => []);
  const row = (Array.isArray(tsJson) ? tsJson[0] : tsJson) || null;

  // ✅ Purge previous MANUAL_PDF evidence rows for this timesheet version
  // and delete their storage keys (but NEVER delete the canonical system PDF key).
  try {
    const { rows: evRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&kind=eq.MANUAL_PDF` +
        `&select=id,storage_key` +
        `&limit=10000`
    );

    const existing = Array.isArray(evRows) ? evRows : [];
    for (const ev of existing) {
      const k = ev?.storage_key ? normalize(ev.storage_key) : null;
      if (!k) continue;

      // never delete canonical system key
      if (cleanKey(k) === canonicalPdfKey) continue;

      // never delete the new target key (if we somehow stored it directly)
      if (targetKey && cleanKey(k) === cleanKey(targetKey)) continue;

      await r2DeleteBestEffort(k);
    }

    // Delete the evidence rows
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence?timesheet_id=eq.${enc(currentTimesheetId)}&kind=eq.MANUAL_PDF`,
      { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return-minimal' } }
    ).catch(() => {});
  } catch (e) {
    // Non-fatal: evidence cleanup shouldn’t block the replace action
    console.warn('[handleTimesheetReplaceManualPdf] evidence cleanup failed (non-fatal)', {
      timesheet_id: currentTimesheetId,
      err: e?.message || String(e)
    });
  }

  // ✅ Delete the old manual_pdf_r2_key object if it was a non-canonical blob
  // (canonical should never be deleted here).
  try {
    if (oldKey) {
      const oldClean = cleanKey(oldKey);
      if (oldClean && oldClean !== canonicalPdfKey) {
        // If we set a new targetKey, old is superseded
        // If we cleared, old is also superseded
        await r2DeleteBestEffort(oldClean);
      }
    }
  } catch {
    // non-fatal
  }

  // Insert a single MANUAL_PDF evidence row when a new manual PDF is set
  if (targetKey) {
    try {
      const payload = [{
        timesheet_id: currentTimesheetId,
        kind: 'MANUAL_PDF',
        display_name: 'Scanned timesheet',
        storage_key: cleanKey(targetKey),
        created_by: user.id || null
      }];

      const evRes = await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheet_evidence`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify(payload)
        }
      );

      if (!evRes.ok) {
        const errTxt = await evRes.text().catch(() => '');
        return withCORS(env, req, serverError(`Failed to record timesheet evidence: ${errTxt}`));
      }
    } catch (e) {
      return withCORS(env, req, serverError(`Failed to record timesheet evidence: ${e?.message || e}`));
    }
  }

  // Audit the PDF replacement (whether we set or cleared it)
  try {
    await writeAudit(
      env,
      user,
      'TIMESHEET_MANUAL_PDF_REPLACED',
      { manual_pdf_r2_key: targetKey },
      { entity: 'timesheets', subject_id: currentTimesheetId, req }
    );
  } catch {}

  return withCORS(env, req, ok({
    timesheet_id: currentTimesheetId,
    current_timesheet_id: currentTimesheetId,
    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale,
    manual_pdf_r2_key: row?.manual_pdf_r2_key || null
  }));
}

async function rebuildWeeklyTsfinForTimesheet(env, timesheetId, contract) {
  // ⚠️ RETIRED (Jan 2026): Do NOT call this in loops/bulk operations. Use tsfinTargetedDrainNow(env, { timesheetIds: [...], reason, chunkSize }) so TSFIN recompute stays SQL-first + batched.

  const enc = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);

  // ─────────────────────────────────────────────────────────────
  // Helper: write snapshot via SQL outbox + batch writer (deterministic reason)
  // ─────────────────────────────────────────────────────────────
 const writeTsfinViaSql = async (tsid, snapshot, reason = 'CONTEXT_CHANGED') => {
  let outboxId = null;

  try {
    // Ensure outbox row exists (priority)
    await sbRpc(env, 'enqueue_ts_financials_priority', {
      _timesheet_ids: [tsid],
      _reason: reason
    });

    // ✅ RPC-only deterministic lease (no REST)
    const leased = await sbRpc(env, 'tsfin_dequeue_specific', {
      p_timesheet_ids: [tsid],
      p_limit: 1
    });

    const row = Array.isArray(leased) ? leased[0] : null;
    outboxId = row?.id || null;

    if (!outboxId) {
      return { ok: false, outbox_id: null, reason: 'NO_OUTBOX_ROW' };
    }

    const wr = await rpcTsfinWriteSnapshotsAndComplete(env, {
      rows: [{
        outbox_id: outboxId,
        timesheet_id: tsid,
        snapshot
      }]
    });

    const ok = (Number(wr?.ok_count || 0) > 0);
    return { ok, outbox_id: outboxId, wr };
  } catch (e) {
    return { ok: false, outbox_id: outboxId, error: String(e?.message || e) };
  }
};

  // ─────────────────────────────────────────────────────────────
  // Load current TS + current TSFIN in ONE RPC (no per-item REST)
  // ─────────────────────────────────────────────────────────────
  const ctxRows = await rpcTsfinLoadContextBatch(env, { timesheetIds: [timesheetId] });
  const ctx = (Array.isArray(ctxRows) && ctxRows[0]) ? ctxRows[0] : null;

  const ts = ctx?.out_timesheet || null;
  const fin = ctx?.out_cur_fin || null;

  if (!fin) return { ok: false, reason: 'NO_SNAPSHOT' };
  if (!ts)  return { ok: false, reason: 'TS_NOT_FOUND' };

  if (fin.locked_by_invoice_id || fin.paid_at_utc) {
    return { ok: false, reason: 'LOCKED_OR_PAID' };
  }

  // Contract rates (weekly uses contract rates; not client-default windows)
  const pc = payChargeFromContract(contract);
  const pay = pc?.pay || null;
  const charge = pc?.charge || null;
  const method = pc?.method || contract?.pay_method_snapshot || contract?.pay_method || null;
  if (!pay || !charge) return { ok: false, reason: 'CONTRACT_RATES_MISSING' };

  const basisRaw = fin.basis || '';
  const basisU = String(basisRaw).toUpperCase();

  // ─────────────────────────────────────────────────────────────
  // Helpers
  // ─────────────────────────────────────────────────────────────
  const toYmd = (d) => {
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const addDaysYmd = (ymd, days) => {
    const d = new Date(`${String(ymd)}T00:00:00Z`);
    if (!Number.isFinite(d.getTime())) return String(ymd || '');
    d.setUTCDate(d.getUTCDate() + Number(days || 0));
    return toYmd(d);
  };

  const parseHHMM = (s) => {
    const m = String(s || '').trim().match(/^(\d{1,2}):(\d{2})$/);
    if (!m) return null;
    const hh = Number(m[1]), mm = Number(m[2]);
    if (!Number.isFinite(hh) || !Number.isFinite(mm)) return null;
    if (hh < 0 || hh > 23 || mm < 0 || mm > 59) return null;
    return hh * 60 + mm;
  };

  const getWeekDates = (weekEndingYmd) => {
    const out = [];
    if (!weekEndingYmd) return out;
    try {
      const base = new Date(`${String(weekEndingYmd)}T00:00:00Z`);
      if (!Number.isFinite(base.getTime())) return out;
      for (let offset = 6; offset >= 0; offset--) {
        const d = new Date(base);
        d.setUTCDate(base.getUTCDate() - offset);
        out.push({ ymd: toYmd(d), dow: d.getUTCDay() });
      }
    } catch {}
    return out;
  };

  const normaliseFreq = (raw) => {
    const s = String(raw || '').toUpperCase();
    if (s === 'ONE_PER_WEEK')          return 'ONE_PER_WEEK';
    if (s === 'ONE_PER_DAY')           return 'ONE_PER_DAY';
    if (s === 'WEEKENDS_AND_BH_ONLY')  return 'WEEKENDS_AND_BH_ONLY';
    if (s === 'WEEKDAYS_EXCL_BH_ONLY') return 'WEEKDAYS_EXCL_BH_ONLY';
    return 'ONE_PER_WEEK';
  };

  // units + additional calculation: prefers ts.additional_units_* then falls back to fin.additional_units_json
  const computeAdditionalFromTsOrFin = async () => {
    const cfgArrRaw = contract.additional_rates_json;
    let cfgArr = Array.isArray(cfgArrRaw) ? cfgArrRaw : [];
    if (typeof cfgArrRaw === 'string') {
      try { cfgArr = JSON.parse(cfgArrRaw); } catch { cfgArr = []; }
    }
    if (!Array.isArray(cfgArr)) cfgArr = [];

    if (!cfgArr.length) {
      return {
        additional_units_json: {},
        additional_pay_ex_vat: 0,
        additional_charge_ex_vat: 0,
        additional_margin_ex_vat: 0
      };
    }

    let unitsWeek = ts.additional_units_week || {};
    let unitsPerDay = ts.additional_units_per_day || {};
    if (typeof unitsWeek === 'string') { try { unitsWeek = JSON.parse(unitsWeek); } catch { unitsWeek = {}; } }
    if (typeof unitsPerDay === 'string') { try { unitsPerDay = JSON.parse(unitsPerDay); } catch { unitsPerDay = {}; } }
    if (!unitsWeek || typeof unitsWeek !== 'object') unitsWeek = {};
    if (!unitsPerDay || typeof unitsPerDay !== 'object') unitsPerDay = {};

    const finStored = (fin.additional_units_json && typeof fin.additional_units_json === 'object') ? fin.additional_units_json : {};
    const weekDates = getWeekDates(ts.week_ending_date || null);

    // BH list via loadPolicy (canonical)
    let bhSet = new Set();
    try {
      const ymd = ts.week_ending_date || null;
      const pol = await loadPolicy(env, contract.client_id, ymd);
      const bhList = Array.isArray(pol?.bh_list) ? pol.bh_list : [];
      bhSet = new Set(bhList.map(String));
    } catch {
      bhSet = new Set();
    }
    const isBH = (ymd) => bhSet.has(String(ymd));

    const shouldIncludeDay = (freq, meta) => {
      const { ymd, dow } = meta;
      const bh = isBH(ymd);
      if (freq === 'ONE_PER_DAY')           return true;
      if (freq === 'WEEKENDS_AND_BH_ONLY')  return bh || dow === 0 || dow === 6;
      if (freq === 'WEEKDAYS_EXCL_BH_ONLY') return !bh && dow >= 1 && dow <= 5;
      return false;
    };

    const additional_units_json = {};
    let additional_pay_ex_vat = 0;
    let additional_charge_ex_vat = 0;

    for (const cfg of cfgArr) {
      if (!cfg || !cfg.code) continue;
      const code = String(cfg.code || '').toUpperCase().trim();
      if (!code) continue;

      const freq = normaliseFreq(cfg.frequency);

      let unitCount = 0;
      let daysUsed = undefined;

      if (freq === 'ONE_PER_WEEK') {
        const u = Number(unitsWeek[code] ?? 0);
        if (Number.isFinite(u) && u > 0) unitCount = u;
        else {
          const stored = finStored[code] || null;
          const su = Number(stored?.unit_count ?? 0);
          if (Number.isFinite(su) && su > 0) unitCount = su;
          if (stored && stored.days && typeof stored.days === 'object') daysUsed = stored.days;
        }
      } else {
        const perRaw = (unitsPerDay[code] && typeof unitsPerDay[code] === 'object') ? unitsPerDay[code] : {};
        const stored = finStored[code] || null;
        const storedDays = (stored && stored.days && typeof stored.days === 'object') ? stored.days : null;

        const perDayOut = {};
        let any = false;

        if (weekDates.length) {
          for (const meta of weekDates) {
            const v = Number(perRaw?.[meta.ymd] ?? 0);
            if (!Number.isFinite(v) || v <= 0) continue;
            if (!shouldIncludeDay(freq, meta)) continue;
            unitCount += v;
            perDayOut[meta.ymd] = (perDayOut[meta.ymd] || 0) + v;
            any = true;
          }
        }

        if (!any && storedDays) {
          for (const [ymd, vv] of Object.entries(storedDays)) {
            const meta = {
              ymd: String(ymd || ''),
              dow: (() => { try { return new Date(`${String(ymd)}T00:00:00Z`).getUTCDay(); } catch { return null; } })()
            };
            const v = Number(vv ?? 0);
            if (!Number.isFinite(v) || v <= 0) continue;
            if (meta.dow == null) continue;
            if (!shouldIncludeDay(freq, meta)) continue;
            unitCount += v;
            perDayOut[meta.ymd] = (perDayOut[meta.ymd] || 0) + v;
            any = true;
          }
        }

        if (any && Object.keys(perDayOut).length) daysUsed = perDayOut;
      }

      if (!Number.isFinite(unitCount) || unitCount <= 0) continue;

      const payRate =
        (cfg.pay_rate != null && Number.isFinite(Number(cfg.pay_rate)))
          ? Number(cfg.pay_rate)
          : Number((finStored[code] && finStored[code].pay_rate) || 0);

      const chargeRate =
        (cfg.charge_rate != null && Number.isFinite(Number(cfg.charge_rate)))
          ? Number(cfg.charge_rate)
          : Number((finStored[code] && finStored[code].charge_rate) || 0);

      const payEx = +Number(unitCount * payRate).toFixed(2);
      const chgEx = +Number(unitCount * chargeRate).toFixed(2);

      additional_units_json[code] = {
        bucket_name: cfg.bucket_name || finStored?.[code]?.bucket_name || null,
        unit_name:   cfg.unit_name   || finStored?.[code]?.unit_name   || null,
        frequency:   freq,
        unit_count:  unitCount,
        pay_rate:    payRate,
        charge_rate: chargeRate,
        pay_ex_vat:  payEx,
        charge_ex_vat: chgEx,
        ...(daysUsed ? { days: daysUsed } : {})
      };

      additional_pay_ex_vat += payEx;
      additional_charge_ex_vat += chgEx;
    }

    additional_pay_ex_vat = +Number(additional_pay_ex_vat).toFixed(2);
    additional_charge_ex_vat = +Number(additional_charge_ex_vat).toFixed(2);
    const additional_margin_ex_vat = +Number(additional_charge_ex_vat - additional_pay_ex_vat).toFixed(2);

    return { additional_units_json, additional_pay_ex_vat, additional_charge_ex_vat, additional_margin_ex_vat };
  };

  const getPreservedBySegmentId = () => {
    const preserved = new Map();
    try {
      const ib = fin.invoice_breakdown_json || null;
      const mode = String(ib?.mode || '').toUpperCase();
      const segs = Array.isArray(ib?.segments) ? ib.segments : null;
      if (mode !== 'SEGMENTS' || !segs) return preserved;

      for (const s of segs) {
        const sid = s?.segment_id ? String(s.segment_id) : null;
        if (!sid) continue;
        preserved.set(sid, {
          exclude_from_pay: (typeof s.exclude_from_pay === 'boolean') ? s.exclude_from_pay : undefined,
          invoice_target_week_start: (s.invoice_target_week_start != null) ? String(s.invoice_target_week_start) : undefined,
          invoice_locked_invoice_id: (s.invoice_locked_invoice_id != null) ? String(s.invoice_locked_invoice_id) : undefined
        });
      }
    } catch {}
    return preserved;
  };

  // Ensure policy_snapshot_json is NOT NULL (DB constraint)
  let policySnap = fin.policy_snapshot_json;
  if (!policySnap || typeof policySnap !== 'object') {
    try {
      const ymd = ts.week_ending_date || null;
      policySnap = ymd ? await loadPolicy(env, contract.client_id, ymd) : {};
    } catch {
      policySnap = {};
    }
  }

  // ─────────────────────────────────────────────────────────────
  // Evidence base routing
  // ─────────────────────────────────────────────────────────────

  // NHSP basis: rebuild using NHSP shifts (SEGMENTS)
  if (basisU === 'NHSP' || basisU === 'NHSP_ADJUSTMENT') {
    // ✅ NEW: batch RPC instead of REST /nhsp_shifts
    let shifts = [];
    try {
      const rows = await sbRpc(env, 'tsfin_load_nhsp_shifts_batch', {
        p_timesheet_ids: [ts.timesheet_id]
      });

      const r0 = Array.isArray(rows) ? rows[0] : null;
      const arr = r0?.shifts;

      if (Array.isArray(arr)) shifts = arr;
      else if (typeof arr === 'string') {
        try {
          const parsed = JSON.parse(arr);
          if (Array.isArray(parsed)) shifts = parsed;
        } catch {}
      } else {
        shifts = [];
      }
    } catch {
      shifts = [];
    }

    // Request-scope policy cache for this call
    const policyCache = new Map();
    const getPolicyCached = async (client_id, ymd) => {
      const key = `${String(client_id || '')}|${String(ymd || '')}`;
      if (policyCache.has(key)) return policyCache.get(key);
      const pol = await loadPolicy(env, client_id, ymd);
      policyCache.set(key, pol);
      return pol;
    };

    if (shifts.length) {
      const nhspImportId = fin.nhsp_import_id || null;

      // buildNhspWeeklySnapshotCached is compute-only and accepts curFin
      const built = await buildNhspWeeklySnapshotCached(
        env,
        ts,
        contract,
        shifts,
        nhspImportId,
        fin.basis || 'NHSP',
        getPolicyCached,
        fin
      );

      if (!built?.ok || !built?.snapshot) return { ok: false, reason: built?.reason || 'NHSP_BUILD_FAILED' };

      const wr = await writeTsfinViaSql(ts.timesheet_id, built.snapshot, 'CONTEXT_CHANGED');
      if (!wr.ok) {
        // fallback legacy write (and clear outbox if we created one)
        await writeSnapshot(env, built.snapshot);
        if (wr.outbox_id) { try { await sbRpc(env, 'tsfin_work_success', { p_id: wr.outbox_id }); } catch {} }
      }

      return { ok: true, mode: 'NHSP_REBUILD' };
    }

    // If no shifts found, fall back to preserving existing segments evidence if present
    const ib = fin.invoice_breakdown_json || null;
    const mode = String(ib?.mode || '').toUpperCase();
    const segs = Array.isArray(ib?.segments) ? ib.segments : null;

    if (mode === 'SEGMENTS' && segs && segs.length) {
      const preservedSegs = segs.map(s => {
        const hDay   = asNumberLocal(s.hours_day);
        const hNight = asNumberLocal(s.hours_night);
        const hSat   = asNumberLocal(s.hours_sat);
        const hSun   = asNumberLocal(s.hours_sun);
        const hBh    = asNumberLocal(s.hours_bh);

        const payEx = round2(
          hDay   * asNumberLocal(pay.day) +
          hNight * asNumberLocal(pay.night) +
          hSat   * asNumberLocal(pay.sat) +
          hSun   * asNumberLocal(pay.sun) +
          hBh    * asNumberLocal(pay.bh)
        );

        const chgEx = round2(
          hDay   * asNumberLocal(charge.day) +
          hNight * asNumberLocal(charge.night) +
          hSat   * asNumberLocal(charge.sat) +
          hSun   * asNumberLocal(charge.sun) +
          hBh    * asNumberLocal(charge.bh)
        );

        return { ...s, pay_amount: payEx, charge_amount: chgEx };
      });

      let sumDay = 0, sumNight = 0, sumSat = 0, sumSun = 0, sumBh = 0;
      let sumPay = 0, sumChg = 0;
      preservedSegs.forEach(s => {
        sumDay += asNumberLocal(s.hours_day);
        sumNight += asNumberLocal(s.hours_night);
        sumSat += asNumberLocal(s.hours_sat);
        sumSun += asNumberLocal(s.hours_sun);
        sumBh += asNumberLocal(s.hours_bh);
        sumPay += asNumberLocal(s.pay_amount);
        sumChg += asNumberLocal(s.charge_amount);
      });

      const addl = await computeAdditionalFromTsOrFin();

      const hours = {
        day: round2(sumDay),
        night: round2(sumNight),
        sat: round2(sumSat),
        sun: round2(sumSun),
        bh: round2(sumBh)
      };
      const total_hours = round2(hours.day + hours.night + hours.sat + hours.sun + hours.bh);

      const total_pay_ex_vat = +Number(round2(sumPay) + Number(addl.additional_pay_ex_vat || 0)).toFixed(2);
      const total_charge_ex_vat = +Number(round2(sumChg) + Number(addl.additional_charge_ex_vat || 0)).toFixed(2);
      const margin_ex_vat = +Number(total_charge_ex_vat - total_pay_ex_vat).toFixed(2);

      const snap = { ...fin };
      delete snap.id;
      delete snap.is_current;

      snap.timesheet_id = ts.timesheet_id;
      snap.timesheet_version = ts.version || fin.timesheet_version || 1;

      snap.candidate_id = contract.candidate_id;
      snap.client_id = contract.client_id;
      snap.pay_method = method;

      snap.policy_snapshot_json = policySnap;
      snap.rate_source_refs_json = { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null };

      snap.hours_day = hours.day;
      snap.hours_night = hours.night;
      snap.hours_sat = hours.sat;
      snap.hours_sun = hours.sun;
      snap.hours_bh = hours.bh;

      snap.pay_day = (pay.day != null) ? Number(pay.day) : null;
      snap.pay_night = (pay.night != null) ? Number(pay.night) : null;
      snap.pay_sat = (pay.sat != null) ? Number(pay.sat) : null;
      snap.pay_sun = (pay.sun != null) ? Number(pay.sun) : null;
      snap.pay_bh = (pay.bh != null) ? Number(pay.bh) : null;

      snap.charge_day = (charge.day != null) ? Number(charge.day) : null;
      snap.charge_night = (charge.night != null) ? Number(charge.night) : null;
      snap.charge_sat = (charge.sat != null) ? Number(charge.sat) : null;
      snap.charge_sun = (charge.sun != null) ? Number(charge.sun) : null;
      snap.charge_bh = (charge.bh != null) ? Number(charge.bh) : null;

      snap.total_hours = total_hours;

      snap.additional_units_json = addl.additional_units_json || {};
      snap.additional_pay_ex_vat = +Number(addl.additional_pay_ex_vat || 0).toFixed(2);
      snap.additional_charge_ex_vat = +Number(addl.additional_charge_ex_vat || 0).toFixed(2);
      snap.additional_margin_ex_vat = +Number(addl.additional_margin_ex_vat || 0).toFixed(2);

      snap.total_pay_ex_vat = total_pay_ex_vat;
      snap.total_charge_ex_vat = total_charge_ex_vat;
      snap.margin_ex_vat = margin_ex_vat;

      snap.invoice_breakdown_json = {
        mode: 'SEGMENTS',
        segments: preservedSegs,
        additional: {
          units: addl.additional_units_json || {},
          pay_ex_vat: +Number(addl.additional_pay_ex_vat || 0).toFixed(2),
          charge_ex_vat: +Number(addl.additional_charge_ex_vat || 0).toFixed(2),
          margin_ex_vat: +Number(addl.additional_margin_ex_vat || 0).toFixed(2)
        },
        totals: { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat }
      };

      const wr = await writeTsfinViaSql(ts.timesheet_id, snap, 'CONTEXT_CHANGED');
      if (!wr.ok) {
        await writeSnapshot(env, snap);
        if (wr.outbox_id) { try { await sbRpc(env, 'tsfin_work_success', { p_id: wr.outbox_id }); } catch {} }
      }

      return { ok: true, mode: 'SEGMENTS_EVIDENCE_REPRICE' };
    }

    return { ok: false, reason: 'NO_SHIFTS_FOR_NHSP_REBUILD' };
  }

  // Schedule-driven weekly -> SEGMENTS
  if (Array.isArray(ts.actual_schedule_json) && ts.actual_schedule_json.length) {
    const preservedById = getPreservedBySegmentId();

    const segments = [];
    let sumDay = 0, sumNight = 0, sumSat = 0, sumSun = 0, sumBh = 0;
    let sumPay = 0, sumChg = 0;

    const scheduleEntryToUtcRange = (seg) => {
      const date = String(seg?.date || '').trim();
      if (!date) return { startUtcIso: null, endUtcIso: null };

      const startIsoRaw = seg?.start_utc || seg?.start_iso || null;
      const endIsoRaw   = seg?.end_utc   || seg?.end_iso   || null;

      const isIsoLike = (s) => {
        const x = String(s || '');
        return x.includes('T') && (x.endsWith('Z') || /[+\-]\d{2}:\d{2}$/.test(x));
      };

      if (startIsoRaw && endIsoRaw && isIsoLike(startIsoRaw) && isIsoLike(endIsoRaw)) {
        return { startUtcIso: String(startIsoRaw), endUtcIso: String(endIsoRaw) };
      }

      const startHH = String(seg?.start || '').trim();
      const endHH   = String(seg?.end   || '').trim();
      if (!startHH || !endHH) return { startUtcIso: null, endUtcIso: null };

      const sMin = parseHHMM(startHH);
      const eMin = parseHHMM(endHH);
      if (sMin == null || eMin == null) return { startUtcIso: null, endUtcIso: null };

      const overnight = (eMin <= sMin);
      const endYmd = overnight ? addDaysYmd(date, 1) : date;

      if (typeof ukLocalToUtcISO !== 'function') return { startUtcIso: null, endUtcIso: null };

      return {
        startUtcIso: ukLocalToUtcISO(date, startHH),
        endUtcIso:   ukLocalToUtcISO(endYmd, endHH)
      };
    };

    for (let i = 0; i < ts.actual_schedule_json.length; i++) {
      const seg = ts.actual_schedule_json[i] || {};
      const mins = await resolveBucketsFromSchedule(env, contract, [seg]);

      const hDay   = +(asNumberLocal(mins.day)   / 60).toFixed(2);
      const hNight = +(asNumberLocal(mins.night) / 60).toFixed(2);
      const hSat   = +(asNumberLocal(mins.sat)   / 60).toFixed(2);
      const hSun   = +(asNumberLocal(mins.sun)   / 60).toFixed(2);
      const hBh    = +(asNumberLocal(mins.bh)    / 60).toFixed(2);

      sumDay += hDay; sumNight += hNight; sumSat += hSat; sumSun += hSun; sumBh += hBh;

      const payEx = round2(
        hDay   * asNumberLocal(pay.day) +
        hNight * asNumberLocal(pay.night) +
        hSat   * asNumberLocal(pay.sat) +
        hSun   * asNumberLocal(pay.sun) +
        hBh    * asNumberLocal(pay.bh)
      );

      const chgEx = round2(
        hDay   * asNumberLocal(charge.day) +
        hNight * asNumberLocal(charge.night) +
        hSat   * asNumberLocal(charge.sat) +
        hSun   * asNumberLocal(charge.sun) +
        hBh    * asNumberLocal(charge.bh)
      );

      sumPay += payEx;
      sumChg += chgEx;

      const sid = `ts:${ts.timesheet_id}:${i}`;
      const preserved = preservedById.get(sid) || null;

      const exclude_from_pay =
        (preserved && typeof preserved.exclude_from_pay === 'boolean') ? preserved.exclude_from_pay : false;

      const invoice_target_week_start =
        (preserved && preserved.invoice_target_week_start != null) ? preserved.invoice_target_week_start : undefined;

      const invoice_locked_invoice_id =
        (preserved && preserved.invoice_locked_invoice_id != null) ? preserved.invoice_locked_invoice_id : undefined;

      const { startUtcIso, endUtcIso } = scheduleEntryToUtcRange(seg);
      const br = Number(seg.break_mins ?? seg.break_minutes ?? 0);

      segments.push({
        segment_id: sid,
        date: seg.date || null,
        start_utc: startUtcIso,
        end_utc: endUtcIso,
        break_mins: Number.isFinite(br) ? br : 0,

        ref_num: (seg.ref_num != null && String(seg.ref_num).trim()) ? String(seg.ref_num).trim() : null,
        breaks: Array.isArray(seg.breaks) ? seg.breaks : [],

        hours_day: hDay,
        hours_night: hNight,
        hours_sat: hSat,
        hours_sun: hSun,
        hours_bh: hBh,

        pay_amount: payEx,
        charge_amount: chgEx,

        exclude_from_pay,
        ...(invoice_target_week_start != null ? { invoice_target_week_start } : {}),
        ...(invoice_locked_invoice_id != null ? { invoice_locked_invoice_id } : {})
      });
    }

    const hours = {
      day: round2(sumDay),
      night: round2(sumNight),
      sat: round2(sumSat),
      sun: round2(sumSun),
      bh: round2(sumBh)
    };
    const total_hours = round2(hours.day + hours.night + hours.sat + hours.sun + hours.bh);

    const addl = await computeAdditionalFromTsOrFin();

    const total_pay_ex_vat = +Number(round2(sumPay) + Number(addl.additional_pay_ex_vat || 0)).toFixed(2);
    const total_charge_ex_vat = +Number(round2(sumChg) + Number(addl.additional_charge_ex_vat || 0)).toFixed(2);
    const margin_ex_vat = +Number(total_charge_ex_vat - total_pay_ex_vat).toFixed(2);

    const snap = { ...fin };
    delete snap.id;
    delete snap.is_current;

    snap.timesheet_id = ts.timesheet_id;
    snap.timesheet_version = ts.version || fin.timesheet_version || 1;
    snap.candidate_id = contract.candidate_id;
    snap.client_id = contract.client_id;
    snap.pay_method = method;

    snap.policy_snapshot_json = policySnap;
    snap.rate_source_refs_json = { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null };

    snap.hours_day = hours.day;
    snap.hours_night = hours.night;
    snap.hours_sat = hours.sat;
    snap.hours_sun = hours.sun;
    snap.hours_bh = hours.bh;

    snap.pay_day = (pay.day != null) ? Number(pay.day) : null;
    snap.pay_night = (pay.night != null) ? Number(pay.night) : null;
    snap.pay_sat = (pay.sat != null) ? Number(pay.sat) : null;
    snap.pay_sun = (pay.sun != null) ? Number(pay.sun) : null;
    snap.pay_bh = (pay.bh != null) ? Number(pay.bh) : null;

    snap.charge_day = (charge.day != null) ? Number(charge.day) : null;
    snap.charge_night = (charge.night != null) ? Number(charge.night) : null;
    snap.charge_sat = (charge.sat != null) ? Number(charge.sat) : null;
    snap.charge_sun = (charge.sun != null) ? Number(charge.sun) : null;
    snap.charge_bh = (charge.bh != null) ? Number(charge.bh) : null;

    snap.total_hours = total_hours;

    snap.additional_units_json = addl.additional_units_json || {};
    snap.additional_pay_ex_vat = +Number(addl.additional_pay_ex_vat || 0).toFixed(2);
    snap.additional_charge_ex_vat = +Number(addl.additional_charge_ex_vat || 0).toFixed(2);
    snap.additional_margin_ex_vat = +Number(addl.additional_margin_ex_vat || 0).toFixed(2);

    snap.total_pay_ex_vat = total_pay_ex_vat;
    snap.total_charge_ex_vat = total_charge_ex_vat;
    snap.margin_ex_vat = margin_ex_vat;

    snap.invoice_breakdown_json = {
      mode: 'SEGMENTS',
      segments,
      additional: {
        units: addl.additional_units_json || {},
        pay_ex_vat: +Number(addl.additional_pay_ex_vat || 0).toFixed(2),
        charge_ex_vat: +Number(addl.additional_charge_ex_vat || 0).toFixed(2),
        margin_ex_vat: +Number(addl.additional_margin_ex_vat || 0).toFixed(2)
      },
      totals: { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat }
    };

    const wr = await writeTsfinViaSql(ts.timesheet_id, snap, 'CONTEXT_CHANGED');
    if (!wr.ok) {
      await writeSnapshot(env, snap);
      if (wr.outbox_id) { try { await sbRpc(env, 'tsfin_work_success', { p_id: wr.outbox_id }); } catch {} }
    }

    return { ok: true, mode: 'SCHEDULE_SEGMENTS_REBUILD' };
  }

  // Existing SEGMENTS evidence (non-NHSP): reprice without changing hours evidence
  {
    const ib = fin.invoice_breakdown_json || null;
    const mode = String(ib?.mode || '').toUpperCase();
    const segs = Array.isArray(ib?.segments) ? ib.segments : null;

    if (mode === 'SEGMENTS' && segs && segs.length) {
      const nextSegments = segs.map(s => {
        const hDay   = asNumberLocal(s.hours_day);
        const hNight = asNumberLocal(s.hours_night);
        const hSat   = asNumberLocal(s.hours_sat);
        const hSun   = asNumberLocal(s.hours_sun);
        const hBh    = asNumberLocal(s.hours_bh);

        const payEx = round2(
          hDay   * asNumberLocal(pay.day) +
          hNight * asNumberLocal(pay.night) +
          hSat   * asNumberLocal(pay.sat) +
          hSun   * asNumberLocal(pay.sun) +
          hBh    * asNumberLocal(pay.bh)
        );

        const chgEx = round2(
          hDay   * asNumberLocal(charge.day) +
          hNight * asNumberLocal(charge.night) +
          hSat   * asNumberLocal(charge.sat) +
          hSun   * asNumberLocal(charge.sun) +
          hBh    * asNumberLocal(charge.bh)
        );

        return { ...s, pay_amount: payEx, charge_amount: chgEx };
      });

      let sumDay = 0, sumNight = 0, sumSat = 0, sumSun = 0, sumBh = 0;
      let sumPay = 0, sumChg = 0;
      nextSegments.forEach(s => {
        sumDay += asNumberLocal(s.hours_day);
        sumNight += asNumberLocal(s.hours_night);
        sumSat += asNumberLocal(s.hours_sat);
        sumSun += asNumberLocal(s.hours_sun);
        sumBh += asNumberLocal(s.hours_bh);
        sumPay += asNumberLocal(s.pay_amount);
        sumChg += asNumberLocal(s.charge_amount);
      });

      const addl = await computeAdditionalFromTsOrFin();

      const hours = {
        day: round2(sumDay),
        night: round2(sumNight),
        sat: round2(sumSat),
        sun: round2(sumSun),
        bh: round2(sumBh)
      };
      const total_hours = round2(hours.day + hours.night + hours.sat + hours.sun + hours.bh);

      const total_pay_ex_vat = +Number(round2(sumPay) + Number(addl.additional_pay_ex_vat || 0)).toFixed(2);
      const total_charge_ex_vat = +Number(round2(sumChg) + Number(addl.additional_charge_ex_vat || 0)).toFixed(2);
      const margin_ex_vat = +Number(total_charge_ex_vat - total_pay_ex_vat).toFixed(2);

      const snap = { ...fin };
      delete snap.id;
      delete snap.is_current;

      snap.timesheet_id = ts.timesheet_id;
      snap.timesheet_version = ts.version || fin.timesheet_version || 1;
      snap.candidate_id = contract.candidate_id;
      snap.client_id = contract.client_id;
      snap.pay_method = method;

      snap.policy_snapshot_json = policySnap;
      snap.rate_source_refs_json = { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null };

      snap.hours_day = hours.day;
      snap.hours_night = hours.night;
      snap.hours_sat = hours.sat;
      snap.hours_sun = hours.sun;
      snap.hours_bh = hours.bh;

      snap.pay_day = (pay.day != null) ? Number(pay.day) : null;
      snap.pay_night = (pay.night != null) ? Number(pay.night) : null;
      snap.pay_sat = (pay.sat != null) ? Number(pay.sat) : null;
      snap.pay_sun = (pay.sun != null) ? Number(pay.sun) : null;
      snap.pay_bh = (pay.bh != null) ? Number(pay.bh) : null;

      snap.charge_day = (charge.day != null) ? Number(charge.day) : null;
      snap.charge_night = (charge.night != null) ? Number(charge.night) : null;
      snap.charge_sat = (charge.sat != null) ? Number(charge.sat) : null;
      snap.charge_sun = (charge.sun != null) ? Number(charge.sun) : null;
      snap.charge_bh = (charge.bh != null) ? Number(charge.bh) : null;

      snap.total_hours = total_hours;

      snap.additional_units_json = addl.additional_units_json || {};
      snap.additional_pay_ex_vat = +Number(addl.additional_pay_ex_vat || 0).toFixed(2);
      snap.additional_charge_ex_vat = +Number(addl.additional_charge_ex_vat || 0).toFixed(2);
      snap.additional_margin_ex_vat = +Number(addl.additional_margin_ex_vat || 0).toFixed(2);

      snap.total_pay_ex_vat = total_pay_ex_vat;
      snap.total_charge_ex_vat = total_charge_ex_vat;
      snap.margin_ex_vat = margin_ex_vat;

      snap.invoice_breakdown_json = {
        mode: 'SEGMENTS',
        segments: nextSegments,
        additional: {
          units: addl.additional_units_json || {},
          pay_ex_vat: +Number(addl.additional_pay_ex_vat || 0).toFixed(2),
          charge_ex_vat: +Number(addl.additional_charge_ex_vat || 0).toFixed(2),
          margin_ex_vat: +Number(addl.additional_margin_ex_vat || 0).toFixed(2)
        },
        totals: { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat }
      };

      const wr = await writeTsfinViaSql(ts.timesheet_id, snap, 'CONTEXT_CHANGED');
      if (!wr.ok) {
        await writeSnapshot(env, snap);
        if (wr.outbox_id) { try { await sbRpc(env, 'tsfin_work_success', { p_id: wr.outbox_id }); } catch {} }
      }

      return { ok: true, mode: 'SEGMENTS_EVIDENCE_REPRICE' };
    }
  }

  // Fallback AGGREGATE only when we truly do not have segment evidence
  const hours = {
    day:   Number(fin.hours_day   || 0),
    night: Number(fin.hours_night || 0),
    sat:   Number(fin.hours_sat   || 0),
    sun:   Number(fin.hours_sun   || 0),
    bh:    Number(fin.hours_bh    || 0)
  };

  const totalHoursPay =
    (hours.day   * (pay.day   || 0)) +
    (hours.night * (pay.night || 0)) +
    (hours.sat   * (pay.sat   || 0)) +
    (hours.sun   * (pay.sun   || 0)) +
    (hours.bh    * (pay.bh    || 0));

  const totalHoursCharge =
    (hours.day   * (charge.day   || 0)) +
    (hours.night * (charge.night || 0)) +
    (hours.sat   * (charge.sat   || 0)) +
    (hours.sun   * (charge.sun   || 0)) +
    (hours.bh    * (charge.bh    || 0));

  const hoursPayEx    = +Number(totalHoursPay).toFixed(2);
  const hoursChargeEx = +Number(totalHoursCharge).toFixed(2);

  const addl = await computeAdditionalFromTsOrFin();

  const total_pay_ex_vat    = +Number(hoursPayEx    + Number(addl.additional_pay_ex_vat || 0)).toFixed(2);
  const total_charge_ex_vat = +Number(hoursChargeEx + Number(addl.additional_charge_ex_vat || 0)).toFixed(2);
  const margin_ex_vat       = +Number(total_charge_ex_vat - total_pay_ex_vat).toFixed(2);

  const invoice_breakdown_json = {
    mode: "AGGREGATE",
    base_hours: {
      day: hours.day,
      night: hours.night,
      sat: hours.sat,
      sun: hours.sun,
      bh: hours.bh,
      pay_rates: { day: pay.day, night: pay.night, sat: pay.sat, sun: pay.sun, bh: pay.bh },
      charge_rates: { day: charge.day, night: charge.night, sat: charge.sat, sun: charge.sun, bh: charge.bh },
      pay_ex_vat: hoursPayEx,
      charge_ex_vat: hoursChargeEx,
    },
    additional: {
      units: addl.additional_units_json || {},
      pay_ex_vat: +Number(addl.additional_pay_ex_vat || 0).toFixed(2),
      charge_ex_vat: +Number(addl.additional_charge_ex_vat || 0).toFixed(2),
      margin_ex_vat: +Number(addl.additional_margin_ex_vat || 0).toFixed(2),
    },
    totals: { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat },
  };

  const snap = { ...fin };
  delete snap.id;
  delete snap.is_current;

  snap.timesheet_id = ts.timesheet_id;
  snap.timesheet_version = ts.version || fin.timesheet_version || 1;
  snap.candidate_id = contract.candidate_id;
  snap.client_id = contract.client_id;
  snap.pay_method = method;

  snap.policy_snapshot_json = policySnap;
  snap.rate_source_refs_json = { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null };

  snap.pay_day = (pay.day != null) ? Number(pay.day) : null;
  snap.pay_night = (pay.night != null) ? Number(pay.night) : null;
  snap.pay_sat = (pay.sat != null) ? Number(pay.sat) : null;
  snap.pay_sun = (pay.sun != null) ? Number(pay.sun) : null;
  snap.pay_bh = (pay.bh != null) ? Number(pay.bh) : null;

  snap.charge_day = (charge.day != null) ? Number(charge.day) : null;
  snap.charge_night = (charge.night != null) ? Number(charge.night) : null;
  snap.charge_sat = (charge.sat != null) ? Number(charge.sat) : null;
  snap.charge_sun = (charge.sun != null) ? Number(charge.sun) : null;
  snap.charge_bh = (charge.bh != null) ? Number(charge.bh) : null;

  snap.total_hours = round2(hours.day + hours.night + hours.sat + hours.sun + hours.bh);

  snap.additional_units_json = addl.additional_units_json || {};
  snap.additional_pay_ex_vat = +Number(addl.additional_pay_ex_vat || 0).toFixed(2);
  snap.additional_charge_ex_vat = +Number(addl.additional_charge_ex_vat || 0).toFixed(2);
  snap.additional_margin_ex_vat = +Number(addl.additional_margin_ex_vat || 0).toFixed(2);

  snap.total_pay_ex_vat = total_pay_ex_vat;
  snap.total_charge_ex_vat = total_charge_ex_vat;
  snap.margin_ex_vat = margin_ex_vat;

  snap.invoice_breakdown_json = invoice_breakdown_json;

  const wr = await writeTsfinViaSql(ts.timesheet_id, snap, 'CONTEXT_CHANGED');
  if (!wr.ok) {
    await writeSnapshot(env, snap);
    if (wr.outbox_id) { try { await sbRpc(env, 'tsfin_work_success', { p_id: wr.outbox_id }); } catch {} }
  }

  return { ok: true, mode: 'AGGREGATE_FALLBACK' };
}


async function handleTimesheetsSubmitWeekly(env, req) {
  // Public / broker: submit weekly timesheet (ELECTRONIC or QR intent)
  const enc = encodeURIComponent;

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const cwId = body.contract_week_id || null;
  if (!cwId) return withCORS(env, req, badRequest('contract_week_id required'));

  // Desired route:
  // - 'ELECTRONIC' (default) => electronic submission
  // - 'QR' => candidate chooses QR route (issue QR timesheet + email)
  const desiredRoute = String(body?.submission_route || body?.desired_route || 'ELECTRONIC').trim().toUpperCase();
  const wantsQR = (desiredRoute === 'QR');

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cwId)}&select=*`
  );
  if (!cw) return withCORS(env, req, notFound('Weekly slot not found'));

  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(cw.contract_id)}&select=*`
  );
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  // Client submission-mode capability: client_settings.default_submission_mode
  // - ELECTRONIC => electronic allowed (and QR allowed)
  // - MANUAL     => electronic NOT allowed, QR allowed
  let supportsElectronic = false;
  try {
    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
        `?client_id=eq.${enc(contract.client_id)}` +
        `&select=default_submission_mode,updated_at,created_at` +
        `&order=updated_at.desc.nullslast,created_at.desc.nullslast` +
        `&limit=1`
    );
    const cs = csRows?.[0] || null;
    const dsm = String(cs?.default_submission_mode || '').toUpperCase();
    supportsElectronic = (dsm === 'ELECTRONIC');
  } catch {
    supportsElectronic = false;
  }

  if (!wantsQR && !supportsElectronic) {
    return withCORS(env, req, badRequest('Electronic submission is not enabled for this client; please use QR'));
  }

  // Determine existing timesheet (if any) and enforce resubmission rules
  let existingTimesheetId = cw.timesheet_id || null;
  let existingTs = null;
  let existingFin = null;

  if (existingTimesheetId) {
    existingTs = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(existingTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=*` +
        `&limit=1`
    );

    // ✅ include hours for minimal “hours changed” audit diff
    existingFin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(existingTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=paid_at_utc,locked_by_invoice_id,processing_status,id,hours_day,hours_night,hours_sat,hours_sun,hours_bh,total_hours` +
        `&limit=1`
    );

    if (existingFin?.paid_at_utc || existingFin?.locked_by_invoice_id) {
      return withCORS(env, req, badRequest('Timesheet already invoiced or paid; resubmission is blocked'));
    }

    // Manual-only hard stop: submission_mode MANUAL and no QR overlay
    const sm = String(existingTs?.submission_mode || '').toUpperCase();
    const qrStatus = String(existingTs?.qr_status || '').toUpperCase() || null;
    const hasQrToken = !!(existingTs?.qr_token && String(existingTs.qr_token).trim());
    const hasQrGen = !!existingTs?.qr_generated_at;
    const hasQrScan = !!existingTs?.qr_scanned_at;

    const isManualOnly =
      (sm === 'MANUAL') &&
      !qrStatus &&
      !hasQrToken &&
      !hasQrGen &&
      !hasQrScan;

    if (isManualOnly) {
      return withCORS(env, req, badRequest('This timesheet is manual-only; candidate resubmission is disabled'));
    }
  }

  // Schedule-first, totals fallback (used for both ELECTRONIC and QR issuance)
  let hours = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
  let actual_schedule_json = null;

  if (Array.isArray(body?.actual_schedule_json) && body.actual_schedule_json.length) {
    actual_schedule_json = body.actual_schedule_json;

    try {
      validateScheduleStructure(actual_schedule_json);
    } catch (e) {
      return withCORS(
        env,
        req,
        badRequest(e?.message || 'Invalid schedule: overlapping shifts or invalid break windows.')
      );
    }

    try {
      const mins = await resolveBucketsFromSchedule(env, contract, actual_schedule_json);
      hours = {
        day:   +(mins.day   / 60).toFixed(2),
        night: +(mins.night / 60).toFixed(2),
        sat:   +(mins.sat   / 60).toFixed(2),
        sun:   +(mins.sun   / 60).toFixed(2),
        bh:    +(mins.bh    / 60).toFixed(2)
      };
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid actual_schedule_json'));
    }
  } else {
    const n = (v) => (v == null ? 0 : Number(v) || 0);
    hours = {
      day:   n(body?.hours?.day),
      night: n(body?.hours?.night),
      sat:   n(body?.hours?.sat),
      sun:   n(body?.hours?.sun),
      bh:    n(body?.hours?.bh)
    };
  }

  // Strict rate guard BEFORE writing anything
  const { pay, charge, method } = payChargeFromContract(contract);
  const anyMissing = (h, P, C) =>
    (h.day   > 0 && (!P.day   && P.day   !== 0 || !C.day   && C.day   !== 0)) ||
    (h.night > 0 && (!P.night && P.night !== 0 || !C.night && C.night !== 0)) ||
    (h.sat   > 0 && (!P.sat   && P.sat   !== 0 || !C.sat   && C.sat   !== 0)) ||
    (h.sun   > 0 && (!P.sun   && P.sun   !== 0 || !C.sun   && C.sun   !== 0)) ||
    (h.bh    > 0 && (!P.bh    && P.bh    !== 0 || !C.bh    && C.bh    !== 0));

  if (anyMissing(hours, pay, charge)) {
    return withCORS(env, req, badRequest('Missing rate(s) in contract for one or more entered hour buckets'));
  }

  // Additional unit buckets (EX1..EX5)
  const unitsWeek = (body.additional_units_week && typeof body.additional_units_week === 'object')
    ? body.additional_units_week
    : {};
  const unitsPerDay = (body.additional_units_per_day && typeof body.additional_units_per_day === 'object')
    ? body.additional_units_per_day
    : {};

  const addlConfig = Array.isArray(contract.additional_rates_json)
    ? contract.additional_rates_json
    : [];

  const weekDates = [];
  try {
    const base = new Date(String(cw.week_ending_date) + 'T00:00:00Z');
    for (let offset = 6; offset >= 0; offset--) {
      const d = new Date(base);
      d.setUTCDate(base.getUTCDate() - offset);
      const yyyy = d.getUTCFullYear();
      const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
      const dd   = String(d.getUTCDate()).toString().padStart(2, '0');
      const ymd  = `${yyyy}-${mm}-${dd}`;
      const dow  = d.getUTCDay();
      weekDates.push({ ymd, dow });
    }
  } catch {}

  let bhSet = new Set();
  try {
    const policy = await loadClientTimePolicy(env, contract.client_id);
    if (policy && policy.bhList) {
      if (policy.bhList instanceof Set) {
        bhSet = policy.bhList;
      } else if (Array.isArray(policy.bhList)) {
        bhSet = new Set(policy.bhList);
      }
    }
  } catch {
    bhSet = new Set();
  }

  const isBH = (ymd) => bhSet.has(ymd);

  const normaliseFreq = (raw) => {
    const s = String(raw || '').toUpperCase();
    if (s === 'ONE_PER_WEEK')          return 'ONE_PER_WEEK';
    if (s === 'ONE_PER_DAY')           return 'ONE_PER_DAY';
    if (s === 'WEEKENDS_AND_BH_ONLY')  return 'WEEKENDS_AND_BH_ONLY';
    if (s === 'WEEKDAYS_EXCL_BH_ONLY') return 'WEEKDAYS_EXCL_BH_ONLY';
    return 'ONE_PER_WEEK';
  };

  const shouldIncludeDay = (freq, meta) => {
    const { ymd, dow } = meta;
    const bh = isBH(ymd);
    if (freq === 'ONE_PER_DAY')           return true;
    if (freq === 'WEEKENDS_AND_BH_ONLY')  return bh || dow === 0 || dow === 6;
    if (freq === 'WEEKDAYS_EXCL_BH_ONLY') return !bh && dow >= 1 && dow <= 5;
    return false;
  };

  let additional_units_json    = {};
  let additional_pay_ex_vat    = 0;
  let additional_charge_ex_vat = 0;
  const badBuckets = [];

  for (const cfgRaw of addlConfig) {
    if (!cfgRaw || typeof cfgRaw !== 'object') continue;
    const code = String(cfgRaw.code || '').toUpperCase() || 'EX1';
    const freq = normaliseFreq(cfgRaw.frequency);
    let unitCount = 0;
    const daysUsed = {};

    if (freq === 'ONE_PER_WEEK') {
      const u = Number(unitsWeek[code] || 0);
      if (u && Number.isFinite(u)) unitCount = u;
    } else {
      const perRaw = (unitsPerDay[code] && typeof unitsPerDay[code] === 'object')
        ? unitsPerDay[code]
        : {};
      for (const meta of weekDates) {
        const raw = perRaw[meta.ymd];
        if (raw == null || raw === '') continue;
        const v = Number(raw);
        if (!Number.isFinite(v) || !v) continue;
        if (!shouldIncludeDay(freq, meta)) continue;
        unitCount += v;
        daysUsed[meta.ymd] = v;
      }
    }

    if (!unitCount || !Number.isFinite(unitCount)) continue;

    const payRate    = (cfgRaw.pay_rate    != null) ? Number(cfgRaw.pay_rate)    : NaN;
    const chargeRate = (cfgRaw.charge_rate != null) ? Number(cfgRaw.charge_rate) : NaN;
    if (!Number.isFinite(payRate) || !Number.isFinite(chargeRate)) {
      badBuckets.push(cfgRaw.bucket_name || code);
      continue;
    }

    const payEx = +Number(unitCount * payRate).toFixed(2);
    const chgEx = +Number(unitCount * chargeRate).toFixed(2);

    additional_units_json[code] = {
      bucket_name:   cfgRaw.bucket_name || null,
      unit_name:     cfgRaw.unit_name   || null,
      frequency:     freq,
      unit_count:    unitCount,
      pay_rate:      payRate,
      charge_rate:   chargeRate,
      pay_ex_vat:    payEx,
      charge_ex_vat: chgEx,
      days:          Object.keys(daysUsed).length ? daysUsed : undefined
    };

    additional_pay_ex_vat    += payEx;
    additional_charge_ex_vat += chgEx;
  }

  if (badBuckets.length) {
    const msg = `Missing additional rate(s) in contract for bucket(s): ${badBuckets.join(', ')}`;
    return withCORS(env, req, badRequest(msg));
  }

  additional_pay_ex_vat    = +Number(additional_pay_ex_vat).toFixed(2);
  additional_charge_ex_vat = +Number(additional_charge_ex_vat).toFixed(2);
  const additional_margin_ex_vat =
    +Number(additional_charge_ex_vat - additional_pay_ex_vat).toFixed(2);

  // Load names for norms + email (for QR route)
  const candidateRec = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(contract.candidate_id)}&select=id,display_name,email`
  );
  const clientRec = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${enc(contract.client_id)}&select=id,name`
  );

  // Actor for audit (public route): show candidate name in audit tab
  const auditActor = {
    id: null,
    display_name: candidateRec?.display_name ? `${candidateRec.display_name} (candidate)` : 'CloudTMS server',
    email: candidateRec?.email || null,
    role: 'candidate'
  };

  const now = nowIso();
  const weC = ymdCompact(cw.week_ending_date);

  // ✅ FIX: makeWeeklyBookingId is async (wraps async makeBookingId)
  const bookingId = await makeWeeklyBookingId(contract.candidate_id, contract, cw);
  if (!bookingId || typeof bookingId !== 'string' || bookingId === '{}' || bookingId === 'null' || bookingId === 'undefined') {
    return withCORS(env, req, badRequest(`Invalid booking_id produced: "${String(bookingId)}"`));
  }

  // If resubmitting into same timesheet_id, rotate version; otherwise create new timesheet_id
  let timesheetIdToUse = existingTimesheetId || null;
  let newVersion = 1;

  // Minimal hours-change detection (for audit)
  const stableJson = (x) => { try { return JSON.stringify(x ?? null); } catch { return ''; } };
  const prevHours = existingFin ? {
    day:   Number(existingFin.hours_day   ?? 0),
    night: Number(existingFin.hours_night ?? 0),
    sat:   Number(existingFin.hours_sat   ?? 0),
    sun:   Number(existingFin.hours_sun   ?? 0),
    bh:    Number(existingFin.hours_bh    ?? 0),
    total: Number(existingFin.total_hours ?? 0),
  } : null;
  const nextHours = {
    day:   Number(hours.day   ?? 0),
    night: Number(hours.night ?? 0),
    sat:   Number(hours.sat   ?? 0),
    sun:   Number(hours.sun   ?? 0),
    bh:    Number(hours.bh    ?? 0),
    total: Number((Number(hours.day||0)+Number(hours.night||0)+Number(hours.sat||0)+Number(hours.sun||0)+Number(hours.bh||0)).toFixed(2))
  };
  const scheduleChanged =
    !!existingTs &&
    stableJson(existingTs.actual_schedule_json) !== stableJson(actual_schedule_json);
  const hoursChanged =
    !!prevHours &&
    stableJson(prevHours) !== stableJson(nextHours);

  if (timesheetIdToUse) {
    // Determine next version number
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(timesheetIdToUse)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const maxV = Number(vRows?.[0]?.version || 1);
    newVersion = (Number.isFinite(maxV) ? maxV : 1) + 1;

    // Revoke old current version
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(timesheetIdToUse)}` +
        `&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          is_current: false,
          status: 'REVOKED',
          revoked_reason: wantsQR ? 'CANDIDATE_SWITCH_TO_QR' : 'CANDIDATE_RESUBMIT_ELECTRONIC',
          revoked_by: null,
          updated_at: now
        })
      }
    ).catch(() => {});
  }

  // If ELECTRONIC: require signatures uploaded for this version
  let nurseKey = null;
  let authKey = null;

  if (!wantsQR) {
    nurseKey = `Signatures/we=${weC}/${bookingId}/v${newVersion}/nurse.png`;
    authKey  = `Signatures/we=${weC}/${bookingId}/v${newVersion}/authoriser.png`;


    try {
      await r2Head(env, nurseKey);
      await r2Head(env, authKey);
    } catch {
      return withCORS(env, req, badRequest('Signatures not uploaded (nurse and authoriser required)'));
    }
  }

  // Create new current timesheet version row
  const tsRow = {
    booking_id: bookingId,

    ...(timesheetIdToUse ? { timesheet_id: timesheetIdToUse } : {}),

    version: newVersion,
    is_current: true,

    status: 'RECEIVED',

    sheet_scope: 'WEEKLY',
    occupant_key_norm: (candidateRec?.display_name || String(candidateRec?.id)).toLowerCase(),
    hospital_norm:     (contract.display_site || clientRec?.name || String(contract.client_id)).toLowerCase(),
    ward_norm:         (contract.ward_hint || 'contract').toLowerCase(),
    job_title_norm:    (contract.role || 'weekly').toLowerCase(),
    shift_label_norm:  'weekly',
    week_ending_date:  cw.week_ending_date,

    r2_nurse_key:      wantsQR ? null : nurseKey,
    r2_auth_key:       wantsQR ? null : authKey,

    contract_id:       contract.id,

    submission_mode:   wantsQR ? 'MANUAL' : 'ELECTRONIC',
    authorised_at_server: wantsQR ? null : now,

    // ✅ Persist addl-units on timesheets (these columns are used elsewhere in your system)
    additional_units_week:   unitsWeek,
    additional_units_per_day: unitsPerDay,

    manual_pdf_r2_key: null,
    line_type:         'HOURS',
    actual_schedule_json,

    created_at: now,
    updated_at: now,

    // Keep NOT NULL safe + avoid accidental “QR-looking” rows on ELECTRONIC
    qr_payload_json: {},
    qr_status: null,
    qr_token: null,
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null,

    // ✅ new QR hash fields default null
    qr_last_sent_hash: null,
    qr_last_sent_at_utc: null,
    qr_signed_hash: null,
    qr_signed_at_utc: null
  };

  const tsIns = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify([tsRow])
    }
  );
  if (!tsIns.ok) {
    return withCORS(env, req, serverError(await tsIns.text()));
  }
  const ts = (await tsIns.json().catch(() => []))[0];

  // Link week to timesheet_id if first time; otherwise keep existing id
  if (!timesheetIdToUse) {
    timesheetIdToUse = ts.timesheet_id;
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          timesheet_id: ts.timesheet_id,
          status: wantsQR ? 'SUBMITTED' : 'AUTHORISED',
          updated_at: now
        })
      }
    );
  } else {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          status: wantsQR ? 'SUBMITTED' : 'AUTHORISED',
          updated_at: now
        })
      }
    ).catch(() => {});
  }

  // ─────────────────────────────────────────────────────────────
  // ✅ TIMESHEET TAB AUDIT (minimal + meaningful)
  // ─────────────────────────────────────────────────────────────
  try {
    if (!existingTimesheetId) {
      await writeAudit(
        env,
        auditActor,
        'TIMESHEET_CREATED',
        {
          timesheet_id: ts.timesheet_id,
          sheet_scope: 'WEEKLY',
          submission_route: wantsQR ? 'QR' : 'ELECTRONIC',
          submission_mode: wantsQR ? 'MANUAL' : 'ELECTRONIC',
          version: newVersion,
          contract_week_id: cw.id,
          contract_id: contract.id
        },
        { entity: 'timesheets', subject_id: ts.timesheet_id, req }
      );
    } else {
      await writeAudit(
        env,
        auditActor,
        'TIMESHEET_RESUBMITTED',
        {
          timesheet_id: ts.timesheet_id,
          sheet_scope: 'WEEKLY',
          submission_route: wantsQR ? 'QR' : 'ELECTRONIC',
          version: newVersion,
          previous_version: newVersion - 1,
          schedule_changed: !!scheduleChanged,
          hours_changed: !!hoursChanged
        },
        { entity: 'timesheets', subject_id: ts.timesheet_id, req }
      );

      if (scheduleChanged || hoursChanged) {
        await writeAudit(
          env,
          auditActor,
          'TIMESHEET_HOURS_CHANGED',
          {
            timesheet_id: ts.timesheet_id,
            sheet_scope: 'WEEKLY',
            version: newVersion,
            before_hours: prevHours,
            after_hours: nextHours,
            schedule_changed: !!scheduleChanged
          },
          { entity: 'timesheets', subject_id: ts.timesheet_id, req }
        );
      }
    }

    await writeAudit(
      env,
      auditActor,
      'TIMESHEET_SUBMITTED',
      {
        timesheet_id: ts.timesheet_id,
        sheet_scope: 'WEEKLY',
        submission_route: wantsQR ? 'QR' : 'ELECTRONIC',
        submission_mode: wantsQR ? 'MANUAL' : 'ELECTRONIC',
        version: newVersion
      },
      { entity: 'timesheets', subject_id: ts.timesheet_id, req }
    );

    if (!wantsQR) {
      await writeAudit(
        env,
        auditActor,
        'TIMESHEET_AUTHORISED',
        {
          timesheet_id: ts.timesheet_id,
          sheet_scope: 'WEEKLY',
          version: newVersion,
          authorised_at_server: now,
          r2_nurse_key: nurseKey,
          r2_auth_key: authKey
        },
        { entity: 'timesheets', subject_id: ts.timesheet_id, req }
      );
    }
  } catch {}

  // Snapshot
  const n2 = (x) => Number(x) || 0;
  const base_pay =
    +(hours.day   * n2(pay.day)   +
      hours.night * n2(pay.night) +
      hours.sat   * n2(pay.sat)   +
      hours.sun   * n2(pay.sun)   +
      hours.bh    * n2(pay.bh)).toFixed(2);
  const base_charge =
    +(hours.day   * n2(charge.day)   +
      hours.night * n2(charge.night) +
      hours.sat   * n2(charge.sat)   +
      hours.sun   * n2(charge.sun)   +
      hours.bh    * n2(charge.bh)).toFixed(2);

  const total_pay    = +Number(base_pay    + additional_pay_ex_vat).toFixed(2);
  const total_charge = +Number(base_charge + additional_charge_ex_vat).toFixed(2);
  const margin       = +Number(total_charge - total_pay).toFixed(2);

  if (!wantsQR && margin < 0) {
    return withCORS(env, req, badRequest('Negative margin: total charge is less than total pay for the submitted hours/rates.'));
  }

  const invoice_breakdown_json = {
    mode: "AGGREGATE",
    base_hours: {
      day:   hours.day,
      night: hours.night,
      sat:   hours.sat,
      sun:   hours.sun,
      bh:    hours.bh,
      pay_rates: {
        day:   pay.day,
        night: pay.night,
        sat:   pay.sat,
        sun:   pay.sun,
        bh:    pay.bh,
      },
      charge_rates: {
        day:   charge.day,
        night: charge.night,
        sat:   charge.sat,
        sun:   charge.sun,
        bh:    charge.bh,
      },
      pay_ex_vat:     base_pay,
      charge_ex_vat:  base_charge,
    },
    additional: {
      units:         additional_units_json,
      pay_ex_vat:    additional_pay_ex_vat,
      charge_ex_vat: additional_charge_ex_vat,
      margin_ex_vat: additional_margin_ex_vat,
    },
    totals: {
      total_pay_ex_vat:    total_pay,
      total_charge_ex_vat: total_charge,
      margin_ex_vat:       margin,
    },
  };

  // processing_status
  // - ELECTRONIC => READY_FOR_INVOICE
  // - QR => AWAITING_MANUAL_SIGNATURE
  const processingStatus = wantsQR ? 'AWAITING_MANUAL_SIGNATURE' : 'READY_FOR_INVOICE';

  const snap = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: newVersion,
    basis: 'CONTRACT_WEEKLY',
    candidate_id: contract.candidate_id,
    client_id:    contract.client_id,
    candidate_assignment: 'ASSIGNED',
    processing_status: processingStatus,
    pay_method: method,

    hours_day:   hours.day,
    hours_night: hours.night,
    hours_sat:   hours.sat,
    hours_sun:   hours.sun,
    hours_bh:    hours.bh,

    pay_rate_day:   pay.day,
    pay_rate_night: pay.night,
    pay_rate_sat:   pay.sat,
    pay_rate_sun:   pay.sun,
    pay_rate_bh:    pay.bh,

    rate_day:   charge.day,
    rate_night: charge.night,
    rate_sat:   charge.sat,
    rate_sun:   charge.sun,
    rate_bh:    charge.bh,

    total_pay_ex_vat:    total_pay,
    total_charge_ex_vat: total_charge,
    margin_ex_vat:       margin,

    additional_units_json,
    additional_pay_ex_vat,
    additional_charge_ex_vat,
    additional_margin_ex_vat,

    created_at: now,
    invoice_breakdown_json
  };

  await writeSnapshot(env, snap);

  // ✅ audit: processed (after snapshot)
  try {
    await writeAudit(
      env,
      auditActor,
      'TIMESHEET_PROCESSED',
      {
        timesheet_id: ts.timesheet_id,
        sheet_scope: 'WEEKLY',
        submission_route: wantsQR ? 'QR' : 'ELECTRONIC',
        version: newVersion,
        processing_status: processingStatus,
        hours: nextHours
      },
      { entity: 'timesheets', subject_id: ts.timesheet_id, req }
    );
  } catch {}

  // If QR route, issue QR immediately, generate PDF, and queue email
  let qrPdfKey = null;
  let qrToken = null;
  let qr_r2_key = null;
  let emailQueued = false;

  if (wantsQR) {
    // token first
    try {
      if (typeof crypto !== 'undefined' && typeof crypto.randomUUID === 'function') {
        qrToken = crypto.randomUUID();
      } else {
        qrToken = `${ts.timesheet_id}:${Date.now()}`;
      }
    } catch {
      qrToken = `${ts.timesheet_id}:${Date.now()}`;
    }

    // Generate/store QR payload
    const qrRes = await generateAndStoreTimesheetQr(env, {
      timesheet_id:     ts.timesheet_id,
      contract_week_id: cw.id,
      contract_id:      contract.id,
      candidate_id:     contract.candidate_id || null,
      client_id:        contract.client_id || null,
      week_ending_ymd:  cw.week_ending_date,
      qr_token:         qrToken
    });
    qr_r2_key = qrRes?.qr_r2_key || null;

    // Patch QR fields on the timesheet (⚠️ DO NOT include is_qr — it is not a column on timesheets)
    const qrPatchRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          qr_token: qrToken,
          qr_status: 'PENDING',
          qr_generated_at: now,
          qr_scanned_at: null,
          qr_scan_info_json: null,
          // qr_payload_json left as set by generateAndStoreTimesheetQr
          qr_r2_key: qr_r2_key || null,
          updated_at: now
        })
      }
    );

    if (!qrPatchRes.ok) {
      const t = await qrPatchRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to set QR fields on timesheet: ${t}`));
    }

    // Generate PDF
    try {
      qrPdfKey = await ensureTimesheetPdf(env, ts.timesheet_id);
      if (qrPdfKey) {
        await fetch(
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              manual_pdf_r2_key: qrPdfKey,
              updated_at: now
            })
          }
        ).catch(() => {});
      }
    } catch {}

    // Queue email (TIMESHEET_QR)
    try {
      const email = (candidateRec?.email && String(candidateRec.email).trim()) || null;
      if (email && qrPdfKey) {
        const subject = `Weekly QR timesheet – week ending ${cw.week_ending_date}`;

        const bodyText =
          `Please print the attached timesheet, ask the ward manager to sign it, ` +
          `and then upload the signed copy via the app.\n\n` +
          `Week ending: ${cw.week_ending_date}\n` +
          `Timesheet ID: ${ts.timesheet_id}\n`;

        const bodyHtml =
          `<p>` +
          `Please print the attached timesheet, ask the ward manager to sign it, and then upload the signed copy via the app.<br/><br/>` +
          `Week ending: ${cw.week_ending_date}<br/>` +
          `Timesheet ID: ${ts.timesheet_id}` +
          `</p>`;

        const ins = await fetch(
          `${env.SUPABASE_URL}/rest/v1/mail_outbox`,
          {
            method: 'POST',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              type: 'TIMESHEET_QR',
              to: email,
              cc: null,
              subject,
              body_text: bodyText,
              body_html: bodyHtml,
              attachments: [{
                r2_key: qrPdfKey,
                filename: `Timesheet_${cw.week_ending_date}.pdf`
              }],
              status: 'QUEUED',
              reference: `timesheet_qr:weekly:${ts.timesheet_id}:${cw.week_ending_date}:candidate`,
              created_by: null
            })
          }
        );

        emailQueued = !!ins?.ok;
        if (!ins?.ok) {
          const t = await ins.text().catch(() => '');
          console.warn('[WEEKLY_QR][SUBMIT] mail_outbox insert failed (non-fatal)', {
            timesheet_id: ts.timesheet_id,
            status: ins.status,
            bodyPreview: (t || '').slice(0, 200)
          });
        }
      }
    } catch (e) {
      console.warn('[WEEKLY_QR][SUBMIT] mail queue failed (non-fatal)', {
        timesheet_id: ts.timesheet_id,
        err: e?.message || String(e)
      });
    }

    // ✅ NEW: when the email is queued, compute + persist last-sent hash
    if (emailQueued) {
      try {
        const stableClone = (v) => {
          if (Array.isArray(v)) return v.map(stableClone);
          if (v && typeof v === 'object') {
            const out = {};
            for (const k of Object.keys(v).sort()) out[k] = stableClone(v[k]);
            return out;
          }
          return v;
        };

        const hashObj = {
          sheet_scope: 'WEEKLY',
          week_ending_date: cw.week_ending_date || null,
          actual_schedule_json: actual_schedule_json || null,
          reference_number: ts.reference_number || null,
          day_references_json: ts.day_references_json || null,
          additional_units_week: unitsWeek || {},
          additional_units_per_day: unitsPerDay || {}
        };

        const current_hash = await sha256Hex(JSON.stringify(stableClone(hashObj)));
        const sentAt = nowIso();

        await fetch(
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              qr_last_sent_hash: current_hash,
              qr_last_sent_at_utc: sentAt,
              updated_at: sentAt
            })
          }
        ).catch(() => {});
      } catch (e) {
        console.warn('[WEEKLY_QR][SUBMIT] failed to persist qr_last_sent_* (non-fatal)', {
          timesheet_id: ts.timesheet_id,
          err: e?.message || String(e)
        });
      }
    }

    // ✅ audit: QR issued (includes pdf key)
    try {
      await writeAudit(
        env,
        auditActor,
        'TIMESHEET_QR_ISSUED',
        {
          timesheet_id: ts.timesheet_id,
          sheet_scope: 'WEEKLY',
          version: newVersion,
          qr_status: 'PENDING',
          qr_token: qrToken,
          qr_r2_key: qr_r2_key || null,
          pdf_r2_key: qrPdfKey || null
        },
        { entity: 'timesheets', subject_id: ts.timesheet_id, req }
      );
    } catch {}
  }

  return withCORS(env, req, ok({
    timesheet_id: ts.timesheet_id,
    processing_status,
    submission_route: wantsQR ? 'QR' : 'ELECTRONIC',
    qr_pdf_key: qrPdfKey || null,
    qr_token: qrToken || null,
    qr_r2_key: qr_r2_key || null,
    email_queued: wantsQR ? !!emailQueued : null
  }));
}
// ─────────────────────────────────────────────────────────────
// NEW HELPER: purge superseded (non-current) timesheet artifacts
// for a booking_id, while keeping restore candidates.
// Keeps:
//   - current version
//   - most recent non-current version (undo safety)
//   - most recent REVOKED+pending (qr_scanned_at is null) (restore PENDING)
//   - most recent REVOKED+signed  (qr_scanned_at is not null) (restore SIGNED)
//   - most recent non-current with authorised_at_server (electronic restore safety)
// Purges all other non-current versions’ PDFs + evidence blobs.
// ─────────────────────────────────────────────────────────────
async function purgeSupersededTimesheetArtifactsForBooking(env, bookingId) {
  const enc = encodeURIComponent;
  const cleanKey = (k) => String(k || '').replace(/^\/+/, '').trim();
  const bucket = env.R2_BUCKET || env.R2;

  if (!bookingId || !String(bookingId).trim()) {
    return { ok: false, reason: 'booking_id missing' };
  }

  // If bucket isn't configured, we can still clean DB evidence rows/keys,
  // but we cannot actually reclaim R2 space.
  const canR2 = !!(bucket && typeof bucket.delete === 'function');

  // 1) Load all versions for this booking_id
  const { rows: tsRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(String(bookingId))}` +
      `&select=timesheet_id,is_current,version,status,qr_scanned_at,manual_pdf_r2_key,qr_r2_key,authorised_at_server,submission_mode` +
      `&order=version.desc` +
      `&limit=2000`
  );

  const rows = Array.isArray(tsRows) ? tsRows : [];
  if (rows.length <= 1) {
    return { ok: true, booking_id: String(bookingId), purged_timesheet_ids: [], deleted_keys: 0, deleted_evidence_rows: 0 };
  }

  // 2) Identify keep set
  const keep = new Set();

  let currentId = null;
  let keepMostRecentNonCurrent = null;
  let keepPendingRevoked = null;
  let keepSignedRevoked = null;
  let keepElectronicNonCurrent = null;

  for (const r of rows) {
    const id = r?.timesheet_id ? String(r.timesheet_id) : '';
    if (!id) continue;

    if (r?.is_current === true && !currentId) {
      currentId = id;
      keep.add(id);
      continue;
    }

    if (r?.is_current === false) {
      // most recent non-current safety net (highest version)
      if (!keepMostRecentNonCurrent) {
        keepMostRecentNonCurrent = id;
        keep.add(id);
      }

      const status = String(r?.status || '').toUpperCase();
      const hasScan = !!r?.qr_scanned_at;

      // matches your SQL restore selectors: status='REVOKED' + scan null vs not null
      if (status === 'REVOKED') {
        if (!hasScan && !keepPendingRevoked) {
          keepPendingRevoked = id;
          keep.add(id);
        }
        if (hasScan && !keepSignedRevoked) {
          keepSignedRevoked = id;
          keep.add(id);
        }
      }

      // electronic restore safety: authorised_at_server exists on a non-current version
      if (!keepElectronicNonCurrent && r?.authorised_at_server) {
        keepElectronicNonCurrent = id;
        keep.add(id);
      }
    }
  }

  // If somehow no current id was found, do not purge (avoid accidental wipe)
  if (!currentId) {
    return { ok: false, booking_id: String(bookingId), reason: 'no current timesheet found for booking_id' };
  }

  // 3) Determine purge candidates (all other non-current)
  const purgeRows = rows
    .filter(r => r?.is_current === false)
    .filter(r => {
      const id = r?.timesheet_id ? String(r.timesheet_id) : '';
      return id && !keep.has(id);
    });

  if (!purgeRows.length) {
    return { ok: true, booking_id: String(bookingId), purged_timesheet_ids: [], deleted_keys: 0, deleted_evidence_rows: 0 };
  }

  const purgeIds = purgeRows.map(r => String(r.timesheet_id));
  const purgeIdsParam = purgeIds.map(enc).join(',');

  // 4) Gather R2 keys to delete (dedupe)
  const keysToDelete = new Set();

  for (const r of purgeRows) {
    const tid = String(r.timesheet_id);
    const canonical = cleanKey(`docs-pdf/timesheets/ts_${tid}.pdf`);
    if (canonical) keysToDelete.add(canonical);

    const manualKey = r?.manual_pdf_r2_key ? cleanKey(r.manual_pdf_r2_key) : '';
    if (manualKey && manualKey !== canonical) keysToDelete.add(manualKey);

    const qrKey = r?.qr_r2_key ? cleanKey(r.qr_r2_key) : '';
    if (qrKey && qrKey !== canonical && qrKey !== manualKey) keysToDelete.add(qrKey);
  }

  // 5) Load and delete timesheet_evidence rows for purged versions, and delete their storage keys
  let evidenceRows = [];
  try {
    const { rows: evRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence` +
        `?timesheet_id=in.(${purgeIdsParam})` +
        `&select=id,timesheet_id,storage_key` +
        `&limit=10000`
    );
    evidenceRows = Array.isArray(evRows) ? evRows : [];
  } catch {
    evidenceRows = [];
  }

  for (const ev of evidenceRows) {
    const k = ev?.storage_key ? cleanKey(ev.storage_key) : '';
    if (k) keysToDelete.add(k);
  }

  // 6) Best-effort delete R2 keys
  let deletedKeys = 0;
  let failedKeys = 0;

  if (canR2) {
    for (const k of keysToDelete) {
      try {
        await bucket.delete(k);
        deletedKeys++;
      } catch (e) {
        failedKeys++;
        try {
          console.warn('[PURGE] R2 delete failed (non-fatal)', { booking_id: String(bookingId), key: k, err: e?.message || String(e) });
        } catch {}
      }
    }
  }

  // 7) Delete evidence DB rows (so they don’t show up anywhere)
  // (Even if R2 delete failed, removing DB rows avoids UI dangling pointers.)
  let deletedEvidenceRows = 0;
  try {
    const delEvRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence?timesheet_id=in.(${purgeIdsParam})`,
      { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return-minimal' } }
    );
    if (delEvRes.ok) deletedEvidenceRows = evidenceRows.length;
  } catch {}

  // 8) Null out blob pointers on those old timesheets (safety)
  try {
    const now = nowIso();
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=in.(${purgeIdsParam})&is_current=eq.false`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          manual_pdf_r2_key: null,
          qr_r2_key: null,
          updated_at: now
        })
      }
    ).catch(() => {});
  } catch {}

  return {
    ok: true,
    booking_id: String(bookingId),
    kept_timesheet_ids: Array.from(keep),
    purged_timesheet_ids: purgeIds,
    deleted_keys: deletedKeys,
    failed_keys: failedKeys,
    deleted_evidence_rows: deletedEvidenceRows,
    r2_configured: canR2
  };
}

async function handleTimesheetConvertQrToManual(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // ✅ NEW: guarded write (optimistic concurrency)
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expectedTimesheetId = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expectedTimesheetId) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // Stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));

  const currentTimesheetId = resolved.current_timesheet_id;

  // Guard: if the caller's expected id is no longer current, refuse
  if (String(expectedTimesheetId) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({
        error: 'TIMESHEET_MOVED',
        current_timesheet_id: currentTimesheetId
      }), { status: 409, headers: { 'Content-Type': 'application/json' } })
    );
  }

  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  const bookingId = ts.booking_id || resolved.booking_id || null;
  if (!bookingId) return withCORS(env, req, badRequest('Timesheet booking_id is missing; cannot version'));

  // ✅ UPDATED: backend defence-in-depth — block import-authoritative routes using summary view / contract overrides
  try {
    // Prefer contract via contract_week pointer (weekly), fallback to ts.contract_id
    let contractId = ts.contract_id || null;
    let contractWeekId = null;

    try {
      const cwRow = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&select=id,contract_id` +
          `&limit=1`
      );
      if (cwRow?.contract_id) contractId = cwRow.contract_id;
      if (cwRow?.id) contractWeekId = cwRow.id;
    } catch {}

    const rr = await resolveImportAuthoritative(env, {
      timesheet_id: currentTimesheetId,
      contract_week_id: contractWeekId,
      contract_id: contractId
    });

    if (rr && rr.is_import_authoritative) {
      return withCORS(
        env,
        req,
        badRequest('Import-authoritative timesheets (NHSP / HealthRoster weekly no-timesheets) cannot change submission route')
      );
    }
  } catch {
    // fail-open if flags cannot be loaded
  }

  const scope = String(ts.sheet_scope || '').toUpperCase();
  if (scope && scope !== 'WEEKLY' && scope !== 'DAILY') {
    return withCORS(env, req, badRequest('Unsupported sheet_scope for QR conversion'));
  }

  const subMode = String(ts.submission_mode || '').toUpperCase();
  if (subMode !== 'MANUAL') {
    return withCORS(env, req, badRequest('Timesheet is not in MANUAL mode; QR conversion not applicable'));
  }

  const qrStatus = String(ts.qr_status || '').toUpperCase();
  if (!qrStatus) {
    return withCORS(env, req, badRequest('Timesheet does not have QR metadata; nothing to convert'));
  }

  const fin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );
  if (!fin) return withCORS(env, req, badRequest('No financial snapshot for timesheet'));

  const hardLocked =
    !!fin.paid_at_utc ||
    !!fin.locked_by_invoice_id ||
    !!fin.locked_by_invoice ||
    !!fin.locked_by_invoice_line_id ||
    !!fin.locked_by_invoice_at_utc;

  if (hardLocked) {
    return withCORS(env, req, badRequest('Cannot convert QR: timesheet already invoiced or paid'));
  }

  const now = nowIso();

  // Next version by booking_id
  let nextVersion = Number(ts.version || 1) + 1;
  try {
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const maxV = vRows?.[0]?.version != null ? Number(vRows[0].version) : Number(ts.version || 1);
    nextVersion = Number.isFinite(maxV) ? maxV + 1 : (Number(ts.version || 1) + 1);
  } catch {}

  // 1) Demote current by booking_id
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: false,
        status: 'REVOKED',
        revoked_reason: 'QR_CONVERTED_TO_MANUAL',
        revoked_by: user.id || null,
        updated_at: now
      })
    }
  ).catch(() => {});

  // 2) Insert new current manual non-QR (NO timesheet_id)
  const base = { ...ts };
  delete base.id;
  delete base.timesheet_id;

  const newRow = {
    ...base,
    booking_id: bookingId,
    version: nextVersion,
    is_current: true,
    submission_mode: 'MANUAL',

    qr_status: null,
    qr_token: null,
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null,
    qr_payload_json: {},

    manual_pdf_r2_key: null,

    created_at: now,
    updated_at: now
  };

  const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify([newRow])
  });

  if (!insRes.ok) {
    const txt = await insRes.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create manual non-QR version: ${txt}`));
  }

  const inserted = (await insRes.json().catch(() => []))[0] || null;
  const newTimesheetId = inserted?.timesheet_id || null;
  if (!newTimesheetId) return withCORS(env, req, serverError('Insert succeeded but no timesheet_id returned'));

  // 2b) Move contract_week pointer if it points at old current row (weekly case)
  try {
    const cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=id` +
        `&limit=1`
    );
    if (cw?.id) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({ timesheet_id: newTimesheetId, updated_at: now })
        }
      ).catch(() => {});
    }
  } catch {}

  // 3) TSFIN: move row to new timesheet_id and gate evidence
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        timesheet_id: newTimesheetId,
        timesheet_version: inserted?.version ?? nextVersion,
        processing_status: 'AWAITING_MANUAL_SIGNATURE',
        updated_at: now
      })
    }
  ).catch(() => {});

  // 4) Audit
  try {
    await writeAudit(
      env,
      user,
      'QR_CONVERTED_TO_MANUAL',
      {
        booking_id: bookingId,
        old_timesheet_id: currentTimesheetId,
        new_timesheet_id: newTimesheetId,
        old_version: ts.version,
        new_version: inserted?.version ?? nextVersion,
        sheet_scope: scope || null,
        had_qr_status: qrStatus
      },
      { entity: 'timesheets', subject_id: newTimesheetId, req }
    );
  } catch {}

  // ✅ NEW: Purge superseded versions immediately (best-effort; never blocks conversion)
  try {
    await purgeSupersededTimesheetArtifactsForBooking(env, bookingId);
  } catch (e) {
    try {
      console.warn('[QR_CONVERT_TO_MANUAL] purge failed (non-fatal)', {
        booking_id: bookingId,
        err: e?.message || String(e)
      });
    } catch {}
  }

  return withCORS(env, req, ok({
    converted: true,
    booking_id: bookingId,
    old_timesheet_id: currentTimesheetId,
    current_timesheet_id: newTimesheetId,
    new_version: inserted?.version ?? nextVersion,

    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale
  }));
}

async function handleUsersList(env, req) {
  const actor = await requireUser(env, req, ['admin']);
  if (!actor) return unauthorized('Unauthorized');

  const url = new URL(req.url);
  const q = (url.searchParams.get('q') || '').trim();
  const role = (url.searchParams.get('role') || '').trim();
  const isActiveRaw = (url.searchParams.get('is_active') || '').trim();

  const params = new URLSearchParams();

  // NOTE: last_login_at_utc requires the SQL migration to exist.
  params.set('select', [
    'id',
    'email',
    'display_name',
    'role',
    'is_active',
    'created_at',
    'updated_at',
    'last_login_at_utc',
    'email_settings'
  ].join(','));

  params.set('order', 'created_at.desc');

  // Optional filters
  if (role) params.set('role', `eq.${role}`);

  if (isActiveRaw) {
    const v = isActiveRaw.toLowerCase();
    if (v === 'true' || v === 'false') params.set('is_active', `eq.${v}`);
  }

  // q search: email OR display_name
  if (q) {
    const qq = q.replace(/[%*]/g, ''); // keep it simple/safe for ilike patterns
    // PostgREST OR filter syntax
    params.set('or', `(email.ilike.*${qq}*,display_name.ilike.*${qq}*)`);
  }

  const apiUrl = `${env.SUPABASE_URL}/rest/v1/${AUTH.USERS_TABLE}?${params.toString()}`;
  const res = await fetch(apiUrl, { headers: sbAuthHeaders(env) });

  if (!res.ok) {
    const err = await res.text().catch(() => '');
    return serverError(`Failed to list users (${res.status}): ${err}`);
  }

  const rows = await res.json().catch(() => []);
  return ok({ ok: true, users: Array.isArray(rows) ? rows : [] });
}


async function handleUsersCreate(env, req) {
  const actor = await requireUser(env, req, ['admin']);
  if (!actor) return unauthorized('Unauthorized');

  const body = await parseJSONBody(req);
  if (!body) return badRequest('invalid_json');

  const email = String(body.email || '').trim().toLowerCase();
  const displayName = (body.display_name == null) ? null : String(body.display_name || '').trim();
  const role = String(body.role || '').trim().toLowerCase();
  const pw = String(body.password || '');
  let emailSettings = body.email_settings;

  if (!email) return badRequest('email_required');
  if (!pw) return badRequest('password_required');

  // minimal email sanity (consistent with your overall approach)
  if (!/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(email)) return badRequest('invalid_email');

  // roles currently supported
  if (!(role === 'admin' || role === 'user')) return badRequest('invalid_role');

  // strong password: same rules as /auth/reset
  const strong = pw.length >= 8 && /[a-z]/.test(pw) && /[A-Z]/.test(pw) && /[0-9]/.test(pw);
  if (!strong) return badRequest('WEAK_PASSWORD');

  // email_settings must be an object (or omitted)
  if (emailSettings == null) emailSettings = {};
  if (typeof emailSettings !== 'object' || Array.isArray(emailSettings)) return badRequest('invalid_email_settings');

  const hash = await pbkdf2Hash(pw);

  const row = {
    email,
    display_name: displayName || null,
    role,
    is_active: true,
    password_hash: hash,
    session_version: 1,
    email_settings: emailSettings
  };

  const apiUrl = `${env.SUPABASE_URL}/rest/v1/${AUTH.USERS_TABLE}`;
  const res = await fetch(apiUrl, {
    method: 'POST',
    headers: { ...sbAuthHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(row)
  });

  if (!res.ok) {
    const errText = await res.text().catch(() => '');
    // Uniqueness is enforced by tms_users_email_key
    return badRequest(`Failed to create user (${res.status})`, errText);
  }

  const created = await res.json().catch(() => []);
  const u = Array.isArray(created) && created[0] ? created[0] : null;
  return ok({ ok: true, user: u });
}

async function handleUsersPatch(env, req, userId) {
  const actor = await requireUser(env, req, ['admin']);
  if (!actor) return unauthorized('Unauthorized');

  // basic uuid sanity (prevents accidental routing issues)
  if (!/^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i.test(String(userId || ''))) {
    return badRequest('invalid_user_id');
  }

  const body = await parseJSONBody(req);
  if (!body) return badRequest('invalid_json');

  const patch = {};

  if ('email' in body) {
    const email = String(body.email || '').trim().toLowerCase();
    if (!email) return badRequest('email_required');
    if (!/^[^\s@]+@[^\s@]+\.[^\s@]+$/.test(email)) return badRequest('invalid_email');
    patch.email = email;
  }

  if ('display_name' in body) {
    const dn = (body.display_name == null) ? null : String(body.display_name || '').trim();
    patch.display_name = dn || null;
  }

  if ('role' in body) {
    const role = String(body.role || '').trim().toLowerCase();
    if (!(role === 'admin' || role === 'user')) return badRequest('invalid_role');
    patch.role = role;
  }

  if ('is_active' in body) {
    if (typeof body.is_active !== 'boolean') return badRequest('invalid_is_active');
    patch.is_active = body.is_active;
  }

  if ('email_settings' in body) {
    let s = body.email_settings;
    if (s == null) s = {};
    if (typeof s !== 'object' || Array.isArray(s)) return badRequest('invalid_email_settings');
    patch.email_settings = s;
  }

  if (!Object.keys(patch).length) return badRequest('empty_patch');

  const apiUrl = `${env.SUPABASE_URL}/rest/v1/${AUTH.USERS_TABLE}?id=eq.${encodeURIComponent(userId)}`;
  const res = await fetch(apiUrl, {
    method: 'PATCH',
    headers: { ...sbAuthHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(patch)
  });

  if (!res.ok) {
    const errText = await res.text().catch(() => '');
    return badRequest(`Failed to patch user (${res.status})`, errText);
  }

  const rows = await res.json().catch(() => []);
  const u = Array.isArray(rows) && rows[0] ? rows[0] : null;
  if (!u) return badRequest('user_not_found');

  return ok({ ok: true, user: u });
}

async function handleUsersResetPassword(env, req, userId) {
  const actor = await requireUser(env, req, ['admin']);
  if (!actor) return unauthorized('Unauthorized');

  if (!/^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i.test(String(userId || ''))) {
    return badRequest('invalid_user_id');
  }

  const body = await parseJSONBody(req);
  if (!body) return badRequest('invalid_json');

  const newPw = String(body.new_password ?? body.password ?? '');
  if (!newPw) return badRequest('new_password_required');

  const strong = newPw.length >= 8 && /[a-z]/.test(newPw) && /[A-Z]/.test(newPw) && /[0-9]/.test(newPw);
  if (!strong) return badRequest('WEAK_PASSWORD');

  const newHash = await pbkdf2Hash(newPw);

  try {
    await sbUpdateUserPassword(env, userId, newHash); // updates hash + bumps session_version
  } catch (e) {
    return serverError(`Reset password failed: ${e?.message || e}`);
  }

  return ok({ ok: true });
}

async function handleUserChangePassword(env, req) {
  const u = await requireUser(env, req); // any logged-in user
  if (!u) return unauthorized('Unauthorized');

  const body = await parseJSONBody(req);
  if (!body) return badRequest('invalid_json');

  const oldPw = String(body.old_password || '');
  const newPw = String(body.new_password || '');
  const newPw2 = String(body.new_password2 || '');

  if (!oldPw || !newPw || !newPw2) return badRequest('old_and_new_password_required');
  if (newPw !== newPw2) return badRequest('new_password_mismatch');

  const strong = newPw.length >= 8 && /[a-z]/.test(newPw) && /[A-Z]/.test(newPw) && /[0-9]/.test(newPw);
  if (!strong) return badRequest('WEAK_PASSWORD');

  const userRow = await sbGetUserById(env, u.id); // includes password_hash per your current helper
  if (!userRow || userRow.is_active !== true) return unauthorized('Unauthorized');

  const okOld = await pbkdf2Verify(oldPw, userRow.password_hash || '');
  if (!okOld) return unauthorized('Invalid credentials');

  const newHash = await pbkdf2Hash(newPw);

  try {
    await sbUpdateUserPassword(env, u.id, newHash); // bumps session_version => tokens invalid
  } catch (e) {
    return serverError(`Change password failed: ${e?.message || e}`);
  }

  // Kill current KV session (best-effort)
  try { if (u.sid) await kvDelSession(env, u.sid); } catch {}

  // Clear refresh cookie to force logout (Option A)
  const headers = new Headers(JSON_HEADERS);
  setCookie(headers, cookieName(env), '', {
    maxAgeSec: 0,
    domain: env.COOKIE_DOMAIN || undefined,
    sameSite: pickCookieSameSite(env),
    secure: true,
    httpOnly: true,
    path: '/'
  });

  return new Response(JSON.stringify({ ok: true, logged_out: true }), { status: 200, headers });
}


// ----------------------------------------------------------------------------
// D) Manual & Expenses (supplementary)
// ----------------------------------------------------------------------------

 async function handleManualPresign(env, req) {
  // Public alias: worker uploads manual scan for a chosen contract_week
  let body; try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }
  const weekId = body.contract_week_id || null;
  const candidateId = body.candidate_id || null;
  if (!weekId || !candidateId) return withCORS(env, req, badRequest('contract_week_id and candidate_id required'));

  const cw = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/v_contract_weeks_enriched?id=eq.${enc(weekId)}&select=id,contract_id,week_ending_date,candidate_id`);
  if (!cw) return withCORS(env, req, notFound('Week not found'));
  if (String(cw.candidate_id) !== String(candidateId)) return withCORS(env, req, unauthorized());

  const weC = ymdCompact(cw.week_ending_date);
  const key = `paper_ts/we=${weC}/cw_${cw.id}_${Date.now()}.upload`;
  const token = await createToken(env, 'UPLOAD', { key, c: 'manual_ts', ttlSec: 3600, maxBytes: 25*1024*1024, contentTypes: ['application/pdf','image/jpeg','image/png','image/heic','image/heif'] });
  const upload_url = `${new URL(req.url).origin}/api/files/upload?key=${enc(key)}&token=${enc(token)}`;

  // Optimistically attach key
  await patchContractWeekScan(env, cw.id, key);

  return withCORS(env, req, ok({ key, upload_url, token, expires_in: 3600 }));
}

async function handleTimesheetAllowElectronicAgain(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // ✅ NEW: guarded write
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expectedTimesheetId = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expectedTimesheetId) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // Stale-safe resolve (accept historical/stale ids)
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));

  const currentTimesheetId = resolved.current_timesheet_id;

  if (String(expectedTimesheetId) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({
        error: 'TIMESHEET_MOVED',
        current_timesheet_id: currentTimesheetId
      }), { status: 409, headers: { 'Content-Type': 'application/json' } })
    );
  }

  // Load current version row by PK
  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  // ✅ NEW: adjustment sheets cannot be converted to ELECTRONIC
  if (ts.is_adjustment === true) {
    return withCORS(env, req, badRequest('Adjustment timesheets cannot be converted to electronic submission'));
  }

  const bookingId = ts.booking_id || resolved.booking_id || null;
  if (!bookingId) return withCORS(env, req, badRequest('Timesheet booking_id is missing; cannot version'));

  // ✅ UPDATED: backend defence-in-depth — block import-authoritative routes using summary view / contract overrides
  try {
    let contractId = ts.contract_id || null;
    let contractWeekId = null;

    try {
      const cwRow = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&select=id,contract_id,is_adjustment` +
          `&limit=1`
      );
      if (cwRow?.contract_id) contractId = cwRow.contract_id;
      if (cwRow?.id) contractWeekId = cwRow.id;

      // ✅ NEW: block weekly adjustment conversion even if ts.is_adjustment was absent
      if (cwRow?.is_adjustment === true) {
        return withCORS(env, req, badRequest('Adjustment timesheets cannot be converted to electronic submission'));
      }
    } catch {}

    const rr = await resolveImportAuthoritative(env, {
      timesheet_id: currentTimesheetId,
      contract_week_id: contractWeekId,
      contract_id: contractId
    });

    if (rr && rr.is_import_authoritative) {
      return withCORS(
        env,
        req,
        badRequest('Import-authoritative timesheets (NHSP / HealthRoster weekly no-timesheets) cannot use Allow electronic again')
      );
    }
  } catch {
    // fail-open if flags cannot be loaded
  }

  // Lock guard
  const fin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=id,locked_by_invoice_id,paid_at_utc,timesheet_version,processing_status,client_id` +
      `&limit=1`
  );
  if (fin && (fin.locked_by_invoice_id || fin.paid_at_utc)) {
    return withCORS(env, req, badRequest('Cannot allow electronic again: timesheet is invoiced/locked or paid'));
  }

  // Must be manual-only (derived)
  const sm = String(ts.submission_mode || '').toUpperCase();
  const qrStatusNow = String(ts.qr_status || '').toUpperCase() || '';
  const hasQrToken = !!(ts.qr_token && String(ts.qr_token).trim());
  const hasQrGen = !!ts.qr_generated_at;
  const hasQrScan = !!ts.qr_scanned_at;

  const isManualOnly =
    (sm === 'MANUAL') &&
    !qrStatusNow &&
    !hasQrToken &&
    !hasQrGen &&
    !hasQrScan;

  if (!isManualOnly) {
    return withCORS(env, req, badRequest('Allow electronic again is only valid for manual-only timesheets'));
  }

  // Determine client_id for eligibility check
  let clientId = fin?.client_id || null;
  if (!clientId && ts.contract_id) {
    const contract = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?id=eq.${enc(ts.contract_id)}` +
        `&select=id,client_id` +
        `&limit=1`
    );
    clientId = contract?.client_id || null;
  }
  if (!clientId) {
    return withCORS(env, req, badRequest('Cannot resolve client_id for electronic eligibility check'));
  }

  let supportsElectronic = false;
  try {
    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
        `?client_id=eq.${enc(clientId)}` +
        `&select=default_submission_mode,updated_at,created_at` +
        `&order=updated_at.desc.nullslast,created_at.desc.nullslast` +
        `&limit=1`
    );
    const cs = csRows?.[0] || null;
    supportsElectronic = (String(cs?.default_submission_mode || '').toUpperCase() === 'ELECTRONIC');
  } catch {
    supportsElectronic = false;
  }

  if (!supportsElectronic) {
    return withCORS(env, req, badRequest('Client does not support electronic submission'));
  }

  const now = nowIso();

  // Next version number by booking_id
  let nextVersion = 2;
  try {
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const maxV = vRows?.[0]?.version != null ? Number(vRows[0].version) : Number(ts.version || 1);
    nextVersion = Number.isFinite(maxV) ? maxV + 1 : (Number(ts.version || 1) + 1);
  } catch {
    nextVersion = Number(ts.version || 1) + 1;
  }

  // 1) Demote current for booking_id
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: false,
        status: 'REVOKED',
        revoked_reason: 'ALLOW_ELECTRONIC_AGAIN',
        revoked_by: user?.id || null,
        updated_at: now
      })
    }
  ).catch(() => {});

  // 2) Insert new ELECTRONIC current version (NO timesheet_id)
  const newRowBase = { ...ts };
  delete newRowBase.id;
  delete newRowBase.timesheet_id;

  const newRow = {
    ...newRowBase,
    booking_id: bookingId,
    version: nextVersion,
    is_current: true,
    status: 'RECEIVED',
    submission_mode: 'ELECTRONIC',

    manual_pdf_r2_key: null,
    authorised_at_server: null,
    r2_nurse_key: null,
    r2_auth_key: null,

    qr_status: null,
    qr_token: null,
    qr_payload_json: {}, // NOT NULL
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null,

    created_at: now,
    updated_at: now
  };

  const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify([newRow])
  });

  if (!insRes.ok) {
    const t = await insRes.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create electronic version: ${t}`));
  }

  const inserted = (await insRes.json().catch(() => []))[0] || null;
  const newTimesheetId = inserted?.timesheet_id || null;
  if (!newTimesheetId) {
    return withCORS(env, req, serverError('Insert succeeded but no timesheet_id returned'));
  }

  // 2b) Move contract_week pointer if it points at old current row
  try {
    const cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=id` +
        `&limit=1`
    );
    if (cw?.id) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({ timesheet_id: newTimesheetId, updated_at: now })
        }
      ).catch(() => {});
    }
  } catch {}

  // 3) TSFIN: move row to new timesheet_id + reset status
  if (fin?.id) {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          timesheet_id: newTimesheetId,
          timesheet_version: inserted?.version ?? nextVersion,
          processing_status: 'UNASSIGNED',
          updated_at: now
        })
      }
    ).catch(() => {});
  }

  // 4) Audit
  try {
    await writeAudit(
      env,
      user,
      'ELECTRONIC_ALLOWED_AGAIN',
      {
        booking_id: bookingId,
        old_timesheet_id: currentTimesheetId,
        new_timesheet_id: newTimesheetId,
        old_version: ts.version,
        new_version: inserted?.version ?? nextVersion,
        client_id: clientId
      },
      { entity: 'timesheets', subject_id: newTimesheetId, req }
    );
  } catch {}

  // Purge superseded versions immediately (best-effort)
  try { await purgeSupersededTimesheetArtifactsForBooking(env, bookingId); } catch {}

  return withCORS(env, req, ok({
    ok: true,
    booking_id: bookingId,
    old_timesheet_id: currentTimesheetId,
    current_timesheet_id: newTimesheetId,
    new_version: inserted?.version ?? nextVersion,

    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale
  }));
}

async function handleTimesheetAllowQrAgain(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // ✅ guarded write
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expectedTimesheetId = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expectedTimesheetId) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));

  const currentTimesheetId = resolved.current_timesheet_id;

  if (String(expectedTimesheetId) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({
        error: 'TIMESHEET_MOVED',
        current_timesheet_id: currentTimesheetId
      }), { status: 409, headers: { 'Content-Type': 'application/json' } })
    );
  }

  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  // ✅ NEW: adjustment sheets cannot be converted to QR
  if (ts.is_adjustment === true) {
    return withCORS(env, req, badRequest('Adjustment timesheets cannot be converted to QR submission'));
  }

  const bookingId = ts.booking_id || resolved.booking_id || null;
  if (!bookingId) return withCORS(env, req, badRequest('Timesheet booking_id is missing; cannot version'));

  // Lock guard (current TSFIN row for current PK)
  const fin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=id,locked_by_invoice_id,paid_at_utc,timesheet_version,processing_status` +
      `&limit=1`
  );
  if (fin && (fin.locked_by_invoice_id || fin.paid_at_utc)) {
    return withCORS(env, req, badRequest('Cannot allow QR again: timesheet is invoiced/locked or paid'));
  }

  // Must be manual-only (derived)
  const sm = String(ts.submission_mode || '').toUpperCase();
  const qrStatusNow = String(ts.qr_status || '').toUpperCase() || '';
  const hasQrToken = !!(ts.qr_token && String(ts.qr_token).trim());
  const hasQrGen = !!ts.qr_generated_at;
  const hasQrScan = !!ts.qr_scanned_at;

  const isManualOnly =
    (sm === 'MANUAL') &&
    !qrStatusNow &&
    !hasQrToken &&
    !hasQrGen &&
    !hasQrScan;

  if (!isManualOnly) {
    return withCORS(env, req, badRequest('Allow QR again is only valid for manual-only timesheets'));
  }

  const now = nowIso();

  // Next version number by booking_id
  let nextVersion = 2;
  try {
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const maxV = vRows?.[0]?.version != null ? Number(vRows[0].version) : Number(ts.version || 1);
    nextVersion = Number.isFinite(maxV) ? maxV + 1 : (Number(ts.version || 1) + 1);
  } catch {
    nextVersion = Number(ts.version || 1) + 1;
  }

  // 1) Demote any current row for this booking_id (defensive)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: false,
        status: 'REVOKED',
        revoked_reason: 'ALLOW_QR_AGAIN',
        revoked_by: user?.id || null,
        updated_at: now
      })
    }
  ).catch(() => {});

  // 2) Insert new current version (NO timesheet_id)
  const newRowBase = { ...ts };
  delete newRowBase.id;
  delete newRowBase.timesheet_id;

  const newRow = {
    ...newRowBase,
    booking_id: bookingId,
    version: nextVersion,
    is_current: true,
    status: 'RECEIVED',

    submission_mode: 'MANUAL',

    manual_pdf_r2_key: null,
    r2_nurse_key: null,
    r2_auth_key: null,
    authorised_at_server: null,

    qr_status: 'PENDING',
    qr_token: null,
    qr_payload_json: {}, // NOT NULL
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null,

    qr_last_sent_hash: null,
    qr_last_sent_at_utc: null,
    qr_signed_hash: null,
    qr_signed_at_utc: null,

    created_at: now,
    updated_at: now
  };

  const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify([newRow])
  });

  if (!insRes.ok) {
    const t = await insRes.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create QR-enabled version: ${t}`));
  }

  const inserted = (await insRes.json().catch(() => []))[0] || null;
  const newTimesheetId = inserted?.timesheet_id || null;
  if (!newTimesheetId) {
    return withCORS(env, req, serverError('Insert succeeded but no timesheet_id returned'));
  }

  // 2b) Move contract_week pointer if it points at the old current row
  try {
    const cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=id` +
        `&limit=1`
    );
    if (cw?.id) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({ timesheet_id: newTimesheetId, updated_at: now })
        }
      ).catch(() => {});
    }
  } catch {}

  // 3) TSFIN: move the current TSFIN row to the new timesheet_id + set gate
  if (fin?.id) {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          timesheet_id: newTimesheetId,
          timesheet_version: inserted?.version ?? nextVersion,
          processing_status: 'AWAITING_MANUAL_SIGNATURE',
          updated_at: now
        })
      }
    ).catch(() => {});
  }

  // Audit + purge unchanged
  try {
    await writeAudit(
      env,
      user,
      'QR_ALLOWED_AGAIN',
      {
        booking_id: bookingId,
        old_timesheet_id: currentTimesheetId,
        new_timesheet_id: newTimesheetId,
        old_version: ts.version,
        new_version: inserted?.version ?? nextVersion
      },
      { entity: 'timesheets', subject_id: newTimesheetId, req }
    );
  } catch {}

  try { await purgeSupersededTimesheetArtifactsForBooking(env, bookingId); } catch {}

  return withCORS(env, req, ok({
    ok: true,
    booking_id: bookingId,
    old_timesheet_id: currentTimesheetId,
    current_timesheet_id: newTimesheetId,
    new_version: inserted?.version ?? nextVersion,

    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale
  }));
}


async function handleTimesheetSwitchToManual(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // ✅ NEW: guarded write
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expectedTimesheetId = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expectedTimesheetId) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // Stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = resolved.current_timesheet_id;

  if (String(expectedTimesheetId) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({
        error: 'TIMESHEET_MOVED',
        current_timesheet_id: currentTimesheetId
      }), { status: 409, headers: { 'Content-Type': 'application/json' } })
    );
  }

  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  const bookingId = ts.booking_id || resolved.booking_id || null;
  if (!bookingId) return withCORS(env, req, badRequest('Timesheet booking_id is missing; cannot version'));

  const scope = String(ts.sheet_scope || '').toUpperCase();
  if (scope && scope !== 'WEEKLY') {
    return withCORS(env, req, badRequest('Only WEEKLY timesheets can be switched to manual'));
  }

  const subMode = String(ts.submission_mode || '').toUpperCase();
  if (subMode !== 'ELECTRONIC') {
    return withCORS(env, req, badRequest('Timesheet is not an electronic weekly timesheet'));
  }

  // Find contract_week that currently points at this timesheet row
  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&select=*` +
      `&limit=1`
  );
  if (!cw) return withCORS(env, req, badRequest('Timesheet not linked to a contract week'));

  // ✅ UPDATED: backend defence-in-depth — block import-authoritative routes using summary view / contract overrides
  try {
    const rr = await resolveImportAuthoritative(env, {
      timesheet_id: currentTimesheetId,
      contract_week_id: cw.id,
      contract_id: cw.contract_id || ts.contract_id || null
    });

    if (rr && rr.is_import_authoritative) {
      return withCORS(
        env,
        req,
        badRequest('Import-authoritative timesheets (NHSP / HealthRoster weekly no-timesheets) cannot be converted to manual')
      );
    }
  } catch {
    // fail-open if flags cannot be loaded
  }

  const tsfin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );
  if (!tsfin) return withCORS(env, req, badRequest('No financial snapshot to switch'));

  const hardLocked =
    !!tsfin.paid_at_utc ||
    !!tsfin.locked_by_invoice_id ||
    !!tsfin.locked_by_invoice ||
    !!tsfin.locked_by_invoice_line_id ||
    !!tsfin.locked_by_invoice_at_utc;

  if (hardLocked) return withCORS(env, req, badRequest('Cannot switch: timesheet already invoiced or paid'));

  const basis = String(tsfin.basis || '').toUpperCase();
  if (basis !== 'CONTRACT_WEEKLY') {
    return withCORS(env, req, badRequest('Only CONTRACT_WEEKLY timesheets can be switched to manual'));
  }

  const now = nowIso();

  // Next version by booking_id
  let nextVersion = 2;
  try {
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const maxV = vRows?.[0]?.version != null ? Number(vRows[0].version) : Number(ts.version || 1);
    nextVersion = Number.isFinite(maxV) ? maxV + 1 : (Number(ts.version || 1) + 1);
  } catch {
    nextVersion = Number(ts.version || 1) + 1;
  }

  // 1) Demote current by booking_id
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: false,
        status: 'REVOKED',
        revoked_reason: 'SWITCHED_TO_MANUAL',
        revoked_by: user?.id || null,
        updated_at: now
      })
    }
  ).catch(() => {});

  // 2) Insert MANUAL version (NO timesheet_id)
  const base = { ...ts };
  delete base.id;
  delete base.timesheet_id;

  const newManual = {
    ...base,
    booking_id: bookingId,
    version: nextVersion,
    is_current: true,
    submission_mode: 'MANUAL',

    r2_nurse_key: null,
    r2_auth_key: null,

    qr_token: null,
    qr_status: null,
    qr_payload_json: {},
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null,

    manual_pdf_r2_key: null,

    created_at: now,
    updated_at: now
  };

  const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify([newManual])
  });
  if (!insRes.ok) {
    const txt = await insRes.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create manual version: ${txt}`));
  }

  const inserted = (await insRes.json().catch(() => []))[0] || null;
  const newTimesheetId = inserted?.timesheet_id || null;
  if (!newTimesheetId) return withCORS(env, req, serverError('Insert succeeded but no timesheet_id returned'));

  // 3) Update contract_week: point to the new timesheet row + mark manual snapshot
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        timesheet_id: newTimesheetId,
        submission_mode_snapshot: 'MANUAL',
        updated_at: now
      })
    }
  ).catch(() => {});

  // 4) TSFIN: move row to new timesheet_id + update version marker
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(tsfin.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        timesheet_id: newTimesheetId,
        timesheet_version: inserted?.version ?? nextVersion,
        updated_at: now
      })
    }
  ).catch(() => {});

  // 5) Audit
  try {
    await writeAudit(
      env,
      user,
      'WEEKLY_SWITCHED_TO_MANUAL',
      {
        booking_id: bookingId,
        contract_week_id: cw.id,
        old_timesheet_id: currentTimesheetId,
        new_timesheet_id: newTimesheetId,
        old_version: ts.version,
        new_version: inserted?.version ?? nextVersion,
        basis
      },
      { entity: 'timesheets', subject_id: newTimesheetId, req }
    );
  } catch {}

  // ✅ NEW: Purge superseded versions immediately (best-effort; never blocks switch)
  try {
    await purgeSupersededTimesheetArtifactsForBooking(env, bookingId);
  } catch (e) {
    try {
      console.warn('[WEEKLY_SWITCH_TO_MANUAL] purge failed (non-fatal)', {
        booking_id: bookingId,
        err: e?.message || String(e)
      });
    } catch {}
  }

  return withCORS(env, req, ok({
    switched: true,
    booking_id: bookingId,
    contract_week_id: cw.id,
    old_timesheet_id: currentTimesheetId,
    current_timesheet_id: newTimesheetId,
    manual_version: inserted?.version ?? nextVersion,
    has_electronic_original: true,
    electronic_version: ts.version ?? 1,

    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale
  }));
}







// ✅ NEW/UPDATED HANDLER: guarded DAILY switch-to-manual
async function handleTimesheetSwitchDailyToManual(env, req, timesheetId) {
  const enc = encodeURIComponent;

  // Switch a DAILY non-NHSP/HR electronic timesheet to MANUAL via a new version
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // ✅ NEW: guarded write
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expectedTimesheetId = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expectedTimesheetId) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // Stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = resolved.current_timesheet_id;

  if (String(expectedTimesheetId) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({
        error: 'TIMESHEET_MOVED',
        current_timesheet_id: currentTimesheetId
      }), { status: 409, headers: { 'Content-Type': 'application/json' } })
    );
  }

  // Load FULL current timesheet row
  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  const bookingId = ts.booking_id || resolved.booking_id || null;
  const badBooking =
    !bookingId ||
    String(bookingId).trim() === '' ||
    String(bookingId).trim() === '{}' ||
    String(bookingId).trim().toLowerCase() === 'null' ||
    String(bookingId).trim().toLowerCase() === 'undefined';

  if (badBooking) {
    return withCORS(env, req, badRequest('Timesheet booking_id is invalid; cannot rotate versions. Please repair booking_id.'));
  }

  const scope = String(ts.sheet_scope || '').toUpperCase();
  if (scope && scope !== 'DAILY') {
    return withCORS(env, req, badRequest('Only DAILY timesheets can be switched to manual via this endpoint'));
  }

  const subMode = String(ts.submission_mode || '').toUpperCase();
  if (subMode !== 'ELECTRONIC') {
    return withCORS(env, req, badRequest('Timesheet is not an electronic daily timesheet'));
  }

  // Ensure not invoiced/paid and basis is not NHSP/HR self-bill
  const fin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!fin) return withCORS(env, req, badRequest('No financial snapshot to switch'));

  const hardLocked =
    !!fin.paid_at_utc ||
    !!fin.locked_by_invoice_id ||
    !!fin.locked_by_invoice ||
    !!fin.locked_by_invoice_line_id ||
    !!fin.locked_by_invoice_at_utc;

  if (hardLocked) return withCORS(env, req, badRequest('Cannot switch: timesheet already invoiced or paid'));

  const basis = String(fin.basis || '').toUpperCase();
  const disallowed = new Set([
    'NHSP',
    'NHSP_ADJUSTMENT',
    'HEALTHROSTER_SELF_BILL',
    'HEALTHROSTER_ADJUSTMENT'
  ]);
  if (disallowed.has(basis)) {
    return withCORS(env, req, badRequest('Cannot switch NHSP/HR-based daily timesheets to manual'));
  }

  const now = nowIso();

  // Determine next version for this booking_id (NOT timesheet_id)
  let nextVersion = Number(ts.version || 1) + 1;
  try {
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const currentMax = vRows?.[0]?.version != null ? Number(vRows[0].version) : Number(ts.version || 1);
    nextVersion = Number.isFinite(currentMax) ? currentMax + 1 : (Number(ts.version || 1) + 1);
  } catch {
    nextVersion = Number(ts.version || 1) + 1;
  }

  // 1) Demote current row for this booking_id (defensive)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: false,
        status: 'REVOKED',
        revoked_reason: 'SWITCHED_TO_MANUAL',
        revoked_by: user?.id || null,
        updated_at: now
      })
    }
  ).catch(() => {});

  // 2) Insert MANUAL version v+1 (NO timesheet_id)
  const manualTs = { ...ts };
  delete manualTs.id;
  delete manualTs.timesheet_id;

  const newManual = {
    ...manualTs,
    booking_id: bookingId,
    version: nextVersion,
    is_current: true,
    submission_mode: 'MANUAL',

    r2_nurse_key: null,
    r2_auth_key: null,

    qr_token: null,
    qr_status: null,
    qr_payload_json: {},
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null,

    manual_pdf_r2_key: null,

    created_at: now,
    updated_at: now
  };

  const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify([newManual])
  });
  if (!insRes.ok) {
    const txt = await insRes.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create daily manual version: ${txt}`));
  }

  const inserted = (await insRes.json().catch(() => []))[0] || null;
  const newTimesheetId = inserted?.timesheet_id || null;
  if (!newTimesheetId) return withCORS(env, req, serverError('Insert succeeded but no timesheet_id returned'));

  // 3) TSFIN: move current TSFIN row to new timesheet_id + align version marker
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        timesheet_id: newTimesheetId,
        timesheet_version: inserted?.version ?? nextVersion,
        updated_at: now
      })
    }
  ).catch(() => {});

  // 4) Audit
  try {
    await writeAudit(
      env,
      user,
      'DAILY_SWITCHED_TO_MANUAL',
      {
        booking_id: bookingId,
        old_timesheet_id: currentTimesheetId,
        new_timesheet_id: newTimesheetId,
        old_version: ts.version,
        new_version: inserted?.version ?? nextVersion,
        basis
      },
      { entity: 'timesheets', subject_id: newTimesheetId, req }
    );
  } catch (e) {
    console.warn('[TS][DAILY_SWITCH_TO_MANUAL] audit failed', e?.message || e);
  }

  // ✅ NEW: Purge superseded versions immediately (best-effort; never blocks switch)
  try {
    await purgeSupersededTimesheetArtifactsForBooking(env, bookingId);
  } catch (e) {
    try {
      console.warn('[DAILY_SWITCH_TO_MANUAL] purge failed (non-fatal)', {
        booking_id: bookingId,
        err: e?.message || String(e)
      });
    } catch {}
  }

  return withCORS(env, req, ok({
    switched: true,
    booking_id: bookingId,
    old_timesheet_id: currentTimesheetId,
    current_timesheet_id: newTimesheetId,
    manual_version: inserted?.version ?? nextVersion,
    has_electronic_original: true,
    electronic_version: ts.version ?? 1,

    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale
  }));
}
export async function handleTimesheetRevertToElectronic(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const expectedTimesheetId = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expectedTimesheetId) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const allowManualOnly = !!body?.allow_manual_only;

  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = resolved.current_timesheet_id;

  if (String(expectedTimesheetId) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({
        error: 'TIMESHEET_MOVED',
        current_timesheet_id: currentTimesheetId
      }), { status: 409, headers: { 'Content-Type': 'application/json' } })
    );
  }

  const current = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!current) return withCORS(env, req, notFound('Timesheet not found'));

  // ✅ NEW: adjustment sheets cannot be reverted/converted to ELECTRONIC
  if (current.is_adjustment === true) {
    return withCORS(env, req, badRequest('Adjustment timesheets cannot be reverted/converted to electronic submission'));
  }

  const bookingId = current.booking_id || resolved.booking_id || null;
  if (!bookingId) return withCORS(env, req, badRequest('Timesheet booking_id is missing; cannot revert'));

  // Load all versions by booking_id
  const { rows: tsRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&select=*`
  );
  const versions = tsRows || [];
  if (!versions.length) return withCORS(env, req, notFound('Timesheet not found'));

  const elec = versions
    .filter((r) => String(r.submission_mode || '').toUpperCase() === 'ELECTRONIC')
    .sort((a, b) => (b.version || 1) - (a.version || 1))[0] || null;

  if (!elec) return withCORS(env, req, badRequest('No electronic version exists for this timesheet'));

  const hasAnySegmentInvoiceLock = (tf) => {
    try {
      const ib = tf?.invoice_breakdown_json;
      if (!ib || typeof ib !== 'object') return false;
      const mode = String(ib?.mode || '').toUpperCase();
      if (mode !== 'SEGMENTS') return false;
      const segs = Array.isArray(ib?.segments) ? ib.segments : [];
      return segs.some(s => {
        const v = s?.invoice_locked_invoice_id;
        return v != null && String(v).trim() !== '';
      });
    } catch {
      return false;
    }
  };

  // TSFIN lock check uses the CURRENT row id
  const tsfin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );
  if (tsfin) {
    const hardLocked =
      !!tsfin.paid_at_utc ||
      !!tsfin.locked_by_invoice_id ||
      !!tsfin.locked_by_invoice ||
      !!tsfin.locked_by_invoice_line_id ||
      !!tsfin.locked_by_invoice_at_utc ||
      hasAnySegmentInvoiceLock(tsfin);

    if (hardLocked) {
      return withCORS(env, req, badRequest('Cannot revert: current timesheet is invoiced or paid'));
    }
  }

  const currentSubMode = String(current.submission_mode || '').toUpperCase();
  const currentQrStatus = String(current.qr_status || '').toUpperCase() || '';
  const hasQrToken = !!(current.qr_token && String(current.qr_token).trim());
  const hasQrGen = !!current.qr_generated_at;
  const hasQrScan = !!current.qr_scanned_at;

  const isManualOnly =
    (currentSubMode === 'MANUAL') &&
    !currentQrStatus &&
    !hasQrToken &&
    !hasQrGen &&
    !hasQrScan;

  if (isManualOnly && !allowManualOnly) {
    return withCORS(env, req, badRequest('Cannot revert: current is manual-only (set allow_manual_only=true to override)'));
  }

  if (current.timesheet_id === elec.timesheet_id && current.is_current) {
    return withCORS(env, req, ok({
      reverted: false,
      reason: 'Electronic version is already current',
      booking_id: bookingId,
      current_timesheet_id: current.timesheet_id,
      current_version: elec.version || 1
    }));
  }

  const now = nowIso();

  // 1) Demote current for booking_id (defensive)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({ is_current: false, updated_at: now })
    }
  ).catch(() => {});

  // 2) Promote electronic row to current by its PK
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(elec.timesheet_id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: true,

        qr_status: null,
        qr_token: null,
        qr_generated_at: null,
        qr_scanned_at: null,
        qr_scan_info_json: null,
        qr_r2_key: null,
        qr_payload_json: {},

        qr_last_sent_hash: null,
        qr_last_sent_at_utc: null,
        qr_signed_hash: null,
        qr_signed_at_utc: null,

        updated_at: now
      })
    }
  ).catch(() => {});

  // 2b) Move contract_week pointer if it points at old current row
  try {
    const cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=id` +
        `&limit=1`
    );
    if (cw?.id) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({ timesheet_id: elec.timesheet_id, updated_at: now })
        }
      ).catch(() => {});
    }
  } catch {}

  // 3) TSFIN: move current TSFIN row from old current PK to new current PK
  try {
    if (tsfin?.id) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(tsfin.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            timesheet_id: elec.timesheet_id,
            timesheet_version: elec.version || 1,
            updated_at: now
          })
        }
      ).catch(() => {});
    }
  } catch {}

  // ✅ FIX: enqueue_ts_financials signature uses (_timesheet_id, _reason)
  try {
    await sbRpc(env, 'enqueue_ts_financials', {
      _timesheet_id: elec.timesheet_id,
      _reason: 'REVERT_TO_ELECTRONIC'
    });
  } catch {}

  // Audit + purge unchanged
  try {
    await writeAudit(
      env,
      user,
      'REVERTED_TO_ELECTRONIC',
      {
        booking_id: bookingId,
        previous_current_timesheet_id: currentTimesheetId,
        new_current_timesheet_id: elec.timesheet_id,
        electronic_version: elec.version || 1,
        allow_manual_only: allowManualOnly
      },
      { entity: 'timesheets', subject_id: elec.timesheet_id, req }
    );
  } catch {}

  try { await purgeSupersededTimesheetArtifactsForBooking(env, bookingId); } catch {}

  return withCORS(env, req, ok({
    reverted: true,
    booking_id: bookingId,
    previous_current_timesheet_id: currentTimesheetId,
    current_timesheet_id: elec.timesheet_id,
    electronic_version: elec.version || 1,

    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale
  }));
}



 async function handleTimesheetPresignExpensePdf(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']); // backoffice presign; workers can use public files if needed
  if (!user) return withCORS(env, req, unauthorized());

  const key = `docs/receipts/ts_${timesheetId}/${Date.now()}_${Math.random().toString(16).slice(2)}.upload`;
  const token = await createToken(env, 'UPLOAD', { key, c: 'receipt', ttlSec: 3600, maxBytes: 20*1024*1024, contentTypes: ['application/pdf','image/jpeg','image/png','image/heic','image/heif'] });
  const upload_url = `${new URL(req.url).origin}/api/files/upload?key=${enc(key)}&token=${enc(token)}`;
  return withCORS(env, req, ok({ key, upload_url, token, expires_in: 3600 }));
}

// ────────────────────────────────────────────────────────────────
// 3.5 Helper: resolve “import-authoritative” route using best source
// Priority:
//   1) v_timesheets_summary (route_type + client_no_timesheet_required)
//   2) contracts override booleans (is_nhsp/autoprocess_hr/no_timesheet_required)
// Fallback is fail-open (returns is_import_authoritative:false) if it can’t resolve.
// ────────────────────────────────────────────────────────────────
async function resolveImportAuthoritative(env, input = {}) {
  const enc = encodeURIComponent;

  const timesheet_id     = input.timesheet_id ? String(input.timesheet_id) : null;
  const contract_week_id = input.contract_week_id ? String(input.contract_week_id) : null;
  const contract_id      = input.contract_id ? String(input.contract_id) : null;

  const toBool = (v) => {
    if (v === true) return true;
    if (v === false) return false;
    if (v == null) return false;
    const s = String(v).trim().toLowerCase();
    return (s === 'true' || s === '1' || s === 'yes' || s === 'y' || s === 'on');
  };

  const isImportAuthoritativeFromSummary = (routeType, clientNoTsRequired) => {
    const rt = String(routeType || '').toUpperCase();
    const noTs = toBool(clientNoTsRequired);
    return (
      rt === 'WEEKLY_NHSP' ||
      rt === 'WEEKLY_NHSP_ADJUSTMENT' ||
      (rt === 'WEEKLY_HEALTHROSTER' && noTs === true)
    );
  };

  // 1) Best source: v_timesheets_summary (authoritative derived route fields)
  // Prefer timesheet_id (for timesheet endpoints), otherwise contract_week_id (for planned week endpoints).
  try {
    let api = null;

    if (timesheet_id) {
      api =
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
        `?timesheet_id=eq.${enc(timesheet_id)}` +
        `&select=route_type,client_no_timesheet_required,contract_id,contract_week_id,timesheet_id` +
        `&limit=1`;
    } else if (contract_week_id) {
      api =
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
        `?contract_week_id=eq.${enc(contract_week_id)}` +
        `&select=route_type,client_no_timesheet_required,contract_id,contract_week_id,timesheet_id` +
        `&limit=1`;
    }

    if (api) {
      const { rows } = await sbFetch(env, api);
      const r = (rows && rows[0]) || null;

      if (r) {
        const route_type = String(r.route_type || '').toUpperCase();
        const client_no_timesheet_required = toBool(r.client_no_timesheet_required);

        return {
          ok: true,
          source: 'v_timesheets_summary',
          route_type,
          client_no_timesheet_required,
          contract_id: r.contract_id || contract_id || null,
          contract_week_id: r.contract_week_id || contract_week_id || null,
          timesheet_id: r.timesheet_id || timesheet_id || null,
          is_import_authoritative: isImportAuthoritativeFromSummary(route_type, client_no_timesheet_required)
        };
      }
    }
  } catch {
    // fall through to contract fallback
  }

  // 2) Fallback: contract override booleans (route driven by these)
  if (contract_id) {
    try {
      const api =
        `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?id=eq.${enc(contract_id)}` +
        `&select=id,is_nhsp,autoprocess_hr,no_timesheet_required` +
        `&limit=1`;

      const { rows } = await sbFetch(env, api);
      const c = (rows && rows[0]) || null;

      if (c) {
        const is_nhsp = toBool(c.is_nhsp);
        const autoprocess_hr = toBool(c.autoprocess_hr);
        const no_timesheet_required = toBool(c.no_timesheet_required);

        const is_import_authoritative =
          (is_nhsp === true) ||
          (autoprocess_hr === true && no_timesheet_required === true);

        return {
          ok: true,
          source: 'contracts',
          route_type: null,
          client_no_timesheet_required: null,
          contract_id: c.id,
          contract_week_id: contract_week_id || null,
          timesheet_id: timesheet_id || null,
          is_import_authoritative
        };
      }
    } catch {
      // fall through
    }
  }

  return {
    ok: false,
    source: 'none',
    route_type: null,
    client_no_timesheet_required: null,
    contract_id: contract_id || null,
    contract_week_id: contract_week_id || null,
    timesheet_id: timesheet_id || null,
    is_import_authoritative: false
  };
}




// POST /api/contracts/:id/truncate-tail
 async function handleContractsTruncateTailSafely(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body; try { body = await parseJSONBody(req); } catch { 
    return withCORS(env, req, badRequest('Invalid JSON')); 
  }
  const desiredEnd = String(body?.desired_end || body?.end_date || '').trim();
  if (!/^\d{4}-\d{2}-\d{2}$/.test(desiredEnd)) {
    return withCORS(env, req, badRequest('desired_end (YYYY-MM-DD) is required'));
  }

  // 1) Load current window
  const c = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts`
      + `?id=eq.${enc(contractId)}&select=id,start_date,end_date`
  );
  if (!c) return withCORS(env, req, notFound('Contract not found'));

  // If desired_end >= current end, nothing to do
  if (desiredEnd >= c.end_date) {
    return withCORS(env, req, ok({ ok:true, safe_end: c.end_date, clamped:false }));
  }

  // 2) Find last week-ending date in the tail with a REAL timesheet linked
  //    Use contract_weeks only; do NOT exclude credit/invoice-locked sheets.
  let lastTsWE = null;
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks`
        + `?contract_id=eq.${enc(contractId)}`
        + `&week_ending_date=gt.${enc(desiredEnd)}&week_ending_date=lte.${enc(c.end_date)}`
        + `&timesheet_id=not.is.null`
        + `&select=week_ending_date`
        + `&order=week_ending_date.desc&limit=1`
    );
    lastTsWE = (rows && rows[0] && rows[0].week_ending_date) || null;
  } catch (e) {}

  const safeEnd = lastTsWE ? (lastTsWE > desiredEnd ? lastTsWE : desiredEnd) : desiredEnd;
  const clamped = safeEnd > desiredEnd;

  // 3) Unplan weeks AFTER safeEnd (but only those WITHOUT a timesheet)
  try {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks`
        + `?contract_id=eq.${enc(contractId)}`
        + `&week_ending_date=gt.${enc(safeEnd)}`
        + `&timesheet_id=is.null`,
      {
        method: 'DELETE',
        headers: { ...sbHeaders(env), Prefer: 'return=minimal' }
      }
    );
  } catch (e) {
    return withCORS(env, req, badRequest('Failed to unassign tail weeks: ' + (e?.message||e)));
  }

  // 4) Patch contract end_date to safeEnd
  try {
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify({ end_date: safeEnd, updated_at: nowIso() })
      }
    );
    if (!res.ok) {
      const t = await res.text();
      return withCORS(env, req, badRequest('Contract end update failed: ' + t));
    }
  } catch (e) {
    return withCORS(env, req, badRequest('Contract end update error: ' + (e?.message||e)));
  }

  return withCORS(env, req, ok({ ok:true, safe_end: safeEnd, clamped }));
}

async function handleTimesheetDelete(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  const enc = encodeURIComponent;

  // ✅ Guarded write: require expected_timesheet_id in JSON body
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // ✅ stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = resolved.current_timesheet_id;

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  // Guard: current TSFIN must not be paid or invoiced (and respect other hard locks defensively)
  const tsfin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );

  if (tsfin) {
    const hardLocked =
      !!tsfin.paid_at_utc ||
      !!tsfin.locked_by_invoice_id ||
      !!tsfin.locked_by_invoice ||
      !!tsfin.locked_by_invoice_line_id ||
      !!tsfin.locked_by_invoice_at_utc;

    if (hardLocked) return withCORS(env, req, badRequest('Cannot delete: invoiced or paid'));
  }

  // Confirm the timesheet row exists (chain/version record)
  const { rows: tsRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&select=timesheet_id&limit=1`
  );
  const versions = tsRows || [];
  if (!versions.length) return withCORS(env, req, notFound('Timesheet not found'));

  // Unlink any contract_weeks that point at this timesheet_id
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?timesheet_id=eq.${enc(currentTimesheetId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        timesheet_id: null,
        status: 'OPEN',
        updated_at: nowIso()
      })
    }
  ).catch(() => {});

  // Unlink any nhsp_shifts that point at this timesheet_id (defensive)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/nhsp_shifts?timesheet_id=eq.${enc(currentTimesheetId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        timesheet_id: null,
        updated_at: nowIso()
      })
    }
  ).catch(() => {});

  // Delete validations (defensive cleanup)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheet_validations?timesheet_id=eq.${enc(currentTimesheetId)}`,
    {
      method: 'DELETE',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' }
    }
  ).catch(() => {});

  // Delete TSFIN snapshots (avoid orphaned financials)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?timesheet_id=eq.${enc(currentTimesheetId)}`,
    {
      method: 'DELETE',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' }
    }
  ).catch(() => {});

  // Delete timesheet row (current version id)
  const del = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}`,
    {
      method: 'DELETE',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' }
    }
  );
  if (!del.ok) return withCORS(env, req, serverError(await del.text()));

  // Audit
  try {
    await writeAudit(
      env,
      user,
      'TIMESHEET_DELETED',
      { timesheet_id: currentTimesheetId },
      { entity: 'timesheets', subject_id: currentTimesheetId, req }
    );
  } catch (e) {
    console.warn('[TS][DELETE] audit failed', e?.message || e);
  }

  return withCORS(env, req, ok({
    deleted: true,
    timesheet_id: currentTimesheetId,
    current_timesheet_id: currentTimesheetId,
    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale
  }));
}




// ----------------------------------------------------------------------------
// E) Funnel & Prechecks (read-only views)
// ----------------------------------------------------------------------------

 async function handleFunnelTimesheets(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const url = new URL(req.url);
  const q = (k) => url.searchParams.get(k);

  let api = `${env.SUPABASE_URL}/rest/v1/v_timesheets_funnel?select=*`;

  if (q('candidate_id'))    api += `&candidate_id=eq.${enc(q('candidate_id'))}`;
  if (q('client_id'))       api += `&client_id=eq.${enc(q('client_id'))}`;
  if (q('status'))          api += `&status=eq.${enc(q('status'))}`;
  if (q('submission_mode')) api += `&submission_mode=eq.${enc(q('submission_mode'))}`;
  if (q('week_ending_from'))api += `&week_ending_date=gte.${enc(q('week_ending_from'))}`;
  if (q('week_ending_to'))  api += `&week_ending_date=lte.${enc(q('week_ending_to'))}`;

  // NEW: allow funnel filters by sheet_scope / route_type / qr_status if the view exposes them
  const sheetScopeRaw = q('sheet_scope');
  const sheetScope    = sheetScopeRaw ? sheetScopeRaw.toUpperCase() : null;

  const routeTypeRaw  = q('route_type');
  const routeType     = routeTypeRaw ? routeTypeRaw.toUpperCase() : null;

  const qrStatusRaw   = q('qr_status');
  const qrStatus      = qrStatusRaw ? qrStatusRaw.toUpperCase() : null;

  if (sheetScope) api += `&sheet_scope=eq.${enc(sheetScope)}`;
  if (routeType)  api += `&route_type=eq.${enc(routeType)}`;
  if (qrStatus)   api += `&qr_status=eq.${enc(qrStatus)}`;

  api += `&order=week_ending_date.asc`;

  const { rows } = await sbFetch(env, api);
  return withCORS(env, req, ok(rows || []));
}

async function handleInvoiceIssue(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_issue_one', {
      p_invoice_id: invoiceId,
      p_actor_user_id: actorUserId
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x) return withCORS(env, req, serverError('Issue RPC returned no result'));

    const st = String(x.status || '').toUpperCase();
    if (st === 'ON_HOLD') {
      return withCORS(env, req, ok({
        status: 'ON_HOLD',
        reasons: x.reasons || [],
        on_hold_reason: x.on_hold_reason || null
      }));
    }

    if (st === 'ISSUED') {
      return withCORS(env, req, ok({
        status: 'ISSUED',
        issued_at_utc: x.issued_at_utc || null
      }));
    }

    return withCORS(env, req, serverError(`Unexpected issue status: ${x.status}`));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to issue invoice'));
  }
}


 async function handleInvoicesPrecheck(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  const url = new URL(req.url);
  const ids = url.searchParams.getAll('timesheet_id');
  if (!ids.length) return withCORS(env, req, badRequest('timesheet_id (one or more) required'));

  const inList = ids.map(enc).join(',');
  const { rows } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/v_ts_invoice_precheck?timesheet_id=in.(${inList})`);
  return withCORS(env, req, ok(rows || []));
}

// ----------------------------------------------------------------------------
// F) Rates Presets CRUD
// ----------------------------------------------------------------------------
// ---------------------------------------------------------------------------
// Local helpers for rates_presets
// ---------------------------------------------------------------------------

function validatePresetBucketLabels(obj) {
  // Mirror contract bucket_labels_json rules: either null or full 5 non-empty strings
  if (!obj || typeof obj !== 'object') return null;
  const keys = ['day', 'night', 'sat', 'sun', 'bh'];
  const out = {};
  for (const k of keys) {
    const v = obj[k];
    if (typeof v !== 'string' || !v.trim()) return null;
    out[k] = v.trim();
  }
  return out;
}

const numOrNull = (v) => {
  if (v === '' || v === null || v === undefined) return null;
  const n = Number(v);
  return Number.isFinite(n) ? n : null;
};

async function derivePresetMileageDefaultsForClient(env, clientId, base) {
  let charge = numOrNull(base.mileage_charge_rate);
  let pay    = numOrNull(base.mileage_pay_rate);

  // Only derive defaults for CLIENT-scoped presets when charge/pay missing
  if (clientId && charge == null) {
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=eq.${enc(clientId)}` +
          `&select=mileage_charge_rate&limit=1`
      );
      const cli = (rows && rows[0]) || null;
      if (cli && cli.mileage_charge_rate != null) {
        const n = Number(cli.mileage_charge_rate);
        if (Number.isFinite(n)) charge = n;
      }
    } catch {
      // ignore, leave charge as null
    }
  }

  if (charge != null && pay == null) {
    // knock 0.10 off, clamp at 0, round 2dp
    const raw = charge - 0.10;
    const clamped = raw < 0 ? 0 : raw;
    pay = Math.round(clamped * 100) / 100;
  }

  if (charge != null && charge < 0) {
    throw new Error('mileage_charge_rate must be non-negative');
  }
  if (pay != null && pay < 0) {
    throw new Error('mileage_pay_rate must be non-negative');
  }

  return { mileage_charge_rate: charge, mileage_pay_rate: pay };
}

// ----------------------------------------------------------------------------
// F) Rates Presets CRUD
// ----------------------------------------------------------------------------

 async function handleRatesPresetsCreate(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  if (!body?.scope || !['GLOBAL', 'CLIENT'].includes(String(body.scope).toUpperCase())) {
    return withCORS(env, req, badRequest('scope must be GLOBAL or CLIENT'));
  }
  const scope = String(body.scope).toUpperCase();

  if (scope === 'CLIENT' && !body.client_id) {
    return withCORS(env, req, badRequest('client_id required for CLIENT scope'));
  }
  if (!body.role || !body.name) {
    return withCORS(env, req, badRequest('role and name required'));
  }

  // Normalise flags
  const enable_paye      = clampBool(body.enable_paye, false);
  const enable_umbrella  = clampBool(body.enable_umbrella, false);

  if (!enable_paye && !enable_umbrella) {
    return withCORS(env, req, badRequest('At least one of enable_paye or enable_umbrella must be true'));
  }

  // Optional bucket labels (mirror contracts)
  const bucketLabels = validatePresetBucketLabels(body.bucket_labels_json) || null;

  // Schedule: for presets we store as-is or null (no derived hours here)
  const std_schedule_json = body.std_schedule_json || null;

  // Normalise rates
  const buckets = ['day', 'night', 'sat', 'sun', 'bh'];
  const paye = {};
  const umb  = {};
  const charge = {};

  for (const b of buckets) {
    paye[b]   = numOrNull(body[`paye_${b}`]);
    umb[b]    = numOrNull(body[`umb_${b}`]);
    charge[b] = numOrNull(body[`charge_${b}`]);
  }

  // Non-negative pay/charge (if provided)
  for (const b of buckets) {
    if (paye[b] != null && paye[b] < 0) {
      return withCORS(env, req, badRequest(`paye_${b} must be a non-negative number if provided`));
    }
    if (umb[b] != null && umb[b] < 0) {
      return withCORS(env, req, badRequest(`umb_${b} must be a non-negative number if provided`));
    }
    if (charge[b] != null && charge[b] < 0) {
      return withCORS(env, req, badRequest(`charge_${b} must be a non-negative number if provided`));
    }
  }

  // Margin check: for each bucket, charge >= pay for any enabled pay panel
  for (const b of buckets) {
    const ch = charge[b];
    if (ch == null) continue;
    if (enable_paye && paye[b] != null && ch < paye[b]) {
      return withCORS(env, req, badRequest(`Negative margin not allowed for PAYE ${b}`));
    }
    if (enable_umbrella && umb[b] != null && ch < umb[b]) {
      return withCORS(env, req, badRequest(`Negative margin not allowed for Umbrella ${b}`));
    }
  }

  // Mileage: derive defaults for CLIENT scope if missing, and enforce non-negative
  let mileage_charge_rate = numOrNull(body.mileage_charge_rate);
  let mileage_pay_rate    = numOrNull(body.mileage_pay_rate);

  try {
    if (scope === 'CLIENT') {
      const derived = await derivePresetMileageDefaultsForClient(env, body.client_id, {
        mileage_charge_rate,
        mileage_pay_rate
      });
      mileage_charge_rate = derived.mileage_charge_rate;
      mileage_pay_rate    = derived.mileage_pay_rate;
    } else {
      if (mileage_charge_rate != null && mileage_charge_rate < 0) {
        return withCORS(env, req, badRequest('mileage_charge_rate must be non-negative'));
      }
      if (mileage_pay_rate != null && mileage_pay_rate < 0) {
        return withCORS(env, req, badRequest('mileage_pay_rate must be non-negative'));
      }
    }
  } catch (e) {
    return withCORS(env, req, badRequest(e.message || 'Invalid mileage defaults'));
  }

  // Untick semantics: if a panel is disabled, null out its pay values
  const payload = {
    scope,
    client_id: scope === 'CLIENT' ? (body.client_id || null) : null,
    role: body.role,
    band: body.band ?? null,
    name: body.name,
    display_site: body.display_site || null,
    bucket_labels_json: bucketLabels,
    std_schedule_json,
    enable_paye,
    enable_umbrella,

    paye_day:   enable_paye ? paye.day   : null,
    paye_night: enable_paye ? paye.night : null,
    paye_sat:   enable_paye ? paye.sat   : null,
    paye_sun:   enable_paye ? paye.sun   : null,
    paye_bh:    enable_paye ? paye.bh    : null,

    umb_day:    enable_umbrella ? umb.day   : null,
    umb_night:  enable_umbrella ? umb.night : null,
    umb_sat:    enable_umbrella ? umb.sat   : null,
    umb_sun:    enable_umbrella ? umb.sun   : null,
    umb_bh:     enable_umbrella ? umb.bh    : null,

    charge_day:   charge.day,
    charge_night: charge.night,
    charge_sat:   charge.sat,
    charge_sun:   charge.sun,
    charge_bh:    charge.bh,

    mileage_pay_rate,
    mileage_charge_rate,
    created_at: nowIso(),
    updated_at: nowIso()
  };

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/rates_presets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify(payload)
  });
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const row = (await res.json().catch(() => []))[0];
  return withCORS(env, req, ok(row));
}
 async function handleRatesPresetsList(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const filters = [];

  // Explicit select including all rate columns + client name
  let api =
    `${env.SUPABASE_URL}/rest/v1/rates_presets?select=` +
    [
      'id',
      'scope',
      'client_id',
      'role',
      'band',
      'name',
      'display_site',
      'bucket_labels_json',
      'std_schedule_json',
      'enable_paye',
      'enable_umbrella',

      // full bucket set so picker/manager can render summaries
      'paye_day',
      'paye_night',
      'paye_sat',
      'paye_sun',
      'paye_bh',
      'umb_day',
      'umb_night',
      'umb_sat',
      'umb_sun',
      'umb_bh',
      'charge_day',
      'charge_night',
      'charge_sat',
      'charge_sun',
      'charge_bh',

      'mileage_pay_rate',
      'mileage_charge_rate',
      'updated_at',
      'client:clients(name)'
    ].join(',');

  const scope     = q('scope');
  const clientId  = q('client_id');
  const role      = q('role');
  const band      = q('band');
  const name      = q('name');
  const text      = q('q');   // NEW: free-text filter (name/role/band)

  if (scope)    filters.push(`scope=eq.${enc(scope.toUpperCase())}`);
  if (clientId) filters.push(`client_id=eq.${enc(clientId)}`);
  if (role)     filters.push(`role=eq.${enc(role)}`);

  // Keep existing band semantics (exact match if provided)
  if (band != null) {
    filters.push(`band=eq.${enc(band)}`);
  }

  // Free-text q wins over exact name filter
  if (text) {
    const trimmed = String(text || '').trim();
    if (trimmed) {
      const like = `%${trimmed}%`;
      filters.push(
        `or=(` +
          `name.ilike.${enc(like)},` +
          `role.ilike.${enc(like)},` +
          `band.ilike.${enc(like)}` +
        `)`
      );
    }
  } else if (name) {
    // Legacy exact-name filter preserved when q is not present
    filters.push(`name=eq.${enc(name)}`);
  }

  if (filters.length) api += `&${filters.join('&')}`;
  api += '&order=updated_at.desc';

  const { rows } = await sbFetch(env, api);
  return withCORS(env, req, ok(rows || []));
}

 async function handleRatesPresetsUpdate(env, req, presetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  // Load existing row so we can merge + validate final state
  let before;
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/rates_presets?id=eq.${enc(presetId)}&select=*`
    );
    before = (rows && rows[0]) || null;
  } catch (e) {
    return withCORS(env, req, serverError('Failed to load existing preset'));
  }
  if (!before) return withCORS(env, req, badRequest('Preset not found'));

  const scope = String(((body.scope ?? before.scope) || '')).toUpperCase();
  if (!['GLOBAL', 'CLIENT'].includes(scope)) {
    return withCORS(env, req, badRequest('scope must be GLOBAL or CLIENT'));
  }

  const client_id =
    scope === 'CLIENT'
      ? (body.client_id ?? before.client_id ?? null)
      : null;

  if (scope === 'CLIENT' && !client_id) {
    return withCORS(env, req, badRequest('client_id required for CLIENT scope'));
  }

  const role = body.role ?? before.role;
  const name = body.name ?? before.name;
  const band = (body.band !== undefined) ? body.band : before.band;

  if (!role || !name) {
    return withCORS(env, req, badRequest('role and name required'));
  }

  const enable_paye     = clampBool(body.enable_paye, before.enable_paye);
  const enable_umbrella = clampBool(body.enable_umbrella, before.enable_umbrella);

  if (!enable_paye && !enable_umbrella) {
    return withCORS(env, req, badRequest('At least one of enable_paye or enable_umbrella must be true'));
  }

  const display_site =
    ('display_site' in body)
      ? (body.display_site || null)
      : (before.display_site || null);

  const rawBucketLabels =
    ('bucket_labels_json' in body)
      ? body.bucket_labels_json
      : before.bucket_labels_json;

  const bucketLabels = validatePresetBucketLabels(rawBucketLabels) || null;

  const std_schedule_json =
    ('std_schedule_json' in body)
      ? (body.std_schedule_json || null)
      : (before.std_schedule_json || null);

  const buckets = ['day', 'night', 'sat', 'sun', 'bh'];
  const paye = {};
  const umb  = {};
  const charge = {};

  for (const b of buckets) {
    const payeRaw   = (('paye_'   + b) in body) ? body[`paye_${b}`]   : before[`paye_${b}`];
    const umbRaw    = (('umb_'    + b) in body) ? body[`umb_${b}`]    : before[`umb_${b}`];
    const chargeRaw = (('charge_' + b) in body) ? body[`charge_${b}`] : before[`charge_${b}`];

    paye[b]   = numOrNull(payeRaw);
    umb[b]    = numOrNull(umbRaw);
    charge[b] = numOrNull(chargeRaw);
  }

  // Non-negative pay/charge (if provided)
  for (const b of buckets) {
    if (paye[b] != null && paye[b] < 0) {
      return withCORS(env, req, badRequest(`paye_${b} must be a non-negative number if provided`));
    }
    if (umb[b] != null && umb[b] < 0) {
      return withCORS(env, req, badRequest(`umb_${b} must be a non-negative number if provided`));
    }
    if (charge[b] != null && charge[b] < 0) {
      return withCORS(env, req, badRequest(`charge_${b} must be a non-negative number if provided`));
    }
  }

  // Margin check
  for (const b of buckets) {
    const ch = charge[b];
    if (ch == null) continue;
    if (enable_paye && paye[b] != null && ch < paye[b]) {
      return withCORS(env, req, badRequest(`Negative margin not allowed for PAYE ${b}`));
    }
    if (enable_umbrella && umb[b] != null && ch < umb[b]) {
      return withCORS(env, req, badRequest(`Negative margin not allowed for Umbrella ${b}`));
    }
  }

  // Mileage: merge existing + patch, enforce non-negative
  let mileage_charge_rate =
    ('mileage_charge_rate' in body)
      ? numOrNull(body.mileage_charge_rate)
      : numOrNull(before.mileage_charge_rate);

  let mileage_pay_rate =
    ('mileage_pay_rate' in body)
      ? numOrNull(body.mileage_pay_rate)
      : numOrNull(before.mileage_pay_rate);

  if (mileage_charge_rate != null && mileage_charge_rate < 0) {
    return withCORS(env, req, badRequest('mileage_charge_rate must be non-negative'));
  }
  if (mileage_pay_rate != null && mileage_pay_rate < 0) {
    return withCORS(env, req, badRequest('mileage_pay_rate must be non-negative'));
  }

  // Untick semantics for update: if a panel is disabled, null out its pay fields
  const payload = {
    scope,
    client_id,
    role,
    band: band ?? null,
    name,
    display_site,
    bucket_labels_json: bucketLabels,
    std_schedule_json,
    enable_paye,
    enable_umbrella,

    paye_day:   enable_paye ? paye.day   : null,
    paye_night: enable_paye ? paye.night : null,
    paye_sat:   enable_paye ? paye.sat   : null,
    paye_sun:   enable_paye ? paye.sun   : null,
    paye_bh:    enable_paye ? paye.bh    : null,

    umb_day:    enable_umbrella ? umb.day   : null,
    umb_night:  enable_umbrella ? umb.night : null,
    umb_sat:    enable_umbrella ? umb.sat   : null,
    umb_sun:    enable_umbrella ? umb.sun   : null,
    umb_bh:     enable_umbrella ? umb.bh    : null,

    charge_day:   charge.day,
    charge_night: charge.night,
    charge_sat:   charge.sat,
    charge_sun:   charge.sun,
    charge_bh:    charge.bh,

    mileage_pay_rate,
    mileage_charge_rate,
    updated_at: nowIso()
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/rates_presets?id=eq.${enc(presetId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload)
    }
  );
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));
  const row = (await res.json().catch(() => []))[0];
  return withCORS(env, req, ok(row));
}

 async function handleRatesPresetsDelete(env, req, presetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/rates_presets?id=eq.${enc(presetId)}`,
    {
      method: 'DELETE',
      headers: {
        ...sbHeaders(env),
        'Prefer': 'return=minimal'
      }
    }
  );

  if (!res.ok) {
    return withCORS(env, req, serverError(await res.text()));
  }

  return withCORS(env, req, ok({ deleted: true }));
}

 async function handleRatesPresetsGet(env, req, presetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  // Reuse the same column set as handleRatesPresetsList
  const selectCols = [
    'id',
    'scope',
    'client_id',
    'role',
    'band',
    'name',
    'display_site',
    'bucket_labels_json',
    'std_schedule_json',
    'enable_paye',
    'enable_umbrella',

    'paye_day',
    'paye_night',
    'paye_sat',
    'paye_sun',
    'paye_bh',
    'umb_day',
    'umb_night',
    'umb_sat',
    'umb_sun',
    'umb_bh',
    'charge_day',
    'charge_night',
    'charge_sat',
    'charge_sun',
    'charge_bh',

    'mileage_pay_rate',
    'mileage_charge_rate',
    'updated_at',
    'client:clients(name)'
  ].join(',');

  const api =
    `${env.SUPABASE_URL}/rest/v1/rates_presets` +
    `?id=eq.${enc(presetId)}` +
    `&select=${selectCols}`;

  let rows;
  try {
    const res = await sbFetch(env, api);
    rows = res.rows;
  } catch (e) {
    return withCORS(env, req, serverError('Failed to load preset'));
  }

  const row = (rows && rows[0]) || null;
  if (!row) {
    // if you don't have notFound(), you can swap this for badRequest('Preset not found')
    return withCORS(env, req, notFound('Preset not found'));
  }

  return withCORS(env, req, ok(row));
}

//
// NEW HANDLERS ONLY — per your request
// Assumes shared helpers exist in your codebase: requireUser, withCORS, ok, badRequest, notFound, unauthorized, serverError, parseJSONBody, sbFetch, sbHeaders, writeAudit, sbRpc (optional).
//

// ───────────────────────────────────────────────────────────────────────────────
// Shared local helpers (lightweight, self-contained)
// ───────────────────────────────────────────────────────────────────────────────

const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
const csvEsc = (v) => {
  if (v == null) return '';
  const s = String(v);
  return /[",\n]/.test(s) ? `"${s.replace(/"/g, '""')}"` : s;
};
const csvJoin = (cols) => cols.map(csvEsc).join(',');

async function getDefaultSettings(env, asOfYmd = null) {
  // Finance windows RPC (cached): settings_finance_pick(p_date)
  const fin = await loadFinanceGlobals(env, asOfYmd);

  return {
    vat: Number(fin?.vat_rate_pct ?? 20),
    wtr: Number(fin?.holiday_pay_pct ?? 12.07),
  };
}


function resolveWtrPctForRow(row, defaults, clientHolidayMap) {
  // Prefer snapshot if present (already frozen)
  if (row?.pay_wtr_rate_pct_snapshot != null && row?.pay_wtr_rate_pct_snapshot !== '')
    return Number(row.pay_wtr_rate_pct_snapshot);

  // Then prefer policy snapshot values
  const pol = row?.policy_snapshot_json || {};
  const polPct = pol.holiday_pay_pct;
  const apply = String(pol.apply_holiday_to || '').toUpperCase();
  if (apply === 'NONE') return 0;
  if (polPct != null && isFinite(Number(polPct))) return Number(polPct);

  // Else check client settings
  const cs = clientHolidayMap[row.client_id];
  if (cs) {
    if (cs.applyTo === 'NONE') return 0;
    if (isFinite(Number(cs.pct))) return Number(cs.pct);
  }

  // Fallback to defaults
  return Number(defaults.wtr);
}

function deriveUmbrellaVatSnapshots(rowEx, hintRatePct, umbrellaVatChargeable) {
  if (!umbrellaVatChargeable) {
    return { rate: null, vat: 0, inc: rowEx };
  }
  const rate = Number(hintRatePct ?? 0);
  const vat = round2(rowEx * (rate / 100));
  const inc = round2(rowEx + vat);
  return { rate, vat, inc };
}
async function getClientHolidayPctMap(env, clientIds, asOfYmd = null) {
  const enc = encodeURIComponent;
  if (!clientIds?.length) return {};

  // Determine as-of date (YYYY-MM-DD). If missing/invalid, use today (UTC->YMD)
  let ymd = (typeof asOfYmd === 'string' && /^\d{4}-\d{2}-\d{2}$/.test(asOfYmd)) ? asOfYmd : null;
  if (!ymd) ymd = new Date().toISOString().slice(0, 10);

  const url = `${env.SUPABASE_URL}/rest/v1/client_settings` +
    `?select=client_id,holiday_pay_pct,apply_holiday_to,effective_from` +
    `&client_id=in.(${clientIds.map(enc).join(',')})` +
    `&effective_from=lte.${enc(ymd)}` +
    `&order=client_id.asc,effective_from.desc`;

  const { rows } = await sbFetch(env, url);

  const map = {};
  for (const r of rows || []) {
    if (map[r.client_id]) continue; // first (latest in-scope) only
    map[r.client_id] = {
      pct: (r.holiday_pay_pct == null ? null : Number(r.holiday_pay_pct)),
      applyTo: (r.apply_holiday_to || '').toUpperCase(), // PAYE_ONLY | ALL | NONE
    };
  }
  return map;
}

// /api/me handler — remove admin-only gate
 async function handleMe(env, req) {
  const user = await requireUser(env, req /* no role gating here */);
  if (!user) return withCORS(env, req, unauthorized());

  const me = {
    id: user.id,
    email: user.email || null,
    display_name: user.display_name || user.name || user.email || null,
    roles: Array.isArray(user.roles) ? user.roles : (user.role ? [user.role] : [])
  };

  return withCORS(env, req, ok({ user: me }));
}

async function handleInvoiceSaveEdits(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let payload = null;
  try { payload = await parseJSONBody(req); } catch {}
  if (!payload || typeof payload !== 'object') {
    return withCORS(env, req, badRequest('Invalid JSON payload'));
  }

  // ✅ Pre-check invoice status to return a clean 409 (and avoid wasted RPC call)
  try {
    const enc = encodeURIComponent;
    const inv = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoiceId)}&select=id,status,paid_at_utc,issued_at_utc`
    );

    if (!inv || !inv.id) {
      return withCORS(env, req, notFound('Invoice not found'));
    }

    const st = String(inv.status || '').toUpperCase();

    // Issued invoices cannot be edited; user must unissue first (modal save pipeline handles this)
    if (st === 'ISSUED') {
      return withCORS(env, req, conflict('Invoice is issued. Unissue it before editing.'));
    }

    // Paid invoices cannot be edited
    if (inv.paid_at_utc) {
      return withCORS(env, req, conflict('Invoice is paid and cannot be edited.'));
    }

    // Defensive: only allow DRAFT / ON_HOLD
    if (st !== 'DRAFT' && st !== 'ON_HOLD') {
      return withCORS(env, req, conflict(`Invoice is not editable (status=${st || 'UNKNOWN'})`));
    }
  } catch (e) {
    // If pre-check fails for any reason, fall back to the DB RPC enforcement below.
  }

  try {
    // ✅ Single atomic SQL transaction applies all edits + returns updated manifest
    // RPC supports:
    // - remove_invoice_line_ids
    // - add_timesheet_ids
    // - add_adjustments
    // - remove_segment_refs
    // - add_segment_refs
    // - reference_updates
  const manRes = await sbRpc(
  env,
  'invoice_apply_edits',
  {
    p_invoice_id: invoiceId,
    p_payload: payload,
    p_actor_user_id: user?.id || null
  },
  { timeoutMs: 25000 } // ✅ avoid hanging forever on row locks
);

    const manRows = Array.isArray(manRes) ? manRes : (manRes?.data || []);
    const manifest = (manRows && manRows.length) ? manRows[0] : manRes;

    if (!manifest || typeof manifest !== 'object') {
      return withCORS(env, req, serverError('Failed to apply invoice edits (no manifest returned)'));
    }

    const invoice = manifest.invoice || manifest.invoice_row || null;
    if (!invoice || !invoice.id) {
      return withCORS(env, req, serverError('Failed to apply invoice edits (malformed manifest)'));
    }

    const header_snapshot_json =
      (manifest.header_snapshot_json && typeof manifest.header_snapshot_json === 'object')
        ? manifest.header_snapshot_json
        : (invoice.header_snapshot_json && typeof invoice.header_snapshot_json === 'object' ? invoice.header_snapshot_json : {});

    const lineRows = Array.isArray(manifest.lines) ? manifest.lines : [];

    const items = lineRows.map(l => ( {
      invoice_line_id: l.id ?? null,
      source_key: l.source_key ?? null,
      booking_id: l.booking_id ?? null,
      timesheet_id: l.timesheet_id ?? null,

      // ✅ helpers for UI (timesheet vs adjustment)
      is_adjustment: (l.is_adjustment != null)
        ? !!l.is_adjustment
        : (!l.timesheet_id || String(l?.meta_json?.line_type || '').toUpperCase() === 'ADJUSTMENT'),
      line_type_norm: (typeof l.line_type_norm === 'string' && l.line_type_norm)
        ? l.line_type_norm
        : String(l?.meta_json?.line_type || '').toUpperCase(),

      qty: {
        day: l.hours_day, night: l.hours_night, sat: l.hours_sat, sun: l.hours_sun, bh: l.hours_bh
      },
      pay_rate: {
        day: l.pay_day, night: l.pay_night, sat: l.pay_sat, sun: l.pay_sun, bh: l.pay_bh
      },
      charge_rate: {
        day: l.charge_day, night: l.charge_night, sat: l.charge_sat, sun: l.charge_sun, bh: l.charge_bh
      },

      total_pay_ex_vat: l.total_pay_ex_vat ?? null,
      total_charge_ex_vat: l.total_charge_ex_vat ?? null,
      margin_ex_vat: l.margin_ex_vat ?? null,

      vat_rate_pct: l.vat_rate_pct ?? null,
      vat_amount: l.vat_amount ?? null,
      total_inc_vat: l.total_inc_vat ?? null,

      description: l.description ?? null,
      paper_ts_r2_key: l.paper_ts_r2_key ?? l.effective_paper_ts_r2_key ?? null,

      meta_json: (l.meta_json && typeof l.meta_json === 'object') ? l.meta_json : {}
    } ));

    // ✅ Pass-through fields the FE expects to be “one-call” refreshed after apply
    const segments_on_invoice_by_timesheet =
      (manifest.segments_on_invoice_by_timesheet && typeof manifest.segments_on_invoice_by_timesheet === 'object')
        ? manifest.segments_on_invoice_by_timesheet
        : ((manifest.segments_by_timesheet && typeof manifest.segments_by_timesheet === 'object')
            ? manifest.segments_by_timesheet
            : {});

    const history = Array.isArray(manifest.history) ? manifest.history : [];

    const tsfin_id_by_timesheet_id =
      (manifest.tsfin_id_by_timesheet_id && typeof manifest.tsfin_id_by_timesheet_id === 'object')
        ? manifest.tsfin_id_by_timesheet_id
        : {};

    const reference_rows = Array.isArray(manifest.reference_rows) ? manifest.reference_rows : [];

    // Audit (best-effort) — records expanded payload too (segments + references)
    try {
      await writeAudit(
        env,
        user,
        'INVOICE_EDITS_APPLIED',
        { invoice_id: invoiceId, payload },
        { entity: 'invoice', subject_id: invoiceId, req }
      );
    } catch {}

    return withCORS(env, req, ok({
      ok: true,

      invoice,
      items,
      header_snapshot_json,
      email_summary: manifest.email_summary ?? null,

      attach_policy: manifest.attach_policy ?? null,

      evidence: Array.isArray(manifest.evidence) ? manifest.evidence : [],
      timesheet_evidence: Array.isArray(manifest.timesheet_evidence) ? manifest.timesheet_evidence : [],
      evidence_other: Array.isArray(manifest.evidence_other) ? manifest.evidence_other : [],

      hr_source_rows_cache: Array.isArray(manifest.hr_source_rows_cache) ? manifest.hr_source_rows_cache : [],
      tsfin_external_source_rows: Array.isArray(manifest.tsfin_external_source_rows) ? manifest.tsfin_external_source_rows : [],

      // ✅ Segment expansion + invoice history + tsfin map + reference rows
      segments_on_invoice_by_timesheet,
      segments_by_timesheet: segments_on_invoice_by_timesheet,
      history,
      tsfin_id_by_timesheet_id,
      reference_rows,

      // also return the raw manifest for any future UI needs
      manifest
    }));
  } catch (e) {
    const msg = String(e?.message || e || '');

    // ✅ Map DB-level "not editable" errors to a clean 409 so UI can guide the user
    if (/Invoice is not editable/i.test(msg)) {
      return withCORS(env, req, conflict(msg));
    }
    if (/already paid/i.test(msg)) {
      return withCORS(env, req, conflict(msg));
    }

    // ✅ Segment-move gating errors (expected user-actionable)
    if (/Segments cannot be moved when additional rates exist/i.test(msg)) {
      return withCORS(env, req, conflict(msg));
    }
    if (/Segments cannot be moved when expenses or mileage exist/i.test(msg)) {
      return withCORS(env, req, conflict(msg));
    }

    // ✅ Reference gating for segments can be user-actionable too
    if (/missing reference number/i.test(msg)) {
      return withCORS(env, req, badRequest(msg));
    }

    return withCORS(env, req, serverError(msg));
  }
}


async function handleInvoiceEligibleTimesheets(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    const res = await sbRpc(env, 'invoice_eligible_timesheets_for_invoice', { p_invoice_id: invoiceId });

    // RPC returns JSONB; sbRpc may return object or array depending on wrapper
    const out = Array.isArray(res) ? (res[0] ?? res) : (res?.data ?? res);

    return withCORS(env, req, ok(out));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}



// ───────────────────────────────────────────────────────────────────────────────
// 1) PAYMENTS & REMITTANCES
// ───────────────────────────────────────────────────────────────────────────────

// ───────────────────────────────────────────────────────────────────────────────
// PAYMENTS — CSV (authorised gate + 16-char payment reference cap)
// ───────────────────────────────────────────────────────────────────────────────
async function handlePaymentsGenerateCsv(env, req) {
  const enc    = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const capRef = (s, max = 16) => (s ? String(s).slice(0, max) : '');
  const csvEsc = (v) => {
    const s = String(v ?? '');
    return /[",\n]/.test(s) ? `"${s.replace(/"/g, '""')}"` : s;
  };

  // Monday of a given date (UTC) as YYYY-MM-DD
  const computeMondayWeekStartForDate = (d) => {
    if (!(d instanceof Date) || Number.isNaN(d.getTime())) return null;
    const base = new Date(Date.UTC(d.getUTCFullYear(), d.getUTCMonth(), d.getUTCDate()));
    const day  = base.getUTCDay();           // 0=Sun..6=Sat
    const offset = (day + 6) % 7;            // days since Monday
    base.setUTCDate(base.getUTCDate() - offset);
    const yyyy = base.getUTCFullYear();
    const mm   = String(base.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(base.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const clientIds    = Array.isArray(body?.client_ids)    ? body.client_ids.filter(Boolean)    : [];
  const candidateIds = Array.isArray(body?.candidate_ids) ? body.candidate_ids.filter(Boolean) : [];
  const payMethod    = body?.pay_method ? String(body.pay_method).toUpperCase() : null;
  const umbrellaIds  = Array.isArray(body?.umbrella_ids)  ? body.umbrella_ids.filter(Boolean)  : [];

  // One pay-run week start for *this* CSV generation.
  // Used for missing-shift repayments and scheduled advances/repayments.
  const payWeekStart = computeMondayWeekStartForDate(new Date());

  // ==== Query TSFIN — only current, unpaid, not on hold, AUTHORISED timesheets
  let url =
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?select=` +
    [
      'id',
      'timesheet_id',
      'candidate_id',
      'client_id',
      'pay_method',
      'processing_status',
      'total_pay_ex_vat',
      'additional_pay_ex_vat',
      'expenses_pay_ex_vat',
      'mileage_pay_ex_vat',
      'pay_wtr_rate_pct_snapshot',
      'policy_snapshot_json',
      'pay_vat_rate_pct_snapshot',
      'pay_vat_amount_snapshot',
      'pay_total_inc_vat_snapshot',
      'paid_at_utc',
      'pay_on_hold',
      'invoice_breakdown_json',
      'timesheet:timesheets(week_ending_date,authorised_at_server,contract_id,reference_number)'
    ].join(',') +
    `&is_current=eq.true&paid_at_utc=is.null&pay_on_hold=eq.false` +
    `&timesheet.authorised_at_server=not.is.null`;

  if (clientIds.length)    url += `&client_id=in.(${clientIds.map(enc).join(',')})`;
  if (candidateIds.length) url += `&candidate_id=in.(${candidateIds.map(enc).join(',')})`;
  if (payMethod)           url += `&pay_method=eq.${enc(payMethod)}`;

  const { rows: tsRowsRaw } = await sbFetch(env, url, false);
  const tsRows = Array.isArray(tsRowsRaw) ? tsRowsRaw : [];

  // ==== Load unpaid pay adjustments (only as_advance=false)
  // NOTE: this allows "adjustments-only" runs even when there are no TSFIN rows.
  let adjRows = [];
  try {
    let adjUrl =
      `${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments` +
      `?paid_at_utc=is.null` +
      `&as_advance=eq.false` +
      `&select=id,timesheet_id,candidate_id,client_id,week_ending_date,delta_pay_ex_vat,reason,as_advance,advance_reason,meta_json,note`;

    if (clientIds.length)    adjUrl += `&client_id=in.(${clientIds.map(enc).join(',')})`;
    if (candidateIds.length) adjUrl += `&candidate_id=in.(${candidateIds.map(enc).join(',')})`;

    const { rows } = await sbFetch(env, adjUrl, false);
    adjRows = rows || [];
  } catch (e) {
    console.warn('[PAY_CSV] failed to load ts_pay_adjustments', e?.message || e);
    adjRows = [];
  }

  if (!tsRows.length && !adjRows.length) {
    return withCORS(env, req, notFound('Nothing to pay (no eligible timesheets and no unpaid pay adjustments).'));
  }

  // ==== Load contracts for reference gate (require_reference_to_pay – CONTRACT-LEVEL)
  // (only relevant for TSFIN rows)
  const contractIds = [...new Set(tsRows.map(r => r?.timesheet?.contract_id).filter(Boolean))];
  let requireRefMap = {};
  if (contractIds.length) {
    const { rows: crows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?id=in.(${contractIds.map(enc).join(',')})` +
      `&select=id,require_reference_to_pay`
    );
    requireRefMap = Object.fromEntries((crows || []).map(c => [c.id, !!c.require_reference_to_pay]));
  }

  // ==== Candidate and Umbrella lookups (must include candidates from TSFIN rows + adjustments)
  const candIdsAll = [
    ...new Set([
      ...tsRows.map(r => r?.candidate_id).filter(Boolean),
      ...adjRows.map(a => a?.candidate_id).filter(Boolean)
    ])
  ];

  const { rows: candRows } = candIdsAll.length
    ? await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates?` +
        `select=id,display_name,first_name,last_name,email,account_holder,bank_name,sort_code,account_number,pay_method,umbrella_id` +
        `&id=in.(${candIdsAll.map(enc).join(',')})`
      )
    : { rows: [] };

  const mapCand = Object.fromEntries((candRows || []).map(c => [c.id, c]));

  const umbIdsAll = [...new Set((candRows || []).map(c => c.umbrella_id).filter(Boolean))];
  const { rows: umbRows } = umbIdsAll.length
    ? await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/umbrellas` +
        `?id=in.(${umbIdsAll.map(enc).join(',')})` +
        `&select=id,name,enabled,vat_chargeable,bank_name,sort_code,account_number`
      )
    : { rows: [] };

  const mapUmb = Object.fromEntries((umbRows || []).map(u => [u.id, u]));

  // ==== Optional umbrella filter + safety gates + contract reference gate (TSFIN rows only)
  const filtered = tsRows.filter(r => {
    const ps = String(r.processing_status || '').toUpperCase();
    if (ps === 'UNASSIGNED' || ps === 'CLIENT_UNRESOLVED' || ps === 'RATE_MISSING' || ps === 'PAY_CHANNEL_MISSING') {
      return false;
    }

    const cand = mapCand[r.candidate_id];
    if (!cand) return false;

    const candMethod = String(cand.pay_method || '').toUpperCase();
    if (!candMethod || (candMethod !== 'PAYE' && candMethod !== 'UMBRELLA')) return false;

    if (payMethod && candMethod !== payMethod) return false;

    if (umbrellaIds.length) {
      const u = cand.umbrella_id;
      if (!u || !umbrellaIds.includes(u)) return false;
    }

    if (candMethod === 'UMBRELLA') {
      const umb = mapUmb[cand.umbrella_id];
      if (!umb?.enabled) return false;
    }

    if (candMethod === 'PAYE') {
      if (!cand.sort_code || !cand.account_number || !cand.account_holder) return false;
    }

    if (!r?.timesheet?.authorised_at_server) return false;

    const requireRef = r?.timesheet?.contract_id ? !!requireRefMap[r.timesheet.contract_id] : false;
    if (requireRef) {
      const ref = (r?.timesheet?.reference_number || '').trim();
      if (!ref) return false;
    }

    return true;
  });

  // ==== Defaults / client WTR
  const defaults = await getDefaultSettings(env);
  const clientIdSet = [...new Set(filtered.map(r => r.client_id).filter(Boolean))];
  const clientHolidayMap = clientIdSet.length ? await getClientHolidayPctMap(env, clientIdSet) : {};

  // ==== Group by candidate_id (NOT week_ending_date)
  // Goal: pay run includes all outstanding TSFIN + all outstanding non-advance adjustments for each candidate.
  const groups = new Map(); // candidate_id -> { candidate_id, rows: [], adjustments: [] }

  for (const r of filtered) {
    const key = String(r.candidate_id);
    let g = groups.get(key);
    if (!g) {
      g = { candidate_id: r.candidate_id, rows: [], adjustments: [] };
      groups.set(key, g);
    }
    g.rows.push(r);
  }

  for (const a of adjRows) {
    const key = String(a.candidate_id);
    let g = groups.get(key);
    if (!g) {
      g = { candidate_id: a.candidate_id, rows: [], adjustments: [] };
      groups.set(key, g);
    }
    g.adjustments.push(a);
  }

  // ==== CSV compose (Monzo format)
  const csvHeader = ['Payment reference','Payee name','Sort code','Bank account number','Bank account type','Amount'];
  const csvRows = [csvHeader.map(csvEsc).join(',')];

  const nowIso = new Date().toISOString();
  const batchRef = `PAY:${nowIso.slice(0,10)}`;
  const payRunCorrelationId = `PAYRUN:${nowIso}`; // used to fetch deductions/adjustments later for remittances

  const affectedTsIds = [];
  const patchQueue = [];       // TSFIN patches
  const payAdjPatchQueue = []; // pay adjustment patches
  const skippedCandidates = []; // for diagnostics

  let bankTransferLines = 0;
  let internalSettledCandidates = 0;

  for (const g of groups.values()) {
    const cand = mapCand[g.candidate_id];
    if (!cand) continue;

    const payMethodEff = String(cand.pay_method || '').toUpperCase();
    if (!payMethodEff || (payMethodEff !== 'PAYE' && payMethodEff !== 'UMBRELLA')) continue;

    if (payMethod && payMethodEff !== payMethod) continue;
    if (umbrellaIds.length && payMethodEff === 'UMBRELLA') {
      const u = cand.umbrella_id;
      if (!u || !umbrellaIds.includes(u)) continue;
    }

    // Bank/channel eligibility (covers adjustments-only too)
    if (payMethodEff === 'UMBRELLA') {
      const umb = mapUmb[cand?.umbrella_id];
      if (!umb?.enabled) continue;
      if (!umb.sort_code || !umb.account_number || !umb.name) continue;
    } else {
      if (!cand.sort_code || !cand.account_number || !cand.account_holder) continue;
    }

    // 1) Compute gross from TSFIN rows
    let sumEx  = 0; // PAYE (ex VAT)
    let sumInc = 0; // Umbrella (inc VAT)

    for (const r of g.rows) {
      const payEx = Number(r.total_pay_ex_vat || 0);
      const expEx = Number(r.expenses_pay_ex_vat || 0);
      const milEx = Number(r.mileage_pay_ex_vat || 0);
      const rowEx = round2(payEx + expEx + milEx);

      if (payMethodEff === 'PAYE') {
        const wtrPct = resolveWtrPctForRow(r, defaults, clientHolidayMap);
        if (r.pay_wtr_rate_pct_snapshot == null) {
          patchQueue.push({ id: r.id, body: { pay_wtr_rate_pct_snapshot: wtrPct } });
        }
        sumEx += rowEx;
      } else {
        const umb = mapUmb[cand?.umbrella_id];
        const vatChargeable = !!umb?.vat_chargeable;

        let rate   = r.pay_vat_rate_pct_snapshot;
        let vatAmt = r.pay_vat_amount_snapshot;
        let incAmt = r.pay_total_inc_vat_snapshot;

        if (vatChargeable) {
          if (incAmt == null || Number(incAmt) === 0) {
            rate = (rate == null ? defaults.vat : Number(rate));
            const derived = deriveUmbrellaVatSnapshots(rowEx, rate, true);
            rate   = derived.rate;
            vatAmt = derived.vat;
            incAmt = derived.inc;
            patchQueue.push({
              id: r.id,
              body: {
                pay_vat_rate_pct_snapshot: rate,
                pay_vat_amount_snapshot:   vatAmt,
                pay_total_inc_vat_snapshot: incAmt
              }
            });
          }
          sumInc += Number(incAmt || 0);
        } else {
          if (
            (r.pay_vat_amount_snapshot && Number(r.pay_vat_amount_snapshot) !== 0) ||
            (r.pay_total_inc_vat_snapshot && Number(r.pay_total_inc_vat_snapshot) !== round2(rowEx))
          ) {
            patchQueue.push({
              id: r.id,
              body: {
                pay_vat_rate_pct_snapshot: null,
                pay_vat_amount_snapshot:   0,
                pay_total_inc_vat_snapshot: rowEx
              }
            });
          }
          sumInc += rowEx;
        }
      }
    }

    // 1b) Add pay adjustments (non-advance only), regardless of their stored week_ending_date
    const adjList = (g.adjustments || []).map(a => ({
      id: a.id,
      timesheet_id: a.timesheet_id || null,
      delta_pay_ex_vat: round2(Number(a.delta_pay_ex_vat || 0)),
      reason: a.reason || null,
      note: a.note || null,
      meta_json: a.meta_json || null
    }));
    const adjTotal = round2(adjList.reduce((acc, a) => acc + Number(a.delta_pay_ex_vat || 0), 0));

    if (payMethodEff === 'PAYE') sumEx  = round2(sumEx  + adjTotal);
    else                         sumInc = round2(sumInc + adjTotal);

    const grossBeforeDeductions = payMethodEff === 'PAYE' ? round2(sumEx) : round2(sumInc);

    // If gross is <= 0, we cannot produce a valid pay run for this candidate.
    // (We also do NOT mark anything paid; this requires manual resolution.)
    if (!(grossBeforeDeductions > 0)) {
      skippedCandidates.push({
        candidate_id: g.candidate_id,
        reason: 'GROSS_NON_POSITIVE',
        gross_before_deductions: grossBeforeDeductions
      });
      continue;
    }

    // 2) Apply deductions/repayments with net-pay floor for THIS pay run week start
    let baseGross = grossBeforeDeductions;
    let scheduleEntries = [];
    let advanceUpdates = [];

    if (payWeekStart) {
      // For each TSFIN row, register missing-shift repayments into THIS pay run week
      for (const r of g.rows) {
        if (!r.client_id) continue;
        await createMissingShiftRepayEntriesForTs(env, g.candidate_id, r.client_id, r, payWeekStart);
      }

      const loaded = await loadScheduledAdvanceEntries(env, g.candidate_id, payWeekStart);
      scheduleEntries = loaded?.entries || [];

      if (scheduleEntries.length) {
        const applied = await applyAdvanceScheduleEntriesForWeek(env, g.candidate_id, payWeekStart, baseGross, scheduleEntries);
        baseGross = Number(applied?.newGross ?? baseGross);
        advanceUpdates = Array.isArray(applied?.updates) ? applied.updates : [];
        await persistAdvanceRepayments(env, advanceUpdates, payWeekStart);
      }
    }

    // Net after deductions (guaranteed >= 0 by applyAdvanceScheduleEntriesForWeek; clamp defensively anyway)
    const netAfterDeductions = round2(Math.max(0, Number(baseGross || 0)));

    // 3) Determine payee + bank details + account type
    let payeeName, sortCode, accountNumber, accountType;
    if (payMethodEff === 'UMBRELLA') {
      const umb = mapUmb[cand?.umbrella_id];
      if (!umb?.enabled) continue;
      payeeName     = umb.name || 'Umbrella';
      sortCode      = umb.sort_code || '';
      accountNumber = umb.account_number || '';
      accountType   = 'Business';
    } else {
      const first   = (cand?.first_name || '').trim();
      const last    = (cand?.last_name  || '').trim();
      const display = [first, last].filter(Boolean).join(' ').trim();
      payeeName     = display || cand?.account_holder || cand?.display_name || 'Candidate';
      sortCode      = cand?.sort_code || '';
      accountNumber = cand?.account_number || '';
      accountType   = 'Personal';
    }

    // 4) PAYMENT REFERENCE: Candidate "Surname Firstname"
    const refLast  = (cand?.last_name  || '').trim();
    const refFirst = (cand?.first_name || '').trim();
    const lineRef  = capRef([refLast, refFirst].filter(Boolean).join(' ').trim(), 16);

    // 5) CSV ROW RULES:
    // - 100% guarantee no negatives: we never emit a negative amount
    // - no zero lines: if net is 0, we do NOT emit a bank row
    // BUT we *still* settle the run internally by marking TSFIN + adjustments paid,
    // because the gross was consumed by deductions/repayments.
    const bankTransferNeeded = netAfterDeductions > 0;
    if (bankTransferNeeded) {
      csvRows.push([
        csvEsc(lineRef),
        csvEsc(payeeName),
        csvEsc(sortCode),
        csvEsc(accountNumber),
        csvEsc(accountType),
        csvEsc(netAfterDeductions.toFixed(2)),
      ].join(','));
      bankTransferLines++;
    }

    // 6) Mark TSFIN rows as paid (even if net transfer is 0, because the pay run is settled via deductions)
    for (const r of g.rows) {
      affectedTsIds.push(r.timesheet_id);
      patchQueue.push({
        id: r.id,
        body: {
          paid_at_utc: nowIso,
          paid_by_user_id: user.id || null,
          payment_reference: lineRef
        }
      });
    }

    // 7) Mark pay adjustments as paid (same logic: settled even if net transfer is 0)
    for (const a of (g.adjustments || [])) {
      payAdjPatchQueue.push({
        id: a.id,
        body: {
          paid_at_utc: nowIso,
          paid_by_user_id: user.id || null,
          payment_reference: lineRef
        }
      });
    }

    // 8) Audit per candidate: allows remittance to show deductions + adjustments itemised.
    try {
      const deductionsApplied = (advanceUpdates || [])
        .filter(u => u && typeof u === 'object')
        .map(u => ({
          advance_id: u.advance_id || null,
          reason: u.reason || null,
          scheduled_amount: Number(u.amount || 0),   // signed
          actual: Number(u.actual || 0),            // >= 0 (amount taken or paid)
          remainder: Number(u.remainder || 0)       // >0 if could not take it all
        }));

      await writeAudit(
        env,
        user,
        'PAY_RUN_CANDIDATE_SETTLED',
        {
          paid_at_utc: nowIso,
          pay_week_start: payWeekStart,
          payment_reference: lineRef,
          pay_method: payMethodEff,
          gross_before_deductions: grossBeforeDeductions,
          net_after_deductions: netAfterDeductions,
          bank_transfer_needed: bankTransferNeeded,
          bank_transfer_amount: bankTransferNeeded ? netAfterDeductions : 0,

          timesheet_ids: (g.rows || []).map(r => r.timesheet_id).filter(Boolean),
          tsfin_ids: (g.rows || []).map(r => r.id).filter(Boolean),

          pay_adjustments: adjList,
          pay_adjustments_total: adjTotal,

          deductions: deductionsApplied
        },
        { entity: 'candidate', subject_id: g.candidate_id, reason: 'PAYMENT', correlation_id: payRunCorrelationId, req }
      );
    } catch (e) {
      console.warn('[PAY_CSV] candidate settle audit failed', e?.message || e);
    }

    internalSettledCandidates++;
  }

  if (!patchQueue.length && !payAdjPatchQueue.length) {
    // nothing was settled (e.g. everything skipped for negative/zero gross or bank invalid)
    return withCORS(env, req, notFound('Nothing to pay.'));
  }

  // ==== Apply TSFIN patches
  for (const p of patchQueue) {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(p.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(p.body)
      }
    );
  }

  // ==== Apply pay-adjustment patches
  for (const p of payAdjPatchQueue) {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments?id=eq.${enc(p.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(p.body)
      }
    );
  }

  // ==== Closeout: create £0 ISSUED do_not_send invoices for any zero-charge timesheets that were just paid
  // IMPORTANT:
  // - This is best-effort and must not fail the pay run.
  // - We pass all affected timesheet_ids; SQL will filter to those eligible.
  const uniqueTsIds = [...new Set(affectedTsIds.filter(Boolean))];

  let closeout = null;
  if (uniqueTsIds.length) {
    try {
      // Chunk to avoid oversized RPC payloads
      const chunkArr = (arr, n) => {
        const out = [];
        for (let i = 0; i < (arr || []).length; i += n) out.push(arr.slice(i, i + n));
        return out;
      };

      const invoiceIds = [];
      let okCount = 0;
      let totalRows = 0;

      for (const ch of chunkArr(uniqueTsIds, 200)) {
        const r = await sbRpc(env, 'invoice_closeout_zero_charge_timesheets', {
          p_timesheet_ids: ch,
          p_actor_user_id: user.id || null
        });

        const rows = Array.isArray(r) ? r : (r ? [r] : []);
        totalRows += rows.length;

        for (const row of rows) {
          if (row && row.ok === true) okCount++;
          if (row && row.invoice_id) invoiceIds.push(row.invoice_id);
        }
      }

      closeout = {
        attempted: true,
        ok_count: okCount,
        total_rows: totalRows,
        invoice_ids: invoiceIds
      };
    } catch (e) {
      closeout = {
        attempted: true,
        ok: false,
        error: (e && (e.message || String(e))) || 'CLOSEOUT_FAILED'
      };
    }
  }

  // ==== Audit summary for the run
  await writeAudit(
    env,
    user,
    'PAY_CSV_GENERATED',
    {
      batch_reference: batchRef,
      pay_week_start: payWeekStart,
      paid_at_utc: nowIso,
      timesheets_count: uniqueTsIds.length,
      bank_transfer_lines: bankTransferLines,
      internal_settled_candidates: internalSettledCandidates,
      skipped_candidates: skippedCandidates.slice(0, 50),
      closeout
    },
    { entity: 'timesheet', subject_id: null, reason: 'PAYMENT', correlation_id: payRunCorrelationId, req }
  );

  // CSV contains header + only positive lines (no zero, no negatives)
  const csv = csvRows.join('\n');

  return withCORS(env, req, ok({
    csv,
    affected_timesheet_ids: uniqueTsIds,
    batch_reference: batchRef,
    pay_week_start: payWeekStart,
    paid_at_utc: nowIso,
    bank_transfer_lines: bankTransferLines,
    internal_settled_candidates: internalSettledCandidates,
    skipped_candidates: skippedCandidates,
    closeout
  }));
}


async function handleRemittancesSend(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const ids = Array.isArray(body?.timesheet_ids) ? [...new Set(body.timesheet_ids)].filter(Boolean) : [];
  const resend = body?.resend === true;
  if (!ids.length) return withCORS(env, req, badRequest('timesheet_ids[] required'));

  // Pull current snapshots for those timesheets
  // NEW: include paid_at_utc + payment_reference so we can match adjustments/deductions for the same pay run.
  const url = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?is_current=eq.true&timesheet_id=in.(${ids.map(enc).join(',')})&select=` + [
      'id','timesheet_id','candidate_id','client_id',
      'pay_method',
      'hours_day','hours_night','hours_sat','hours_sun','hours_bh',
      'pay_day','pay_night','pay_sat','pay_sun','pay_bh',
      'total_hours','total_pay_ex_vat',
      'additional_pay_ex_vat',
      'additional_units_json',
      'expenses_pay_ex_vat','mileage_pay_ex_vat',
      'pay_wtr_rate_pct_snapshot','policy_snapshot_json',
      'pay_vat_rate_pct_snapshot','pay_vat_amount_snapshot','pay_total_inc_vat_snapshot',
      'paid_at_utc','payment_reference',
      'remittance_last_sent_at_utc','remittance_send_count',
      'timesheet:timesheets(timesheet_id,booking_id,week_ending_date,hospital_norm,ward_norm,shift_label_norm)',
      'client:clients(name)'
    ].join(',');

  const { rows: finRowsRaw } = await sbFetch(env, url, false);
  if (!finRowsRaw?.length) return withCORS(env, req, notFound('No matching current timesheets.'));

  const finRows = resend ? finRowsRaw : finRowsRaw.filter(r => !r.remittance_last_sent_at_utc && !r.remittance_send_count);
  if (!finRows.length) return withCORS(env, req, ok({ queued: 0, skipped: finRowsRaw.length, reason: 'already_sent' }));

  // Resolve per-row labels via timesheet -> contract_week -> contract.bucket_labels_json
  const DEFAULT_LABELS = { day: 'Day', night: 'Night', sat: 'Sat', sun: 'Sun', bh: 'BH' };
  const tsIdsAll = [...new Set(finRows.map(r => r.timesheet_id).filter(Boolean))];
  let labelsByTsId = {};
  if (tsIdsAll.length) {
    const { rows: wkRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?timesheet_id=in.(${tsIdsAll.map(enc).join(',')})&select=timesheet_id,contract_id`
    );
    const tsToContract = Object.fromEntries(
      (wkRows || [])
        .map(w => [w.timesheet_id, w.contract_id])
        .filter(([a, b]) => a && b)
    );
    const contractIds = [...new Set(Object.values(tsToContract).filter(Boolean))];
    let mapCon = {};
    if (contractIds.length) {
      const { rows: conRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contracts?id=in.(${contractIds.map(enc).join(',')})&select=id,bucket_labels_json`
      );
      mapCon = Object.fromEntries((conRows || []).map(c => [c.id, c.bucket_labels_json || null]));
    }
    labelsByTsId = Object.fromEntries(
      tsIdsAll.map(id => {
        const cid = tsToContract[id];
        const lbl = cid ? mapCon[cid] : null;
        return [id, (lbl && typeof lbl === 'object') ? lbl : DEFAULT_LABELS];
      })
    );
  }

  const candIds = [...new Set(finRows.map(r => r.candidate_id).filter(Boolean))];
  const { rows: candRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/candidates?id=in.(${candIds.map(enc).join(',')})&select=id,email,display_name,first_name,last_name,pay_method,umbrella_id`
  );
  const mapCand = Object.fromEntries((candRows || []).map(c => [c.id, c]));

  const umbIds = [...new Set((candRows || []).map(c => c.umbrella_id).filter(Boolean))];
  const { rows: umbRows } = umbIds.length
    ? await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/umbrellas?id=in.(${umbIds.map(enc).join(',')})&select=id,name,vat_chargeable`)
    : { rows: [] };
  const mapUmb = Object.fromEntries((umbRows || []).map(u => [u.id, u]));

  // Group by (candidate_id, paid_at_utc) so deductions/adjustments match the correct pay run.
  const groups = new Map(); // key -> { candId, paidAt, rows: [] }
  for (const r of finRows) {
    const paidAt = r.paid_at_utc || null;
    const key = `${r.candidate_id}__${paidAt || 'UNPAID'}`;
    const g = groups.get(key) || { candId: r.candidate_id, paidAt, rows: [] };
    g.rows.push(r);
    groups.set(key, g);
  }

  // Precompute clientIdSet once (used for per-pay-date holiday-map loads)
  const clientIdSet = [...new Set(finRows.map(r => r.client_id).filter(Boolean))];

  // Cache per asOfYmd to minimize calls:
  // - getDefaultSettings(env, ymd) -> uses loadFinanceGlobals RPC (cached by ymd)
  // - getClientHolidayPctMap(env, clientIds, ymd) -> one REST call per ymd
  const holidayMapCache = new Map();  // ymd -> map
  const defaultsCache = new Map();    // ymd -> {vat,wtr}

  const getYmdForPaidAt = (paidAt) => {
    // Use pay-date for deterministic resend behaviour
    let ymd = null;
    if (paidAt) {
      try {
        ymd = (toLocalParts(paidAt, null)?.ymd || null);
      } catch {}
      if (!ymd && typeof paidAt === 'string' && /^\d{4}-\d{2}-\d{2}/.test(paidAt)) {
        ymd = paidAt.slice(0, 10);
      }
    }
    // If unpaid, fall back to today (non-deterministic by definition because no pay date exists)
    if (!ymd) ymd = new Date().toISOString().slice(0, 10);
    return ymd;
  };

  let totalQueued = 0;
  const outboxIds = [];

  for (const { candId, paidAt, rows } of groups.values()) {
    const cand = mapCand[candId];
    if (!cand) continue;
    const toEmail = (cand.email || '').trim();
    if (!toEmail) continue;

    const asOfYmd = getYmdForPaidAt(paidAt);

    // Defaults (VAT/WTR) per pay-date
    let defaults = defaultsCache.get(asOfYmd);
    if (!defaults) {
      defaults = await getDefaultSettings(env, asOfYmd);
      defaultsCache.set(asOfYmd, defaults);
    }

    // Client holiday settings per pay-date
    let clientHolidayMap = holidayMapCache.get(asOfYmd);
    if (!clientHolidayMap) {
      clientHolidayMap = await getClientHolidayPctMap(env, clientIdSet, asOfYmd);
      holidayMapCache.set(asOfYmd, clientHolidayMap);
    }

    // Period labels from date range in rows
    const dates = rows.map(r => r?.timesheet?.week_ending_date).filter(Boolean).sort();
    const first = dates[0], last = dates[dates.length - 1];
    const periodLabel = (first && last) ? (first === last ? `WE ${first}` : `WE ${first}–${last}`) : 'Selected timesheets';
    const periodKey = (first && last) ? (first === last ? `${first}` : `${first}_${last}`) : 'selected';

    // Correlation to pay-run audit
    const payRunCorrelationId = paidAt ? `PAYRUN:${paidAt}` : null;

    // Pull pay adjustments that were paid in THIS pay run (same paid_at_utc + candidate_id)
    let paidAdjustments = [];
    if (paidAt) {
      try {
        const { rows: adj } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments` +
            `?candidate_id=eq.${enc(candId)}` +
            `&paid_at_utc=eq.${enc(paidAt)}` +
            `&as_advance=eq.false` +
            `&select=id,timesheet_id,delta_pay_ex_vat,reason,note,meta_json`
        );
        paidAdjustments = adj || [];
      } catch {
        paidAdjustments = [];
      }
    }

    // Pull deductions/repayments actually applied from audit event written by PAY CSV run
    let payRunDetails = null;
    if (payRunCorrelationId) {
      try {
        const audQ =
          `${env.SUPABASE_URL}/rest/v1/audit_events` +
          `?correlation_id=eq.${enc(payRunCorrelationId)}` +
          `&object_type=eq.candidate` +
          `&object_id_text=eq.${enc(candId)}` +
          `&action=eq.PAY_RUN_CANDIDATE_SETTLED` +
          `&select=after_json` +
          `&limit=1`;
        const { rows: audRows } = await sbFetch(env, audQ);
        payRunDetails = audRows?.[0]?.after_json || null;
      } catch {
        payRunDetails = null;
      }
    }

    const deductions = Array.isArray(payRunDetails?.deductions) ? payRunDetails.deductions : [];
    const grossBefore = Number(payRunDetails?.gross_before_deductions || 0);
    const netAfter    = Number(payRunDetails?.net_after_deductions || 0);
    const bankNeeded  = payRunDetails?.bank_transfer_needed === true;
    const bankAmount  = Number(payRunDetails?.bank_transfer_amount || 0);

    // Pay method label
    const candPayMethod = String(cand.pay_method || '').toUpperCase();
    const umb = cand.umbrella_id ? mapUmb[cand.umbrella_id] : null;
    const payMethodLabel =
      candPayMethod === 'UMBRELLA'
        ? (umb ? `Umbrella – ${umb.name}` : 'Umbrella')
        : 'PAYE (paid directly)';

    // HTML helpers
    const esc = (s) => String(s ?? '').replace(/[&<>"']/g, (c) => ({
      '&': '&amp;',
      '<': '&lt;',
      '>': '&gt;',
      '"': '&quot;',
      '\'': '&#39;'
    }[c]));
    const fmt = (n) => (n == null ? '' : Number(n).toFixed(2));
    const toNum = (v) => (v == null ? 0 : Number(v) || 0);

    const hasPAYE = rows.some(r => String(r.pay_method || '').toUpperCase() === 'PAYE');
    const hasUmb  = rows.some(r => String(r.pay_method || '').toUpperCase() === 'UMBRELLA');

    let totalPayEx = 0, totalExpEx = 0, totalMilEx = 0, totalEx = 0;
    let totalWtrBasic = 0, totalWtrElem = 0;
    let totalVat = 0, totalInc = 0;

    // Main table columns count (for colspan in nested tables)
    const baseCols = 19 + (hasPAYE ? 1 : 0) + (hasUmb ? 2 : 0);

    const splitRate = (rate, wtrPct) => {
      const t = Number(rate || 0) || 0;
      const pct = Number(wtrPct || 0) || 0;
      const mult = 1 + (pct / 100);
      if (!(mult > 0)) return { basic: 0, hol: 0, total: round2(t) };
      const basic = t / mult;
      const hol = t - basic;
      return { basic: round2(basic), hol: round2(hol), total: round2(t) };
    };

    const rowsHtml = rows.map((r) => {
      const ts = r.timesheet || {}; const cli = r.client || {};
      const payMethod = String(r.pay_method || '').toUpperCase();

      const payEx = toNum(r.total_pay_ex_vat);
      const expEx = toNum(r.expenses_pay_ex_vat);
      const milEx = toNum(r.mileage_pay_ex_vat);
      const rowEx = round2(payEx + expEx + milEx);

      totalPayEx += payEx; totalExpEx += expEx; totalMilEx += milEx; totalEx += rowEx;

      const L = labelsByTsId[r.timesheet_id] || DEFAULT_LABELS;

      // PAYE informational WTR split + PAYE rate breakdown table
      let wtrInfoHtml = '—';
      let payeRateBreakdownHtml = '';

      if (payMethod === 'PAYE') {
        const wtrPct = resolveWtrPctForRow(r, defaults, clientHolidayMap);

        // Total PAYE split (informational): basic + WTR element = total payEx
        const base = (payEx > 0) ? (payEx / (1 + (wtrPct / 100))) : 0;
        const wtr = payEx - base;
        totalWtrBasic += base; totalWtrElem += wtr;

        wtrInfoHtml = `${fmt(base)} basic + ${fmt(wtr)} WTR @ ${fmt(wtrPct)}%`;

        // Hourly breakdown per bucket: Hourly (basic) / Holiday / Total
        const buckets = [
          { label: L.day,   hours: toNum(r.hours_day),   rate: toNum(r.pay_day) },
          { label: L.night, hours: toNum(r.hours_night), rate: toNum(r.pay_night) },
          { label: L.sat,   hours: toNum(r.hours_sat),   rate: toNum(r.pay_sat) },
          { label: L.sun,   hours: toNum(r.hours_sun),   rate: toNum(r.pay_sun) },
          { label: L.bh,    hours: toNum(r.hours_bh),    rate: toNum(r.pay_bh) },
        ].filter(b => (b.hours > 0) || (b.rate > 0));

        if (buckets.length) {
          const rateRows = buckets.map(b => {
            const s = splitRate(b.rate, wtrPct);
            return `
              <tr>
                <td>${esc(b.label)}</td>
                <td style="text-align:right">${fmt(b.hours)}</td>
                <td style="text-align:right">${fmt(s.basic)}</td>
                <td style="text-align:right">${fmt(s.hol)}</td>
                <td style="text-align:right"><strong>${fmt(s.total)}</strong></td>
              </tr>`;
          }).join('');

          payeRateBreakdownHtml = `
            <tr>
              <td colspan="${baseCols}" style="padding:0 0 8px 0;">
                <table width="100%" border="0" cellspacing="0" cellpadding="4" style="border-collapse:collapse;margin-top:4px;background:#f7fbff">
                  <thead>
                    <tr>
                      <th align="left" style="font-size:12px;border-bottom:1px solid #dbeafe">PAYE rate breakdown</th>
                      <th align="right" style="font-size:12px;border-bottom:1px solid #dbeafe">Hours</th>
                      <th align="right" style="font-size:12px;border-bottom:1px solid #dbeafe">Hourly (basic)</th>
                      <th align="right" style="font-size:12px;border-bottom:1px solid #dbeafe">Holiday (WTR)</th>
                      <th align="right" style="font-size:12px;border-bottom:1px solid #dbeafe">Total hourly</th>
                    </tr>
                  </thead>
                  <tbody>
                    ${rateRows}
                  </tbody>
                </table>
              </td>
            </tr>`;
        }
      }

      // Umbrella VAT
      let vatHtml = '';
      let incHtml = '';
      let rowVat = 0;
      let rowInc = rowEx;

      if (payMethod === 'UMBRELLA') {
        const umbRow = mapUmb[cand.umbrella_id];
        const vatChargeable = !!umbRow?.vat_chargeable;
        let rate = r.pay_vat_rate_pct_snapshot;
        let vatAmt = r.pay_vat_amount_snapshot;
        let incAmt = r.pay_total_inc_vat_snapshot;

        if (vatChargeable) {
          if (!incAmt || Number(incAmt) === 0) {
            // ✅ defaults.vat is now finance-window VAT as-of pay date (paid_at_utc)
            rate = (rate == null ? defaults.vat : Number(rate));
            const derived = deriveUmbrellaVatSnapshots(rowEx, rate, true);
            rate = derived.rate; vatAmt = derived.vat; incAmt = derived.inc;
          }
          rowVat = Number(vatAmt || 0);
          rowInc = Number(incAmt || 0);
          totalVat += rowVat;
          totalInc += rowInc;
          vatHtml = `${fmt(rowVat)}${(rate || rate === 0) ? ` @ ${fmt(rate)}%` : ''}`;
          incHtml = `${fmt(rowInc)}`;
        } else {
          rowVat = 0;
          rowInc = rowEx;
          totalInc += rowInc;
          vatHtml = '—';
          incHtml = `${fmt(rowEx)}`;
        }
      }

      // Additional units detail (if any)
      let extrasHtml = '';
      let addUnits = r.additional_units_json || {};
      if (typeof addUnits === 'string') {
        try { addUnits = JSON.parse(addUnits); } catch { addUnits = {}; }
      }
      if (!addUnits || typeof addUnits !== 'object') addUnits = {};

      const extraRows = [];
      for (const [codeRaw, ex] of Object.entries(addUnits)) {
        if (!ex || typeof ex !== 'object') continue;
        const unitCount = Number(ex.unit_count || 0);
        if (!Number.isFinite(unitCount) || unitCount <= 0) continue;

        const bucketName = (ex.bucket_name && String(ex.bucket_name).trim()) || String(codeRaw || '').toUpperCase();
        const unitName   = (ex.unit_name && String(ex.unit_name).trim()) || 'units';
        const payRate    = Number(ex.pay_rate || 0);
        const payLine    = Number(ex.pay_ex_vat || (unitCount * payRate));

        extraRows.push(`
          <tr>
            <td>${esc(bucketName)}</td>
            <td>${esc(unitName)}</td>
            <td style="text-align:right">${fmt(unitCount)}</td>
            <td style="text-align:right">${fmt(payRate)}</td>
            <td style="text-align:right">${fmt(payLine)}</td>
          </tr>`);
      }

      if (extraRows.length) {
        extrasHtml = `
          <tr>
            <td colspan="${baseCols}" style="padding:0 0 8px 0;">
              <table width="100%" border="0" cellspacing="0" cellpadding="4" style="border-collapse:collapse;margin-top:4px;background:#fafafa">
                <thead>
                  <tr>
                    <th align="left" style="font-size:12px;border-bottom:1px solid #e0e0e0">Additional rate</th>
                    <th align="left" style="font-size:12px;border-bottom:1px solid #e0e0e0">Unit</th>
                    <th align="right" style="font-size:12px;border-bottom:1px solid #e0e0e0">Quantity</th>
                    <th align="right" style="font-size:12px;border-bottom:1px solid #e0e0e0">Rate (ex VAT)</th>
                    <th align="right" style="font-size:12px;border-bottom:1px solid #e0e0e0">Amount (ex VAT)</th>
                  </tr>
                </thead>
                <tbody>
                  ${extraRows.join('')}
                </tbody>
              </table>
            </td>
          </tr>`;
      }

      return `
        <tr>
          <td>${esc(ts.week_ending_date || '')}</td>
          <td>${esc(cli.name || '')}</td>
          <td>${esc(ts.hospital_norm || '')}</td>
          <td>${esc(ts.ward_norm || '')}</td>
          <td>${esc(ts.shift_label_norm || '')}</td>
          <td style="text-align:right">${fmt(r.hours_day)}</td>
          <td style="text-align:right">${fmt(r.pay_day)}</td>
          <td style="text-align:right">${fmt(r.hours_night)}</td>
          <td style="text-align:right">${fmt(r.pay_night)}</td>
          <td style="text-align:right">${fmt(r.hours_sat)}</td>
          <td style="text-align:right">${fmt(r.pay_sat)}</td>
          <td style="text-align:right">${fmt(r.hours_sun)}</td>
          <td style="text-align:right">${fmt(r.pay_sun)}</td>
          <td style="text-align:right">${fmt(r.hours_bh)}</td>
          <td style="text-align:right">${fmt(r.pay_bh)}</td>
          <td style="text-align:right"><strong>${fmt(payEx)}</strong></td>
          <td style="text-align:right">${fmt(expEx)}</td>
          <td style="text-align:right">${fmt(milEx)}</td>
          <td style="text-align:right"><strong>${fmt(rowEx)}</strong></td>
          ${hasPAYE ? `<td style="text-align:right">${wtrInfoHtml}</td>` : ''}
          ${hasUmb ? `<td style="text-align:right">${vatHtml}</td>` : ''}
          ${hasUmb ? `<td style="text-align:right"><strong>${incHtml}</strong></td>` : ''}
        </tr>
        ${payeRateBreakdownHtml}
        ${extrasHtml}`;
    }).join('');

    // Itemised adjustments section
    const adjTotal = round2((paidAdjustments || []).reduce((acc, a) => acc + Number(a.delta_pay_ex_vat || 0), 0));
    const adjRowsHtml = (paidAdjustments || []).length
      ? `
        <table width="100%" border="0" cellspacing="0" cellpadding="6" style="border-collapse:collapse;margin-top:8px">
          <thead>
            <tr style="background:#f5f5f5">
              <th align="left">Pay adjustment</th>
              <th align="left">Reason</th>
              <th align="right">Amount (ex VAT)</th>
            </tr>
          </thead>
          <tbody>
            ${(paidAdjustments || []).map(a => `
              <tr>
                <td>${esc(a.id || '')}</td>
                <td>${esc(a.reason || '')}</td>
                <td align="right">${fmt(a.delta_pay_ex_vat)}</td>
              </tr>
            `).join('')}
          </tbody>
          <tfoot>
            <tr>
              <td colspan="2" align="right" style="border-top:1px solid #e5e5e5"><strong>Adjustments total:</strong></td>
              <td align="right" style="border-top:1px solid #e5e5e5"><strong>${fmt(adjTotal)}</strong></td>
            </tr>
          </tfoot>
        </table>`
      : `<p style="margin:8px 0 0;color:#666">Pay adjustments: none</p>`;

    // Itemised deductions section (from pay-run audit)
    const dedTotal = round2((deductions || []).reduce((acc, d) => acc + Number(d.actual || 0), 0));
    const dedRowsHtml = (deductions || []).length
      ? `
        <table width="100%" border="0" cellspacing="0" cellpadding="6" style="border-collapse:collapse;margin-top:8px">
          <thead>
            <tr style="background:#f5f5f5">
              <th align="left">Deduction / repayment</th>
              <th align="left">Reason</th>
              <th align="right">Scheduled (signed)</th>
              <th align="right">Taken this run</th>
              <th align="right">Remaining</th>
            </tr>
          </thead>
          <tbody>
            ${(deductions || []).map(d => `
              <tr>
                <td>${esc(d.advance_id || '')}</td>
                <td>${esc(d.reason || '')}</td>
                <td align="right">${fmt(d.scheduled_amount)}</td>
                <td align="right"><strong>${fmt(d.actual)}</strong></td>
                <td align="right">${fmt(d.remainder)}</td>
              </tr>
            `).join('')}
          </tbody>
          <tfoot>
            <tr>
              <td colspan="3" align="right" style="border-top:1px solid #e5e5e5"><strong>Deductions taken:</strong></td>
              <td align="right" style="border-top:1px solid #e5e5e5"><strong>${fmt(dedTotal)}</strong></td>
              <td style="border-top:1px solid #e5e5e5"></td>
            </tr>
          </tfoot>
        </table>`
      : `<p style="margin:8px 0 0;color:#666">Deductions / repayments: none</p>`;

    const extraPAYECol = hasPAYE ? '<th align="right">Basic + WTR (info)</th>' : '';
    const extraUmbCols = hasUmb ? '<th align="right">VAT</th><th align="right">Total (inc VAT)</th>' : '';
    const candName = cand.display_name || [cand.first_name, cand.last_name].filter(Boolean).join(' ') || 'Candidate';
    const nowIso2 = new Date().toISOString();
    const titleSuffix = hasUmb ? ' – Umbrella' : (hasPAYE ? ' – PAYE' : '');

    const summaryHtml = paidAt ? `
      <div style="margin:12px 0;padding:10px;border:1px solid #e5e5e5;border-radius:8px;background:#fafafa">
        <div><strong>Payment run:</strong> ${esc(paidAt)}</div>
        <div><strong>Gross before deductions:</strong> ${fmt(grossBefore)}</div>
        <div><strong>Deductions taken:</strong> ${fmt(dedTotal)}</div>
        <div><strong>Net after deductions:</strong> ${fmt(netAfter)}</div>
        <div><strong>Bank transfer:</strong> ${bankNeeded ? `YES (${fmt(bankAmount)})` : 'NO (net was £0.00)'}</div>
        <div style="color:#666;margin-top:6px"><strong>WTR/VAT scope date:</strong> ${esc(asOfYmd)}</div>
      </div>
    ` : `
      <div style="margin:12px 0;padding:10px;border:1px solid #e5e5e5;border-radius:8px;background:#fafafa">
        <div><strong>Payment run:</strong> Not available (timesheets not marked paid yet)</div>
        <div style="color:#666;margin-top:6px"><strong>WTR/VAT scope date:</strong> ${esc(asOfYmd)}</div>
      </div>
    `;

    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;font-size:14px;line-height:1.4">
        <h2 style="margin:0 0 8px">Remittance Advice${titleSuffix}</h2>
        <p style="margin:0 0 4px"><strong>${esc(candName)}</strong></p>
        <p style="margin:0 0 4px"><strong>Pay method:</strong> ${esc(payMethodLabel)}</p>
        <p style="margin:0 0 4px"><strong>Period:</strong> ${esc(periodLabel)}</p>
        <p style="margin:0 0 8px"><strong>Payment reference:</strong> ${esc(rows?.[0]?.payment_reference || '')}</p>
        <p style="margin:0 0 16px;color:#666">Generated: ${esc(nowIso2)}</p>

        ${summaryHtml}

        <table width="100%" border="0" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead>
            <tr style="background:#f5f5f5">
              <th align="left">Week Ending</th>
              <th align="left">Client</th>
              <th align="left">Hospital</th>
              <th align="left">Ward</th>
              <th align="left">Shift</th>
              <th align="right">Hrs Day</th>
              <th align="right">Pay Day</th>
              <th align="right">Hrs Night</th>
              <th align="right">Pay Night</th>
              <th align="right">Hrs Sat</th>
              <th align="right">Pay Sat</th>
              <th align="right">Hrs Sun</th>
              <th align="right">Pay Sun</th>
              <th align="right">Hrs BH</th>
              <th align="right">Pay BH</th>
              <th align="right">Pay (ex VAT)</th>
              <th align="right">Expenses</th>
              <th align="right">Mileage</th>
              <th align="right">Total (ex VAT)</th>
              ${extraPAYECol}
              ${extraUmbCols}
            </tr>
          </thead>
          <tbody>${rowsHtml}</tbody>
          <tfoot>
            <tr>
              <td colspan="15" align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>Totals:</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${round2(totalPayEx).toFixed(2)}</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${round2(totalExpEx).toFixed(2)}</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${round2(totalMilEx).toFixed(2)}</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${round2(totalEx).toFixed(2)}</strong></td>
              ${hasPAYE ? `<td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${round2(totalWtrBasic).toFixed(2)} basic + ${round2(totalWtrElem).toFixed(2)} WTR</strong></td>` : ''}
              ${hasUmb ? `<td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${round2(totalVat).toFixed(2)}</strong></td>` : ''}
              ${hasUmb ? `<td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${round2(totalInc).toFixed(2)}</strong></td>` : ''}
            </tr>
          </tfoot>
        </table>

        ${adjRowsHtml}
        ${dedRowsHtml}

        ${hasPAYE ? `<p style="margin-top:12px;color:#666">For PAYE, the pay rate is WTR-inclusive. The hourly breakdown shows: Hourly (basic) + Holiday (WTR) = Total hourly rate, and the pay split is informational.</p>` : ''}
        ${hasUmb ? `<p style="margin-top:8px;color:#666">For Umbrella assignments where VAT applies, totals show ex VAT and inc VAT amounts using the VAT rate in scope for the payment date (unless a snapshot VAT was already stored).</p>` : ''}
      </div>`;

    // Plain text remittance (also itemised)
    const fmt2 = (n) => (n == null ? '' : Number(n).toFixed(2));
    const tlines = [
      `Remittance Advice${titleSuffix}`,
      `${candName}`,
      `Pay method: ${payMethodLabel}`,
      `Period: ${periodLabel}`,
      `Payment reference: ${(rows?.[0]?.payment_reference || '').trim()}`,
      `Generated: ${nowIso2}`,
      `Scope date (WTR/VAT): ${asOfYmd}`,
      ''
    ];

    if (paidAt) {
      tlines.push(`Payment run: ${paidAt}`);
      tlines.push(`Gross before deductions: ${fmt2(grossBefore)}`);
      tlines.push(`Deductions taken: ${fmt2(dedTotal)}`);
      tlines.push(`Net after deductions: ${fmt2(netAfter)}`);
      tlines.push(`Bank transfer: ${bankNeeded ? `YES (${fmt2(bankAmount)})` : 'NO (net was 0.00)'}`);
      tlines.push('');
    }

    for (const r of rows) {
      const ts = r.timesheet || {}; const cli = r.client || {};
      const pm = String(r.pay_method || '').toUpperCase();
      const payEx = toNum(r.total_pay_ex_vat);
      const expEx = toNum(r.expenses_pay_ex_vat);
      const milEx = toNum(r.mileage_pay_ex_vat);
      const rowEx = round2(payEx + expEx + milEx);
      const L = labelsByTsId[r.timesheet_id] || DEFAULT_LABELS;

      tlines.push(`WE ${ts.week_ending_date || ''} — ${cli.name || ''} / ${ts.hospital_norm || ''} / ${ts.ward_norm || ''} / ${ts.shift_label_norm || ''}`);
      tlines.push(`${L.day}: ${fmt2(r.hours_day)} @ ${fmt2(r.pay_day)}, ${L.night}: ${fmt2(r.hours_night)} @ ${fmt2(r.pay_night)}, ${L.sat}: ${fmt2(r.hours_sat)} @ ${fmt2(r.pay_sat)}, ${L.sun}: ${fmt2(r.hours_sun)} @ ${fmt2(r.pay_sun)}, ${L.bh}: ${fmt2(r.hours_bh)} @ ${fmt2(r.pay_bh)}`);
      tlines.push(`Pay ex VAT: ${fmt2(payEx)} | Expenses: ${fmt2(expEx)} | Mileage: ${fmt2(milEx)} | Total ex VAT: ${fmt2(rowEx)}`);

      if (pm === 'PAYE') {
        const wtrPct = resolveWtrPctForRow(r, defaults, clientHolidayMap);

        const base = (payEx > 0) ? (payEx / (1 + (wtrPct / 100))) : 0;
        const wtr = payEx - base;
        tlines.push(`(PAYE) Pay split (info): ${fmt2(base)} basic + ${fmt2(wtr)} WTR @ ${fmt2(wtrPct)}%`);

        const buckets = [
          { label: L.day,   hours: toNum(r.hours_day),   rate: toNum(r.pay_day) },
          { label: L.night, hours: toNum(r.hours_night), rate: toNum(r.pay_night) },
          { label: L.sat,   hours: toNum(r.hours_sat),   rate: toNum(r.pay_sat) },
          { label: L.sun,   hours: toNum(r.hours_sun),   rate: toNum(r.pay_sun) },
          { label: L.bh,    hours: toNum(r.hours_bh),    rate: toNum(r.pay_bh) },
        ].filter(b => (b.hours > 0) || (b.rate > 0));

        if (buckets.length) {
          tlines.push('(PAYE) Hourly rate breakdown (basic + holiday = total):');
          for (const b of buckets) {
            const s = splitRate(b.rate, wtrPct);
            tlines.push(`  - ${b.label}: hrs=${fmt2(b.hours)} | ${fmt2(s.basic)} + ${fmt2(s.hol)} = ${fmt2(s.total)}`);
          }
        }
      }

      tlines.push('');
    }

    tlines.push(`Totals — Pay ex VAT: ${round2(totalPayEx).toFixed(2)}, Expenses: ${round2(totalExpEx).toFixed(2)}, Mileage: ${round2(totalMilEx).toFixed(2)}, Total ex VAT: ${round2(totalEx).toFixed(2)}`);

    if ((paidAdjustments || []).length) {
      tlines.push('');
      tlines.push('Pay adjustments:');
      for (const a of paidAdjustments) {
        tlines.push(`- ${a.id}: ${a.reason || ''}  ${fmt2(a.delta_pay_ex_vat)}`);
      }
      tlines.push(`Adjustments total: ${fmt2(adjTotal)}`);
    } else {
      tlines.push('');
      tlines.push('Pay adjustments: none');
    }

    if ((deductions || []).length) {
      tlines.push('');
      tlines.push('Deductions / repayments applied:');
      for (const d of deductions) {
        tlines.push(`- ${d.advance_id || ''} (${d.reason || ''}) scheduled=${fmt2(d.scheduled_amount)} taken=${fmt2(d.actual)} remaining=${fmt2(d.remainder)}`);
      }
      tlines.push(`Deductions taken: ${fmt2(dedTotal)}`);
    } else {
      tlines.push('');
      tlines.push('Deductions / repayments: none');
    }

    const text = tlines.join('\n');

    const reference = `remit:candidate:${candId}:${periodKey}:${paidAt || 'unpaid'}`;

    // Queue email (mail_outbox)
    const outRes = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({
        type: 'REMITTANCE',
        to: toEmail,
        cc: null,
        subject: `Remittance Advice – ${periodLabel}`,
        body_html: html,
        body_text: text,
        attachments: null,
        status: 'QUEUED',
        reference,
        created_by: user?.id || null,
      })
    });

    if (!outRes.ok) continue;
    const outJson = await outRes.json().catch(() => []);
    const mail = Array.isArray(outJson) ? outJson[0] : outJson;
    const mailId = mail?.id || null;
    if (mailId) outboxIds.push(mailId);

    // Audit (candidate)
    await writeAudit(env, user, 'EMAIL_QUEUED', {
      to: toEmail,
      subject: `Remittance Advice – ${periodLabel}`,
      period: { start: first || null, end: last || null },
      mail_id: mailId,
      timesheets: rows.map(r => r.timesheet_id),
      pay_adjustments_count: (paidAdjustments || []).length,
      deductions_count: (deductions || []).length,
      scope_ymd: asOfYmd
    }, { entity: 'candidate', subject_id: candId, reason: 'REMITTANCE', correlation_id: mailId, req });

    // Audit (each timesheet) + update remittance counters
    const nowIsoSend = new Date().toISOString();
    for (const r of rows) {
      await writeAudit(env, user, 'EMAIL_QUEUED',
        { to: toEmail, subject: `Remittance Advice – ${periodLabel}`, mail_id: mailId, scope_ymd: asOfYmd },
        { entity: 'timesheet', subject_id: r.timesheet_id, reason: 'REMITTANCE', correlation_id: mailId, req });

      const newCount = Number(r.remittance_send_count || 0) + 1;
      await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(r.id)}`, {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({ remittance_last_sent_at_utc: nowIsoSend, remittance_send_count: newCount })
      });
    }

    totalQueued += 1;
  }

  return withCORS(env, req, ok({ queued: totalQueued, outbox_ids: outboxIds }));
}



 async function handleContractsCheckOverlap(env, req) {
  const user = await requireUser (env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body; 
  try { body = await parseJSONBody(req); } 
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const candidateId = body?.candidate_id;
  const start = body?.start_date ? toYmd(body.start_date) : null;
  const end   = body?.end_date   ? toYmd(body.end_date)   : null;
  const ignoreId = body?.ignore_contract_id ? String(body.ignore_contract_id) : null;

  if (!candidateId || !start || !end) {
    return withCORS(env, req, badRequest('candidate_id, start_date, end_date are required'));
  }
  const dStart = new Date(`${start}T00:00:00Z`);
  const dEnd   = new Date(`${end}T00:00:00Z`);
  if (isNaN(dStart) || isNaN(dEnd) || dEnd < dStart) {
    return withCORS(env, req, badRequest('end_date must be on/after start_date'));
  }

  // Fetch existing contracts for this candidate that overlap [start,end]:
  // overlap condition: existing.start <= end AND existing.end >= start
  let api = `${env.SUPABASE_URL}/rest/v1/contracts` +
            `?select=id,candidate_id,client_id,role,band,start_date,end_date,` +
            `client:clients(name)` +
            `&candidate_id=eq.${enc(candidateId)}` +
            `&start_date=lte.${enc(end)}` +
            `&end_date=gte.${enc(start)}`;
  if (ignoreId) {
    api += `&id=neq.${enc(ignoreId)}`;
  }

  const { rows } = await sbFetch(env, api);
  const results = (rows || []).map(r => {
    const eStart = new Date(`${r.start_date}T00:00:00Z`);
    const eEnd   = new Date(`${(r.end_date || r.start_date)}T00:00:00Z`);
    const oStart = new Date(Math.max(eStart.getTime(), dStart.getTime()));
    const oEnd   = new Date(Math.min(eEnd.getTime(),   dEnd.getTime()));
    const days   = Math.floor((oEnd - oStart) / 86400000) + 1;

    return {
      contract_id: String(r.id),
      client_id: r.client_id || null,
      client_name: r?.client?.name ?? null,
      role: r?.role ?? null,
      band: r?.band ?? null,
      existing_start_date: r.start_date,
      existing_end_date: r.end_date,
      overlap_start_date: days > 0 ? oStart.toISOString().slice(0,10) : null,
      overlap_end_date:   days > 0 ? oEnd.toISOString().slice(0,10)   : null,
      overlap_days:       days > 0 ? days : 0
    };
  }).filter(x => x.overlap_days > 0);

  return withCORS(env, req, ok({
    candidate_id: String(candidateId),
    requested_start_date: start,
    requested_end_date: end,
    ignore_contract_id: ignoreId || null,
    has_overlap: results.length > 0,
    overlaps: results
  }));
}

// ───────────────────────────────────────────────────────────────────────────────
// 2) TIMESHEETS — PAY STATE
// ───────────────────────────────────────────────────────────────────────────────
async function handleTimesheetPayHold(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  // NEW: guarded write (optimistic concurrency)
  const expectedTimesheetId = body?.expected_timesheet_id || null;
  const guard = await guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId);
  if (!guard.ok) return guard.res;

  const currentTimesheetId = guard.resolved.current_timesheet_id;

  const onHold = body?.on_hold === true;
  const reason = (body?.reason || '').trim() || null;

  // Update the current financial snapshot for the CURRENT timesheet
  const patch = onHold
    ? { pay_on_hold: true, pay_on_hold_reason: reason, pay_on_hold_since_utc: new Date().toISOString() }
    : { pay_on_hold: false, pay_on_hold_reason: null, pay_on_hold_since_utc: null };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?is_current=eq.true&timesheet_id=eq.${enc(currentTimesheetId)}`,
    { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(patch) }
  );
  if (!res.ok) {
    const t = await res.text();
    return withCORS(env, req, serverError(`Failed to update pay hold: ${t}`));
  }
  const json = await res.json().catch(() => []);
  const row = Array.isArray(json) ? json[0] : json;

  await writeAudit(env, user, onHold ? 'PAY_HOLD_SET' : 'PAY_HOLD_CLEARED', {
    reason,
  }, { entity: 'timesheet', subject_id: currentTimesheetId, reason: 'PAYMENT', correlation_id: null, req });

  return withCORS(env, req, ok({
    updated: true,
    on_hold: onHold,
    row,
    // NEW: return resolution metadata so FE can adopt the current id if needed
    booking_id: guard.resolved.booking_id || null,
    requested_timesheet_id: guard.resolved.requested_timesheet_id || timesheetId,
    current_timesheet_id: currentTimesheetId,
    current_version: guard.resolved.current_version ?? null,
    was_stale: !!guard.resolved.was_stale
  }));
}

async function handleTimesheetMarkPaid(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  // NEW: guarded write (optimistic concurrency)
  const expectedTimesheetId = body?.expected_timesheet_id || null;
  const guard = await guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId);
  if (!guard.ok) return guard.res;

  const currentTimesheetId = guard.resolved.current_timesheet_id;

  const paid = body?.paid === true;
  const paymentRef = (body?.payment_reference || '').trim() || `MANUAL:${new Date().toISOString().slice(0,10)}`;

  // Load current TSFIN row FOR CURRENT timesheet id (include charge + lock/segment state for closeout eligibility)
  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?is_current=eq.true&timesheet_id=eq.${enc(currentTimesheetId)}` +
    `&select=id,candidate_id,client_id,pay_method,total_pay_ex_vat,total_charge_ex_vat,locked_by_invoice_id,invoice_breakdown_json,` +
    `expenses_pay_ex_vat,mileage_pay_ex_vat,policy_snapshot_json,` +
    `pay_wtr_rate_pct_snapshot,pay_vat_rate_pct_snapshot,pay_vat_amount_snapshot,pay_total_inc_vat_snapshot`
  );
  const row = rows?.[0];
  if (!row) return withCORS(env, req, notFound('Timesheet financial snapshot not found'));

  // Closeout eligibility (zero client charge AND not already invoice-locked, incl. segment locks)
  const chargeEx = Number(row.total_charge_ex_vat || 0);
  const isZeroCharge = (round2(chargeEx) === 0);

  const hasSummaryInvoiceLock = !!(row.locked_by_invoice_id);

  const hasAnySegmentInvoiceLock = (() => {
    const ib = (row?.invoice_breakdown_json && typeof row.invoice_breakdown_json === 'object') ? row.invoice_breakdown_json : null;
    const mode = String(ib?.mode || '').toUpperCase();
    if (mode !== 'SEGMENTS') return false;
    const segs = Array.isArray(ib?.segments) ? ib.segments : [];
    for (const s of segs) {
      const v = (s && typeof s === 'object') ? s : null;
      const invId = (v?.invoice_locked_invoice_id != null) ? String(v.invoice_locked_invoice_id).trim() : '';
      if (invId) return true;
    }
    return false;
  })();

  const closeoutEligible = (paid && isZeroCharge && !hasSummaryInvoiceLock && !hasAnySegmentInvoiceLock);

  const patch = {};
  if (paid) {
    patch.paid_at_utc = new Date().toISOString();
    patch.paid_by_user_id = user.id || null;
    patch.payment_reference = paymentRef;

    // Fill snapshots if missing (WTR for PAYE, VAT for Umbrella)
    const defaults = await getDefaultSettings(env);
    if (String(row.pay_method || '').toUpperCase() === 'PAYE') {
      if (row.pay_wtr_rate_pct_snapshot == null) {
        const clientMap = await getClientHolidayPctMap(env, [row.client_id].filter(Boolean));
        patch.pay_wtr_rate_pct_snapshot = resolveWtrPctForRow(row, defaults, clientMap);
      }
    } else {
      // Umbrella VAT
      // Need umbrella VAT-chargeable. Fetch candidate -> umbrella
      const { rows: cRows } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(row.candidate_id)}&select=umbrella_id`);
      const umbId = cRows?.[0]?.umbrella_id || null;
      let vatChargeable = false;
      if (umbId) {
        const { rows: uRows } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/umbrellas?id=eq.${enc(umbId)}&select=vat_chargeable`);
        vatChargeable = !!uRows?.[0]?.vat_chargeable;
      }
      const payEx = Number(row.total_pay_ex_vat || 0);
      const expEx = Number(row.expenses_pay_ex_vat || 0);
      const milEx = Number(row.mileage_pay_ex_vat || 0);
      const rowEx = round2(payEx + expEx + milEx);

      if (vatChargeable) {
        const rate = (row.pay_vat_rate_pct_snapshot == null) ? defaults.vat : Number(row.pay_vat_rate_pct_snapshot);
        const derived = deriveUmbrellaVatSnapshots(rowEx, rate, true);
        patch.pay_vat_rate_pct_snapshot = derived.rate;
        patch.pay_vat_amount_snapshot = derived.vat;
        patch.pay_total_inc_vat_snapshot = derived.inc;
      } else {
        patch.pay_vat_rate_pct_snapshot = null;
        patch.pay_vat_amount_snapshot = 0;
        patch.pay_total_inc_vat_snapshot = rowEx;
      }
    }
  } else {
    patch.paid_at_utc = null;
    patch.paid_by_user_id = null;
    patch.payment_reference = null;
  }

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(row.id)}`,
    { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(patch) }
  );
  if (!res.ok) {
    const t = await res.text();
    return withCORS(env, req, serverError(`Failed to update paid state: ${t}`));
  }
  const json = await res.json().catch(() => []);
  const updated = Array.isArray(json) ? json[0] : json;

  // If paid AND zero-charge, create a terminal £0 closeout invoice (ISSUED + do_not_send) and lock timesheet to it
  // IMPORTANT: do not fail the paid update if closeout creation fails; return warning for operator visibility.
  let closeout = null;
  if (closeoutEligible) {
    try {
      const r = await sbRpc(env, 'invoice_closeout_zero_charge_timesheets', {
        p_timesheet_ids: [currentTimesheetId],
        p_actor_user_id: user.id || null
      });

      const rows = Array.isArray(r) ? r : (r ? [r] : []);
      const first = rows[0] || null;

      closeout = {
        attempted: true,
        ok: !!first?.ok,
        invoice_id: first?.invoice_id || null,
        warnings: first?.warnings ?? null
      };
    } catch (e) {
      closeout = {
        attempted: true,
        ok: false,
        invoice_id: null,
        error: (e && (e.message || String(e))) || 'CLOSEOUT_FAILED'
      };
    }
  }

  await writeAudit(env, user, paid ? 'MARK_PAID' : 'MARK_UNPAID', {
    payment_reference: paymentRef,
    closeout
  }, { entity: 'timesheet', subject_id: currentTimesheetId, reason: 'PAYMENT', correlation_id: null, req });

  // Optionally enqueue worker to re-evaluate eligibility on UNPAID
  if (!paid) {
    try {
      // NOTE: SQL signature is enqueue_ts_financials(_timesheet_id uuid, _reason ts_fin_reason_enum)
      await sbRpc(env, 'enqueue_ts_financials', { _timesheet_id: currentTimesheetId, _reason: 'CONTEXT_CHANGED' });
    } catch { /* noop */ }
  }

  return withCORS(env, req, ok({
    updated,
    closeout,
    // NEW: return resolution metadata so FE can adopt the current id if needed
    booking_id: guard.resolved.booking_id || null,
    requested_timesheet_id: guard.resolved.requested_timesheet_id || timesheetId,
    current_timesheet_id: currentTimesheetId,
    current_version: guard.resolved.current_version ?? null,
    was_stale: !!guard.resolved.was_stale
  }));
}



// ───────────────────────────────────────────────────────────────────────────────
// 3) REPORTS (screen/print/CSV) — minimal but complete implementations
// ───────────────────────────────────────────────────────────────────────────────

// ───────────────────────────────────────────────────────────────────────────────
// REPORTS — Timesheets (unchanged; already supports print/csv)
// ───────────────────────────────────────────────────────────────────────────────

async function handleReportTimesheets(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const qs = (k) => urlObj.searchParams.getAll(k);

  const format = (q('format') || 'json').toLowerCase(); // 'json' | 'csv' | 'print'
  const includeOnHold = (q('include_on_hold') === 'true');

  const from = q('week_ending_from');
  const to = q('week_ending_to');
  const payMethod = q('pay_method') ? q('pay_method').toUpperCase() : null;

  const clientIdsRaw = qs('client_id');
  const candidateIdsRaw = qs('candidate_id');

  const paid = q('paid'); // 'true' | 'false' | null
  const invoiced = q('invoiced'); // 'true' | 'false' | null

  const parseTriBool = (v) => {
    if (v === 'true') return true;
    if (v === 'false') return false;
    return null;
  };

  const paidBool = parseTriBool(paid);
  const invoicedBool = parseTriBool(invoiced);

  const uniq = (arr) => Array.from(new Set((arr || []).map(String).filter(Boolean)));
  const clientIds = uniq(clientIdsRaw);
  const candidateIds = uniq(candidateIdsRaw);

  // ✅ single RPC call (segment-aware invoiced logic lives in SQL)
  let rows = [];
  try {
    const r = await sbRpc(env, 'tsfin_report_timesheets_v2', {
      p_week_ending_from: from || null,
      p_week_ending_to: to || null,
      p_pay_method: payMethod || null,
      p_client_ids: clientIds.length ? clientIds : null,
      p_candidate_ids: candidateIds.length ? candidateIds : null,
      p_include_on_hold: !!includeOnHold,
      p_paid: (paidBool === null ? null : !!paidBool),
      p_invoiced: (invoicedBool === null ? null : !!invoicedBool)
    });
    rows = Array.isArray(r) ? r : (r ? [r] : []);
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }

  if (!rows?.length) return withCORS(env, req, ok({ rows: [], totals: {} }));

  // Totals (unchanged)
  const totals = rows.reduce((a, r) => {
    a.pay_ex_vat += Number(r.total_pay_ex_vat || 0);
    a.charge_ex_vat += Number(r.total_charge_ex_vat || 0);
    a.margin_ex_vat += Number(r.margin_ex_vat || 0);
    a.expenses_charge_ex_vat += Number(r.expenses_charge_ex_vat || 0);
    a.mileage_charge_ex_vat += Number(r.mileage_charge_ex_vat || 0);
    return a;
  }, { pay_ex_vat: 0, charge_ex_vat: 0, margin_ex_vat: 0, expenses_charge_ex_vat: 0, mileage_charge_ex_vat: 0 });
  Object.keys(totals).forEach(k => { totals[k] = round2(totals[k]); });

  const invoicedFlag = (r) => {
    if (r && r.invoiced_any === true) return true;
    return !!(r && r.locked_by_invoice_id);
  };

  if (format === 'csv') {
    const header = ['WeekEnding','Client','PayMethod','Paid','Invoiced','PayExVAT','ChargeExVAT','MarginExVAT','ExpensesChargeExVAT','MileageChargeExVAT'];
    const out = [csvJoin(header)];

    for (const r of rows) {
      out.push(csvJoin([
        r?.timesheet?.week_ending_date || '',
        r?.client?.name || '',
        (r.pay_method || '').toUpperCase(),
        r.paid_at_utc ? 'Y' : 'N',
        invoicedFlag(r) ? 'Y' : 'N',
        round2(r.total_pay_ex_vat).toFixed(2),
        round2(r.total_charge_ex_vat).toFixed(2),
        round2(r.margin_ex_vat).toFixed(2),
        round2(r.expenses_charge_ex_vat).toFixed(2),
        round2(r.mileage_charge_ex_vat).toFixed(2),
      ]));
    }

    return withCORS(env, req, ok({ csv: out.join('\n'), totals, count: rows.length }));
  }

  if (format === 'print') {
    const rowsHtml = rows.map(r => `
      <tr>
        <td>${r?.timesheet?.week_ending_date || ''}</td>
        <td>${r?.client?.name || ''}</td>
        <td>${(r.pay_method || '').toUpperCase()}</td>
        <td>${r.paid_at_utc ? 'Y' : 'N'}</td>
        <td>${invoicedFlag(r) ? 'Y' : 'N'}</td>
        <td style="text-align:right">${round2(r.total_pay_ex_vat).toFixed(2)}</td>
        <td style="text-align:right">${round2(r.total_charge_ex_vat).toFixed(2)}</td>
        <td style="text-align:right">${round2(r.margin_ex_vat).toFixed(2)}</td>
      </tr>`
    ).join('');

    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Timesheets Report</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead>
            <tr style="background:#f5f5f5">
              <th>Week Ending</th>
              <th>Client</th>
              <th>Pay Method</th>
              <th>Paid</th>
              <th>Invoiced</th>
              <th>Pay ex VAT</th>
              <th>Charge ex VAT</th>
              <th>Margin ex VAT</th>
            </tr>
          </thead>
          <tbody>${rowsHtml}</tbody>
        </table>
        <p><strong>Totals —</strong> Pay ex VAT: ${totals.pay_ex_vat.toFixed(2)}, Charge ex VAT: ${totals.charge_ex_vat.toFixed(2)}, Margin ex VAT: ${totals.margin_ex_vat.toFixed(2)}</p>
      </div>`;

    return withCORS(env, req, ok({ html, totals, count: rows.length }));
  }

  return withCORS(env, req, ok({ rows, totals, count: rows.length }));
}


// ───────────────────────────────────────────────────────────────────────────────
// REPORTS — Invoices (add print)
// ───────────────────────────────────────────────────────────────────────────────

 async function handleReportInvoices(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const qs = (k) => urlObj.searchParams.getAll(k);
  const format = (q('format') || 'json').toLowerCase();

  const from = q('issued_from');
  const to   = q('issued_to');
  const status = q('status'); // DRAFT | ISSUED | ON_HOLD | PAID
  const clientIds = qs('client_id');

  let url = `${env.SUPABASE_URL}/rest/v1/invoices?select=id,client_id,type,status,issued_at_utc,subtotal_ex_vat,vat_amount,total_inc_vat,invoice_no&order=issued_at_utc.desc`;
  if (from) url += `&issued_at_utc=gte.${enc(from)}`;
  if (to)   url += `&issued_at_utc=lte.${enc(to)}`;
  if (status) url += `&status=eq.${enc(status)}`;
  if (clientIds.length) url += `&client_id=in.(${clientIds.map(enc).join(',')})`;

  const { rows: invs } = await sbFetch(env, url);
  if (!invs?.length) return withCORS(env, req, ok({ rows: [], totals: {} }));

  // Get margin by summing invoice_lines.margin_ex_vat
  const invIds = invs.map(i => i.id);
  const { rows: lines } = await sbFetch(env,
    `${env.SUPABASE_URL}/rest/v1/invoice_lines?select=invoice_id,margin_ex_vat&invoice_id=in.(${invIds.map(enc).join(',')})`
  );
  const marginByInv = {};
  for (const ln of lines || []) {
    marginByInv[ln.invoice_id] = round2((marginByInv[ln.invoice_id] || 0) + Number(ln.margin_ex_vat || 0));
  }

  const rows = invs.map(i => ({
    ...i,
    margin_ex_vat: marginByInv[i.id] || 0
  }));

  const totals = rows.reduce((a, r) => {
    a.subtotal_ex_vat += Number(r.subtotal_ex_vat || 0);
    a.vat_amount += Number(r.vat_amount || 0);
    a.total_inc_vat += Number(r.total_inc_vat || 0);
    a.margin_ex_vat += Number(r.margin_ex_vat || 0);
    return a;
  }, { subtotal_ex_vat:0, vat_amount:0, total_inc_vat:0, margin_ex_vat:0 });
  Object.keys(totals).forEach(k => totals[k] = round2(totals[k]));

  if (format === 'csv') {
    const header = ['InvoiceNo','Status','IssuedAt','SubtotalExVAT','VAT','TotalIncVAT','MarginExVAT'];
    const out = [csvJoin(header)];
    for (const r of rows) {
      out.push(csvJoin([
        r.invoice_no || '',
        r.status || '',
        r.issued_at_utc || '',
        round2(r.subtotal_ex_vat).toFixed(2),
        round2(r.vat_amount).toFixed(2),
        round2(r.total_inc_vat).toFixed(2),
        round2(r.margin_ex_vat).toFixed(2)
      ]));
    }
    return withCORS(env, req, ok({ csv: out.join('\n'), totals, count: rows.length }));
  }

  if (format === 'print') {
    const rowsHtml = rows.map(r => `
      <tr>
        <td>${r.invoice_no || ''}</td>
        <td>${r.status || ''}</td>
        <td>${r.issued_at_utc || ''}</td>
        <td style="text-align:right">${round2(r.subtotal_ex_vat).toFixed(2)}</td>
        <td style="text-align:right">${round2(r.vat_amount).toFixed(2)}</td>
        <td style="text-align:right">${round2(r.total_inc_vat).toFixed(2)}</td>
        <td style="text-align:right">${round2(r.margin_ex_vat).toFixed(2)}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Invoices Report</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5">
            <th>Invoice No</th><th>Status</th><th>Issued At</th>
            <th>Subtotal ex VAT</th><th>VAT</th><th>Total inc VAT</th><th>Margin ex VAT</th>
          </tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
        <p><strong>Totals —</strong> Subtotal: ${totals.subtotal_ex_vat.toFixed(2)}, VAT: ${totals.vat_amount.toFixed(2)}, Total: ${totals.total_inc_vat.toFixed(2)}, Margin: ${totals.margin_ex_vat.toFixed(2)}</p>
      </div>`;
    return withCORS(env, req, ok({ html, totals, count: rows.length }));
  }

  return withCORS(env, req, ok({ rows, totals, count: rows.length }));
}


// ───────────────────────────────────────────────────────────────────────────────
// REPORTS — Candidates (add print)
// ───────────────────────────────────────────────────────────────────────────────

 async function handleReportCandidates(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const qs = (k) => urlObj.searchParams.getAll(k);
  const format = (q('format') || 'json').toLowerCase();

  const from = q('week_ending_from');
  const to   = q('week_ending_to');
  const candidateIds = qs('candidate_id');

  let url = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?select=candidate_id,total_charge_ex_vat,total_pay_ex_vat,margin_ex_vat,timesheet:timesheets(week_ending_date)` +
    `&is_current=eq.true`;
  if (from) url += `&timesheet.week_ending_date=gte.${enc(from)}`;
  if (to)   url += `&timesheet.week_ending_date=lte.${enc(to)}`;
  if (candidateIds.length) url += `&candidate_id=in.(${candidateIds.map(enc).join(',')})`;

  const { rows } = await sbFetch(env, url);
  const agg = {};
  for (const r of rows || []) {
    if (!r.candidate_id) continue;
    const a = (agg[r.candidate_id] ||= { candidate_id: r.candidate_id, charge_ex_vat:0, pay_ex_vat:0, margin_ex_vat:0 });
    a.charge_ex_vat += Number(r.total_charge_ex_vat || 0);
    a.pay_ex_vat += Number(r.total_pay_ex_vat || 0);
    a.margin_ex_vat += Number(r.margin_ex_vat || 0);
  }
  const outRows = Object.values(agg).map((a) => ({
    ...a,
    charge_ex_vat: round2(a.charge_ex_vat),
    pay_ex_vat: round2(a.pay_ex_vat),
    margin_ex_vat: round2(a.margin_ex_vat)
  }));

  if (format === 'csv') {
    const header = ['CandidateId','ChargeExVAT','PayExVAT','MarginExVAT'];
    const out = [csvJoin(header)];
    for (const r of outRows) out.push(csvJoin([r.candidate_id, r.charge_ex_vat.toFixed(2), r.pay_ex_vat.toFixed(2), r.margin_ex_vat.toFixed(2)]));
    return withCORS(env, req, ok({ csv: out.join('\n'), count: outRows.length }));
  }

  if (format === 'print') {
    const rowsHtml = outRows.map(r => `
      <tr>
        <td>${r.candidate_id}</td>
        <td style="text-align:right">${r.charge_ex_vat.toFixed(2)}</td>
        <td style="text-align:right">${r.pay_ex_vat.toFixed(2)}</td>
        <td style="text-align:right">${r.margin_ex_vat.toFixed(2)}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Candidates Report</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5"><th>Candidate</th><th>Charge ex VAT</th><th>Pay ex VAT</th><th>Margin ex VAT</th></tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;
    return withCORS(env, req, ok({ html, count: outRows.length }));
  }

  return withCORS(env, req, ok({ rows: outRows, count: outRows.length }));
}


// ───────────────────────────────────────────────────────────────────────────────
// REPORTS — Clients (add print)
// ───────────────────────────────────────────────────────────────────────────────

 async function handleReportClients(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const qs = (k) => urlObj.searchParams.getAll(k);
  const format = (q('format') || 'json').toLowerCase();

  const from = q('week_ending_from');
  const to   = q('week_ending_to');
  const clientIds = qs('client_id');

  let url = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?select=client_id,total_charge_ex_vat,total_pay_ex_vat,margin_ex_vat,timesheet:timesheets(week_ending_date)` +
    `&is_current=eq.true`;
  if (from) url += `&timesheet.week_ending_date=gte.${enc(from)}`;
  if (to)   url += `&timesheet.week_ending_date=lte.${enc(to)}`;
  if (clientIds.length) url += `&client_id=in.(${clientIds.map(enc).join(',')})`;

  const { rows } = await sbFetch(env, url);
  const agg = {};
  for (const r of rows || []) {
    if (!r.client_id) continue;
    const a = (agg[r.client_id] ||= { client_id: r.client_id, charge_ex_vat:0, pay_ex_vat:0, margin_ex_vat:0 });
    a.charge_ex_vat += Number(r.total_charge_ex_vat || 0);
    a.pay_ex_vat += Number(r.total_pay_ex_vat || 0);
    a.margin_ex_vat += Number(r.margin_ex_vat || 0);
  }
  const outRows = Object.values(agg).map((a) => ({
    ...a,
    charge_ex_vat: round2(a.charge_ex_vat),
    pay_ex_vat: round2(a.pay_ex_vat),
    margin_ex_vat: round2(a.margin_ex_vat)
  }));

  if (format === 'csv') {
    const header = ['ClientId','ChargeExVAT','PayExVAT','MarginExVAT'];
    const out = [csvJoin(header)];
    for (const r of outRows) out.push(csvJoin([r.client_id, r.charge_ex_vat.toFixed(2), r.pay_ex_vat.toFixed(2), r.margin_ex_vat.toFixed(2)]));
    return withCORS(env, req, ok({ csv: out.join('\n'), count: outRows.length }));
  }

  if (format === 'print') {
    const rowsHtml = outRows.map(r => `
      <tr>
        <td>${r.client_id}</td>
        <td style="text-align:right">${r.charge_ex_vat.toFixed(2)}</td>
        <td style="text-align:right">${r.pay_ex_vat.toFixed(2)}</td>
        <td style="text-align:right">${r.margin_ex_vat.toFixed(2)}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Clients Report</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5"><th>Client</th><th>Charge ex VAT</th><th>Pay ex VAT</th><th>Margin ex VAT</th></tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;
    return withCORS(env, req, ok({ html, count: outRows.length }));
  }

  return withCORS(env, req, ok({ rows: outRows, count: outRows.length }));
}


// ───────────────────────────────────────────────────────────────────────────────
// REPORTS — Umbrellas (add charge/margin + print)
// ───────────────────────────────────────────────────────────────────────────────

 async function handleReportUmbrellas(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const format = (q('format') || 'json').toLowerCase();

  // Pull candidate <- umbrella mapping (and names for display)
  const { rows: candUmb } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/candidates?select=id,umbrella_id&umbrella_id=not.is.null`);
  const mapCandUmb = Object.fromEntries((candUmb || []).map(c => [c.id, c.umbrella_id]));
  const umbIds = [...new Set((candUmb || []).map(c => c.umbrella_id))];
  if (!umbIds.length) return withCORS(env, req, ok({ rows: [], count: 0 }));

  const { rows: umbMeta } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/umbrellas?id=in.(${umbIds.map(enc).join(',')})&select=id,name`);
  const umbName = Object.fromEntries((umbMeta || []).map(u => [u.id, u.name || u.id]));

  // Get ts-fin grouped for those candidates (include pay, charge, margin)
  const { rows } = await sbFetch(env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?select=candidate_id,total_pay_ex_vat,total_charge_ex_vat,margin_ex_vat` +
    `&is_current=eq.true&candidate_id=in.(${Object.keys(mapCandUmb).map(enc).join(',')})`
  );

  const agg = {};
  for (const r of rows || []) {
    const umb = mapCandUmb[r.candidate_id];
    const a = (agg[umb] ||= { umbrella_id: umb, umbrella_name: umbName[umb] || umb, pay_ex_vat: 0, charge_ex_vat: 0, margin_ex_vat: 0 });
    a.pay_ex_vat += Number(r.total_pay_ex_vat || 0);
    a.charge_ex_vat += Number(r.total_charge_ex_vat || 0);
    a.margin_ex_vat += Number(r.margin_ex_vat || 0);
  }
  for (const k of Object.keys(agg)) {
    agg[k].pay_ex_vat = round2(agg[k].pay_ex_vat);
    agg[k].charge_ex_vat = round2(agg[k].charge_ex_vat);
    agg[k].margin_ex_vat = round2(agg[k].margin_ex_vat);
  }

  const outRows = Object.values(agg);

  if (format === 'csv') {
    const header = ['UmbrellaId','UmbrellaName','PayExVAT','ChargeExVAT','MarginExVAT'];
    const out = [csvJoin(header)];
    for (const r of outRows) out.push(csvJoin([r.umbrella_id, r.umbrella_name, r.pay_ex_vat.toFixed(2), r.charge_ex_vat.toFixed(2), r.margin_ex_vat.toFixed(2)]));
    return withCORS(env, req, ok({ csv: out.join('\n'), count: outRows.length }));
  }

  if (format === 'print') {
    const rowsHtml = outRows.map(r => `
      <tr>
        <td>${r.umbrella_name}</td>
        <td style="text-align:right">${r.pay_ex_vat.toFixed(2)}</td>
        <td style="text-align:right">${r.charge_ex_vat.toFixed(2)}</td>
        <td style="text-align:right">${r.margin_ex_vat.toFixed(2)}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Umbrellas Report</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5"><th>Umbrella</th><th>Pay ex VAT</th><th>Charge ex VAT</th><th>Margin ex VAT</th></tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;
    return withCORS(env, req, ok({ html, count: outRows.length }));
  }

  return withCORS(env, req, ok({ rows: outRows, count: outRows.length }));
}
// ───────────────────────────────────────────────────────────────────────────────
// 4) SEARCH (rich filters per section) — pragmatic implementations
// ───────────────────────────────────────────────────────────────────────────────

// ───────────────────────────────────────────────────────────────────────────────
// SEARCH — Timesheets (richer filters + csv/print)
// ───────────────────────────────────────────────────────────────────────────────
async function handleSearchTimesheets(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q  = (k) => urlObj.searchParams.get(k);
  const qa = (k) => urlObj.searchParams.getAll(k); // repeated params (e.g., status)

  const page     = Math.max(1, parseInt(q('page') || '1', 10));
  const pageSize = Math.max(1, Math.min(200, parseInt(q('page_size') || '50', 10)));

  const format = (q('format') || 'json').toLowerCase(); // 'json'|'csv'|'print'

  const includeOnHold = q('include_on_hold') === 'true';
  const paid      = q('paid');     // 'true' | 'false' | null
  const invoiced  = q('invoiced'); // 'true' | 'false' | null

  const weFrom      = q('week_ending_from');
  const weTo        = q('week_ending_to');
  const clientId    = q('client_id');
  const candidateId = q('candidate_id');
  const payMethod   = q('pay_method') ? q('pay_method').toUpperCase() : null;

  const sheetScope  = q('sheet_scope') ? q('sheet_scope').toUpperCase() : null;
  const qrStatus    = q('qr_status')   ? q('qr_status').toUpperCase()   : null;

  const bookingId   = q('booking_id');
  const occKey      = q('occupant_key_norm');
  const hospital    = q('hospital_norm');
  const workedFrom  = q('worked_from');
  const workedTo    = q('worked_to');
  const createdFrom = q('created_from');
  const createdTo   = q('created_to');
  const statuses    = qa('status');

  // explicit-ID selection support (timesheet_ids)
  const idInExpr = q('id');  // expect 'in.(uuid1,uuid2,...)'
  const idsRaw   = q('ids'); // optional 'uuid1,uuid2,...'

  let timesheetIds = [];
  if (idInExpr && /^in\.(\(.+\))$/.test(idInExpr)) {
    const inner = idInExpr.replace(/^in\.\(/, '').replace(/\)$/, '');
    timesheetIds = inner.split(',').map(s => s.trim()).filter(Boolean);
  } else if (idsRaw) {
    timesheetIds = idsRaw.split(',').map(s => s.trim()).filter(Boolean);
  }
  timesheetIds = Array.from(new Set(timesheetIds.map(String))).filter(Boolean);

  const orderBy = (q('order_by') || 'week_ending_date').toLowerCase();
  const orderDir = (q('order_dir') || 'desc').toLowerCase() === 'asc' ? 'asc' : 'desc';

  const parseTriBool = (v) => {
    if (v === 'true') return true;
    if (v === 'false') return false;
    return null;
  };

  const paidBool = parseTriBool(paid);
  const invoicedBool = parseTriBool(invoiced);

  const statusList = Array.isArray(statuses)
    ? statuses.map(s => String(s).toUpperCase().replace(/[(),]/g, '')).filter(Boolean)
    : [];

  const offset = (page - 1) * pageSize;

  // ✅ single RPC call (segment-aware invoiced logic lives in SQL)
  let rows = [];
  try {
    const r = await sbRpc(env, 'tsfin_search_timesheets_v2', {
      p_week_ending_from: weFrom || null,
      p_week_ending_to: weTo || null,
      p_client_id: clientId || null,
      p_candidate_id: candidateId || null,
      p_pay_method: payMethod || null,
      p_include_on_hold: !!includeOnHold,
      p_paid: (paidBool === null ? null : !!paidBool),
      p_invoiced: (invoicedBool === null ? null : !!invoicedBool),

      p_sheet_scope: sheetScope || null,
      p_qr_status: qrStatus || null,

      p_booking_id: bookingId || null,
      p_occupant_key_norm: occKey || null,
      p_hospital_norm: hospital || null,
      p_worked_from: workedFrom || null,
      p_worked_to: workedTo || null,
      p_created_from: createdFrom || null,
      p_created_to: createdTo || null,
      p_statuses: statusList.length ? statusList : null,
      p_timesheet_ids: timesheetIds.length ? timesheetIds : null,

      p_order_by: orderBy || 'week_ending_date',
      p_order_dir: orderDir || 'desc',
      p_limit: pageSize,
      p_offset: offset
    });
    rows = Array.isArray(r) ? r : (r ? [r] : []);
  } catch (err) {
    return withCORS(env, req, ok({
      error: String(err?.message || err),
      rows: [],
      page,
      page_size: pageSize,
      count: 0
    }));
  }

  const invoicedFlag = (r) => {
    if (r && r.invoiced_any === true) return true;
    return !!(r && r.locked_by_invoice_id);
  };

  // Local rounder reused in CSV/print
  const round2Local = (n) => Math.round((Number(n) || 0) * 100) / 100;

  if (format === 'csv') {
    const header = [
      'WeekEnding',
      'Client',
      'PayMethod',
      'OnHold',
      'Paid',
      'Invoiced',
      'PayExVAT',
      'ChargeExVAT',
      'MarginExVAT',
      'ProcessingStatus',
      'Basis'
    ];

    const out = [csvJoin(header)];

    for (const r of rows || []) {
      out.push(csvJoin([
        r?.timesheet?.week_ending_date || '',
        r?.client?.name || '',
        (r.pay_method || '').toUpperCase(),
        r.pay_on_hold ? 'Y' : 'N',
        r.paid_at_utc ? 'Y' : 'N',
        invoicedFlag(r) ? 'Y' : 'N',
        round2Local(r.total_pay_ex_vat || 0).toFixed(2),
        round2Local(r.total_charge_ex_vat || 0).toFixed(2),
        round2Local(r.margin_ex_vat || 0).toFixed(2),
        (r.processing_status || '').toUpperCase(),
        (r.basis || '').toUpperCase()
      ]));
    }

    return withCORS(env, req, ok({
      csv: out.join('\n'),
      count: rows?.length || 0,
      page,
      page_size: pageSize
    }));
  }

  if (format === 'print') {
    const rowsHtml = (rows || []).map(r => `
      <tr>
        <td>${r?.timesheet?.week_ending_date || ''}</td>
        <td>${r?.client?.name || ''}</td>
        <td>${(r.pay_method || '').toUpperCase()}</td>
        <td>${r.pay_on_hold ? 'Y' : 'N'}</td>
        <td>${r.paid_at_utc ? 'Y' : 'N'}</td>
        <td>${invoicedFlag(r) ? 'Y' : 'N'}</td>
        <td style="text-align:right">${round2Local(r.total_pay_ex_vat || 0).toFixed(2)}</td>
        <td style="text-align:right">${round2Local(r.total_charge_ex_vat || 0).toFixed(2)}</td>
        <td style="text-align:right">${round2Local(r.margin_ex_vat || 0).toFixed(2)}</td>
        <td>${(r.processing_status || '').toUpperCase()}</td>
        <td>${(r.basis || '').toUpperCase()}</td>
      </tr>`).join('');

    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Timesheets — Search Results</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead>
            <tr style="background:#f5f5f5">
              <th>Week Ending</th><th>Client</th><th>Pay Method</th>
              <th>On Hold</th><th>Paid</th><th>Invoiced</th>
              <th>Pay ex VAT</th><th>Charge ex VAT</th><th>Margin ex VAT</th>
              <th>Status</th><th>Basis</th>
            </tr>
          </thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;

    return withCORS(env, req, ok({
      html,
      count: rows?.length || 0,
      page,
      page_size: pageSize
    }));
  }

  return withCORS(env, req, ok({
    rows,
    page,
    page_size: pageSize,
    count: rows?.length || 0
  }));
}

// ─────────────────────────────────────────────────────────────
// Helpers: HTML entity decode + HTML <table> → string[][]
// ─────────────────────────────────────────────────────────────

function decodeHtmlEntities(str) {
  if (!str) return '';
  return String(str)
    .replace(/&nbsp;/gi, ' ')
    .replace(/&amp;/gi, '&')
    .replace(/&lt;/gi, '<')
    .replace(/&gt;/gi, '>')
    .replace(/&quot;/gi, '"')
    .replace(/&apos;/gi, "'")
    // numeric entities
    .replace(/&#(\d+);/g, (_, n) => String.fromCharCode(parseInt(n, 10)))
    .replace(/&#x([0-9a-f]+);/gi, (_, n) => String.fromCharCode(parseInt(n, 16)));
}

// Parse the NHSP HTML  (e.g.  (4).xls) into rows: string[][]
function parseNhspHtmlTableToRows(html) {
  if (!html) return [];

  // Try to narrow to the NHSP table (id="dynamicTable"), fallback to first <table>
  const tableMatch =
    html.match(/<table[^>]*id=["']dynamicTable["'][^>]*>[\s\S]*?<\/table>/i) ||
    html.match(/<table[^>]*>[\s\S]*?<\/table>/i);

  if (!tableMatch) return [];

  const tableHtml = tableMatch[0];

  const rowRe  = /<tr[^>]*>([\s\S]*?)<\/tr>/gi;
  const cellRe = /<t[hd][^>]*>([\s\S]*?)<\/t[hd]>/gi;

  const rows = [];
  let rowMatch;

  // Iterate over <tr>...</tr>
  // eslint-disable-next-line no-cond-assign
  while ((rowMatch = rowRe.exec(tableHtml)) !== null) {
    const rowHtml = rowMatch[1];
    const cells   = [];
    let cellMatch;

    // Iterate over <th>/<td> in the row
    // eslint-disable-next-line no-cond-assign
    while ((cellMatch = cellRe.exec(rowHtml)) !== null) {
      let cellInner = cellMatch[1];

      // Convert <br> to newline so wards like "...<br/>Liaison..." don't get smashed
      cellInner = cellInner.replace(/<br\s*\/?>/gi, '\n');

      // Strip any remaining tags inside the cell
      cellInner = cellInner.replace(/<[^>]+>/g, '');

      // Decode HTML entities and normalise whitespace
      let text = decodeHtmlEntities(cellInner);
      text     = text.replace(/\s+/g, ' ').trim();

      cells.push(text);
    }

    if (!cells.length) continue;

    // Skip the big title row "Timesheets Previously Released"
    if (cells.length === 1 &&
        /timesheets previously released/i.test(cells[0])) {
      continue;
    }

    rows.push(cells);
  }

  return rows;
}

// ─────────────────────────────────────────────────────────────
// Main NHSP parser: handles both HTML “fake xls” and real Excel
// ─────────────────────────────────────────────────────────────
async function parseNhspWorkbookIntoHrRows(env, { import_id, file_key, tz = 'Europe/London' }) {
  console.log('[NHSP_PARSE_VERSION]', 'v2025-12-12-col-aliases-assignment_code');
  console.log('[NHSP_PARSE] start', { import_id, file_key, tz });

  // ─────────────────────────────────────────────────────────────
  // 0) Load bytes from R2
  // ─────────────────────────────────────────────────────────────
  const u8 = await r2GetBytes(env, file_key);
  if (!u8 || !u8.length) {
    console.warn('[NHSP_PARSE] no file bytes', { import_id, file_key });
    return {
      status: 'PARSED',
      rows_total: 0,
      rows_parsed: 0,
      rows_skipped: 0,
      notes: 'No bytes returned from R2',
      header_columns: []
    };
  }

  const text  = new TextDecoder('utf-8').decode(u8);
  const sniff = text.slice(0, 2048).toLowerCase();

  const looksLikeHtml =
    sniff.replace(/^[\uFEFF\s]+/, '').startsWith('<table') ||
    sniff.includes('<table') ||
    sniff.includes('<html') ||
    sniff.startsWith('<!doctype html');

  let rows = [];
  let wb;

  // ─────────────────────────────────────────────────────────────
  // 1) Parse workbook → rows[] (HTML or real XLS)
  // ─────────────────────────────────────────────────────────────
  if (looksLikeHtml) {
    // For NHSP "fake XLS" s, always use our HTML table parser.
    // This avoids Excel serial dates like 45699 and keeps "02/11/2025"
    // as a string so excelDateToYmd can interpret dd/mm correctly.
    if (typeof parseNhspHtmlTableToRows === 'function') {
      rows = parseNhspHtmlTableToRows(text);
      console.log('[NHSP_PARSE] using HTML <table> parser', {
        import_id,
        file_key,
        length: Array.isArray(rows) ? rows.length : 0
      });
    } else {
      // Fallback: if helper is missing, fall back to SheetJS HTML parsing.
      try {
        console.log('[NHSP_PARSE] HTML-like .xls but parseNhspHtmlTableToRows not defined; falling back to SheetJS', {
          import_id,
          file_key
        });

        wb = XLSX.read(text, { type: 'string' });

        if (wb.SheetNames && wb.SheetNames.length) {
          const sheet = wb.Sheets[wb.SheetNames[0]];
          rows = XLSX.utils.sheet_to_json(sheet, {
            header: 1,
            raw:    true,
            defval: ''
          }) || [];
        } else {
          rows = [];
        }
      } catch (err) {
        console.warn('[NHSP_PARSE] SheetJS HTML read failed and no HTML helper available', {
          import_id,
          file_key,
          err: err?.message || String(err)
        });
        rows = [];
      }
    }
  } else {
    // Not HTML – treat as real Excel bytes (original behaviour)
    try {
      wb = XLSX.read(u8, { type: 'array' });

      if (wb.SheetNames && wb.SheetNames.length) {
        const sheet = wb.Sheets[wb.SheetNames[0]];
        rows = XLSX.utils.sheet_to_json(sheet, {
          header: 1,
          raw:    true,
          defval: ''
        }) || [];
      } else {
        rows = [];
      }
    } catch (err) {
      console.warn('[NHSP_PARSE] binary XLSX read failed', {
        import_id,
        file_key,
        err: err?.message || String(err)
      });
      rows = [];
    }
  }

  console.log('[NHSP_PARSE] raw_rows_length', {
    import_id,
    length: Array.isArray(rows) ? rows.length : 0
  });

  if (!rows || !rows.length) {
    console.warn('[NHSP_PARSE] no rows after HTML/XLSX parsing', { import_id, file_key });
    return {
      status: 'PARSED',
      rows_total: 0,
      rows_parsed: 0,
      rows_skipped: 0,
      notes: 'No rows found in NHSP file (after HTML/XLSX parsing)',
      header_columns: []
    };
  }

  // ─────────────────────────────────────────────────────────────
  // 2) Helpers for date/time & keys
  // ─────────────────────────────────────────────────────────────
  const pad2 = (n) => String(n).padStart(2, '0');

  function excelDateToYmd(v) {
    if (v === '' || v == null) return null;
    if (typeof v === 'number') {
      const d = XLSX.SSF.parse_date_code(v);
      if (!d || !d.y || !d.m || !d.d) return null;
      return `${d.y}-${pad2(d.m)}-${pad2(d.d)}`;
    }
    const s = String(v).trim();
    if (!s) return null;
    let m = s.match(/^(\d{4})[-/](\d{1,2})[-/](\d{1,2})$/);
    if (m) {
      const [_, Y, M, D] = m;
      return `${Y}-${pad2(Number(M))}-${pad2(Number(D))}`;
    }
    m = s.match(/^(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{2,4})$/);
    if (m) {
      let [_, d, mo, y] = m;
      if (y.length === 2) y = (Number(y) >= 70 ? '19' : '20') + y;
      return `${y}-${pad2(Number(mo))}-${pad2(Number(d))}`;
    }
    return null;
  }

  function excelTimeToHhmm(v) {
    if (v === '' || v == null) return null;
    if (typeof v === 'number') {
      const d = XLSX.SSF.parse_date_code(v);
      if (!d) return null;
      const H = (d.H != null ? d.H : d.h) || 0;
      const M = (d.M != null ? d.M : d.m) || 0;
      return `${pad2(H)}:${pad2(M)}`;
    }
    const s = String(v).trim();
    if (!s) return null;
    const m = s.match(/^(\d{1,2}):(\d{2})(?::\d{2})?$/);
    if (!m) return null;
    const HH = pad2(Number(m[1]));
    const MM = pad2(Number(m[2]));
    return `${HH}:${MM}`;
  }

  function localToUtcIso(ymd, hhmm, tzName, addDays = 0) {
    if (!ymd || !hhmm) return null;
    const [Y, M, D] = ymd.split('-').map(n => Number(n));
    let [h, m]      = hhmm.split(':').map(n => Number(n));
    if (!Number.isFinite(Y) || !Number.isFinite(M) || !Number.isFinite(D)) return null;

    let offsetHours = 0;
    if (tzName === 'Europe/London') {
      if (isBSTLocalDate(Y, M, D)) offsetHours = 1;
    }
    const base = new Date(Date.UTC(Y, M - 1, D));
    if (addDays) {
      base.setUTCDate(base.getUTCDate() + addDays);
    }
    const y2  = base.getUTCFullYear();
    const m2  = base.getUTCMonth();
    const d2  = base.getUTCDate();
    const utcMs = Date.UTC(y2, m2, d2, h - offsetHours, m, 0);
    return new Date(utcMs).toISOString();
  }

  function normalizeStr(s) {
    return String(s || '').trim();
  }

  function normalizeKeyParts(parts) {
    return parts
      .map(s => String(s || '').replace(/[|]/g, ' ').trim().toLowerCase())
      .join('|');
  }

  // Infer role_type_enum (RMN | HCA) from assignment / ward text
  function inferRoleTypeEnum(assignment, ward) {
    const s = `${assignment || ''} ${ward || ''}`.toLowerCase();
    if (
      s.includes('hca') ||
      s.includes('healthcare assistant') ||
      s.includes('support worker') ||
      s.includes('csw') ||
      s.includes('hcsw')
    ) {
      return 'HCA';
    }
    return 'RMN';
  }

  // ─────────────────────────────────────────────────────────────
  // 3) Header detection (first row with "date" & "ref")
  // ─────────────────────────────────────────────────────────────
  let headerIdx = 0;
  for (let i = 0; i < rows.length; i++) {
    const r = rows[i] || [];
    const lower = r.map(c => String(c || '').toLowerCase());
    if (lower.some(h => h.includes('date')) && lower.some(h => h.includes('ref'))) {
      headerIdx = i;
      break;
    }
  }

  // ✅ FIX: NHSP has a 2-row header (row1 has Contract/Actual groups, row2 has Start/End/Break/Total)
  const headerRow1 = Array.isArray(rows[headerIdx]) ? rows[headerIdx] : [];
  const headerRow2 = Array.isArray(rows[headerIdx + 1]) ? rows[headerIdx + 1] : [];

  const norm = (s) => String(s || '').trim().toLowerCase();

  const row2Norm = headerRow2.map(norm);
  const hasSubheaders =
    row2Norm.filter(x => x === 'start').length >= 2 &&
    row2Norm.filter(x => x === 'end').length   >= 2 &&
    row2Norm.filter(x => x === 'total').length >= 2 &&
    row2Norm.some(x => x.includes('break') && x.includes('minute'));

  // Use a consistent column count across the file for header/raw alignment
  // Prefer header widths, but also ensure we never truncate real row data.
  let nCols = Math.max(headerRow1.length, hasSubheaders ? headerRow2.length : 0);
  try {
    // Ensure nCols covers the widest row we saw (defensive, supports "extra columns sometimes")
    for (let i = 0; i < rows.length; i++) {
      const r = rows[i];
      if (Array.isArray(r) && r.length > nCols) nCols = r.length;
    }
  } catch {}

  // Build a single flattened header array aligned to raw_columns[].
  // - For normal columns: take row1 value.
  // - For Contract/Actual subcolumns: take row2 value (Start/End/Break/Total).
  // This ensures FE can map and format times/money correctly.
  const header_columns = [];
  for (let i = 0; i < nCols; i++) {
    const top = String(headerRow1[i] ?? '').trim();
    const sub = hasSubheaders ? String(headerRow2[i] ?? '').trim() : '';

    // If the top cell is a group label (Contract/Actual) and sub exists, use the sub label.
    // If top is blank and sub exists, use sub.
    const topNorm = norm(top);
    if (hasSubheaders && sub) {
      if (!top || topNorm === 'contract' || topNorm === 'actual') {
        header_columns.push(sub);
        continue;
      }
    }

    if (top) header_columns.push(top);
    else if (sub) header_columns.push(sub);
    else header_columns.push(''); // keep blanks (do not drop; preserves alignment)
  }

  console.log('[NHSP_PARSE] header_detected', {
    import_id,
    headerIdx,
    hasSubheaders,
    nCols,
    header_columns_preview: header_columns.slice(0, 30)
  });

  // IMPORTANT: Use a header row for matcher-based col detection that includes subheaders when present.
  // (This is what allows us to find Start/End/Break even though row1 has merged blanks.)
  const headerRowForFind = header_columns;

  // Load column aliases for NHSP assignment once per parse
  let assignmentAliases = [];
  try {
    if (typeof getImportColumnAliasesCached === 'function') {
      assignmentAliases = await getImportColumnAliasesCached(env, 'NHSP', 'ASSIGNMENT');
    }
  } catch (e) {
    console.warn('[NHSP_PARSE] getImportColumnAliasesCached failed; using fallback matcher', {
      import_id,
      err: e?.message || String(e)
    });
    assignmentAliases = [];
  }

  const findCol = (fallbackIdx, matcher) => {
    const idx = headerRowForFind.findIndex(cell => matcher(String(cell || '').toLowerCase()));
    return idx >= 0 ? idx : fallbackIdx;
  };

  // Find the Nth matching column (1-based). Used to prefer ACTUAL columns in 2-level NHSP headers.
  const findNthCol = (fallbackIdx, matcher, nth) => {
    const want = Math.max(1, Number(nth || 1));
    let seen = 0;
    for (let i = 0; i < headerRowForFind.length; i++) {
      const v = String(headerRowForFind[i] || '').toLowerCase();
      if (matcher(v)) {
        seen++;
        if (seen === want) return i;
      }
    }
    return fallbackIdx;
  };

  // Fallback local implementation in case helper isn't wired yet
  const findColByAliasesLocal = (hdrRow, aliases, fallbackIdx, fallbackMatcher) => {
    const normAliases = (aliases || [])
      .map(a => String(a || '').trim().toLowerCase())
      .filter(Boolean);

    if (normAliases.length) {
      const idx = (hdrRow || []).findIndex(cell => {
        const h = String(cell || '').trim().toLowerCase();
        if (!h) return false;
        return normAliases.some(a => h === a || h.includes(a));
      });
      if (idx >= 0) return idx;
    }

    // fallbackMatcher works on lowercased header string
    const idx2 = (hdrRow || []).findIndex(cell => fallbackMatcher(String(cell || '').toLowerCase()));
    return idx2 >= 0 ? idx2 : fallbackIdx;
  };

  const findColByAliasesFn =
    (typeof findColByAliases === 'function')
      ? findColByAliases
      : findColByAliasesLocal;

  const dateColIdx   = findCol(0,  h => h.includes('date'));
  const refColIdx    = findCol(1,  h => h.includes('ref'));
  const staffColIdx  = findCol(2,  h => h.includes('staff') || h.includes('worker') || h.includes('name'));
  const uniqueColIdx = findCol(
    3,
    h =>
      h.includes('unique') ||
      h.includes('staff no') ||
      (h.includes('agency') && h.includes('id'))
  );
  const trustColIdx  = findCol(4,  h => h.includes('hospital') || h.includes('trust') || h.includes('client'));
  const wardColIdx   = findCol(5,  h => h.includes('ward') || h.includes('unit') || h.includes('dept'));

  // ✅ assignment uses configured aliases first, then fallback to "assign"
  const assignmentColIdx = findColByAliasesFn(headerRowForFind, assignmentAliases, 6, h => h.includes('assign'));

  // ✅ FIX: For NHSP two-level header, prefer the SECOND occurrence of Start/End/Break/Total (the ACTUAL block),
  // with fallback to your historical indices (11,12,13) so existing files still parse correctly.
  const startColIdx =
    hasSubheaders
      ? findNthCol(11, h => h.includes('start'), 2)
      : findCol(11, h => h.includes('start'));

  const endColIdx =
    hasSubheaders
      ? findNthCol(12, h => (h.includes('end') || h.includes('finish')), 2)
      : findCol(12, h => (h.includes('end') || h.includes('finish')));

  const breakColIdx =
    hasSubheaders
      ? findNthCol(13, h => h.includes('break'), 2)
      : findCol(13, h => h.includes('break'));

  const hoursColIdx  = findCol(-1, h => h.includes('hours') && (h.includes('worked') || h.includes('actual')));

  let rows_total   = 0;
  let rows_parsed  = 0;
  let rows_skipped = 0;

  const hrRowsPayload = [];

  // ✅ If we detected the NHSP subheader row, data starts AFTER BOTH header rows
  const dataStartIdx = headerIdx + (hasSubheaders ? 2 : 1);

  // ─────────────────────────────────────────────────────────────
  // 4) Row loop → hr_rows payload (DB-compliant)
  // ─────────────────────────────────────────────────────────────
  for (let i = dataStartIdx; i < rows.length; i++) {
    const row = rows[i];
    if (!row || row.length === 0) continue;
    rows_total++;

    const rawDate    = row[dateColIdx];
    const rawRef     = row[refColIdx];
    const rawName    = row[staffColIdx];
    const rawUnique  = row[uniqueColIdx];
    const rawTrust   = row[trustColIdx];
    const rawWard    = row[wardColIdx];
    const rawAssign  = row[assignmentColIdx];
    const rawStart   = row[startColIdx];
    const rawEnd     = row[endColIdx];
    const rawBreak   = row[breakColIdx];
    const rawHours   = hoursColIdx >= 0 ? row[hoursColIdx] : null;

    const workDateYmd = excelDateToYmd(rawDate);
    const staffName   = normalizeStr(rawName);
    const uniqueId    = normalizeStr(rawUnique);
    const trust       = normalizeStr(rawTrust);
    const ward        = normalizeStr(rawWard);
    const assignment  = normalizeStr(rawAssign);
    const startHhmm   = excelTimeToHhmm(rawStart);
    const endHhmm     = excelTimeToHhmm(rawEnd);
    const breakMins   = Number(rawBreak || 0) || 0;

    if (!workDateYmd || !staffName || !startHhmm || !endHhmm) {
      rows_skipped++;
      continue;
    }

    const [sh, sm] = startHhmm.split(':').map(Number);
    const [eh, em] = endHhmm.split(':').map(Number);
    const startMins = sh * 60 + sm;
    const endMins   = eh * 60 + em;
    const addDaysForEnd = endMins <= startMins ? 1 : 0;

    const startUtcIso = localToUtcIso(workDateYmd, startHhmm, tz, 0);
    const endUtcIso   = localToUtcIso(workDateYmd, endHhmm, tz, addDaysForEnd);

    if (!startUtcIso || !endUtcIso) {
      rows_skipped++;
      continue;
    }

    let hoursWorked = null;
    if (typeof rawHours === 'number') {
      hoursWorked = rawHours;
    } else if (rawHours !== '' && rawHours != null) {
      const hs = String(rawHours).trim();
      if (hs) hoursWorked = hs;
    }

    const staffNorm = staffName.toLowerCase();
    const trustNorm = trust.toLowerCase();
    const keyParts  = [workDateYmd, staffNorm, trustNorm, ward.toLowerCase(), normalizeStr(rawRef), uniqueId];
    const external_row_key = normalizeKeyParts(keyParts);

    const refStr = normalizeStr(rawRef);

    // ✅ FIX: Preserve the full row as raw_columns aligned to header_columns length (nCols)
    const raw_columns = Array.from({ length: nCols }, (_, idx) => row[idx]);

    const payload_json = {
      type: 'NHSP_WEEKLY',
      staff_name: staffName,
      worker_name: staffName,
      work_date: workDateYmd,
      date_raw: rawDate,
      reference: refStr,
      ref_num: refStr,
      unique_id: uniqueId,

      // ✅ CHANGED: write both keys for stability
      assignment,
      assignment_code: assignment,

      trust,
      client: trust,
      ward,
      start_local: startHhmm,
      end_local: endHhmm,
      break_mins: breakMins,
      start_utc: startUtcIso,
      end_utc: endUtcIso,
      hours_worked: hoursWorked,
      raw_columns
    };

    // Decide role_type_enum value (RMN | HCA)
    const roleType = inferRoleTypeEnum(assignment, ward);

    // IMPORTANT: only use columns that actually exist on public.hr_rows
    hrRowsPayload.push({
      import_id,
      hr_request_id: refStr || null,
      date_local: workDateYmd,
      start_time_local: startHhmm,
      end_time_local: endHhmm,
      staff_norm: staffNorm || null,
      role_type: roleType,                 // role_type_enum, NOT NULL
      unit_raw: trust || null,            // text, nullable
      unit_hint: ward || null,            // text, nullable
      agency_raw: 'NHSP',                 // text, nullable – helpful for diagnostics
      external_row_key,
      payload_json,
      staff_raw: staffName || null,
      assignment_grade_norm: null,        // can be normalised later if needed
      hours_worked: typeof hoursWorked === 'number' ? hoursWorked : null
    });

    rows_parsed++;
  }

  // ─────────────────────────────────────────────────────────────
  // 5) Bulk insert into hr_rows
  // ─────────────────────────────────────────────────────────────
  const chunkSize = 500;
  for (let i = 0; i < hrRowsPayload.length; i += chunkSize) {
    const chunk = hrRowsPayload.slice(i, i + chunkSize);
    if (!chunk.length) continue;
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/hr_rows`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(chunk)
      }
    );
    if (!res.ok) {
      const err = await res.text().catch(() => '');
      console.error('[NHSP_PARSE] hr_rows insert failed', { import_id, err });
      throw new Error(`hr_rows insert failed for NHSP import ${import_id}: ${err}`);
    }
  }

  console.log('[NHSP_PARSE] done', { import_id, rows_total, rows_parsed, rows_skipped });

  return {
    rows_total,
    rows_parsed,
    rows_skipped,
    notes: null,
    header_columns
  };
}

async function parseHealthRosterWorkbookIntoHrRows(
  env,
  { import_id, file_key, client_id, tz = 'Europe/London' }
) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const enc = encodeURIComponent;

  if (LOG) {
    console.log('[HR_PARSE]', JSON.stringify({
      stage: 'start',
      import_id,
      file_key,
      client_id,
      tz
    }));
  }

  // ─────────────────────────────────────────────────────────────
  // Determine source_system for this import so we can branch weekly vs daily rota
  // ─────────────────────────────────────────────────────────────
  let importSourceSystem = 'HEALTHROSTER';
  try {
    const { rows: impRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_imports` +
        `?id=eq.${enc(import_id)}` +
        `&select=source_system` +
        `&limit=1`
    );
    if (impRows && impRows[0] && impRows[0].source_system) {
      importSourceSystem = String(impRows[0].source_system || '').toUpperCase();
    }
  } catch (e) {
    if (LOG) {
      console.warn('[HR_PARSE]', JSON.stringify({
        stage: 'load_import_failed',
        import_id,
        err: e?.message || String(e)
      }));
    }
  }

  // ─────────────────────────────────────────────────────────────
  // Load bytes from R2 and sniff for HTML vs real XLS
  // ─────────────────────────────────────────────────────────────
  const u8 = await r2GetBytes(env, file_key);
  if (!u8) {
    if (LOG) {
      console.error('[HR_PARSE]', JSON.stringify({
        stage: 'r2_not_found',
        import_id,
        file_key
      }));
    }
    throw new Error(`R2 object not found for key ${file_key}`);
  }

  const text  = new TextDecoder('utf-8').decode(u8);
  const sniff = text.slice(0, 2048).toLowerCase();

  const looksLikeHtml =
    sniff.replace(/^[\uFEFF\s]+/, '').startsWith('<table') ||
    sniff.includes('<table') ||
    sniff.includes('<html') ||
    sniff.startsWith('<!doctype html');

  let wb = null;
  let rows = [];

  // ─────────────────────────────────────────────────────────────
  // Workbook / HTML parsing with date-safe behaviour
  // ─────────────────────────────────────────────────────────────
  try {
    if (looksLikeHtml && typeof parseNhspHtmlTableToRows === 'function') {
      // For HTML-style HealthRoster s, reuse the NHSP HTML table parser
      // so we get raw strings (e.g. "02/11/2025") not Excel serials.
      rows = parseNhspHtmlTableToRows(text);
      if (LOG) {
        console.log('[HR_PARSE]', JSON.stringify({
          stage: 'html_table_parsed',
          import_id,
          file_key,
          length: Array.isArray(rows) ? rows.length : 0
        }));
      }
    } else {
      // Normal path: treat as real Excel bytes
      wb = XLSX.read(u8, { type: 'array' });

      if (!wb.SheetNames || !wb.SheetNames.length) {
        if (LOG) {
          console.error('[HR_PARSE]', JSON.stringify({
            stage: 'no_sheets',
            import_id,
            file_key
          }));
        }
        throw new Error('HealthRoster workbook has no sheets');
      }

      const sheet = wb.Sheets[wb.SheetNames[0]];
      rows = XLSX.utils.sheet_to_json(sheet, {
        header: 1,
        raw:    true,
        defval: ''
      });
    }
  } catch (e) {
    if (LOG) {
      console.warn('[HR_PARSE]', JSON.stringify({
        stage: 'wb_read_failed',
        import_id,
        file_key,
        err: e?.message || String(e)
      }));
    }
    // Last resort: try Excel array read if not already tried
    if (!rows || !rows.length) {
      wb = XLSX.read(u8, { type: 'array' });
      if (!wb.SheetNames || !wb.SheetNames.length) {
        throw new Error('HealthRoster workbook has no sheets');
      }
      const sheet = wb.Sheets[wb.SheetNames[0]];
      rows = XLSX.utils.sheet_to_json(sheet, {
        header: 1,
        raw:    true,
        defval: ''
      });
    }
  }

  if (!rows.length) {
    if (LOG) {
      console.warn('[HR_PARSE]', JSON.stringify({
        stage: 'empty_sheet',
        import_id,
        file_key
      }));
    }
    return {
      rows_total: 0,
      rows_parsed: 0,
      rows_skipped: 0,
      notes: 'Empty HealthRoster sheet',
      header_columns: []
    };
  }

  // ─────────────────────────────────────────────────────────────
  // Utilities
  // ─────────────────────────────────────────────────────────────
  const pad2 = (n) => String(n).padStart(2, '0');

  function excelDateToYmd(v) {
    if (v === '' || v == null) return null;
    if (typeof v === 'number') {
      const d = XLSX.SSF.parse_date_code(v);
      if (!d || !d.y || !d.m || !d.d) return null;
      return `${d.y}-${pad2(d.m)}-${pad2(d.d)}`;
    }
    const s = String(v).trim();
    if (!s) return null;
    let m = s.match(/^(\d{4})[-/](\d{1,2})[-/](\d{1,2})$/);
    if (m) {
      const [_, Y, M, D] = m;
      return `${Y}-${pad2(Number(M))}-${pad2(Number(D))}`;
    }
    m = s.match(/^(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{2,4})$/);
    if (m) {
      let [_, d, mo, y] = m;
      if (y.length === 2) y = (Number(y) >= 70 ? '19' : '20') + y;
      return `${y}-${pad2(Number(mo))}-${pad2(Number(d))}`;
    }
    return null;
  }

  function excelTimeToHhmm(v) {
    if (v === '' || v == null) return null;
    if (typeof v === 'number') {
      const d = XLSX.SSF.parse_date_code(v);
      if (!d) return null;
      const H = (d.H != null ? d.H : d.h) || 0;
      const M = (d.M != null ? d.M : d.m) || 0;
      return `${pad2(H)}:${pad2(M)}`;
    }
    const s = String(v).trim();
    if (!s) return null;
    const m = s.match(/^(\d{1,2}):(\d{2})(?::\d{2})?$/);
    if (!m) return null;
    const HH = pad2(Number(m[1]));
    const MM = pad2(Number(m[2]));
    return `${HH}:${MM}`;
  }

  function localToUtcIso(ymd, hhmm, tzName, addDays = 0) {
    if (!ymd || !hhmm) return null;
    const [Y, M, D] = ymd.split('-').map(n => Number(n));
    let [h, m]      = hhmm.split(':').map(n => Number(n));
    if (!Number.isFinite(Y) || !Number.isFinite(M) || !Number.isFinite(D)) return null;

    let offsetHours = 0;
    if (tzName === 'Europe/London') {
      if (isBSTLocalDate(Y, M, D)) offsetHours = 1;
    }
    const base = new Date(Date.UTC(Y, M - 1, D));
    if (addDays) {
      base.setUTCDate(base.getUTCDate() + addDays);
    }
    const y2  = base.getUTCFullYear();
    const m2  = base.getUTCMonth();
    const d2  = base.getUTCDate();
    const utcMs = Date.UTC(y2, m2, d2, h - offsetHours, m, 0);
    return new Date(utcMs).toISOString();
  }

  function normalizeStr(s) {
    return String(s || '').trim();
  }

  function normalizeKeyParts(parts) {
    return parts
      .map(s => String(s || '').replace(/[|]/g, ' ').trim().toLowerCase())
      .join('|');
  }

  function inferRoleTypeFromText(textA, textB) {
    const s = `${textA || ''} ${textB || ''}`.toLowerCase();
    if (
      s.includes('hca') ||
      s.includes('healthcare assistant') ||
      s.includes('support worker') ||
      s.includes('csw') ||
      s.includes('hcsw')
    ) {
      return 'HCA';
    }
    return 'RMN';
  }

  // header detection
  let headerRow = rows[0] || [];
  let headerIdx = 0;
  const firstHasText = headerRow.some(c => String(c || '').match(/[A-Za-z]/));
  if (!firstHasText && rows.length > 1) {
    headerRow = rows[1];
    headerIdx = 1;
  }
  const header_columns = headerRow.map(c => String(c ?? ''));

  if (LOG) {
    console.log('[HR_PARSE]', JSON.stringify({
      stage: 'header_detected',
      import_id,
      source_system: importSourceSystem,
      header_columns
    }));
  }

  const findCol = (fallbackIdx, matcher) => {
    const idx = headerRow.findIndex(cell => matcher(String(cell || '').toLowerCase()));
    return idx >= 0 ? idx : fallbackIdx;
  };

  // Fallback local implementation in case helper isn't wired yet
  const findColByAliasesLocal = (hdrRow, aliases, fallbackIdx, fallbackMatcher) => {
    const normAliases = (aliases || [])
      .map(a => String(a || '').trim().toLowerCase())
      .filter(Boolean);

    if (normAliases.length) {
      const idx = (hdrRow || []).findIndex(cell => {
        const h = String(cell || '').trim().toLowerCase();
        if (!h) return false;
        return normAliases.some(a => h === a || h.includes(a));
      });
      if (idx >= 0) return idx;
    }

    const idx2 = (hdrRow || []).findIndex(cell => fallbackMatcher(String(cell || '').toLowerCase()));
    return idx2 >= 0 ? idx2 : fallbackIdx;
  };

  const findColByAliasesFn =
    (typeof findColByAliases === 'function')
      ? findColByAliases
      : findColByAliasesLocal;

  // ─────────────────────────────────────────────────────────────
  // Load grade column aliases (once) depending on branch
  // ─────────────────────────────────────────────────────────────
  let gradeAliases = [];
  try {
    if (typeof getImportColumnAliasesCached === 'function') {
      const sys = (importSourceSystem === 'HEALTHROSTER_DAILY') ? 'HR_DAILY' : 'HR_WEEKLY';
      gradeAliases = await getImportColumnAliasesCached(env, sys, 'GRADE');
    }
  } catch (e) {
    if (LOG) {
      console.warn('[HR_PARSE]', JSON.stringify({
        stage: 'grade_alias_load_failed',
        import_id,
        source_system: importSourceSystem,
        err: e?.message || String(e)
      }));
    }
    gradeAliases = [];
  }

  let rows_total   = 0;
  let rows_parsed  = 0;
  let rows_skipped = 0;

  const hrRowsPayload = [];

  // ─────────────────────────────────────────────────────────────
  // DAILY ROTA
  // ─────────────────────────────────────────────────────────────
  if (importSourceSystem === 'HEALTHROSTER_DAILY') {
    const reqIdIdx       = findCol(-1, h => h.includes('request') && h.includes('id'));
    const dateIdx        = findCol(-1, h => h.includes('date'));
    const staffIdx       = findCol(-1, h => h.includes('staff') || h.includes('worker') || h.includes('name'));
    const unitIdx        = findCol(-1, h => h.includes('unit') || h.includes('ward') || h.includes('location'));

    // ✅ CHANGED: grade column uses alias list first, then fallback to includes('grade')
    const gradeIdx       = findColByAliasesFn(headerRow, gradeAliases, -1, h => h.includes('grade'));

    const startIdx       = findCol(-1, h => h.includes('start') || h.includes('from'));
    const endIdx         = findCol(-1, h => h.includes('end') || h.includes('finish') || h.includes('to'));
    const actualHoursIdx = findCol(-1, h => h.includes('actual') && h.includes('hour'));
    const bookedHoursIdx = findCol(-1, h => h.includes('booked') && h.includes('hour'));
    const rateIdx        = findCol(-1, h => h === 'rate' || h.includes('rate'));

    if (LOG) {
      console.log('[HR_PARSE_DAILY_COLUMNS]', JSON.stringify({
        import_id,
        reqIdIdx,
        dateIdx,
        staffIdx,
        unitIdx,
        gradeIdx,
        startIdx,
        endIdx,
        actualHoursIdx,
        bookedHoursIdx,
        rateIdx
      }));
    }

    for (let i = headerIdx + 1; i < rows.length; i++) {
      const row = rows[i];
      if (!row || row.length === 0) continue;
      rows_total++;

      const rawReqId  = reqIdIdx       >= 0 ? row[reqIdIdx]       : null;
      const rawDate   = dateIdx        >= 0 ? row[dateIdx]        : null;
      const rawStaff  = staffIdx       >= 0 ? row[staffIdx]       : null;
      const rawUnit   = unitIdx        >= 0 ? row[unitIdx]        : null;

      // ✅ Uses gradeIdx computed via aliases
      const rawGrade  = gradeIdx       >= 0 ? row[gradeIdx]       : null;

      const rawStart  = startIdx       >= 0 ? row[startIdx]       : null;
      const rawEnd    = endIdx         >= 0 ? row[endIdx]         : null;
      const rawActual = actualHoursIdx >= 0 ? row[actualHoursIdx] : null;
      const rawBooked = bookedHoursIdx >= 0 ? row[bookedHoursIdx] : null;
      const rawRate   = rateIdx        >= 0 ? row[rateIdx]        : null;

      const requestId   = normalizeStr(rawReqId);
      const staffRaw    = normalizeStr(rawStaff);
      const dateYmd     = excelDateToYmd(rawDate);
      const unitRaw     = normalizeStr(rawUnit);
      const gradeRaw    = normalizeStr(rawGrade);
      const gradeNorm   = gradeRaw ? gradeRaw.toLowerCase() : null;
      const startHhmm   = excelTimeToHhmm(rawStart);
      const endHhmm     = excelTimeToHhmm(rawEnd);

      if (!staffRaw || !dateYmd || !startHhmm || !endHhmm) {
        rows_skipped++;
        continue;
      }

      let hoursWorked = null;
      if (typeof rawActual === 'number') {
        hoursWorked = rawActual;
      } else if (rawActual !== '' && rawActual != null) {
        const s = String(rawActual).trim();
        const n = Number(s);
        if (Number.isFinite(n)) hoursWorked = n;
        else hoursWorked = s;
      }

      const staffNorm = staffRaw.toLowerCase();
      const unitNorm  = unitRaw.toLowerCase();

      const keyParts = [
        dateYmd,
        staffNorm,
        unitNorm,
        String(client_id || ''),
        requestId
      ];
      const external_row_key = normalizeKeyParts(keyParts);

      const fullRow = {};
      headerRow.forEach((col, idx) => {
        fullRow[String(col || `col_${idx}`)] = row[idx];
      });
      fullRow.date_local        = dateYmd;
      fullRow.start_time_local  = startHhmm;
      fullRow.end_time_local    = endHhmm;
      fullRow.request_id        = requestId;
      fullRow.staff_name        = staffRaw;
      fullRow.unit              = unitRaw;
      fullRow.grade_raw         = gradeRaw;      // existing behaviour retained
      fullRow.actual_hours      = hoursWorked;
      fullRow.booked_hours      = rawBooked;
      fullRow.rate              = rawRate;

      const roleType = inferRoleTypeFromText(gradeRaw, staffRaw);

      hrRowsPayload.push({
        import_id,
        hr_request_id: requestId || null,
        date_local: dateYmd,
        start_time_local: startHhmm,
        end_time_local: endHhmm,
        staff_norm: staffNorm || '',
        role_type: roleType,
        unit_raw: unitRaw || null,
        unit_hint: null,
        agency_raw: 'HEALTHROSTER_DAILY',
        external_row_key,
        payload_json: fullRow,
        staff_raw: staffRaw || null,
        assignment_grade_norm: gradeNorm, // existing behaviour retained
        hours_worked: typeof hoursWorked === 'number' ? hoursWorked : null
      });

      rows_parsed++;
    }

  } else {
    // ─────────────────────────────────────────────────────────────
    // WEEKLY HEALTHROSTER (autoprocess)
    // ─────────────────────────────────────────────────────────────

    const requestColIdx   = findCol(0,  h => h.includes('request'));
    const staffColIdx     = findCol(1,  h => h.includes('staff') || h.includes('name'));
    const dateColIdx      = findCol(4,  h => h.includes('date'));
    const wardColIdx      = findCol(5,  h => h.includes('unit') || h.includes('ward') || h.includes('location'));

    // ✅ NEW: grade column index for weekly (aliases first, fallback to includes('grade'))
    const gradeColIdx     = findColByAliasesFn(headerRow, gradeAliases, -1, h => h.includes('grade'));

    const startColIdx     = findCol(10, h => h.includes('start'));
    const endColIdx       = findCol(11, h => h.includes('end') || h.includes('finish'));
    const breakColIdx     = findCol(12, h => h.includes('break'));
    const hoursColIdx     = findCol(13, h => h.includes('hours') && h.includes('actual'));
    const finalisedColIdx = findCol(15, h => h.includes('finalis') || h.includes('finaliz'));

    if (LOG) {
      console.log('[HR_PARSE_WEEKLY_COLUMNS]', JSON.stringify({
        import_id,
        requestColIdx,
        staffColIdx,
        dateColIdx,
        wardColIdx,
        gradeColIdx,
        startColIdx,
        endColIdx,
        breakColIdx,
        hoursColIdx,
        finalisedColIdx
      }));
    }

    for (let i = headerIdx + 1; i < rows.length; i++) {
      const row = rows[i];
      if (!row || row.length === 0) continue;
      rows_total++;

      const rawRequest   = row[requestColIdx];
      const rawName      = row[staffColIdx];
      const rawDate      = row[dateColIdx];
      const rawWard      = row[wardColIdx];

      // ✅ NEW: raw grade for weekly
      const rawGrade     = gradeColIdx >= 0 ? row[gradeColIdx] : null;

      const rawStart     = row[startColIdx];
      const rawEnd       = row[endColIdx];
      const rawBreak     = row[breakColIdx];
      const rawHours     = hoursColIdx >= 0 ? row[hoursColIdx] : null;
      const rawFinalised = finalisedColIdx >= 0 ? row[finalisedColIdx] : null;

      const requestId   = normalizeStr(rawRequest);
      const staffName   = normalizeStr(rawName);
      const workDateYmd = excelDateToYmd(rawDate);
      const ward        = normalizeStr(rawWard);

      // ✅ NEW: grade raw/norm for weekly
      const gradeRaw    = normalizeStr(rawGrade);
      const gradeNorm   = gradeRaw ? gradeRaw.toLowerCase() : null;

      const startHhmm   = excelTimeToHhmm(rawStart);
      const endHhmm     = excelTimeToHhmm(rawEnd);
      const breakMins   = Number(rawBreak || 0) || 0;
      const finalised   = normalizeStr(rawFinalised);

      if (!staffName || !workDateYmd || !startHhmm || !endHhmm) {
        rows_skipped++;
        continue;
      }

      const [sh, sm] = startHhmm.split(':').map(Number);
      const [eh, em] = endHhmm.split(':').map(Number);
      const startMins = sh * 60 + sm;
      const endMins   = eh * 60 + em;
      const addDaysForEnd = endMins <= startMins ? 1 : 0;

      const startUtcIso = localToUtcIso(workDateYmd, startHhmm, tz, 0);
      const endUtcIso   = localToUtcIso(workDateYmd, endHhmm, tz, addDaysForEnd);

      if (!startUtcIso || !endUtcIso) {
        rows_skipped++;
        continue;
      }

      let hoursWorked = null;
      if (typeof rawHours === 'number') {
        hoursWorked = rawHours;
      } else if (rawHours !== '' && rawHours != null) {
        const hs = String(rawHours).trim();
        if (hs) hoursWorked = hs;
      }

      const staffNorm = staffName.toLowerCase();
      const wardNorm  = ward.toLowerCase();
      const keyParts  = [workDateYmd, staffNorm, wardNorm, String(client_id || ''), requestId];
      const external_row_key = normalizeKeyParts(keyParts);

      const raw_columns = headerRow.map((_, idx) => row[idx]);

      const payload_json = {
        type: 'HEALTHROSTER_WEEKLY',
        staff_name: staffName,
        work_date: workDateYmd,
        ward,
        client_id,
        request_id: requestId,

        // ✅ NEW: store grade_raw in payload_json
        grade_raw: gradeRaw,

        start_local: startHhmm,
        end_local: endHhmm,
        break_mins: breakMins,
        start_utc: startUtcIso,
        end_utc: endUtcIso,
        hours_worked: hoursWorked,
        finalized_date: finalised,
        raw_columns
      };

      const roleType = inferRoleTypeFromText(ward, staffName);

      hrRowsPayload.push({
        import_id,
        hr_request_id: requestId || null,
        date_local: workDateYmd,
        start_time_local: startHhmm,
        end_time_local: endHhmm,
        staff_norm: staffNorm || '',
        role_type: roleType,
        unit_raw: ward || null,
        unit_hint: null,
        agency_raw: 'HEALTHROSTER',
        external_row_key,
        payload_json,
        staff_raw: staffName || null,

        // ✅ CHANGED: not null anymore when grade is present
        assignment_grade_norm: gradeNorm,

        hours_worked: typeof hoursWorked === 'number' ? hoursWorked : null
      });

      rows_parsed++;
    }
  }

  // Insert hr_rows in chunks
  const chunkSize = 500;
  for (let i = 0; i < hrRowsPayload.length; i += chunkSize) {
    const chunk = hrRowsPayload.slice(i, i + chunkSize);
    if (!chunk.length) continue;
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/hr_rows`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(chunk)
      }
    );
    if (!res.ok) {
      const err = await res.text().catch(() => '');
      if (LOG) {
        console.error('[HR_PARSE]', JSON.stringify({
          stage: 'hr_rows_insert_failed',
          import_id,
          error: err
        }));
      }
      throw new Error(`hr_rows insert failed for HealthRoster import ${import_id}: ${err}`);
    }
  }

  if (LOG) {
    console.log('[HR_PARSE]', JSON.stringify({
      stage: 'completed',
      import_id,
      source_system: importSourceSystem,
      rows_total,
      rows_parsed,
      rows_skipped
    }));
  }

  return {
    rows_total,
    rows_parsed,
    rows_skipped,
    notes: null,
    header_columns
  };
}
async function buildNhspWeeklySnapshot(
  env,
  ts,
  contract,
  shifts,
  nhspImportId,
  basis = 'NHSP',
  getPolicyCached,
  curFin,
  options = {}
) {
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);

  const {
    outbox_id = null,
    write_now = false,
    // optional HR enrich inputs (so snapshot contains hr_crosscheck_* before write)
    hr_eff_flags = null,
    hr_preloaded_shifts = null,

    // ✅ NEW: allow caller to pass SQL policy (ctx.out_policy) to avoid REST
    policy_override = null
  } = (options && typeof options === 'object') ? options : {};

  const hasPolicyOverride = !!(policy_override && typeof policy_override === 'object');

  if (!shifts || !shifts.length) return { ok: false, reason: 'NO_SHIFTS' };

  const pc  = payChargeFromContract(contract);
  const pay = pc?.pay || null;
  const chg = pc?.charge || null;
  const method = pc?.method || contract?.pay_method_snapshot || contract?.pay_method || null;

  if (!pay || !chg) return { ok: false, reason: 'CONTRACT_RATES_MISSING' };

  const candidate_id = contract.candidate_id || null;
  const client_id    = contract.client_id   || null;

  // ---- Policy helper ----
  // If policy_override is provided, we do not need getPolicyCached at all.
  if (!hasPolicyOverride && typeof getPolicyCached !== 'function') {
    throw new Error('buildNhspWeeklySnapshot: getPolicyCached must be provided (or pass options.policy_override)');
  }

  // ─────────────────────────────────────────────────────────────
  // ✅ Stable segment identity helpers (NHSP weekly)
  //
  // Fixes delayed segment corruption by:
  // - generating deterministic segment_id from immutable shift attributes (not sh.id)
  // - preserving per-segment controls by mapping old→new using the same fingerprint
  //
  // NOTE: We intentionally do NOT include ref_num in identity (it may be amended later).
  // ─────────────────────────────────────────────────────────────
  const _normStr = (v) => (v == null ? '' : String(v).trim());
  const _normNumInt = (v, d = 0) => {
    const n = Number(v);
    return Number.isFinite(n) ? n : d;
  };

  // FNV-1a 32-bit hash (deterministic, fast, no async crypto)
  const _hash32 = (s) => {
    let h = 0x811c9dc5;
    for (let i = 0; i < s.length; i++) {
      h ^= s.charCodeAt(i);
      h = Math.imul(h, 0x01000193);
    }
    return (h >>> 0).toString(16).padStart(8, '0');
  };

  const _stableKeyFromParts = (dateYmd, startUtc, endUtc, breakMins, requestId) => {
    const d = _normStr(dateYmd);
    const s = _normStr(startUtc);
    const e = _normStr(endUtc);
    const b = _normNumInt(breakMins ?? 0, 0);
    const r = _normStr(requestId); // optional but stable if present; safe to include
    // If we have no useful timestamps, return empty => will fall back to legacy segment_id matching only.
    if (!d && !s && !e) return '';
    return `d:${d}|s:${s}|e:${e}|b:${b}|r:${r}`;
  };

  const _stableKeyFromShift = (sh) => {
    if (!sh || typeof sh !== 'object') return '';
    const workDate = _normStr(sh.work_date);
    const startUtc = _normStr(sh.start_utc);
    const endUtc   = _normStr(sh.end_utc);
    const breakM   = _normNumInt(sh.break_mins ?? sh.break_minutes ?? 0, 0);
    const reqId    = _normStr(sh.hr_request_id || sh.request_id || '');
    return _stableKeyFromParts(workDate, startUtc, endUtc, breakM, reqId);
  };

  const _stableKeyFromExistingSegment = (s) => {
    if (!s || typeof s !== 'object') return '';
    const dateYmd = _normStr(s.date);
    const startUtc = _normStr(s.start_utc || s.start_iso || '');
    const endUtc   = _normStr(s.end_utc || s.end_iso || '');
    const breakM   = _normNumInt(s.break_mins ?? s.break_minutes ?? 0, 0);
    const reqId    = _normStr(s.request_id || '');
    return _stableKeyFromParts(dateYmd, startUtc, endUtc, breakM, reqId);
  };

  const _stableSegId = (tsId, stableKey) => {
    const k = _normStr(stableKey);
    if (!k) return `nhsp:${tsId}:unknown`;
    return `nhsp:${tsId}:${_hash32(k)}`;
  };

  // ✅ Policy snapshot: prefer override; else old behaviour (fetch by week-ending/first date)
  // (Computed here so it is available for ERNI margin without any TDZ/ordering issues.)
  let policy_snapshot_json = {};
  if (hasPolicyOverride) {
    policy_snapshot_json = policy_override;
  } else {
    try {
      const we = (ts && ts.week_ending_date)
        ? String(ts.week_ending_date)
        : (shifts?.[0]?.work_date ? String(shifts[0].work_date) : null);
      policy_snapshot_json = (we && client_id) ? (await getPolicyCached(client_id, we)) : {};
      if (!policy_snapshot_json || typeof policy_snapshot_json !== 'object') policy_snapshot_json = {};
    } catch {
      policy_snapshot_json = {};
    }
  }

  // ---- Preserved fields: derive from current TSFIN evidence passed in (no DB fetch) ----
  // ✅ Preserve by stable fingerprint (preferred) and by legacy segment_id (compat).
  // ✅ NEW: also preserve by nhsp_shift_id / external_row_key when present in existing segments.
  const preservedByKey = new Map();
  const preservedByLegacyId = new Map();
  const preservedByNhspShiftId = new Map();
  const preservedByExternalRowKey = new Map();

  try {
    const ib = curFin?.invoice_breakdown_json || null;
    const mode = String(ib?.mode || '').toUpperCase();
    const segs = Array.isArray(ib?.segments) ? ib.segments : null;
    if (mode === 'SEGMENTS' && segs) {
      for (const s of segs) {
        const segment_id = s?.segment_id ? String(s.segment_id) : null;

        const meta = {
          exclude_from_pay:
            (typeof s.exclude_from_pay === 'boolean') ? s.exclude_from_pay : undefined,
          invoice_target_week_start:
            (s.invoice_target_week_start != null) ? String(s.invoice_target_week_start) : undefined,
          invoice_locked_invoice_id:
            (s.invoice_locked_invoice_id != null) ? String(s.invoice_locked_invoice_id) : undefined
        };

        // preserve by legacy id if present
        if (segment_id) preservedByLegacyId.set(segment_id, meta);

        // preserve by stable key if we can compute one from the stored segment fields
        const key = _stableKeyFromExistingSegment(s);
        if (key) preservedByKey.set(key, meta);

        // ✅ NEW: preserve by source identity if present
        const nhspShiftId = (s && s.nhsp_shift_id != null) ? String(s.nhsp_shift_id).trim() : '';
        const extKey = (s && s.external_row_key != null) ? String(s.external_row_key).trim() : '';
        if (nhspShiftId) preservedByNhspShiftId.set(nhspShiftId, meta);
        if (extKey) preservedByExternalRowKey.set(extKey, meta);
      }
    }
  } catch {}

  const segments = [];
  let totalPayEx = 0, totalChgEx = 0;
  let sumDay = 0, sumNight = 0, sumSat = 0, sumSun = 0, sumBh = 0;

  // Cache policies by date (only used when no policy_override)
  const policyByDate = new Map();

  for (const sh of shifts) {
    const workDate = sh.work_date;
    if (!workDate || !sh.start_utc || !sh.end_utc) continue;

    // ✅ Choose policy: SQL policy_override (single-week policy) OR per-date getPolicyCached
    let policy = null;

    if (hasPolicyOverride) {
      policy = policy_override;
    } else {
      policy = policyByDate.get(workDate);
      if (!policy) {
        policy = await getPolicyCached(client_id, workDate);
        policyByDate.set(workDate, policy);
      }
    }

    let segs = [[sh.start_utc, sh.end_utc]];
    segs = subtractBreak(segs, null, null, sh.break_mins || 0);

    const hours = classifyMinutes(env, policy, segs);

    sumDay   += (hours.hours_day   || 0);
    sumNight += (hours.hours_night || 0);
    sumSat   += (hours.hours_sat   || 0);
    sumSun   += (hours.hours_sun   || 0);
    sumBh    += (hours.hours_bh    || 0);

    const payEx = round2(
      (hours.hours_day   || 0) * asNumberLocal(pay.day)   +
      (hours.hours_night || 0) * asNumberLocal(pay.night) +
      (hours.hours_sat   || 0) * asNumberLocal(pay.sat)   +
      (hours.hours_sun   || 0) * asNumberLocal(pay.sun)   +
      (hours.hours_bh    || 0) * asNumberLocal(pay.bh)
    );

    const chgEx = round2(
      (hours.hours_day   || 0) * asNumberLocal(chg.day)   +
      (hours.hours_night || 0) * asNumberLocal(chg.night) +
      (hours.hours_sat   || 0) * asNumberLocal(chg.sat)   +
      (hours.hours_sun   || 0) * asNumberLocal(chg.sun)   +
      (hours.hours_bh    || 0) * asNumberLocal(chg.bh)
    );

    totalPayEx += payEx;
    totalChgEx += chgEx;

    // ✅ Stable segment id (not index-based, not sh.id-based)
    const stableKey = _stableKeyFromShift(sh);
    const segment_id = _stableSegId(ts.timesheet_id, stableKey);

    // Legacy id (compat): old snapshots used nhsp:<sh.id>
    const legacy_segment_id = sh?.id != null ? `nhsp:${sh.id}` : null;

    // ✅ NEW: stable source identity for bulletproof preservation/repair
    const nhsp_shift_id = (sh && sh.id != null) ? String(sh.id) : null;
    const external_row_key = (sh && sh.external_row_key != null) ? String(sh.external_row_key) : null;

    const preserved =
      (nhsp_shift_id && preservedByNhspShiftId.get(String(nhsp_shift_id))) ||
      (external_row_key && preservedByExternalRowKey.get(String(external_row_key))) ||
      (stableKey && preservedByKey.get(stableKey)) ||
      (legacy_segment_id && preservedByLegacyId.get(legacy_segment_id)) ||
      preservedByLegacyId.get(segment_id) ||
      null;

    const exclude_from_pay =
      (preserved && typeof preserved.exclude_from_pay === 'boolean') ? preserved.exclude_from_pay : false;

    const invoice_target_week_start =
      (preserved && preserved.invoice_target_week_start != null) ? preserved.invoice_target_week_start : undefined;

    const invoice_locked_invoice_id =
      (preserved && preserved.invoice_locked_invoice_id != null) ? preserved.invoice_locked_invoice_id : undefined;

    segments.push({
      segment_id,

      // ✅ NEW: embed stable source identity into segment JSON
      nhsp_shift_id: nhsp_shift_id || null,
      external_row_key: external_row_key || null,

      date: workDate,
      ward: sh.ward || null,
      start_utc: sh.start_utc,
      end_utc: sh.end_utc,
      break_mins: sh.break_mins || 0,

      hours_day:   hours.hours_day   || 0,
      hours_night: hours.hours_night || 0,
      hours_sat:   hours.hours_sat   || 0,
      hours_sun:   hours.hours_sun   || 0,
      hours_bh:    hours.hours_bh    || 0,

      pay_amount:    payEx,
      charge_amount: chgEx,

      exclude_from_pay,
      ...(invoice_target_week_start != null ? { invoice_target_week_start } : {}),
      ...(invoice_locked_invoice_id != null ? { invoice_locked_invoice_id } : {}),

      ref_num: (sh.nhsp_ref_num || sh.ref_num || null) || null,
      request_id: (sh.hr_request_id || sh.request_id || null) || null,
      held_back_reason: sh.held_back_reason || null,
      source_system: sh.source_system || null
    });
  }

  if (!segments.length) return { ok: false, reason: 'NO_VALID_SEGMENTS' };

  totalPayEx = round2(totalPayEx);
  totalChgEx = round2(totalChgEx);

  // ✅ ERNI-aware margin (policy comes from SQL context via policy_override / policy_snapshot_json)
  const _polForMargin = (hasPolicyOverride ? policy_override : policy_snapshot_json) || {};
  const _applyErniTo  = String(_polForMargin?.apply_erni_to || 'PAYE_ONLY').toUpperCase();
  const _erniPctRaw   = Number(_polForMargin?.erni_pct ?? 0);

  let _erniMult = 1;
  if (Number.isFinite(_erniPctRaw) && _erniPctRaw > 0) {
    // supports storing 15 or 0.15
    const p = _erniPctRaw > 1 ? (_erniPctRaw / 100) : _erniPctRaw;
    _erniMult = 1 + p;
  }

  const _payMethodU = String(method || '').toUpperCase();
  const _erniApplies =
    (_applyErniTo === 'ALL') ||
    (_applyErniTo === 'PAYE_ONLY' && _payMethodU === 'PAYE');

  const _payCostEx = round2(_erniApplies ? (totalPayEx * _erniMult) : totalPayEx);
  const marginEx = round2(totalChgEx - _payCostEx);

  const invoice_breakdown_json = {
    mode: 'SEGMENTS',
    segments,
    totals: { total_pay_ex_vat: totalPayEx, total_charge_ex_vat: totalChgEx, margin_ex_vat: marginEx }
  };

  const hours_day   = round2(sumDay);
  const hours_night = round2(sumNight);
  const hours_sat   = round2(sumSat);
  const hours_sun   = round2(sumSun);
  const hours_bh    = round2(sumBh);
  const total_hours = round2(hours_day + hours_night + hours_sat + hours_sun + hours_bh);

  const pay_wtr_rate_pct_snapshot =
    (String(method || '').toUpperCase() === 'PAYE')
      ? (Number.isFinite(Number(policy_snapshot_json?.holiday_pay_pct)) ? Number(policy_snapshot_json.holiday_pay_pct) : null)
      : null;

  // Policy B gating: bases require authorisation before “ready”
  const basisU = String(basis || '').toUpperCase();
  const isAuthoriseGatedBase =
    (basisU === 'NHSP' ||
     basisU === 'NHSP_ADJUSTMENT' ||
     basisU === 'HEALTHROSTER_SELF_BILL' ||
     basisU === 'HEALTHROSTER_ADJUSTMENT');

  const isAuthorised = !!(ts && ts.authorised_at_server);
  const processing_status = (isAuthoriseGatedBase && !isAuthorised) ? 'PENDING_AUTH' : 'READY_FOR_INVOICE';

  const snapshot = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,

    basis,
    nhsp_import_id: nhspImportId || null,

    occupant_key_norm: ts.occupant_key_norm || null,

    candidate_id,
    client_id,
    role: contract.role || null,
    band: contract.band || null,

    pay_method: method,

    policy_snapshot_json,
    rate_source_refs_json: { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null },

    hours_day,
    hours_night,
    hours_sat,
    hours_sun,
    hours_bh,

    pay_day:    pay.day   ?? null,
    pay_night:  pay.night ?? null,
    pay_sat:    pay.sat   ?? null,
    pay_sun:    pay.sun   ?? null,
    pay_bh:     pay.bh    ?? null,

    charge_day:   chg.day   ?? null,
    charge_night: chg.night ?? null,
    charge_sat:   chg.sat   ?? null,
    charge_sun:   chg.sun   ?? null,
    charge_bh:    chg.bh    ?? null,

    additional_units_json: {},
    additional_pay_ex_vat: 0,
    additional_charge_ex_vat: 0,
    additional_margin_ex_vat: 0,

    total_hours,
    total_pay_ex_vat: totalPayEx,
    total_charge_ex_vat: totalChgEx,
    margin_ex_vat: marginEx, // now ERNI-aware for PAYE

    pay_wtr_rate_pct_snapshot,

    candidate_assignment: candidate_id ? 'ASSIGNED' : 'UNASSIGNED',
    processing_status,

    has_rate_issue: false,
    has_pay_channel_issue: false,

    invoice_breakdown_json,

    external_source_rows_json: {
      NHSP_WEEKLY: shifts.map(sh => ({
        date: sh.work_date,
        source_system: 'NHSP',
        reference:
          (sh.nhsp_ref_num || sh.ref_num || (sh.payload_json && (sh.payload_json.ref_num || sh.payload_json.Reference))) || null,
        nhsp_shift_id: sh.id,
        raw_row: sh.payload_json || null
      }))
    }
  };

  // ✅ Optional: apply HR cross-check enrichment BEFORE write (mutates snapshot)
  if (typeof enrichTsfinWithHrCrosscheck === 'function') {
    try {
      await enrichTsfinWithHrCrosscheck(env, ts, snapshot, hr_eff_flags || null, hr_preloaded_shifts || null);
    } catch {}
  }

  // ✅ Optional: write through SQL batch writer (single-row)
  if (write_now) {
    if (!outbox_id) throw new Error('buildNhspWeeklySnapshot: write_now requires options.outbox_id');
    const wr = await rpcTsfinWriteSnapshotsAndComplete(env, {
      rows: [{ outbox_id, timesheet_id: ts.timesheet_id, snapshot }]
    });
    return { ok: true, snapshot, write: wr };
  }

  return { ok: true, snapshot };
}


async function buildNhspWeeklySnapshotCached(
  env,
  ts,
  contract,
  shifts,
  nhspImportId,
  basis = 'NHSP',
  getPolicyCached,
  curFin,
  options = {}
) {
  const {
    outbox_id = null,
    write_now = false,
    hr_eff_flags = null,
    hr_preloaded_shifts = null,

    // ✅ NEW: forward policy_override through to the non-cached builder
    policy_override = null
  } = (options && typeof options === 'object') ? options : {};

  // Internally reuse the non-cached builder logic (it already uses getPolicyCached/policy_override).
  const res = await buildNhspWeeklySnapshot(
    env,
    ts,
    contract,
    shifts,
    nhspImportId,
    basis,
    getPolicyCached,
    curFin,
    {
      outbox_id,
      write_now,
      hr_eff_flags,
      hr_preloaded_shifts,
      policy_override
    }
  );

  return res;
}



// BE FIX: require expected_timesheet_id + resolve to CURRENT; strict 409 payload; write against CURRENT id only
async function handleManualPayAdjustmentCreate(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const delta = Number(body?.delta_pay_ex_vat);
  if (!Number.isFinite(delta) || delta === 0) {
    return withCORS(env, req, badRequest('delta_pay_ex_vat must be a non-zero number'));
  }

  const note = typeof body?.note === 'string' ? body.note.trim() : null;

  // ✅ resolve + guard
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  const currentTimesheetId = resolved?.current_timesheet_id ? String(resolved.current_timesheet_id) : '';
  if (!currentTimesheetId) return withCORS(env, req, notFound('Timesheet not found'));

  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }), {
        status: 409,
        headers: { 'Content-Type': 'application/json' }
      })
    );
  }

  try {
    const { rows: finRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,candidate_id,client_id` +
        `&limit=1`
    );
    const fin = finRows?.[0] || null;
    if (!fin) return withCORS(env, req, badRequest('No current financial snapshot for this timesheet'));

    const { rows: tsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=week_ending_date` +
        `&limit=1`
    );
    const weekEnding = tsRows?.[0]?.week_ending_date || null;
    if (!weekEnding) {
      return withCORS(env, req, badRequest('week_ending_date is missing; cannot create pay adjustment'));
    }

    if (!fin.candidate_id || !fin.client_id) {
      return withCORS(env, req, badRequest('candidate_id or client_id missing on TSFIN; cannot create pay adjustment'));
    }

    const adjPayload = [{
      timesheet_id: currentTimesheetId,
      candidate_id: fin.candidate_id,
      client_id: fin.client_id,
      week_ending_date: weekEnding,
      delta_pay_ex_vat: delta,
      reason: 'MANUAL_EXTRA',
      note: note || null
    }];

    const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(adjPayload)
    });

    if (!insRes.ok) {
      const err = await insRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to create manual pay adjustment: ${err}`));
    }

    const json = await insRes.json().catch(() => []);
    const created = Array.isArray(json) ? json[0] : json;

    try {
      await writeAudit(
        env,
        user,
        'PAY_ADJUSTMENT_MANUAL_CREATED',
        {
          timesheet_id: currentTimesheetId,
          ts_pay_adjustment_id: created?.id || null,
          delta_pay_ex_vat: delta,
          reason: 'MANUAL_EXTRA',
          note: note || null
        },
        { entity: 'timesheet', subject_id: currentTimesheetId, req }
      );
    } catch {}

    return withCORS(env, req, ok({ adjustment: created }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to create manual pay adjustment'));
  }
}



// Guard a write against timesheet rotation (optimistic concurrency).
//
// Rule:
// - Resolve requested timesheetId -> current row (by booking_id/is_current).
// - Compare expectedTimesheetId (from client) to current_timesheet_id.
// - If mismatch => return { ok:false, res: 409 Response } payload that caller can early-return.
// - If match    => return { ok:true, resolved } so caller can proceed.
//
// This helper DOES NOT parse JSON bodies; callers should already have expected_timesheet_id.
async function guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId) {
  const expected = expectedTimesheetId ? String(expectedTimesheetId) : '';

  // If caller didn't supply an expected id, this is a client bug.
  // Return 400 so you immediately see it in logs rather than silently allowing unsafe writes.
  if (!expected) {
    return {
      ok: false,
      resolved: null,
      res: withCORS(env, req, badRequest('expected_timesheet_id is required'))
    };
  }

  // Resolve requested -> current
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) {
    return {
      ok: false,
      resolved: null,
      res: withCORS(env, req, notFound('Timesheet not found'))
    };
  }

  const currentId = resolved.current_timesheet_id ? String(resolved.current_timesheet_id) : '';
  if (!currentId) {
    // Data integrity issue: resolver returned no current id.
    return {
      ok: false,
      resolved,
      res: withCORS(env, req, serverError('Failed to resolve current timesheet'))
    };
  }

  // Compare expected to current
  if (expected !== currentId) {
    const payload = {
      error: 'TIMESHEET_MOVED',
      booking_id: resolved.booking_id || null,
      requested_timesheet_id: resolved.requested_timesheet_id || timesheetId || null,
      current_timesheet_id: resolved.current_timesheet_id || null,
      current_version: resolved.current_version != null ? resolved.current_version : null
    };

    return {
      ok: false,
      resolved,
      res: withCORS(
        env,
        req,
        new Response(JSON.stringify(payload), {
          status: 409,
          headers: { 'Content-Type': 'application/json' }
        })
      )
    };
  }

  // OK to proceed
  return {
    ok: true,
    resolved,
    res: null
  };
}


async function applyWeeklyMappingsOnly(env, {
  source_system,
  import_id,
  candidate_mappings,
  client_aliases
}) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L   = (...a) => { if (LOG) console.log('[WEEKLY_MAPPINGS]', ...a); };

  const enc  = encodeURIComponent;
  const norm = (s) => String(s || '').trim().toLowerCase();
  const sys  = String(source_system || '').toUpperCase();

  const nowIso = new Date().toISOString();

  const candMaps = Array.isArray(candidate_mappings)
    ? candidate_mappings.filter(Boolean)
    : [];

  const cliAliases = Array.isArray(client_aliases)
    ? client_aliases.filter(Boolean)
    : [];

  if (LOG) {
    L('applyWeeklyMappingsOnly ENTER', {
      source_system: sys,
      import_id,
      candidate_mappings_count: candMaps.length,
      client_aliases_count: cliAliases.length
    });
  }

  // ─────────────────────────────────────────────
  // 1) hr_name_mappings upserts (unchanged in spirit)
  // ─────────────────────────────────────────────
  for (const m of candMaps) {
    try {
      if (!m) continue;

      // Prefer an explicit staff_norm, but fall back to staff_name if present
      const staffNormRaw = m.staff_norm || m.staff_name || '';
      const hrNameNorm   = norm(staffNormRaw);

      const hospRaw  = (m.hospital_or_trust != null ? m.hospital_or_trust : null);
      const hospNorm = hospRaw != null ? norm(hospRaw) : null;

      const candidateId = m.candidate_id || null;

      if (!hrNameNorm || !candidateId) {
        if (LOG) {
          L('skip candidate mapping (missing hr_name_norm or candidate_id)', {
            staffNormRaw,
            hrNameNorm,
            candidate_id: candidateId
          });
        }
        continue;
      }

      // Look for an existing mapping for (hr_name_norm, hospital_or_trust)
      let existing = null;
      try {
        let url =
          `${env.SUPABASE_URL}/rest/v1/hr_name_mappings` +
          `?hr_name_norm=eq.${enc(hrNameNorm)}` +
          `&select=id,hr_name_norm,hospital_or_trust,candidate_id,active` +
          `&limit=1`;

        if (hospNorm) {
          url += `&hospital_or_trust=eq.${enc(hospNorm)}`;
        } else {
          url += `&hospital_or_trust=is.null`;
        }

        const { rows } = await sbFetch(env, url);
        existing = rows && rows[0] ? rows[0] : null;
      } catch (e) {
        console.warn('[WEEKLY_MAPPINGS] hr_name_mappings lookup failed (non-fatal)', {
          hr_name_norm: hrNameNorm,
          hospital_or_trust: hospNorm,
          err: e?.message || String(e)
        });
      }

      if (existing && existing.id) {
        // PATCH existing row
        try {
          const res = await fetch(
            `${env.SUPABASE_URL}/rest/v1/hr_name_mappings?id=eq.${enc(existing.id)}`,
            {
              method: 'PATCH',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
              body: JSON.stringify({
                candidate_id:      candidateId,
                hospital_or_trust: hospNorm,
                active:            true,
                last_used_at:      nowIso
              })
            }
          );
          if (!res.ok) {
            const txt = await res.text().catch(() => '');
            console.warn('[WEEKLY_MAPPINGS] hr_name_mappings PATCH failed (non-fatal)', {
              id: existing.id,
              status: res.status,
              body: txt
            });
          } else if (LOG) {
            L('hr_name_mappings PATCH ok', {
              id:           existing.id,
              hr_name_norm: hrNameNorm,
              hospital_or_trust: hospNorm,
              candidate_id: candidateId
            });
          }
        } catch (e) {
          console.warn('[WEEKLY_MAPPINGS] hr_name_mappings PATCH failed (non-fatal)', {
            id: existing.id,
            err: e?.message || String(e)
          });
        }
      } else {
        // INSERT new row
        try {
          const payload = [{
            hr_name_norm:      hrNameNorm,
            hospital_or_trust: hospNorm,
            candidate_id:      candidateId,
            active:            true,
            last_used_at:      nowIso
          }];
          const res = await fetch(
            `${env.SUPABASE_URL}/rest/v1/hr_name_mappings`,
            {
              method: 'POST',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
              body: JSON.stringify(payload)
            }
          );
          if (!res.ok) {
            const txt = await res.text().catch(() => '');
            console.warn('[WEEKLY_MAPPINGS] hr_name_mappings INSERT failed (non-fatal)', {
              hr_name_norm: hrNameNorm,
              hospital_or_trust: hospNorm,
              candidate_id: candidateId,
              status: res.status,
              body: txt
            });
          } else if (LOG) {
            L('hr_name_mappings INSERT ok', {
              hr_name_norm: hrNameNorm,
              hospital_or_trust: hospNorm,
              candidate_id: candidateId
            });
          }
        } catch (e) {
          console.warn('[WEEKLY_MAPPINGS] hr_name_mappings INSERT failed (non-fatal)', {
            hr_name_norm: hrNameNorm,
            hospital_or_trust: hospNorm,
            candidate_id: candidateId,
            err: e?.message || String(e)
          });
        }
      }
    } catch (e) {
      console.warn('[WEEKLY_MAPPINGS] candidate mapping loop failed (non-fatal)', {
        err: e?.message || String(e)
      });
    }
  }

  // ─────────────────────────────────────────────
  // 2) client_hospitals upserts — derive aliases from hr_rows
  //    using hr_row_ids when available, falling back to
  //    any legacy hospital_norm strings.
  // ─────────────────────────────────────────────

  // Helper: normalise hospital_name_norm field from Supabase (array or JSON-string)
  const normAliasList = (val) => {
    if (!val) return [];
    if (Array.isArray(val)) return val;
    if (typeof val === 'string') {
      try {
        const parsed = JSON.parse(val);
        return Array.isArray(parsed) ? parsed : [val];
      } catch {
        return [val];
      }
    }
    return [];
  };

  // 2.1 Collect requested hr_row_ids and any legacy string hints
  const hrRowIdsByClient = new Map();  // client_id -> Set<hr_row_id>
  const extraAliasByClient = new Map(); // client_id -> Set<alias from hospital_norm>

  for (const m of cliAliases) {
    if (!m) continue;
    const clientId = m.client_id || null;
    if (!clientId) continue;

    // NEW: preferred path – hr_row_ids
    if (Array.isArray(m.hr_row_ids) && m.hr_row_ids.length) {
      let set = hrRowIdsByClient.get(clientId);
      if (!set) {
        set = new Set();
        hrRowIdsByClient.set(clientId, set);
      }
      m.hr_row_ids
        .map(String)
        .map((id) => id.trim())
        .filter(Boolean)
        .forEach((id) => set.add(id));
    }

    // Backwards-compatible fallback: explicit hospital_norm string
    const hospitalNormRaw = m.hospital_norm || '';
    const aliasFromHint   = norm(hospitalNormRaw);
    if (aliasFromHint) {
      let set = extraAliasByClient.get(clientId);
      if (!set) {
        set = new Set();
        extraAliasByClient.set(clientId, set);
      }
      set.add(aliasFromHint);
    }
  }

  // 2.2 Build alias sets per client_id (from hints + hr_rows)
  const aliasSetsByClient = new Map(); // client_id -> Set<alias>

  // Seed with any extra aliases passed explicitly
  for (const [clientId, set] of extraAliasByClient.entries()) {
    const tgt = aliasSetsByClient.get(clientId) || new Set();
    set.forEach((a) => tgt.add(a));
    aliasSetsByClient.set(clientId, tgt);
  }

  // If we have hr_row_ids, fetch those hr_rows and derive trust_raw exactly
  // as per the SQL nhsp_preview_mappings_phase1 / hr_weekly_preview_mappings_phase1:
  //   trust_raw = coalesce(payload_json->>'trust',
  //                        payload_json->>'hospital_or_trust',
  //                        unit_raw)
  const allHrRowIds = new Set();
  for (const set of hrRowIdsByClient.values()) {
    for (const id of set) allHrRowIds.add(id);
  }

  if (allHrRowIds.size) {
    try {
      const idParam = Array.from(allHrRowIds).map(enc).join(',');
      const { rows: hrRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/hr_rows` +
          `?import_id=eq.${enc(import_id)}` +
          `&id=in.(${idParam})` +
          `&select=id,unit_raw,payload_json`
      );
      const hrMap = new Map(
        (hrRows || []).map((r) => [String(r.id), r])
      );

      for (const [clientId, idSet] of hrRowIdsByClient.entries()) {
        let aliasSet = aliasSetsByClient.get(clientId);
        if (!aliasSet) {
          aliasSet = new Set();
          aliasSetsByClient.set(clientId, aliasSet);
        }

        for (const id of idSet) {
          const row = hrMap.get(String(id));
          if (!row) continue;
          const payload = row.payload_json || {};
          const trustRaw =
            (payload.trust ||
             payload.hospital_or_trust ||
             row.unit_raw ||
             '').toString().trim();

          const alias = norm(trustRaw);
          if (alias) aliasSet.add(alias);
        }
      }
    } catch (e) {
      console.warn('[WEEKLY_MAPPINGS] hr_rows lookup for aliases failed (non-fatal)', {
        import_id,
        err: e?.message || String(e)
      });
    }
  }

  // 2.3 Upsert client_hospitals per client using accumulated alias sets
  for (const [clientId, aliasSet] of aliasSetsByClient.entries()) {
    const aliases = Array.from(aliasSet).filter(Boolean);
    if (!clientId || !aliases.length) continue;

    let existing = null;
    try {
      const { rows: hospRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
          `?client_id=eq.${enc(clientId)}` +
          `&select=id,hospital_name_norm` +
          `&limit=1`
      );
      existing = hospRows && hospRows[0] ? hospRows[0] : null;
    } catch (e) {
      console.warn('[WEEKLY_MAPPINGS] client_hospitals lookup failed (non-fatal)', {
        client_id: clientId,
        err: e?.message || String(e)
      });
    }

    if (!existing) {
      // Insert a new client_hospitals row with all aliases
      const newRow = [{
        client_id:          clientId,
        hospital_name_norm: aliases,
        updated_at:         nowIso
      }];
      try {
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/client_hospitals`,
          {
            method: 'POST',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify(newRow)
          }
        );
        if (!res.ok) {
          const txt = await res.text().catch(() => '');
          console.warn('[WEEKLY_MAPPINGS] client_hospitals INSERT failed (non-fatal)', {
            client_id: clientId,
            aliases,
            status: res.status,
            body: txt
          });
        } else if (LOG) {
          L('client_hospitals INSERT ok', {
            client_id: clientId,
            aliases
          });
        }
      } catch (e) {
        console.warn('[WEEKLY_MAPPINGS] client_hospitals INSERT failed (non-fatal)', {
          client_id: clientId,
          aliases,
          err: e?.message || String(e)
        });
      }
    } else {
      const currentAliases = normAliasList(existing.hospital_name_norm);
      const merged = new Set(currentAliases.map(norm));
      aliases.forEach((a) => merged.add(a));
      const updated = Array.from(merged);

      try {
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/client_hospitals?id=eq.${enc(existing.id)}`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              hospital_name_norm: updated,
              updated_at: nowIso
            })
          }
        );
        if (!res.ok) {
          const txt = await res.text().catch(() => '');
          console.warn('[WEEKLY_MAPPINGS] client_hospitals PATCH failed (non-fatal)', {
            id: existing.id,
            client_id: clientId,
            aliases: updated,
            status: res.status,
            body: txt
          });
        } else if (LOG) {
          L('client_hospitals PATCH ok', {
            id: existing.id,
            client_id: clientId,
            aliases: updated
          });
        }
      } catch (e) {
        console.warn('[WEEKLY_MAPPINGS] client_hospitals PATCH failed (non-fatal)', {
          id: existing.id,
          client_id: clientId,
          aliases: updated,
          err: e?.message || String(e)
        });
      }
    }
  }

  if (LOG) {
    L('applyWeeklyMappingsOnly EXIT', {
      source_system: sys,
      import_id
    });
  }
}



async function assertCandidateHasValidContract(env, {
  candidate_id,
  client_id,
  work_date
}) {
  const enc  = encodeURIComponent;
  const norm = (s) => String(s || '').trim();

  const candId  = norm(candidate_id || '');
  const cliId   = norm(client_id || '');
  const workYmd = norm(work_date || '');

  // We *always* need a candidate and a date. Client is optional.
  if (!candId || !workYmd) {
    throw new Error('Missing candidate_id or work_date for contract validation');
  }

  let rows = [];
  try {
    // Base filter: candidate_id
    let url =
      `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?candidate_id=eq.${enc(candId)}` +
      `&select=id,client_id,start_date,end_date`;

    // If we have a client_id, additionally restrict by that client.
    if (cliId) {
      url += `&client_id=eq.${enc(cliId)}`;
    }

    const { rows: cRows } = await sbFetch(env, url);
    rows = cRows || [];
  } catch (e) {
    console.error('[CONTRACT_VALIDATE] contracts lookup failed', {
      candidate_id: candId,
      client_id: cliId || null,
      work_date: workYmd,
      err: e?.message || String(e)
    });
    // Bubble this up as a generic error; handler will treat as 500.
    throw new Error('Contract lookup failed');
  }

  let ok = false;
  for (const c of rows) {
    const start = c?.start_date || null;
    const end   = c?.end_date   || null;
    if (!start) continue;

    // String comparison is safe for YYYY-MM-DD
    if (start <= workYmd && (!end || end >= workYmd)) {
      ok = true;
      break;
    }
  }

  if (!ok) {
    throw new Error(
      'Due to security reasons when linking a candidate they must have a valid contract. Please create the contract and try again.'
    );
  }
}


async function handleNhspResolveMappings(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) return withCORS(env, req, badRequest('import_id is required'));

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    body = null;
  }

  const candidateMappings = Array.isArray(body?.candidate_mappings)
    ? body.candidate_mappings.filter(Boolean)
    : [];

  const clientAliases = Array.isArray(body?.client_aliases)
    ? body.client_aliases.filter(Boolean)
    : [];

  if (LOG) {
    console.log('[NHSP_RESOLVE]', JSON.stringify({
      stage: 'start',
      import_id: importId,
      candidate_mappings_count: candidateMappings.length,
      client_aliases_count: clientAliases.length
    }));
  }

  // ─────────────────────────────────────────────
  // Contract check for each candidate mapping
  // ─────────────────────────────────────────────
  for (const m of candidateMappings) {
    try {
      if (!m) continue;
      const candidate_id = m.candidate_id || null;
      const client_id    = m.client_id    || null;
      const work_date    = m.work_date    || null;

      await assertCandidateHasValidContract(env, {
        candidate_id,
        client_id,
        work_date
      });
    } catch (e) {
      const msg = e?.message || 'Contract validation failed';

      const isSecurityMsg = msg.startsWith('Due to security reasons when linking a candidate');
      const isMissingMsg  =
        msg.startsWith('Missing candidate_id') ||
        msg.startsWith('Missing candidate_id or work_date');

      const status = (isSecurityMsg || isMissingMsg) ? 400 : 500;
      const payload = {
        error:   (status === 400 ? 'NO_CONTRACT_FOR_DATE' : 'CONTRACT_VALIDATION_FAILED'),
        message: msg
      };

      if (LOG) {
        console.warn('[NHSP_RESOLVE] contract validation failed', {
          import_id: importId,
          mapping: m,
          status,
          msg
        });
      }

      return withCORS(
        env,
        req,
        new Response(JSON.stringify(payload), {
          status,
          headers: { 'content-type': 'application/json' }
        })
      );
    }
  }

  // ─────────────────────────────────────────────
  // If all contract checks pass, persist aliases only
  // ─────────────────────────────────────────────
  try {
    await applyWeeklyMappingsOnly(env, {
      source_system: 'NHSP',
      import_id: importId,
      candidate_mappings: candidateMappings,
      client_aliases:     clientAliases
    });
  } catch (e) {
    console.error('[NHSP_RESOLVE] applyWeeklyMappingsOnly failed', {
      import_id: importId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError(`Failed to apply NHSP weekly mappings: ${e?.message || e}`));
  }

  if (LOG) {
    console.log('[NHSP_RESOLVE]', JSON.stringify({
      stage: 'completed',
      import_id: importId
    }));
  }

  return withCORS(env, req, ok({ ok: true }));
}


async function handleHrAutoprocessResolveMappings(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) return withCORS(env, req, badRequest('import_id is required'));

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    body = null;
  }

  const candidateMappings = Array.isArray(body?.candidate_mappings)
    ? body.candidate_mappings.filter(Boolean)
    : [];

  const clientAliases = Array.isArray(body?.client_aliases)
    ? body.client_aliases.filter(Boolean)
    : [];

  if (LOG) {
    console.log('[HR_AUTOPROC_RESOLVE]', JSON.stringify({
      stage: 'start',
      import_id: importId,
      candidate_mappings_count: candidateMappings.length,
      client_aliases_count: clientAliases.length
    }));
  }

  // ─────────────────────────────────────────────
  // Contract check for each candidate mapping
  // ─────────────────────────────────────────────
  for (const m of candidateMappings) {
    try {
      if (!m) continue;
      const candidate_id = m.candidate_id || null;
      const client_id    = m.client_id    || null;
      const work_date    = m.work_date    || null;

      await assertCandidateHasValidContract(env, {
        candidate_id,
        client_id,
        work_date
      });
    } catch (e) {
      const msg = e?.message || 'Contract validation failed';

      const isSecurityMsg = msg.startsWith('Due to security reasons when linking a candidate');
      const isMissingMsg  = msg.startsWith('Missing candidate_id');

      const status = (isSecurityMsg || isMissingMsg) ? 400 : 500;
      const payload = {
        error:   (status === 400 ? 'NO_CONTRACT_FOR_DATE' : 'CONTRACT_VALIDATION_FAILED'),
        message: msg
      };

      if (LOG) {
        console.warn('[HR_AUTOPROC_RESOLVE] contract validation failed', {
          import_id: importId,
          mapping: m,
          status,
          msg
        });
      }

      return withCORS(
        env,
        req,
        new Response(JSON.stringify(payload), {
          status,
          headers: { 'content-type': 'application/json' }
        })
      );
    }
  }

  // ─────────────────────────────────────────────
  // If all contract checks pass, persist aliases only
  // ─────────────────────────────────────────────
  try {
    await applyWeeklyMappingsOnly(env, {
      source_system: 'HR_WEEKLY',
      import_id: importId,
      candidate_mappings: candidateMappings,
      client_aliases:     clientAliases
    });
  } catch (e) {
    console.error('[HR_AUTOPROC_RESOLVE] applyWeeklyMappingsOnly failed', {
      import_id: importId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError(`Failed to apply HealthRoster weekly mappings: ${e?.message || e}`));
  }

  if (LOG) {
    console.log('[HR_AUTOPROC_RESOLVE]', JSON.stringify({
      stage: 'completed',
      import_id: importId
    }));
  }

  return withCORS(env, req, ok({ ok: true }));
}

async function handleNhspApply(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  // ---- logging helpers (ALL logging is gated by LOG) ----
  const logInfo  = (obj) => { if (LOG) console.log('[NHSP_APPLY]', JSON.stringify(obj)); };
  const logWarn  = (obj) => { if (LOG) console.warn('[NHSP_APPLY]', JSON.stringify(obj)); };
  const logError = (obj) => { if (LOG) console.error('[NHSP_APPLY]', JSON.stringify(obj)); };
  const logFail  = (obj) => { if (LOG) console.warn('[NHSP_APPLY][GROUP_FAIL]', JSON.stringify(obj)); };

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) return withCORS(env, req, badRequest("import_id is required"));

  const enc    = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asBool = (v) => (v === true || v === 'true' || v === 1 || v === '1');

  // Keep existing constant (used later in existing overpay advance logic)
  const NHSP_OVERPAY_ADVANCE_THRESHOLD = 200; // adjust if needed

  const computeWeekStartFromWeekEnding = (weYmd) => {
    if (!weYmd) return null;
    const d = new Date(`${weYmd}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return weYmd;
    d.setUTCDate(d.getUTCDate() - 6);
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  // Default “next pay run” week_ending_date: next Sunday (including upcoming)
  const computeNextPayWeekEnding = () => {
    const now = new Date();
    const ymd = `${now.getUTCFullYear()}-${String(now.getUTCMonth()+1).padStart(2,'0')}-${String(now.getUTCDate()).padStart(2,'0')}`;
    const d = new Date(`${ymd}T00:00:00Z`);
    while (d.getUTCDay() !== 0) d.setUTCDate(d.getUTCDate() + 1);
    return `${d.getUTCFullYear()}-${String(d.getUTCMonth()+1).padStart(2,'0')}-${String(d.getUTCDate()).padStart(2,'0')}`;
  };

  // Default “next recovery” week_start: next week's Monday
  const computeNextRecoveryWeekStart = () => {
    const d = new Date();
    d.setUTCDate(d.getUTCDate() + 7);
    const day = d.getUTCDay();
    const offset = (day + 6) % 7; // days since Monday
    d.setUTCDate(d.getUTCDate() - offset);
    return `${d.getUTCFullYear()}-${String(d.getUTCMonth()+1).padStart(2,'0')}-${String(d.getUTCDate()).padStart(2,'0')}`;
  };

  // Basic “is string” guard (booking_id must be TEXT, and unique index depends on it)
  const isNonEmptyString = (v) => (typeof v === 'string' && v.trim().length > 0);

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const selectedGroupIds = Array.isArray(body?.selected_group_ids)
    ? [...new Set(body.selected_group_ids.map(String).filter(Boolean))]
    : [];

  const candidateMappings = Array.isArray(body?.candidate_mappings) ? body.candidate_mappings : [];
  const clientAliases     = Array.isArray(body?.client_aliases)     ? body.client_aliases     : [];

  // ✅ NEW: decisions map keyed by external_row_key
  const decisions =
    (body && typeof body.decisions === 'object' && body.decisions && !Array.isArray(body.decisions))
      ? body.decisions
      : {};

  logInfo({
    stage: 'start',
    import_id: importId,
    selected_group_ids_count: selectedGroupIds.length,
    candidate_mappings_count: candidateMappings.length,
    client_aliases_count: clientAliases.length,
    decisions_keys_count: Object.keys(decisions || {}).length
  });

  // ---------- PHASE 0: apply explicit mappings (JS, unchanged) ----------
  try {
    await applyWeeklyMappingsOnly(env, {
      source_system: 'NHSP',
      import_id: importId,
      candidate_mappings: candidateMappings,
      client_aliases: clientAliases
    });

    logInfo({
      stage: 'mappings_applied',
      import_id: importId,
      candidate_mappings_attempted: candidateMappings.length,
      client_aliases_attempted: clientAliases.length
    });
  } catch (e) {
    logWarn({
      stage: 'mappings_apply_failed_non_fatal',
      import_id: importId,
      err: e?.message || String(e)
    });
  }

  // ─────────────────────────────────────────────────────────────
  // Request-scoped policy cache (prevents per-shift loadPolicy subrequests)
  // key = `${client_id}__${dateYmd}`
  // ─────────────────────────────────────────────────────────────
  const _policyCache = new Map();
  const getPolicyCached = async (client_id, dateYmd) => {
    const k = `${String(client_id || '')}__${String(dateYmd || '')}`;
    if (_policyCache.has(k)) return _policyCache.get(k);
    const p = await loadPolicy(env, client_id, dateYmd);
    _policyCache.set(k, p);
    return p;
  };

  // Helpers used later in existing overpay advance logic
  async function computeNhspTotalsForShifts(env, contract, shifts) {
    const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);
    const client_id     = contract.client_id || null;

    const pc  = payChargeFromContract(contract);
    const pay = pc?.pay || null;
    const chg = pc?.charge || null;

    const missing = new Set();
    if (!pay || !chg) return { totalPayEx: 0, totalChgEx: 0, missingBuckets: ['CONTRACT_RATES_MISSING'] };

    let totalPayEx = 0;
    let totalChgEx = 0;

    for (const sh of shifts) {
      const workDate = sh.work_date;
      if (!workDate || !sh.start_utc || !sh.end_utc) continue;

      const policy = await getPolicyCached(client_id, workDate);

      let segs = [[sh.start_utc, sh.end_utc]];
      segs = subtractBreak(segs, null, null, sh.break_mins || 0);

      const hours = classifyMinutes(env, policy, segs);

      const used = {
        day:   (hours.hours_day   || 0),
        night: (hours.hours_night || 0),
        sat:   (hours.hours_sat   || 0),
        sun:   (hours.hours_sun   || 0),
        bh:    (hours.hours_bh    || 0)
      };

      for (const k of ['day','night','sat','sun','bh']) {
        if ((used[k] || 0) > 0) {
          const pv = pay[k];
          const cv = chg[k];
          if (pv == null || pv === '' || !Number.isFinite(Number(pv))) missing.add(`pay:${k}`);
          if (cv == null || cv === '' || !Number.isFinite(Number(cv))) missing.add(`charge:${k}`);
        }
      }

      const payEx = round2(
        (used.day   || 0) * asNumberLocal(pay.day)   +
        (used.night || 0) * asNumberLocal(pay.night) +
        (used.sat   || 0) * asNumberLocal(pay.sat)   +
        (used.sun   || 0) * asNumberLocal(pay.sun)   +
        (used.bh    || 0) * asNumberLocal(pay.bh)
      );

      const chgEx = round2(
        (used.day   || 0) * asNumberLocal(chg.day)   +
        (used.night || 0) * asNumberLocal(chg.night) +
        (used.sat   || 0) * asNumberLocal(chg.sat)   +
        (used.sun   || 0) * asNumberLocal(chg.sun)   +
        (used.bh    || 0) * asNumberLocal(chg.bh)
      );

      totalPayEx += payEx;
      totalChgEx += chgEx;
    }

    return {
      totalPayEx: round2(totalPayEx),
      totalChgEx: round2(totalChgEx),
      missingBuckets: Array.from(missing)
    };
  }

  async function createOverpayAdvance(env, { candidate_id, client_id, amount, reason, notes, week_start }) {
    try {
      const amt = Number(amount || 0);
      if (!candidate_id || !client_id || !(amt > 0)) return;

      const nowIso = new Date().toISOString();
      const ws     = week_start || null;
      const schedule = ws ? [{ week_start: ws, amount: -round2(amt) }] : [];

      const payload = [{
        candidate_id,
        client_id,
        reason,
        original_amount:    round2(amt),
        outstanding_amount: round2(amt),
        linked_shift_date:  null,
        schedule_json:      schedule,
        next_due_week_start: ws || null,
        status: 'ACTIVE',
        best_guess_hours: null,
        notes: notes || null,
        created_at: nowIso,
        updated_at: nowIso,
        created_by: null
      }];

      await fetch(
        `${env.SUPABASE_URL}/rest/v1/pay_advances`,
        { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify(payload) }
      );
    } catch (e) {
      logWarn({ stage: 'create_overpay_advance_failed_non_fatal', err: e?.message || String(e) });
    }
  }

  // ============================================================
  // REQUIRED dependency for applyWeeklyHoursCorrections:
  // createShiftPayAdjustment (idempotent via meta_json.correction_id)
  // ============================================================
  async function createShiftPayAdjustment(env, {
    timesheet_id,
    candidate_id,
    client_id,
    week_ending_date,
    delta_pay_ex_vat,
    note,
    meta_json
  }) {
    const delta = Number(delta_pay_ex_vat || 0);
    if (!timesheet_id || !candidate_id || !client_id) return null;
    if (!Number.isFinite(delta) || delta === 0) return null;

    const corrId = meta_json?.correction_id ? String(meta_json.correction_id) : null;

    if (corrId) {
      try {
        const { rows: ex } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments` +
          `?meta_json->>correction_id=eq.${enc(corrId)}` +
          `&select=id&limit=1`
        );
        if (ex && ex[0]) return ex[0];
      } catch {
        // ignore
      }
    }

    const payload = [{
      timesheet_id,
      candidate_id,
      client_id,
      week_ending_date,
      delta_pay_ex_vat: round2(delta),
      reason: 'NHSP_CHANGED_HOURS',
      note: note || null,
      meta_json: (meta_json && typeof meta_json === 'object') ? meta_json : {}
    }];

    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments`,
      { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(payload) }
    );

    if (!res.ok) {
      const t = await res.text().catch(() => '');
      throw new Error(`ts_pay_adjustments insert failed: ${t || res.status}`);
    }

    const json = await res.json().catch(() => []);
    return Array.isArray(json) ? json[0] : json;
  }

   // ============================================================
  // Invoice context for helper-wired invoice correction lines
  // (used by applyWeeklyHoursCorrections → credit/reinvoice helpers)
  // ============================================================
  const getInvoiceCtx = (() => {
    const _clientCache = new Map();

    // Cache VAT by (client_id + anchorYmd) so “today” is stable within this request
    const _vatCache = new Map(); // key: `${client_id}__${anchorYmd}`

    // settings_defaults cache (NON-FINANCE ONLY)
    const _defaultsCache = { loaded: false, row: null };

    const _bucketCache = new Map(); // `${client_id}__${weekStart}` -> invoice row

    // Cache finance VAT default per day (anchorYmd)
    const _financeVatCache = new Map(); // key: `${anchorYmd}` -> vat_rate_pct

    // Today (Europe/London) as YYYY-MM-DD
    const todayLondonYmd = () => {
      try {
        const s = new Intl.DateTimeFormat('en-GB', {
          timeZone: 'Europe/London',
          year: 'numeric',
          month: '2-digit',
          day: '2-digit'
        }).format(new Date());
        const [dd, mm, yyyy] = s.split('/');
        return `${yyyy}-${mm}-${dd}`;
      } catch {
        const d = new Date();
        const y = d.getUTCFullYear();
        const m = String(d.getUTCMonth() + 1).padStart(2, '0');
        const day = String(d.getUTCDate()).padStart(2, '0');
        return `${y}-${m}-${day}`;
      }
    };

    const loadDefaultsOnce = async () => {
      if (_defaultsCache.loaded) return _defaultsCache.row || {};
      try {
        // settings_defaults is NON-FINANCE ONLY (vat_rate_pct now comes from finance windows)
        const { rows: defRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=bank_name,bank_sort_code,bank_account_number,vat_registration_number`
        );
        _defaultsCache.row = defRows?.[0] || {};
      } catch {
        _defaultsCache.row = {};
      }
      _defaultsCache.loaded = true;
      return _defaultsCache.row || {};
    };

    const loadClientRow = async (client_id) => {
      const k = String(client_id || '');
      if (!k) return null;
      if (_clientCache.has(k)) return _clientCache.get(k);

      const { rows: cliRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients?select=id,name,invoice_address,primary_invoice_email,vat_chargeable,payment_terms_days&id=eq.${enc(client_id)}&limit=1`
      );

      const cli = cliRows?.[0] || null;
      _clientCache.set(k, cli);
      return cli;
    };

    // VAT default from finance windows
    // Rule: VAT is the rate in force when we create/amend the invoice (i.e. “today”).
const loadFinanceVatDefaultPct = async (anchorYmd) => {
  const k = String(anchorYmd || '');
  if (_financeVatCache.has(k)) return _financeVatCache.get(k);

  let pct = 20; // safe fallback if finance windows not available
  try {
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), 'content-type': 'application/json' },
        // ✅ Use the caller’s anchor date when provided; else null => SQL uses “today (Europe/London)”
        body: JSON.stringify({ p_date: k || null })
      }
    );

    const txt = await res.text().catch(() => '');
    if (res.ok) {
      const j = txt ? JSON.parse(txt) : null;
      const row = Array.isArray(j) ? j[0] : j;
      const v = Number(row?.vat_rate_pct);
      if (Number.isFinite(v)) pct = v;
    }
  } catch {
    // keep fallback
  }

  _financeVatCache.set(k, pct);
  return pct;
};


    // Client VAT override still applies, but default comes from finance windows (“today”)
    // Also: prevent future-dated client_settings rows from being applied early.
    const loadVatRatePct = async (client_id, clientRow, anchorYmd) => {
      const k0 = String(client_id || '');
      const k1 = String(anchorYmd || '');
      const k = `${k0}__${k1}`;
      if (!k0) return 0;
      if (_vatCache.has(k)) return _vatCache.get(k);

      const defaultVat = await loadFinanceVatDefaultPct(anchorYmd);

      let vatRatePct = defaultVat;
      try {
        const { rows: csRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/client_settings` +
            `?select=client_id,vat_rate_pct,effective_from` +
            `&client_id=eq.${enc(client_id)}` +
            `&effective_from=lte.${enc(anchorYmd)}` +
            `&order=effective_from.desc&limit=1`
        );

        const cs = csRows?.[0] || null;

        const vatChargeable = (clientRow && typeof clientRow.vat_chargeable === 'boolean')
          ? clientRow.vat_chargeable !== false
          : true;

        vatRatePct = vatChargeable === false ? 0 : Number(cs?.vat_rate_pct ?? defaultVat);
      } catch {
        const vatChargeable = (clientRow && typeof clientRow.vat_chargeable === 'boolean')
          ? clientRow.vat_chargeable !== false
          : true;
        vatRatePct = vatChargeable === false ? 0 : defaultVat;
      }

      _vatCache.set(k, vatRatePct);
      return vatRatePct;
    };

    const bumpTotals = async (invoice_id, add_ex, add_vat, add_inc) => {
      try {
        const { rows: invRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoice_id)}&select=id,subtotal_ex_vat,vat_amount,total_inc_vat&limit=1`
        );
        const inv = invRows?.[0] || null;
        if (!inv) return;

        const newSubtotal = round2(Number(inv.subtotal_ex_vat || 0) + Number(add_ex || 0));
        const newVat      = round2(Number(inv.vat_amount || 0) + Number(add_vat || 0));
        const newInc      = round2(Number(inv.total_inc_vat || 0) + Number(add_inc || 0));

        await fetch(
          `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoice_id)}`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              subtotal_ex_vat: newSubtotal,
              vat_amount: newVat,
              total_inc_vat: newInc,
              updated_at: new Date().toISOString()
            })
          }
        ).catch(() => {});
      } catch {
        // ignore
      }
    };

    return async (client_id) => {
      const cli = await loadClientRow(client_id);
      if (!cli) throw new Error(`getInvoiceCtx: client not found (client_id=${client_id})`);

      const defaults = await loadDefaultsOnce();

      // Anchor VAT to “today” (Europe/London) because we are creating/amending invoices NOW.
      const anchorYmd = todayLondonYmd();
      const vatRatePct = await loadVatRatePct(client_id, cli, anchorYmd);

      const findOrCreateBucket = async (weekStart) => {
        const key = `${String(client_id)}__${String(weekStart)}`;
        if (_bucketCache.has(key)) return _bucketCache.get(key);

        const invoice = await findOrCreateSelfBillInvoice(
          env,
          client_id,
          weekStart,
          cli,
          [defaults],
          vatRatePct,
          [],
          []
        );

        if (!invoice || !invoice.id) throw new Error('findOrCreateSelfBillInvoice returned no invoice');
        _bucketCache.set(key, invoice);
        return invoice;
      };

      // Keep return shape unchanged (in case applyWeeklyHoursCorrections relies on vatRatePct)
      return { vatRatePct, findOrCreateBucket, bumpTotals };
    };
  })();


  // ============================================================
  // PHASE 3 decision workflow (helper-wired) BEFORE Phase 1
  // ============================================================
  let phase3 = null;
  let decisionsNorm = null;
  let skipExternalRowKeys = [];
  let forceOverwriteExternalRowKeys = [];
  let skipSet = new Set();
  let changedHoursKeySet = new Set();

  // counters reported back / audited
  let corrStats = {
    pay_adjustments_touched: 0,
    recoveries_touched: 0,
    invoice_credits_touched: 0,
    invoice_reinvoices_touched: 0
  };

  // Phase1 counters
  let created = 0;
  let updated = 0;
  let mappedCandidates = 0;
  let mappedClients = 0;

  // Phase1.5 counters
  let phase15Rows = [];
  let phase15Updated = 0;
  let phase15Ok = 0;

  // group counters
  let groups_total = 0;
  let groups_attempted = 0;
  let groups_succeeded = 0;
  let groups_failed = 0;
  const failSamples = [];

  const addFail = (preview_group_id, action, reason, debugExtra = null) => {
    groups_failed++;
    const sample = { preview_group_id: preview_group_id || null, action: action || null, reason: reason || null };
    if (debugExtra && typeof debugExtra === 'object') sample.debug = debugExtra;
    if (failSamples.length < 10) failSamples.push(sample);
    logFail({ import_id: importId, preview_group_id, action, reason, debug: debugExtra || undefined });
  };

  try {
    // Confirm import exists and is NHSP
    const { rows: impRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_imports` +
      `?id=eq.${enc(importId)}` +
      `&select=id,source_system,file_r2_key,parse_summary_json&limit=1`
    );
    const imp = impRows?.[0] || null;
    if (!imp) return withCORS(env, req, notFound("NHSP import not found"));
    if (imp.source_system !== 'NHSP') {
      return withCORS(env, req, badRequest(`Import ${importId} is not NHSP (source_system=${imp.source_system})`));
    }

    logInfo({ stage: 'import_loaded', import_id: importId, source_system: imp.source_system });

    // 1) Load Phase 3 (helper)
    phase3 = await loadWeeklyChangedHoursPhase3(env, importId, 'NHSP');

    // 2) Validate decisions (helper) — hard error if missing/invalid
    //    (also rejects unknown keys)
    decisionsNorm = validateWeeklyImportDecisions(phase3, decisions, { enforceMondayRange: true });

    // 3) Build skip + force lists for Phase 1
    skipExternalRowKeys = Array.isArray(decisionsNorm.skipKeys) ? decisionsNorm.skipKeys : [];
    forceOverwriteExternalRowKeys = Array.isArray(decisionsNorm.forceKeys) ? decisionsNorm.forceKeys : [];

    skipSet = new Set(skipExternalRowKeys.map(String));
    changedHoursKeySet = new Set([...skipExternalRowKeys, ...forceOverwriteExternalRowKeys].map(String));

    // 4) Execute correction artefacts (helper) — only PROCEED rows; idempotent
    corrStats = await applyWeeklyHoursCorrections(env, {
      user,
      req,
      import_id: importId,
      system_type: 'NHSP',
      phase3,
      decisionsNorm,
      createShiftPayAdjustment,     // local
      findOrCreateSelfBillInvoice,  // existing global in your codebase
      getInvoiceCtx                 // local
    });

    logInfo({
      stage: 'phase3_corrections_done',
      import_id: importId,
      skip_count: skipExternalRowKeys.length,
      force_overwrite_count: forceOverwriteExternalRowKeys.length,
      corrStats
    });

    // 5) Phase 1 apply — MUST pass skip/force lists
    {
      const rpcBody = {
        p_import_id: importId,
        p_selected_group_ids: selectedGroupIds.length ? selectedGroupIds : null,
        p_skip_external_row_keys: skipExternalRowKeys.length ? skipExternalRowKeys : null,
        p_force_overwrite_external_row_keys: forceOverwriteExternalRowKeys.length ? forceOverwriteExternalRowKeys : null
      };

      const rpcRes = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/nhsp_apply_import_phase1`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify(rpcBody)
        }
      );

      const txt = await rpcRes.text().catch(() => '');
      if (!rpcRes.ok) {
        logError({ stage: 'phase1_rpc_failed', import_id: importId, status: rpcRes.status, body: txt });
        throw new Error(`nhsp_apply_import_phase1 failed with status ${rpcRes.status}`);
      }

      let rpcJson;
      try { rpcJson = txt ? JSON.parse(txt) : null; } catch { rpcJson = null; }

      const row0 = Array.isArray(rpcJson) ? rpcJson[0] : rpcJson;
      const payload = row0?.nhsp_apply_import_phase1 || row0 || {};

      created          = Number(payload.shifts_created     ?? 0);
      updated          = Number(payload.shifts_updated     ?? 0);
      mappedCandidates = Number(payload.mapped_candidates  ?? 0);
      mappedClients    = Number(payload.mapped_clients     ?? 0);

      logInfo({
        stage: 'phase1_done',
        import_id: importId,
        summary: { created, updated, mappedCandidates, mappedClients }
      });
    }

    // 6) Phase 1.5: contract/week repair (authoritative)
    {
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/weekly_import_apply_phase2`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify({ p_import_id: importId, p_system_type: 'NHSP' })
        }
      );

      const txt = await res.text().catch(() => '');
      if (!res.ok) {
        logError({ stage: 'phase1_5_rpc_failed_fatal', import_id: importId, status: res.status, body: txt });
        throw new Error(`weekly_import_apply_phase2 failed with status ${res.status}`);
      }

      try {
        const j = txt ? JSON.parse(txt) : [];
        phase15Rows = Array.isArray(j) ? j : [];
        phase15Updated = phase15Rows.filter(r => r && r.shift_updated === true).length;
        phase15Ok = phase15Rows.filter(r => r && String(r.action || '').toUpperCase() === 'OK').length;
      } catch {
        phase15Rows = [];
        phase15Updated = 0;
        phase15Ok = 0;
      }

      logInfo({
        stage: 'phase1_5_contract_alignment_done',
        import_id: importId,
        rows_returned: phase15Rows.length,
        rows_ok: phase15Ok,
        rows_shift_updated: phase15Updated
      });
    }

    // 7) Fetch shifts after repair
    const { rows: allShifts } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
      `?latest_import_id=eq.${enc(importId)}&source_system=eq.NHSP` +
      `&select=*`
    );
    const allShiftsArr = Array.isArray(allShifts) ? allShifts : [];

    const shiftByExternalKey = new Map();
    for (const s of allShiftsArr) {
      if (s && s.external_row_key) shiftByExternalKey.set(String(s.external_row_key), s);
    }

    // 8) Build authoritative groups from Phase1.5 OK rows
    const p2Ok = (phase15Rows || []).filter(r => {
      const act = String(r?.action || '').toUpperCase();
      return (
        act === 'OK' &&
        r?.external_row_key &&
        r?.candidate_id &&
        r?.client_id &&
        r?.contract_id &&
        r?.week_ending_date
      );
    });

    const p2GroupByPreviewId = new Map();
    for (const r of p2Ok) {
      const candidateId = String(r.candidate_id);
      const clientId    = String(r.client_id);
      const contractId  = String(r.contract_id);
      const we          = String(r.week_ending_date);
      const extKey      = String(r.external_row_key);

      const previewGroupId = `grp:${contractId}:${we}:${candidateId}`;
      let g = p2GroupByPreviewId.get(previewGroupId);
      if (!g) {
        g = { candidate_id: candidateId, client_id: clientId, contract_id: contractId, week_ending_date: we, external_row_keys: [] };
        p2GroupByPreviewId.set(previewGroupId, g);
      }
      if (!g.external_row_keys.includes(extKey)) g.external_row_keys.push(extKey);
    }

    // 9) Classifier meta (selection + action semantics)
    const READY_ACTIONS = new Set([
      'NEW_AUTOPROC_TIMESHEET',
      'UPDATE_AUTOPROC_TS',
      'UPDATE_MANUAL_WEEK',
      'UPDATE_ADJUSTMENT_TS',
      'CREATE_ADJUSTMENT_TS',
      'CREATE_PAY_ADJUSTMENT_ONLY'
    ]);

    let classifiedGroups = [];
    try {
      const cls  = await classifyWeeklyImportRows(env, importId, { source_system: 'NHSP' });
      const rows = (cls && Array.isArray(cls.rows)) ? cls.rows : [];
      classifiedGroups = rows.filter(r => r && r.level === 'group');
    } catch (e) {
      classifiedGroups = [];
      logWarn({ stage: 'classify_failed_non_fatal', import_id: importId, err: e?.message || String(e) });
    }

    const metaByPreviewId = new Map();
    for (const g of classifiedGroups) {
      if (g && g.preview_group_id) metaByPreviewId.set(String(g.preview_group_id), g);
    }
    if (!metaByPreviewId.size && p2GroupByPreviewId.size) {
      for (const [pid, g] of p2GroupByPreviewId.entries()) {
        metaByPreviewId.set(pid, {
          level: 'group',
          preview_group_id: pid,
          candidate_id: g.candidate_id,
          client_id: g.client_id,
          contract_id: g.contract_id,
          week_ending_date: g.week_ending_date,
          action: 'NEW_AUTOPROC_TIMESHEET',
          reason: 'No classifier result; apply fallback treats group as new.',
          default_selected: true
        });
      }
    }

    // 10) Load contracts/candidates/clients
    const contractById = new Map();
    {
      const contractIds = [...new Set([...p2GroupByPreviewId.values()].map(g => g.contract_id).filter(Boolean))];
      const chunkSize = 150;
      for (let i = 0; i < contractIds.length; i += chunkSize) {
        const chunk = contractIds.slice(i, i + chunkSize);
        const { rows: cRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/contracts?id=in.(${chunk.map(enc).join(',')})&select=*`
        );
        for (const c of (cRows || [])) contractById.set(c.id, c);
      }
    }

    const candidateById = new Map();
    const clientById    = new Map();
    {
      const candIds = [...new Set([...p2GroupByPreviewId.values()].map(g => g.candidate_id).filter(Boolean))];
      const cliIds  = [...new Set([...p2GroupByPreviewId.values()].map(g => g.client_id).filter(Boolean))];
      const chunkSize = 150;

      for (let i = 0; i < candIds.length; i += chunkSize) {
        const chunk = candIds.slice(i, i + chunkSize);
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/candidates?id=in.(${chunk.map(enc).join(',')})&select=id,display_name,tms_ref`
        );
        for (const r of (rows || [])) candidateById.set(r.id, r);
      }

      for (let i = 0; i < cliIds.length; i += chunkSize) {
        const chunk = cliIds.slice(i, i + chunkSize);
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/clients?id=in.(${chunk.map(enc).join(',')})&select=id,name`
        );
        for (const r of (rows || [])) clientById.set(r.id, r);
      }
    }

    // Helper: fetch TSFIN lock state for timesheets (missing TSFIN => safe)
    const loadTsfinLocks = async (timesheetIds) => {
      const ids = [...new Set((timesheetIds || []).filter(Boolean).map(String))];
      const finByTsId = new Map();
      if (!ids.length) return finByTsId;

      const chunkSize = 200;
      for (let i = 0; i < ids.length; i += chunkSize) {
        const chunk = ids.slice(i, i + chunkSize);
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=in.(${chunk.map(enc).join(',')})` +
          `&is_current=eq.true` +
          `&select=timesheet_id,locked_by_invoice_id,paid_at_utc`
        );
        for (const r of (rows || [])) {
          if (r && r.timesheet_id) finByTsId.set(String(r.timesheet_id), r);
        }
      }
      return finByTsId;
    };

    // ============================================================
    // APPLY LOOP (existing pipeline), with skip-aware movement rules
    // ============================================================
    for (const [previewGroupId, p2g] of p2GroupByPreviewId.entries()) {
      groups_total++;

      const meta = metaByPreviewId.get(previewGroupId) || null;
      const actionUpper = String(meta?.action || 'NEW_AUTOPROC_TIMESHEET').trim().toUpperCase();
      const defaultSelected = (meta ? (meta.default_selected !== false) : true);

      const isSelected =
        selectedGroupIds.length
          ? selectedGroupIds.includes(previewGroupId)
          : defaultSelected;

      if (!isSelected) continue;
      if (!READY_ACTIONS.has(actionUpper)) continue;

      groups_attempted++;

      const clientId       = p2g.client_id || null;
      const candidateId    = p2g.candidate_id || null;
      const contractId     = p2g.contract_id || null;
      const weekEndingDate = p2g.week_ending_date || null;

      if (!clientId || !candidateId || !contractId || !weekEndingDate) {
        addFail(previewGroupId, actionUpper, 'Missing ids on Phase2 group', { clientId, candidateId, contractId, weekEndingDate });
        continue;
      }

      // Shifts for group
      const extKeys = Array.isArray(p2g.external_row_keys) ? p2g.external_row_keys.slice() : [];
      const grpShifts = [];
      for (const k of extKeys) {
        const sh = shiftByExternalKey.get(String(k)) || null;
        if (sh) grpShifts.push(sh);
      }
      if (!grpShifts.length) {
        addFail(previewGroupId, actionUpper, 'No shifts found for Phase2 external_row_keys (cannot apply).', { extKeysCount: extKeys.length });
        continue;
      }

      const contract = contractById.get(contractId) || null;
      if (!contract) {
        addFail(previewGroupId, actionUpper, 'Contract not found for contract_id.', { contract_id: contractId });
        continue;
      }

      const weekStart = computeWeekStartFromWeekEnding(String(weekEndingDate));
      const nowIso = new Date().toISOString();

      // Ensure contract_week exists (seq 0)
      let cw = null;
      try {
        const { rows: cws } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?contract_id=eq.${enc(contract.id)}` +
          `&week_ending_date=eq.${enc(weekEndingDate)}` +
          `&additional_seq=eq.0` +
          `&select=*` +
          `&limit=1`
        );
        cw = cws?.[0] || null;
      } catch {
        cw = null;
      }

      if (!cw) {
        try {
          const insCw = await fetch(
            `${env.SUPABASE_URL}/rest/v1/contract_weeks`,
            {
              method: 'POST',
              headers: { ...sbHeaders(env), Prefer: 'return=representation' },
              body: JSON.stringify([{
                contract_id:        contract.id,
                week_ending_date:   weekEndingDate,
                additional_seq:     0,
                status:             'SUBMITTED',
                created_at:         nowIso,
                updated_at:         nowIso
              }])
            }
          );
          const txt3 = await insCw.text().catch(() => '');
          if (!insCw.ok) {
            addFail(previewGroupId, actionUpper, `contract_weeks insert failed (${insCw.status}): ${txt3 || 'unknown error'}`, { contract_id: contract.id, week_ending_date: weekEndingDate });
            continue;
          }
          const json = txt3 ? JSON.parse(txt3) : [];
          cw = Array.isArray(json) ? json[0] : json;
        } catch (e) {
          addFail(previewGroupId, actionUpper, `contract_weeks insert threw: ${e?.message || String(e)}`, { contract_id: contract.id, week_ending_date: weekEndingDate });
          continue;
        }
      }

      // Ensure/load timesheet
      let ts = null;
      let bookingId = null;
      try { bookingId = await makeWeeklyBookingId(contract.candidate_id || candidateId, contract, cw); } catch { bookingId = null; }

      if (!isNonEmptyString(bookingId)) {
        addFail(previewGroupId, actionUpper, 'Invalid booking_id computed (expected non-empty string).', { bookingId, contract_id: contract.id, week_ending_date: weekEndingDate });
        continue;
      }

      if (cw.timesheet_id) {
        try {
          const { rows: tsRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?timesheet_id=eq.${enc(cw.timesheet_id)}` +
            `&is_current=eq.true&select=*` +
            `&limit=1`
          );
          ts = tsRows?.[0] || null;
        } catch {
          ts = null;
        }
      }

      if (!ts) {
        try {
          const { rows: tsRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?booking_id=eq.${enc(bookingId)}` +
            `&is_current=eq.true&select=*` +
            `&limit=1`
          );
          ts = tsRows?.[0] || null;

          if (ts && !cw.timesheet_id) {
            await fetch(
              `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
              { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify({ timesheet_id: ts.timesheet_id, status: 'SUBMITTED', updated_at: nowIso }) }
            ).catch(() => {});
            cw.timesheet_id = ts.timesheet_id;
          }
        } catch {
          // ignore
        }
      }

     if (!ts) {
  const cand = candidateById.get(candidateId) || null;
  const cli  = clientById.get(clientId) || null;
  const firstShift = grpShifts?.[0] || {};

  const occupantKeyNorm = String(cand?.tms_ref || cand?.display_name || candidateId || 'worker').toLowerCase();
  const hospitalNorm    = String(contract.display_site || cli?.name || clientId || 'client').toLowerCase();
  const wardNorm        = String(contract.ward_hint || firstShift.ward || 'contract').toLowerCase();
  const jobTitleNorm    = String(contract.role || firstShift.assignment_code || 'weekly').toLowerCase();

  // ✅ FIX: determine next version for booking_id (NOT hard-coded 1)
  let nextVersion = 1;
  try {
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const maxV = vRows?.[0]?.version != null ? Number(vRows[0].version) : null;
    nextVersion = Number.isFinite(maxV) ? (maxV + 1) : 1;
  } catch {
    nextVersion = 1;
  }

  // ✅ Optional but recommended: demote any current row for this booking_id (keeps invariants clean)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: false,
        status: 'REVOKED',
        revoked_reason: 'IMPORT_REPLACED_BY_AUTOPROC',
        revoked_by: user?.id || null,
        updated_at: nowIso
      })
    }
  ).catch(() => {});

 const tsPayload = [{
  booking_id: bookingId,
  version: nextVersion,
  is_current: true,
  status: 'RECEIVED',
  sheet_scope: 'WEEKLY',
  submission_mode: 'MANUAL',
  line_type: 'HOURS',
  occupant_key_norm: occupantKeyNorm,
  hospital_norm: hospitalNorm,
  ward_norm: wardNorm,
  job_title_norm: jobTitleNorm,
  shift_label_norm: 'weekly',
  week_ending_date: weekEndingDate,
  contract_id: contract.id,

  manual_pdf_r2_key: null,
  actual_schedule_json: [],
  authorised_at_server: null,

  // ✅ FIX: imports must NEVER default into QR mode
  qr_status: null,
  qr_token: null,
  qr_generated_at: null,
  qr_scanned_at: null,
  qr_scan_info_json: null,
  qr_r2_key: null,
  qr_payload_json: {},

  created_at: nowIso,
  updated_at: nowIso
}];


  const insTs = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets`,
    { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(tsPayload) }
  );

  const txt = await insTs.text().catch(() => '');
  if (!insTs.ok) {
    addFail(
      previewGroupId,
      actionUpper,
      `timesheets insert failed (${insTs.status}): ${txt || 'unknown error'}`,
      { booking_id: bookingId, contract_id: contract.id, attempted_version: nextVersion }
    );
    continue;
  }

  const tsJson = txt ? JSON.parse(txt) : [];
  ts = Array.isArray(tsJson) ? tsJson[0] : tsJson;

  await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({ timesheet_id: ts.timesheet_id, status: 'SUBMITTED', updated_at: nowIso })
    }
  ).catch(() => {});
  cw.timesheet_id = ts.timesheet_id;
}


      if (!ts?.timesheet_id) {
        addFail(previewGroupId, actionUpper, 'Timesheet missing timesheet_id after create/load.', { booking_id: bookingId });
        continue;
      }

      // If group contains changed-hours keys and base timesheet is paid/invoiced, DO NOT run legacy move/rebuild
      // (correction artefacts already created; Phase1 handles overwrite/skip)
      const groupTouchedByChangedHours = extKeys.some(k => changedHoursKeySet.has(String(k)));
      if (groupTouchedByChangedHours) {
        try {
          const { rows: finRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
            `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
            `&is_current=eq.true&select=locked_by_invoice_id,paid_at_utc&limit=1`
          );
          const fin = finRows?.[0] || null;
          const paid = !!fin?.paid_at_utc;
          const invoiced = !!fin?.locked_by_invoice_id;
          if (paid || invoiced) {
            // short-circuit to avoid touching historic locked/paid snapshots in this apply stage
            try {
              await upsertValidation(env, user, {
                timesheet_id: ts.timesheet_id,
                status: 'VALIDATION_OK',
                reason: 'NHSP_IMPORT',
                hr_reference: null,
                import_id: importId
              });
            } catch {}
            groups_succeeded++;
            logInfo({ stage: 'group_short_circuit_changed_hours', import_id: importId, preview_group_id: previewGroupId, timesheet_id: ts.timesheet_id });
            continue;
          }
        } catch {
          // if we can't read fin, proceed with normal logic (safe path will rebuild with preserved locks anyway)
        }
      }

            // Existing-holder safety check (missing TSFIN => safe)
      const existingTsIds = [...new Set(grpShifts.map(s => s && s.timesheet_id).filter(Boolean).map(String))];
      const existingFinByTs = await loadTsfinLocks(existingTsIds);

      // We only block moving a NON-SKIPPED shift off a locked/paid timesheet.
      // Skipped shifts are not moved; non-skipped but already on base is ok.
      const unsafeToMove = [];
      for (const sh of grpShifts) {
        const extKey = sh?.external_row_key ? String(sh.external_row_key) : null;
        const curTsId = sh?.timesheet_id ? String(sh.timesheet_id) : null;
        if (!curTsId) continue;

        if (extKey && skipSet.has(extKey) && curTsId !== String(ts.timesheet_id)) continue; // skipped + not on base => ignore

        const fin = existingFinByTs.get(curTsId) || null;
        if (!fin) continue;
        if ((fin.locked_by_invoice_id || fin.paid_at_utc) && curTsId !== String(ts.timesheet_id)) {
          unsafeToMove.push({ shift_id: sh.id, timesheet_id: curTsId, external_row_key: extKey || null });
        }
      }

      // If unsafe shifts exist, do NOT fail the entire apply; just do not move them.
      // This keeps the import applicable for the rest of the week (as per brief).
      if (unsafeToMove.length) {
        logWarn({
          stage: 'unsafe_shifts_not_moved',
          import_id: importId,
          preview_group_id: previewGroupId,
          count: unsafeToMove.length,
          sample: unsafeToMove.slice(0, 10)
        });
      }

      // Patch shifts to base timesheet:
      // - do not patch skipped shifts unless already on base (no-op)
      // - do not patch shifts that are unsafe to move (locked/paid holders)
      const unsafeShiftIdSet = new Set(unsafeToMove.map(x => String(x.shift_id)));

      const shiftIdsForTs = grpShifts
        .filter(s => {
          if (!s?.id) return false;
          if (unsafeShiftIdSet.has(String(s.id))) return false;

          const ek = s?.external_row_key ? String(s.external_row_key) : null;
          if (!ek) return true;
          if (!skipSet.has(ek)) return true;
          return String(s.timesheet_id || '') === String(ts.timesheet_id);
        })
        .map(s => s.id);

      // ✅ NEW: donor timesheets we actually moved shifts OFF (for TSFIN rebuild)
      const movedFromTimesheetIds = new Set();
      if (shiftIdsForTs.length) {
        const movedShiftIdSet = new Set(shiftIdsForTs.map(x => String(x)));
        for (const sh of grpShifts) {
          if (!sh?.id) continue;
          if (!movedShiftIdSet.has(String(sh.id))) continue;
          const fromTsId = sh?.timesheet_id ? String(sh.timesheet_id) : null;
          if (fromTsId && fromTsId !== String(ts.timesheet_id)) movedFromTimesheetIds.add(fromTsId);
        }
      }

      if (shiftIdsForTs.length) {
        const shParam = shiftIdsForTs.map(enc).join(',');
        await fetch(
          `${env.SUPABASE_URL}/rest/v1/nhsp_shifts?id=in.(${shParam})`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              timesheet_id: ts.timesheet_id,
              contract_id:  contract.id,
              candidate_id: candidateId,
              client_id: clientId,
              updated_at:   new Date().toISOString()
            })
          }
        ).catch(() => {});
      }

      // Snapshot list:
      // - include all shifts that are (a) non-skipped OR skipped but already on base
      // - exclude shifts not moved because they remain on other (possibly locked) timesheets
      const grpShiftsForSnapshot = grpShifts.filter(s => {
        const ek = s?.external_row_key ? String(s.external_row_key) : null;
        if (s?.id && unsafeShiftIdSet.has(String(s.id))) return false; // remains elsewhere
        if (!ek) return true;
        if (!skipSet.has(ek)) return true;
        return String(s.timesheet_id || '') === String(ts.timesheet_id);
      });

      // ✅ IMPORTANT: this is compute/validation-only (does NOT write TSFIN).
      // TSFIN persistence is handled via tsfinTargetedDrainNow below.
      let snapRes = null;
      try {
        snapRes = await buildNhspWeeklySnapshotCached(
          env,
          ts,
          contract,
          grpShiftsForSnapshot,
          importId,
          'NHSP',
          getPolicyCached
        );
      } catch (e) {
        snapRes = { ok: false, reason: e?.message || String(e) };
      }

      if (!snapRes || snapRes.ok !== true) {
        addFail(previewGroupId, actionUpper, `buildNhspWeeklySnapshotCached failed: ${snapRes?.reason || 'UNKNOWN'}`, {
          timesheet_id: ts?.timesheet_id || null,
          contract_id: contract?.id || null
        });
        continue;
      }

      // Per-day references (store for UI)
      try {
        const dayRefs = {};
        for (const sh of grpShiftsForSnapshot) {
          const ymd = sh.work_date;
          const ref = sh.ref_num || sh.nhsp_ref_num || null;
          if (!ymd || !ref) continue;
          if (!dayRefs[ymd]) dayRefs[ymd] = ref;
        }
        await fetch(
          `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              day_references_json: Object.keys(dayRefs).length ? dayRefs : null,
              updated_at: nowIso
            })
          }
        ).catch(() => {});
      } catch (e) {
        logWarn({ stage: 'day_references_patch_failed_non_fatal', import_id: importId, err: e?.message || String(e) });
      }

      try {
        await upsertValidation(env, user, {
          timesheet_id: ts.timesheet_id,
          status: 'VALIDATION_OK',
          reason: 'NHSP_IMPORT',
          hr_reference: null,
          import_id: importId
        });
      } catch {
        // non-fatal
      }

      // Existing overpay-advance logic (kept)
      try {
        const totals = await computeNhspTotalsForShifts(env, contract, grpShiftsForSnapshot);
        if (!(totals?.missingBuckets && totals.missingBuckets.length)) {
          const diff = round2((totals.totalChgEx || 0) - (totals.totalPayEx || 0));
          if (diff > NHSP_OVERPAY_ADVANCE_THRESHOLD) {
            await createOverpayAdvance(env, {
              candidate_id: candidateId,
              client_id: clientId,
              amount: diff,
              reason: 'NHSP_IMPORT',
              notes: `Auto overpay advance from NHSP weekly import ${importId}, week ${weekStart}`,
              week_start: weekStart
            });
          }
        }
      } catch (e) {
        logWarn({ stage: 'overpay_advance_logic_failed_non_fatal', import_id: importId, err: e?.message || String(e) });
      }

      // ✅ FIX (Bug #1): enqueue TSFIN + targeted inline drain (base + donors we moved shifts off)
      try {
        const donorTsIds = Array.from(movedFromTimesheetIds);
        const drainIds = [String(ts.timesheet_id), ...donorTsIds];

        const drainRes = await tsfinTargetedDrainNow(env, {
          timesheetIds: drainIds,
          reason: 'CONTEXT_CHANGED',
          chunkSize: 50
        });

        logInfo({
          stage: 'tsfin_enqueued_and_drained',
          import_id: importId,
          preview_group_id: previewGroupId,
          timesheet_id: ts.timesheet_id,
          donor_timesheet_ids: donorTsIds,
          drain: drainRes
        });
      } catch (e) {
        logWarn({
          stage: 'tsfin_enqueue_or_drain_failed_non_fatal',
          import_id: importId,
          preview_group_id: previewGroupId,
          timesheet_id: ts?.timesheet_id || null,
          err: e?.message || String(e)
        });
      }

      groups_succeeded++;
      logInfo({ stage: 'group_success', import_id: importId, preview_group_id: previewGroupId, timesheet_id: ts.timesheet_id });

    }

    logWarn({
      stage: 'completed',
      import_id: importId,
      shifts_created: created,
      shifts_updated: updated,
      mapped_candidates: mappedCandidates,
      mapped_clients: mappedClients,
      phase2_rows_ok: phase15Ok,
      phase2_rows_shift_updated: phase15Updated,
      groups_total,
      groups_attempted,
      groups_succeeded,
      groups_failed
    });

    await writeAudit(
      env,
      user,
      'NHSP_APPLY_COMPLETED',
      {
        import_id: importId,
        shifts_created: created,
        shifts_updated: updated,
        mapped_candidates: mappedCandidates,
        mapped_clients: mappedClients,
        phase2_rows_ok: phase15Ok,
        phase2_rows_shift_updated: phase15Updated,
        groups_total,
        groups_attempted,
        groups_succeeded,
        groups_failed,
        group_fail_samples: failSamples,

        // changed-hours stats + correction artefacts
        changed_hours_phase3_rows: (phase3?.rows || []).length,
        changed_hours_decision_required_rows: (phase3?.rows || []).filter(r => r && r.requires_any_decision).length,
        changed_hours_skipped_count: skipExternalRowKeys.length,
        changed_hours_forced_overwrite_count: forceOverwriteExternalRowKeys.length,
        changed_hours_correction_stats: corrStats
      },
      { entity: 'hr_imports', subject_id: importId, req }
    );

    return withCORS(env, req, ok({
      import_id: importId,
      shifts_created: created,
      shifts_updated: updated,
      mapped_candidates: mappedCandidates,
      mapped_clients: mappedClients,
      phase2_rows_ok: phase15Ok,
      phase2_rows_shift_updated: phase15Updated,
      groups_total,
      groups_attempted,
      groups_succeeded,
      groups_failed,
      group_fail_samples: failSamples,

      changed_hours: {
        phase3_rows: (phase3?.rows || []).length,
        decision_required_rows: (phase3?.rows || []).filter(r => r && r.requires_any_decision).length,
        skipped_external_row_keys: skipExternalRowKeys,
        forced_overwrite_external_row_keys: forceOverwriteExternalRowKeys,
        correction_stats: corrStats
      }
    }));
  } catch (e) {
    logError({ stage: 'unexpected_error', import_id: importId, error: e?.message || String(e) });
    return withCORS(env, req, serverError(`Failed to apply NHSP import: ${e?.message || e}`));
  }
}


 async function handleNhspRows(env, req, importId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!importId) {
    return withCORS(env, req, badRequest("import_id is required"));
  }

  try {
    const url = new URL(req.url);
    const q = (k) => url.searchParams.get(k);

    const limit  = Math.min(Math.max(parseInt(q('limit')  || '500', 10) || 500, 1), 5000);
    const offset = Math.max(parseInt(q('offset') || '0',   10) || 0, 0);
    const order  = q('order') || 'id.asc';

    const api =
      `${env.SUPABASE_URL}/rest/v1/hr_rows` +
      `?import_id=eq.${encodeURIComponent(importId)}` +
      `&select=*` +
      `&order=${encodeURIComponent(order)}` +
      `&limit=${limit}` +
      `&offset=${offset}`;

    const { rows } = await sbFetch(env, api, false);
    return withCORS(env, req, ok({ rows: rows || [], limit, offset }));
  } catch {
    return withCORS(env, req, serverError("Failed to fetch NHSP rows"));
  }
}

async function handleHrAutoprocessImport(env, req) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await parseJSONBody(req).catch(() => null);
  if (!body) return withCORS(env, req, badRequest("Invalid JSON"));

  const filename = (body.original_name || body.file_key || '').trim();
  const fileKey  = (body.file_key || '').trim();
  const clientId = body.client_id && String(body.client_id).trim();

  if (!filename) {
    return withCORS(env, req, badRequest("original_name or file_key is required"));
  }
  if (!fileKey) {
    return withCORS(env, req, badRequest("file_key is required for HealthRoster autoprocess import"));
  }
  if (!clientId) {
    return withCORS(env, req, badRequest("client_id is required for HealthRoster autoprocess"));
  }

  if (LOG) {
    console.log('[HR_WEEKLY_IMPORT]', JSON.stringify({
      stage: 'start',
      filename,
      file_key: fileKey,
      client_id: clientId,
      tz_assumption: body.tz_assumption || 'Europe/London'
    }));
  }

  try {
    const nowIso = new Date().toISOString();
    const tzAssumption = body.tz_assumption || 'Europe/London';

    // 1) Create hr_imports row for this HealthRoster file
    const payload = {
      filename,
      uploaded_by: user.id,
      uploaded_at_utc: nowIso,
      tz_assumption: tzAssumption,
      source_system: 'HEALTHROSTER',
      client_id: clientId,
      file_r2_key: fileKey,
      import_scope: 'HR_WEEKLY',
      parse_summary_json: {
        status: 'PENDING_PARSE',
        rows_total: 0,
        rows_parsed: 0,
        rows_skipped: 0,
        notes: null,
        header_columns: [] // ✅ ensure key exists from day 0
      }
    };

    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/hr_imports`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload),
    });

    if (!res.ok) {
      const err = await res.text();
      if (LOG) {
        console.error('[HR_WEEKLY_IMPORT]', JSON.stringify({
          stage: 'hr_imports_insert_failed',
          filename,
          file_key: fileKey,
          client_id: clientId,
          error: err
        }));
      }
      return withCORS(env, req, badRequest(`HR autoprocess import create failed: ${err}`));
    }

    const json = await res.json().catch(() => ([]));
    const rec = Array.isArray(json) ? json[0] : json;

    if (!rec || !rec.id) {
      if (LOG) {
        console.error('[HR_WEEKLY_IMPORT]', JSON.stringify({
          stage: 'no_import_id',
          filename,
          file_key: fileKey,
          client_id: clientId
        }));
      }
      return withCORS(env, req, serverError("HR autoprocess import create returned no id"));
    }

    const importId = rec.id;

    // 2) Parse the HealthRoster workbook into hr_rows
    let summary = {
      rows_total: 0,
      rows_parsed: 0,
      rows_skipped: 0,
      notes: null,
      header_columns: []
    };

    try {
      if (typeof parseHealthRosterWorkbookIntoHrRows === 'function') {
        summary = await parseHealthRosterWorkbookIntoHrRows(env, {
          import_id: importId,
          file_key: fileKey,
          client_id: clientId,
          tz: tzAssumption
        });
      } else {
        summary.notes = 'parseHealthRosterWorkbookIntoHrRows helper is not implemented.';
      }
    } catch (e) {
      summary.notes = `Parsing failed: ${e?.message || String(e)}`;
      if (LOG) {
        console.error('[HR_WEEKLY_IMPORT]', JSON.stringify({
          stage: 'parse_failed',
          import_id: importId,
          filename,
          file_key: fileKey,
          client_id: clientId,
          error: e?.message || String(e)
        }));
      }
    }

    // ✅ FIX: persist header_columns into hr_imports.parse_summary_json
    const headerCols =
      (summary && Array.isArray(summary.header_columns))
        ? summary.header_columns
        : [];

    // 3) Update parse_summary_json on hr_imports
    const patchBody = {
      parse_summary_json: {
        status: summary && !summary.error ? 'PARSED' : 'PARSE_FAILED',
        rows_total: Number(summary?.rows_total || 0),
        rows_parsed: Number(summary?.rows_parsed || 0),
        rows_skipped: Number(summary?.rows_skipped || 0),
        notes: summary?.notes || null,
        header_columns: headerCols
      }
    };

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/hr_imports?id=eq.${encodeURIComponent(importId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(patchBody)
      }
    ).catch(() => { /* best effort */ });

    if (LOG) {
      console.log('[HR_WEEKLY_IMPORT]', JSON.stringify({
        stage: 'after_parse',
        import_id: importId,
        filename,
        file_key: fileKey,
        client_id: clientId,
        tz_assumption: tzAssumption,
        parse_summary: patchBody.parse_summary_json
      }));
    }

    // 4) Audit
    await writeAudit(
      env,
      user,
      'HR_AUTOPROC_IMPORT_CREATED',
      {
        import_id: importId,
        filename,
        client_id: clientId,
        parse_summary: patchBody.parse_summary_json
      },
      { entity: 'hr_imports', subject_id: importId, req }
    );

    return withCORS(env, req, ok({
      import_id: importId,
      parse_summary: patchBody.parse_summary_json
    }));
  } catch (e) {
    if (LOG) {
      console.error('[HR_WEEKLY_IMPORT]', JSON.stringify({
        stage: 'unexpected_error',
        filename,
        file_key: fileKey,
        client_id: clientId,
        error: e?.message || String(e)
      }));
    }
    return withCORS(env, req, serverError("Failed to create HR autoprocess import"));
  }
}


async function handleHrAutoprocessApply(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  // ---- logging helpers (ALL logging is gated by LOG) ----
  const logInfo  = (obj) => { if (LOG) console.log('[HR_AUTOPROC_APPLY]', JSON.stringify(obj)); };
  const logWarn  = (obj) => { if (LOG) console.warn('[HR_AUTOPROC_APPLY]', JSON.stringify(obj)); };
  const logError = (obj) => { if (LOG) console.error('[HR_AUTOPROC_APPLY]', JSON.stringify(obj)); };

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) return withCORS(env, req, badRequest("import_id is required"));

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const selectedGroupIds = Array.isArray(body?.selected_group_ids)
    ? [...new Set(body.selected_group_ids.map(String).filter(Boolean))]
    : [];

  const candidateMappings = Array.isArray(body?.candidate_mappings) ? body.candidate_mappings : [];
  const clientAliases     = Array.isArray(body?.client_aliases)     ? body.client_aliases     : [];

  // NEW: decisions map keyed by external_row_key
  const decisions =
    (body && typeof body.decisions === 'object' && body.decisions && !Array.isArray(body.decisions))
      ? body.decisions
      : {};

  // Start log
  if (LOG) {
    logInfo({
      stage: 'start',
      import_id: importId,
      selected_group_ids_count: selectedGroupIds.length,
      candidate_mappings_count: candidateMappings.length,
      client_aliases_count: clientAliases.length,
      decisions_keys_count: Object.keys(decisions || {}).length
    });
  } else {
    console.log('[HR_AUTOPROC_APPLY] start', {
      importId,
      selectedGroupIds_count: selectedGroupIds.length,
      candidateMappings_count: candidateMappings.length,
      clientAliases_count: clientAliases.length,
      decisionsKeysCount: Object.keys(decisions || {}).length
    });
  }

  const enc    = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);

  const chunk = (arr, n) => {
    const out = [];
    for (let i = 0; i < (arr || []).length; i += n) out.push(arr.slice(i, i + n));
    return out;
  };

  // Helper: derive Mon–Sun week start from a week-ending date (ymd)
  const computeWeekStartFromWeekEnding = (weYmd) => {
    if (!weYmd) return null;
    const d = new Date(`${weYmd}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return weYmd;
    d.setUTCDate(d.getUTCDate() - 6);
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  // Threshold for legacy “overpay advance” behaviour (unchanged)
  const HR_OVERPAY_ADVANCE_THRESHOLD = 200;

  // ─────────────────────────────────────────────────────────────
  // request-scoped policy cache (prevents per-shift loadPolicy thrash)
  // key = `${client_id}__${dateYmd}`
  // ─────────────────────────────────────────────────────────────
  const _policyCache = new Map();
  const getPolicyCached = async (client_id, dateYmd) => {
    const k = `${String(client_id || '')}__${String(dateYmd || '')}`;
    if (_policyCache.has(k)) return _policyCache.get(k);
    const p = await loadPolicy(env, client_id, dateYmd);
    _policyCache.set(k, p);
    return p;
  };

  // ✅ Weekly truth totals must use contract rates (payChargeFromContract), not resolveRates
  async function computeHrTotalsForShifts(env, contract, client_id, shifts) {
    const pc  = payChargeFromContract(contract);
    const pay = pc?.pay || null;
    const chg = pc?.charge || null;

    const missing = new Set();

    if (!pay || !chg) {
      return { totalPayEx: 0, totalChgEx: 0, missingBuckets: ['CONTRACT_RATES_MISSING'] };
    }

    let totalPayEx = 0;
    let totalChgEx = 0;

    for (const sh of shifts) {
      const workDate = sh.work_date;
      if (!workDate || !sh.start_utc || !sh.end_utc) continue;

      const policy = await getPolicyCached(client_id, workDate);

      let segs = [[sh.start_utc, sh.end_utc]];
      segs = subtractBreak(segs, null, null, sh.break_mins || 0);

      const hours = classifyMinutes(env, policy, segs);

      const used = {
        day:   (hours.hours_day   || 0),
        night: (hours.hours_night || 0),
        sat:   (hours.hours_sat   || 0),
        sun:   (hours.hours_sun   || 0),
        bh:    (hours.hours_bh    || 0)
      };

      for (const k of ['day','night','sat','sun','bh']) {
        if ((used[k] || 0) > 0) {
          const pv = pay[k];
          const cv = chg[k];
          if (pv == null || pv === '' || !Number.isFinite(Number(pv))) missing.add(`pay:${k}`);
          if (cv == null || cv === '' || !Number.isFinite(Number(cv))) missing.add(`charge:${k}`);
        }
      }

      const payEx = round2(
        (used.day   || 0) * asNumberLocal(pay.day)   +
        (used.night || 0) * asNumberLocal(pay.night) +
        (used.sat   || 0) * asNumberLocal(pay.sat)   +
        (used.sun   || 0) * asNumberLocal(pay.sun)   +
        (used.bh    || 0) * asNumberLocal(pay.bh)
      );

      const chgEx = round2(
        (used.day   || 0) * asNumberLocal(chg.day)   +
        (used.night || 0) * asNumberLocal(chg.night) +
        (used.sat   || 0) * asNumberLocal(chg.sat)   +
        (used.sun   || 0) * asNumberLocal(chg.sun)   +
        (used.bh    || 0) * asNumberLocal(chg.bh)
      );

      totalPayEx += payEx;
      totalChgEx += chgEx;
    }

    return {
      totalPayEx: round2(totalPayEx),
      totalChgEx: round2(totalChgEx),
      missingBuckets: Array.from(missing)
    };
  }

  // legacy helper: “overpay advance” (kept for non-changed-hours legacy paths)
  async function createOverpayAdvance(env, { candidate_id, client_id, amount, reason, notes, week_start }) {
    try {
      const amt = Number(amount || 0);
      if (!candidate_id || !client_id || !(amt > 0)) return;

      const nowIso = new Date().toISOString();
      const ws     = week_start || null;
      const schedule = ws ? [{ week_start: ws, amount: -round2(amt) }] : [];

      const payload = [{
        candidate_id,
        client_id,
        reason,
        original_amount:    round2(amt),
        outstanding_amount: round2(amt),
        linked_shift_date:  null,
        schedule_json:      schedule,
        next_due_week_start: ws || null,
        status: 'ACTIVE',
        best_guess_hours: null,
        notes: notes || null,
        created_at: nowIso,
        updated_at: nowIso,
        created_by: user?.id || null
      }];

      await fetch(
        `${env.SUPABASE_URL}/rest/v1/pay_advances`,
        { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify(payload) }
      );
    } catch (e) {
      logWarn({ stage: 'createOverpayAdvance_failed_non_fatal', err: e?.message || String(e) });
    }
  }

  // ─────────────────────────────────────────────────────────────
  // REQUIRED dependency for applyWeeklyHoursCorrections:
  // createShiftPayAdjustment (idempotent by meta_json.correction_id)
  // ─────────────────────────────────────────────────────────────
  async function createShiftPayAdjustment(env, {
    timesheet_id,
    candidate_id,
    client_id,
    week_ending_date,
    delta_pay_ex_vat,
    note,
    meta_json
  }) {
    const delta = Number(delta_pay_ex_vat || 0);
    if (!timesheet_id || !candidate_id || !client_id) return null;
    if (!Number.isFinite(delta) || delta === 0) return null;

    const corrId = meta_json?.correction_id ? String(meta_json.correction_id) : null;

    if (corrId) {
      try {
        const { rows: ex } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments` +
          `?meta_json->>correction_id=eq.${enc(corrId)}` +
          `&select=id&limit=1`
        );
        if (ex && ex[0]) return ex[0];
      } catch {
        // ignore
      }
    }

    const payload = [{
      timesheet_id,
      candidate_id,
      client_id,
      week_ending_date,
      delta_pay_ex_vat: round2(delta),
      reason: 'HR_CHANGED_HOURS',
      note: note || null,
      meta_json: (meta_json && typeof meta_json === 'object') ? meta_json : {}
    }];

    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/ts_pay_adjustments`,
      { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(payload) }
    );

    if (!res.ok) {
      const t = await res.text().catch(() => '');
      throw new Error(`ts_pay_adjustments insert failed: ${t || res.status}`);
    }

    const json = await res.json().catch(() => []);
    return Array.isArray(json) ? json[0] : json;
  }

   // ─────────────────────────────────────────────────────────────
  // Invoice context helper for applyWeeklyHoursCorrections:
  // returns per-client cached { vatRatePct, findOrCreateBucket(weekStart), bumpTotals(...) }
  // VAT default now comes from finance windows (settings_finance_pick).
  // VAT used is the rate in force when invoice is created/amended (i.e. "today", Europe/London).
  // settings_defaults is NON-FINANCE ONLY here (bank details etc).
  // ─────────────────────────────────────────────────────────────
  const getInvoiceCtx = (() => {
    const _clientCache = new Map();        // client_id -> client row

    // Cache VAT by (client_id + anchorYmd) so "today" is stable during this request
    const _vatCache = new Map();           // key: `${client_id}__${anchorYmd}` -> vat rate pct

    const _defaultsCache = { loaded: false, row: null };
    const _bucketCache = new Map();        // `${client_id}__${weekStart}` -> invoice row

    // Cache finance VAT default per day (anchorYmd)
    const _financeVatCache = new Map();    // key: `${anchorYmd}` -> vat_rate_pct

    // Today (Europe/London) as YYYY-MM-DD
    const todayLondonYmd = () => {
      try {
        const s = new Intl.DateTimeFormat('en-GB', {
          timeZone: 'Europe/London',
          year: 'numeric',
          month: '2-digit',
          day: '2-digit'
        }).format(new Date());
        const [dd, mm, yyyy] = s.split('/');
        return `${yyyy}-${mm}-${dd}`;
      } catch {
        const d = new Date();
        const y = d.getUTCFullYear();
        const m = String(d.getUTCMonth() + 1).padStart(2, '0');
        const day = String(d.getUTCDate()).padStart(2, '0');
        return `${y}-${m}-${day}`;
      }
    };

    const loadDefaultsOnce = async () => {
      if (_defaultsCache.loaded) return _defaultsCache.row || {};
      try {
        // settings_defaults is NON-FINANCE ONLY (vat_rate_pct is now in finance windows)
        const { rows: defRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=bank_name,bank_sort_code,bank_account_number,vat_registration_number`
        );
        _defaultsCache.row = defRows?.[0] || {};
      } catch {
        _defaultsCache.row = {};
      }
      _defaultsCache.loaded = true;
      return _defaultsCache.row || {};
    };

    const loadClientRow = async (client_id) => {
      const k = String(client_id || '');
      if (!k) return null;
      if (_clientCache.has(k)) return _clientCache.get(k);
      const { rows: cliRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients?select=id,name,invoice_address,primary_invoice_email,vat_chargeable,payment_terms_days&id=eq.${enc(client_id)}&limit=1`
      );
      const cli = cliRows?.[0] || null;
      _clientCache.set(k, cli);
      return cli;
    };

    // VAT default from finance windows (settings_finance_pick)
    const loadFinanceVatDefaultPct = async (anchorYmd) => {
      const k = String(anchorYmd || '');
      if (_financeVatCache.has(k)) return _financeVatCache.get(k);

      let pct = 20; // safe fallback
      try {
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
          {
            method: 'POST',
            headers: { ...sbHeaders(env), 'content-type': 'application/json' },
            body: JSON.stringify({ p_date: k || null })
          }
        );
        const txt = await res.text().catch(() => '');
        if (res.ok) {
          const j = txt ? JSON.parse(txt) : null;
          const row = Array.isArray(j) ? j[0] : j;
          const v = Number(row?.vat_rate_pct);
          if (Number.isFinite(v)) pct = v;
        }
      } catch {
        // keep fallback
      }

      _financeVatCache.set(k, pct);
      return pct;
    };

    // Client override still applies, but default comes from finance windows.
    // Prevent future-dated client_settings rows applying early (effective_from <= anchorYmd).
    const loadVatRatePct = async (client_id, clientRow, anchorYmd) => {
      const k0 = String(client_id || '');
      const k1 = String(anchorYmd || '');
      const k = `${k0}__${k1}`;
      if (!k0) return 0;
      if (_vatCache.has(k)) return _vatCache.get(k);

      const defaultVat = await loadFinanceVatDefaultPct(anchorYmd);

      let vatRatePct = defaultVat;
      try {
        const { rows: csRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/client_settings` +
            `?select=client_id,vat_rate_pct,effective_from` +
            `&client_id=eq.${enc(client_id)}` +
            `&effective_from=lte.${enc(anchorYmd)}` +
            `&order=effective_from.desc&limit=1`
        );
        const cs = csRows?.[0] || null;

        const vatChargeable = (clientRow && typeof clientRow.vat_chargeable === 'boolean')
          ? clientRow.vat_chargeable !== false
          : true;

        vatRatePct = vatChargeable === false ? 0 : Number(cs?.vat_rate_pct ?? defaultVat);
      } catch {
        const vatChargeable = (clientRow && typeof clientRow.vat_chargeable === 'boolean')
          ? clientRow.vat_chargeable !== false
          : true;
        vatRatePct = vatChargeable === false ? 0 : defaultVat;
      }

      _vatCache.set(k, vatRatePct);
      return vatRatePct;
    };

    const bumpTotals = async (invoice_id, add_ex, add_vat, add_inc) => {
      try {
        const { rows: invRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoice_id)}&select=id,subtotal_ex_vat,vat_amount,total_inc_vat&limit=1`
        );
        const inv = invRows?.[0] || null;
        if (!inv) return;

        const newSubtotal = round2(Number(inv.subtotal_ex_vat || 0) + Number(add_ex || 0));
        const newVat      = round2(Number(inv.vat_amount || 0) + Number(add_vat || 0));
        const newInc      = round2(Number(inv.total_inc_vat || 0) + Number(add_inc || 0));

        await fetch(
          `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoice_id)}`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              subtotal_ex_vat: newSubtotal,
              vat_amount: newVat,
              total_inc_vat: newInc,
              updated_at: new Date().toISOString()
            })
          }
        ).catch(() => {});
      } catch {
        // ignore
      }
    };

    return async (client_id) => {
      const cli = await loadClientRow(client_id);
      if (!cli) throw new Error(`getInvoiceCtx: client not found (client_id=${client_id})`);

      const defaults = await loadDefaultsOnce();

      // ✅ Anchor VAT to “today” (Europe/London) because we are amending/creating invoices NOW.
      const anchorYmd = todayLondonYmd();
      const vatRatePct = await loadVatRatePct(client_id, cli, anchorYmd);

      const findOrCreateBucket = async (weekStart) => {
        const key = `${String(client_id)}__${String(weekStart)}`;
        if (_bucketCache.has(key)) return _bucketCache.get(key);

        const invoice = await findOrCreateSelfBillInvoice(
          env,
          client_id,
          weekStart,
          cli,
          [defaults],
          vatRatePct,
          [],
          []
        );

        if (!invoice || !invoice.id) throw new Error('findOrCreateSelfBillInvoice returned no invoice');
        _bucketCache.set(key, invoice);
        return invoice;
      };

      return { vatRatePct, findOrCreateBucket, bumpTotals };
    };
  })();


  // ─────────────────────────────────────────────────────────────
  // Helper: fetch TSFIN lock state for a set of timesheet_ids (missing TSFIN => safe)
  // ─────────────────────────────────────────────────────────────
  const loadTsfinLocks = async (timesheetIds) => {
    const ids = [...new Set((timesheetIds || []).filter(Boolean).map(String))];
    const finByTsId = new Map();
    if (!ids.length) return finByTsId;

    const chunkSize = 200;
    for (let i = 0; i < ids.length; i += chunkSize) {
      const c = ids.slice(i, i + chunkSize);
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=in.(${c.map(enc).join(',')})` +
        `&is_current=eq.true` +
        `&select=timesheet_id,locked_by_invoice_id,paid_at_utc`
      );
      for (const r of (rows || [])) {
        if (r && r.timesheet_id) finByTsId.set(String(r.timesheet_id), r);
      }
    }
    return finByTsId;
  };

  // ============================================================
  // MAIN FLOW
  // ============================================================
  try {
    // ─────────────────────────────────────────────
    // PHASE 0: explicit mappings (aliases only)
    // ─────────────────────────────────────────────
    try {
      await applyWeeklyMappingsOnly(env, {
        source_system: 'HEALTHROSTER',
        import_id: importId,
        candidate_mappings: candidateMappings,
        client_aliases:     clientAliases
      });
    } catch (e) {
      logWarn({ stage: 'applyWeeklyMappingsOnly_failed_non_fatal', import_id: importId, err: e?.message || String(e) });
    }

    // ─────────────────────────────────────────────
    // Load import header
    // ─────────────────────────────────────────────
    const { rows: impRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_imports` +
      `?id=eq.${enc(importId)}` +
      `&select=id,source_system,client_id,file_r2_key,parse_summary_json&limit=1`
    );
    const imp = impRows?.[0] || null;
    if (!imp) return withCORS(env, req, notFound("HealthRoster import not found"));
    if (imp.source_system !== 'HEALTHROSTER') {
      return withCORS(env, req, badRequest(`Import ${importId} is not HEALTHROSTER (source_system=${imp.source_system})`));
    }
    if (!imp.client_id) {
      return withCORS(env, req, badRequest("HealthRoster autoprocess import is missing client_id"));
    }

    // ─────────────────────────────────────────────
    // NEW (helper-wired):
    // Phase 3 load + decisions validation + correction actions
    // (before Phase 1)
    // ─────────────────────────────────────────────
    const phase3 = await loadWeeklyChangedHoursPhase3(env, importId, 'HEALTHROSTER');
    const decisionsNorm = validateWeeklyImportDecisions(phase3, decisions, { enforceMondayRange: true });

    const skipExternalRowKeys = Array.isArray(decisionsNorm.skipKeys) ? decisionsNorm.skipKeys : [];
    const forceOverwriteExternalRowKeys = Array.isArray(decisionsNorm.forceKeys) ? decisionsNorm.forceKeys : [];

    const skipSet = new Set(skipExternalRowKeys.map(String));
    const changedHoursKeySet = new Set([...skipExternalRowKeys, ...forceOverwriteExternalRowKeys].map(String));

    // Apply pay/invoice correction artefacts ONLY for PROCEED rows (idempotent)
    const corrStats = await applyWeeklyHoursCorrections(env, {
      user,
      req,
      import_id: importId,
      system_type: 'HEALTHROSTER',
      phase3,
      decisionsNorm,
      createShiftPayAdjustment,          // local helper above
      findOrCreateSelfBillInvoice,       // existing global
      getInvoiceCtx                      // local ctx builder above
    });

    logInfo({
      stage: 'phase3_corrections_done',
      import_id: importId,
      stats: corrStats,
      skip_count: skipExternalRowKeys.length,
      force_overwrite_count: forceOverwriteExternalRowKeys.length
    });

    // ─────────────────────────────────────────────
    // PHASE 1: hr_rows → nhsp_shifts in Postgres
    // UPDATED: pass skip/force arrays to SQL RPC
    // ─────────────────────────────────────────────
    let created = 0;
    let updated = 0;
    let mappedCandidates = 0;

    {
      const rpcBody = {
        import_id: importId,
        selected_group_ids: selectedGroupIds.length ? selectedGroupIds : null,

        // NEW PARAMS (SQL signature already updated):
        p_skip_external_row_keys: skipExternalRowKeys.length ? skipExternalRowKeys : null,
        p_force_overwrite_external_row_keys: forceOverwriteExternalRowKeys.length ? forceOverwriteExternalRowKeys : null
      };

      const rpcRes = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/hr_autoprocess_apply_phase1`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify(rpcBody)
        }
      );

      const txt = await rpcRes.text().catch(() => '');
      if (!rpcRes.ok) throw new Error(`hr_autoprocess_apply_phase1 failed: ${txt || rpcRes.status}`);

      let rpcJson;
      try { rpcJson = txt ? JSON.parse(txt) : null; } catch { rpcJson = null; }
      const row0 = Array.isArray(rpcJson) ? rpcJson[0] : rpcJson;
      const payload = row0?.hr_autoprocess_apply_phase1 || row0 || {};

      created          = Number(payload.shifts_created    ?? row0?.shifts_created ?? 0);
      updated          = Number(payload.shifts_updated    ?? row0?.shifts_updated ?? 0);
      mappedCandidates = Number(payload.mapped_candidates ?? row0?.mapped_candidates ?? 0);

      logInfo({
        stage: 'phase1_done',
        import_id: importId,
        summary: { created, updated, mappedCandidates }
      });
    }

    // ─────────────────────────────────────────────
    // PHASE 1.5: AUTHORITATIVE repair via weekly_import_apply_phase2(importId,'HR_WEEKLY')
    // ─────────────────────────────────────────────
    let phase15Rows = [];
    let phase15Ok = 0;
    let phase15Updated = 0;

    {
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/weekly_import_apply_phase2`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify({ p_import_id: importId, p_system_type: 'HR_WEEKLY' })
        }
      );
      const txt = await res.text().catch(() => '');
      if (!res.ok) throw new Error(`weekly_import_apply_phase2 failed: ${txt || res.status}`);

      try {
        const j = txt ? JSON.parse(txt) : [];
        phase15Rows = Array.isArray(j) ? j : [];
      } catch {
        phase15Rows = [];
      }

      phase15Ok = phase15Rows.filter(r => String(r?.action || '').toUpperCase() === 'OK').length;
      phase15Updated = phase15Rows.filter(r => r && r.shift_updated === true).length;
    }

    // ─────────────────────────────────────────────
    // PHASE 2: fetch shifts AFTER repair (essential)
    // ─────────────────────────────────────────────
    const { rows: allShifts } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
      `?latest_import_id=eq.${enc(importId)}&source_system=eq.HEALTHROSTER` +
      `&select=*`
    );
    const allShiftsArr = Array.isArray(allShifts) ? allShifts : [];

    const shiftByExternalKey = new Map();
    for (const s of allShiftsArr) {
      if (s && s.external_row_key) shiftByExternalKey.set(String(s.external_row_key), s);
    }

    // Build authoritative groups from Phase1.5 output
    const p2Ok = (phase15Rows || []).filter(r => {
      const act = String(r?.action || '').toUpperCase();
      return (
        act === 'OK' &&
        r?.external_row_key &&
        r?.candidate_id &&
        r?.client_id &&
        r?.contract_id &&
        r?.week_ending_date
      );
    });

    const p2GroupByPreviewId = new Map(); // preview_group_id -> {candidate_id, client_id, contract_id, week_ending_date, external_row_keys[]}
    for (const r of p2Ok) {
      const candidateId = String(r.candidate_id);
      const clientId    = String(r.client_id);
      const contractId  = String(r.contract_id);
      const we          = String(r.week_ending_date);
      const extKey      = String(r.external_row_key);

      const previewGroupId = `grp:${contractId}:${we}:${candidateId}`;
      let g = p2GroupByPreviewId.get(previewGroupId);
      if (!g) {
        g = { candidate_id: candidateId, client_id: clientId, contract_id: contractId, week_ending_date: we, external_row_keys: [] };
        p2GroupByPreviewId.set(previewGroupId, g);
      }
      if (!g.external_row_keys.includes(extKey)) g.external_row_keys.push(extKey);
    }

    // Classifier meta (selection + action semantics)
    const READY_ACTIONS = new Set([
      'NEW_AUTOPROC_TIMESHEET',
      'UPDATE_AUTOPROC_TS',
      'UPDATE_MANUAL_WEEK',
      'UPDATE_ADJUSTMENT_TS',
      'CREATE_ADJUSTMENT_TS',
      'CREATE_PAY_ADJUSTMENT_ONLY'
    ]);

    let classifiedGroups = [];
    try {
      const cls = await classifyWeeklyImportRows(env, importId, { source_system: 'HEALTHROSTER' });
      const rows = (cls && Array.isArray(cls.rows)) ? cls.rows : [];
      classifiedGroups = rows.filter(r => r && r.level === 'group');
    } catch (e) {
      classifiedGroups = [];
      logWarn({ stage: 'classify_failed_non_fatal', import_id: importId, err: e?.message || String(e) });
    }

    const metaByPreviewId = new Map();
    for (const g0 of classifiedGroups) {
      if (g0 && g0.preview_group_id) metaByPreviewId.set(String(g0.preview_group_id), g0);
    }
    if (!metaByPreviewId.size && p2GroupByPreviewId.size) {
      for (const [pid, g] of p2GroupByPreviewId.entries()) {
        metaByPreviewId.set(pid, {
          level: 'group',
          preview_group_id: pid,
          candidate_id: g.candidate_id,
          client_id: g.client_id,
          contract_id: g.contract_id,
          week_ending_date: g.week_ending_date,
          action: 'NEW_AUTOPROC_TIMESHEET',
          reason: 'No classifier result; apply fallback treats group as new.',
          default_selected: true
        });
      }
    }

    // Batch load contracts for all groups
    const contractById = new Map();
    {
      const contractIds = [...new Set([...p2GroupByPreviewId.values()].map(g => g.contract_id).filter(Boolean))];
      for (const idChunk of chunk(contractIds, 150)) {
        const { rows: cRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?id=in.(${idChunk.map(enc).join(',')})&select=*`
        );
        for (const c of (cRows || [])) contractById.set(c.id, c);
      }
    }

    // Batch load candidates + clients for norms (timesheets NOT NULL fields)
    const candidateById = new Map();
    const clientById    = new Map();
    {
      const candIds = [...new Set([...p2GroupByPreviewId.values()].map(g => g.candidate_id).filter(Boolean))];
      const cliIds  = [...new Set([...p2GroupByPreviewId.values()].map(g => g.client_id).filter(Boolean))];

      for (const idChunk of chunk(candIds, 150)) {
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/candidates?id=in.(${idChunk.map(enc).join(',')})&select=id,display_name,tms_ref`
        );
        for (const r of (rows || [])) candidateById.set(r.id, r);
      }

      for (const idChunk of chunk(cliIds, 150)) {
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/clients?id=in.(${idChunk.map(enc).join(',')})&select=id,name`
        );
        for (const r of (rows || [])) clientById.set(r.id, r);
      }
    }

    // Outcome counters
    let groups_total = 0;
    let groups_attempted = 0;
    let groups_succeeded = 0;
    let groups_failed = 0;
    const failSamples = [];

    const addFail = (preview_group_id, action, reason, debugExtra = null) => {
      groups_failed++;
      if (failSamples.length < 10) {
        const x = { preview_group_id: preview_group_id || null, action: action || null, reason: reason || null };
        if (debugExtra && typeof debugExtra === 'object') x.debug = debugExtra;
        failSamples.push(x);
      }
    };

    // Iterate authoritative Phase2 groups
    for (const [previewGroupId, p2g] of p2GroupByPreviewId.entries()) {
      groups_total++;

      const meta = metaByPreviewId.get(previewGroupId) || null;
      const actionUpper = String(meta?.action || 'NEW_AUTOPROC_TIMESHEET').trim().toUpperCase();
      const defaultSelected = (meta ? (meta.default_selected !== false) : true);

      const isSelected =
        selectedGroupIds.length
          ? selectedGroupIds.includes(previewGroupId)
          : defaultSelected;

      if (!isSelected) continue;
      if (!READY_ACTIONS.has(actionUpper)) continue;

      groups_attempted++;

      const clientId       = p2g.client_id || null;
      const candidateId    = p2g.candidate_id || null;
      const contractId     = p2g.contract_id || null;
      const weekEndingDate = p2g.week_ending_date || null;

      if (!clientId || !candidateId || !contractId || !weekEndingDate) {
        addFail(previewGroupId, actionUpper, 'Missing ids on Phase2 group', {
          client_id: clientId, candidate_id: candidateId, contract_id: contractId, week_ending_date: weekEndingDate
        });
        continue;
      }

      // Locate shift rows by external_row_key (authoritative row-set)
      const extKeys = Array.isArray(p2g.external_row_keys) ? p2g.external_row_keys.slice() : [];
      const grpShifts = [];
      const missingExt = [];
      for (const k of extKeys) {
        const sh = shiftByExternalKey.get(String(k)) || null;
        if (sh) grpShifts.push(sh);
        else missingExt.push(String(k));
      }
      if (!grpShifts.length) {
        addFail(previewGroupId, actionUpper, 'No shifts found for Phase2 external_row_keys (cannot apply).', {
          phase2_external_row_keys_count: extKeys.length,
          missing_external_row_keys_count: missingExt.length,
          sample_missing_external_row_keys: missingExt.slice(0, 5),
          all_import_rows: allShiftsArr.length
        });
        continue;
      }

      const contract = contractById.get(contractId) || null;
      if (!contract) {
        addFail(previewGroupId, actionUpper, 'Contract not found', { contract_id: contractId });
        continue;
      }

      const pc = payChargeFromContract(contract);
      if (!pc?.pay || !pc?.charge) {
        addFail(previewGroupId, actionUpper, 'Contract rates missing (rates_json incomplete)', { contract_id: contractId });
        continue;
      }

      // Load all contract_weeks for this contract/week (base + adjustments)
      const { rows: cwRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(contract.id)}` +
        `&week_ending_date=eq.${enc(weekEndingDate)}` +
        `&select=id,additional_seq,is_adjustment,timesheet_id,status` +
        `&order=additional_seq.asc`
      );
      let weeks = Array.isArray(cwRows) ? cwRows : [];
      let baseWeek = weeks.find(w => !w.is_adjustment && Number(w.additional_seq || 0) === 0) || null;
      const adjWeeks = weeks.filter(w => !!w.is_adjustment);
      const nowIso = new Date().toISOString();

      // Ensure baseWeek exists
      if (!baseWeek) {
        const ins = await fetch(
          `${env.SUPABASE_URL}/rest/v1/contract_weeks`,
          {
            method: 'POST',
            headers: { ...sbHeaders(env), Prefer: 'return=representation' },
            body: JSON.stringify([{
              contract_id: contract.id,
              week_ending_date: weekEndingDate,
              additional_seq: 0,
              is_adjustment: false,
              status: 'SUBMITTED',
              created_at: nowIso,
              updated_at: nowIso
            }])
          }
        );
        const txt = await ins.text().catch(() => '');
        if (!ins.ok) {
          addFail(previewGroupId, actionUpper, `contract_weeks insert failed: ${txt || ins.status}`);
          continue;
        }
        const j = txt ? JSON.parse(txt) : [];
        baseWeek = Array.isArray(j) ? j[0] : j;
        weeks = [baseWeek, ...weeks];
      }

      // Ensure/locate base timesheet for baseWeek
      let ts = null;

      let bookingId = null;
      try { bookingId = await makeWeeklyBookingId(contract.candidate_id || candidateId, contract, baseWeek); } catch { bookingId = null; }
      if (!bookingId || typeof bookingId !== 'string' || !bookingId.trim()) {
        addFail(previewGroupId, actionUpper, 'Invalid booking_id computed for base week', {
          contract_id: contract.id,
          candidate_id: contract.candidate_id || candidateId,
          week_ending_date: weekEndingDate,
          booking_id: bookingId
        });
        continue;
      }

      if (baseWeek.timesheet_id) {
        const { rows: tsRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(baseWeek.timesheet_id)}&is_current=eq.true&select=*` +
          `&limit=1`
        );
        ts = tsRows?.[0] || null;
      }

      if (!ts) {
        const { rows: tsRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?booking_id=eq.${enc(bookingId)}&is_current=eq.true&select=*` +
          `&limit=1`
        );
        ts = tsRows?.[0] || null;

        if (ts && !baseWeek.timesheet_id) {
          await fetch(
            `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(baseWeek.id)}`,
            { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify({ timesheet_id: ts.timesheet_id, status: 'SUBMITTED', updated_at: nowIso }) }
          ).catch(() => {});
          baseWeek.timesheet_id = ts.timesheet_id;
        }
      }

      if (!ts) {
  const cand = candidateById.get(candidateId) || null;
  const cli  = clientById.get(clientId) || null;
  const firstShift = grpShifts[0] || {};

  const occupantKeyNorm = String(cand?.tms_ref || cand?.display_name || candidateId || 'worker').toLowerCase();
  const hospitalNorm    = String(contract.display_site || cli?.name || clientId || 'client').toLowerCase();
  const wardNorm        = String(contract.ward_hint || firstShift.ward || 'contract').toLowerCase();
  const jobTitleNorm    = String(contract.role || 'hr-weekly').toLowerCase();

  // ✅ FIX: determine next version for booking_id (NOT hard-coded 1)
  let nextVersion = 1;
  try {
    const { rows: vRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(bookingId)}` +
        `&select=version` +
        `&order=version.desc` +
        `&limit=1`
    );
    const maxV = vRows?.[0]?.version != null ? Number(vRows[0].version) : null;
    nextVersion = Number.isFinite(maxV) ? (maxV + 1) : 1;
  } catch {
    nextVersion = 1;
  }

  // ✅ Optional but recommended: demote any current row for this booking_id (keeps invariants clean)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(bookingId)}` +
      `&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({
        is_current: false,
        status: 'REVOKED',
        revoked_reason: 'IMPORT_REPLACED_BY_AUTOPROC',
        revoked_by: user?.id || null,
        updated_at: nowIso
      })
    }
  ).catch(() => {});
// AFTER (fixed – explicitly force “non-QR” on import-created timesheets)
const tsPayload = [{
  booking_id: bookingId,
  version: nextVersion,
  is_current: true,
  status: 'RECEIVED',
  sheet_scope: 'WEEKLY',
  submission_mode: 'MANUAL',
  line_type: 'HOURS',
  occupant_key_norm: occupantKeyNorm,
  hospital_norm: hospitalNorm,
  ward_norm: wardNorm,
  job_title_norm: jobTitleNorm,
  shift_label_norm: 'weekly',
  week_ending_date: weekEndingDate,
  contract_id: contract.id,

  manual_pdf_r2_key: null,
  actual_schedule_json: [],
  authorised_at_server: null,

  // ✅ FIX: imports must NEVER default into QR mode
  qr_status: null,
  qr_token: null,
  qr_generated_at: null,
  qr_scanned_at: null,
  qr_scan_info_json: null,
  qr_r2_key: null,
  qr_payload_json: {},

  created_at: nowIso,
  updated_at: nowIso
}];
  const ins = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets`,
    { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(tsPayload) }
  );
  const txt = await ins.text().catch(() => '');
  if (!ins.ok) {
    addFail(
      previewGroupId,
      actionUpper,
      `timesheets insert failed (base): ${txt || ins.status}`,
      { booking_id: bookingId, attempted_version: nextVersion }
    );
    continue;
  }
  const j = txt ? JSON.parse(txt) : [];
  ts = Array.isArray(j) ? j[0] : j;

  if (!ts?.timesheet_id) {
    addFail(previewGroupId, actionUpper, 'timesheets insert returned no timesheet_id (base)');
    continue;
  }

  await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(baseWeek.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify({ timesheet_id: ts.timesheet_id, status: 'SUBMITTED', updated_at: nowIso })
    }
  ).catch(() => {});
  baseWeek.timesheet_id = ts.timesheet_id;
}


      if (!ts?.timesheet_id) {
        addFail(previewGroupId, actionUpper, 'Base timesheet missing timesheet_id after ensure/create');
        continue;
      }

      // If group is touched by changed-hours keys and base is paid OR invoiced, we skip legacy adjustment logic
      const groupTouchedByChangedHours = extKeys.some(k => changedHoursKeySet.has(String(k)));

      const { rows: finRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true` +
        `&select=id,timesheet_id,locked_by_invoice_id,paid_at_utc,total_pay_ex_vat,total_charge_ex_vat,invoice_breakdown_json` +
        `&limit=1`
      );
      const baseFinRow = finRows?.[0] || null;
      const basePaid = !!(baseFinRow && baseFinRow.paid_at_utc);
      const baseInvoiced = !!(baseFinRow && baseFinRow.locked_by_invoice_id);

      if (groupTouchedByChangedHours && (basePaid || baseInvoiced)) {
        // Corrections were already produced by applyWeeklyHoursCorrections + Phase1 overwrite controls.
        // Do NOT run any legacy delta/adjustment paths for this group.
        try {
          await upsertValidation(env, user, {
            timesheet_id: ts.timesheet_id,
            status: 'VALIDATION_OK',
            reason: 'HEALTHROSTER_IMPORT',
            hr_reference: null,
            import_id: importId
          });
        } catch {}

        groups_succeeded++;
        logInfo({
          stage: 'group_short_circuit_changed_hours',
          import_id: importId,
          preview_group_id: previewGroupId,
          timesheet_id: ts.timesheet_id,
          paid_at_utc: baseFinRow?.paid_at_utc || null,
          locked_by_invoice_id: baseFinRow?.locked_by_invoice_id || null
        });
        continue;
      }

      // Destination base must be safe (missing TSFIN counts as safe)
      if (basePaid || baseInvoiced) {
        addFail(previewGroupId, actionUpper, 'Base timesheet is paid/locked; refusing to move shifts or rebuild.', { timesheet_id: ts.timesheet_id });
        continue;
      }

      // Current-holder lock/paid checks for shifts (missing TSFIN => safe)
      // Skipped shifts must not block the group if they are not being moved.
      const existingTsIds = [...new Set(grpShifts.map(s => s && s.timesheet_id).filter(Boolean).map(String))];
      const existingFinByTs = await loadTsfinLocks(existingTsIds);

      const unsafeShiftIds = [];
      const unsafeTsIds = new Set();
      for (const sh of grpShifts) {
        const curTsId = sh?.timesheet_id ? String(sh.timesheet_id) : null;
        if (!curTsId) continue;

        const ek = sh?.external_row_key ? String(sh.external_row_key) : null;
        if (ek && skipSet.has(ek) && curTsId !== String(ts.timesheet_id)) continue;

        const fin = existingFinByTs.get(curTsId) || null;
        if (!fin) continue;
        if (fin.locked_by_invoice_id || fin.paid_at_utc) {
          unsafeShiftIds.push(sh.id);
          unsafeTsIds.add(curTsId);
        }
      }
      if (unsafeShiftIds.length) {
        addFail(previewGroupId, actionUpper, 'Some shifts are currently linked to paid/locked timesheets; refusing to move them automatically.', {
          unsafe_shift_count: unsafeShiftIds.length,
          unsafe_timesheet_ids: Array.from(unsafeTsIds).slice(0, 10),
          sample_unsafe_shift_ids: unsafeShiftIds.slice(0, 10)
        });
        continue;
      }

          // Move shifts to base, excluding skipped shifts (unless already on base)
      const shiftIdsForTs = grpShifts
        .filter(s => {
          const ek = s?.external_row_key ? String(s.external_row_key) : null;
          if (!ek) return true;
          if (!skipSet.has(ek)) return true;
          return String(s.timesheet_id || '') === String(ts.timesheet_id);
        })
        .map(s => s.id)
        .filter(Boolean);

      // ✅ NEW: donor timesheets we actually moved shifts OFF (for TSFIN rebuild)
      const movedFromTimesheetIds = new Set();
      if (shiftIdsForTs.length) {
        const movedShiftIdSet = new Set(shiftIdsForTs.map(x => String(x)));
        for (const sh of grpShifts) {
          if (!sh?.id) continue;
          if (!movedShiftIdSet.has(String(sh.id))) continue;
          const fromTsId = sh?.timesheet_id ? String(sh.timesheet_id) : null;
          if (fromTsId && fromTsId !== String(ts.timesheet_id)) movedFromTimesheetIds.add(fromTsId);
        }
      }

      if (shiftIdsForTs.length) {
        const shParam = shiftIdsForTs.map(enc).join(',');
        await fetch(
          `${env.SUPABASE_URL}/rest/v1/nhsp_shifts?id=in.(${shParam})`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({
              timesheet_id: ts.timesheet_id,
              contract_id: contract.id,
              candidate_id: candidateId,
              client_id: clientId,
              updated_at: nowIso
            })
          }
        ).catch(() => {});
      }

      // Refresh shifts for snapshot rebuild (exclude skipped unless already on base)
      const grpShiftsFresh = grpShifts
        .filter(s => {
          const ek = s?.external_row_key ? String(s.external_row_key) : null;
          if (!ek) return true;
          if (!skipSet.has(ek)) return true;
          return String(s.timesheet_id || '') === String(ts.timesheet_id);
        })
        .map(s => {
          const k = s && s.external_row_key ? String(s.external_row_key) : null;
          return k ? (shiftByExternalKey.get(k) || s) : s;
        });

      // Compute truth totals (for legacy selection / validation)
      const truthRes = await computeHrTotalsForShifts(env, contract, clientId, grpShiftsFresh);
      if (truthRes?.missingBuckets && truthRes.missingBuckets.length) {
        addFail(previewGroupId, actionUpper, `Missing contract buckets: ${truthRes.missingBuckets.join(', ')}`);
        continue;
      }

      // Safe path: base unpaid/uninvoiced => rebuild snapshot from repaired shifts
      // (uses your patched snapshot builder that preserves per-segment flags/locks)
      // ✅ IMPORTANT: this is compute/validation-only (does NOT persist TSFIN rows).
      const okSnap = await (async () => {
        try {
   const r = await buildNhspWeeklySnapshotCached(
  env,
  ts,
  contract,
  grpShiftsFresh,
  importId,
  'HEALTHROSTER_SELF_BILL',
  getPolicyCached
);

          return !!(r && r.ok === true);
        } catch {
          return false;
        }
      })();

      if (!okSnap) {
        addFail(previewGroupId, actionUpper, 'build snapshot failed (base rebuild)');
        continue;
      }

      try {
        await upsertValidation(env, user, {
          timesheet_id: ts.timesheet_id,
          status: 'VALIDATION_OK',
          reason: 'HEALTHROSTER_IMPORT',
          hr_reference: null,
          import_id: importId
        });
      } catch {}

      // ✅ FIX (Bug #1): enqueue TSFIN + targeted inline drain (base + donors we moved shifts off)
      try {
        const donorTsIds = Array.from(movedFromTimesheetIds);
        const drainIds = [String(ts.timesheet_id), ...donorTsIds];

        const drainRes = await tsfinTargetedDrainNow(env, {
          timesheetIds: drainIds,
          reason: 'CONTEXT_CHANGED',
          chunkSize: 50
        });

        logInfo({
          stage: 'tsfin_enqueued_and_drained',
          import_id: importId,
          preview_group_id: previewGroupId,
          timesheet_id: ts.timesheet_id,
          donor_timesheet_ids: donorTsIds,
          drain: drainRes
        });
      } catch (e) {
        logWarn({
          stage: 'tsfin_enqueue_or_drain_failed_non_fatal',
          import_id: importId,
          preview_group_id: previewGroupId,
          timesheet_id: ts?.timesheet_id || null,
          err: e?.message || String(e)
        });
      }

      groups_succeeded++;

    }

    // ─────────────────────────────────────────────
    // Mark import as applied + scope
    // ─────────────────────────────────────────────
    try {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/hr_imports?id=eq.${enc(importId)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            import_scope: 'HR_WEEKLY',
            applied_at: new Date().toISOString()
          })
        }
      );
    } catch (e) {
      logWarn({ stage: 'mark_import_applied_failed_non_fatal', import_id: importId, err: e?.message || String(e) });
    }

    // HR weekly cross-check for all affected slots
    await applyWeeklyHealthRosterCrosscheck(env, { import_id: importId });

    await writeAudit(
      env,
      user,
      'HR_AUTOPROC_APPLY_COMPLETED',
      {
        import_id: importId,
        shifts_created: created,
        shifts_updated: updated,
        mapped_candidates: mappedCandidates,
        phase2_rows_ok: phase15Ok,
        phase2_rows_shift_updated: phase15Updated,
        groups_total,
        groups_attempted,
        groups_succeeded,
        groups_failed,
        group_fail_samples: failSamples,
        changed_hours_phase3_rows: phase3.rows.length,
        changed_hours_decision_required_rows: (phase3.rows || []).filter(r => r && r.requires_any_decision).length,
        changed_hours_skipped_count: (skipExternalRowKeys || []).length,
        changed_hours_forced_overwrite_count: (forceOverwriteExternalRowKeys || []).length
      },
      { entity: 'hr_imports', subject_id: importId, req }
    );

    return withCORS(env, req, ok({
      import_id: importId,
      shifts_created: created,
      shifts_updated: updated,
      mapped_candidates: mappedCandidates,
      phase2_rows_ok: phase15Ok,
      phase2_rows_shift_updated: phase15Updated,
      groups_total,
      groups_attempted,
      groups_succeeded,
      groups_failed,
      group_fail_samples: failSamples,
      changed_hours: {
        phase3_rows: phase3.rows.length,
        decision_required_rows: (phase3.rows || []).filter(r => r && r.requires_any_decision).length,
        skipped_external_row_keys: skipExternalRowKeys,
        forced_overwrite_external_row_keys: forceOverwriteExternalRowKeys
      }
    }));
  } catch (e) {
    console.error('[HR_AUTOPROC_APPLY]', JSON.stringify({
      stage: 'unexpected_error',
      import_id: importId,
      err: e?.message || String(e)
    }));
    return withCORS(env, req, serverError(`Failed to apply HealthRoster autoprocess import: ${e?.message || e}`));
  }
}

// ─────────────────────────────────────────────────────────────
// HR weekly cross-check enricher for TSFIN (DB-correct)
// Signature matches: enrichTsfinWithHrCrosscheck(env, ts, tsfinRow)
// ─────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────
// HR weekly cross-check enricher for TSFIN
// ✅ Now accepts optional effFlags to avoid per-timesheet context RPC
// Signature: enrichTsfinWithHrCrosscheck(env, ts, tsfinRow, effFlagsIn?)
// ─────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────
// HR weekly cross-check enricher for TSFIN
// ✅ Updated: accepts effFlags + preloaded NHSP shifts (batched) to avoid per-timesheet REST calls
// Signature: enrichTsfinWithHrCrosscheck(env, ts, tsfinRow, effFlagsIn = null, nhspShiftsIn = null)
// ─────────────────────────────────────────────────────────────
async function enrichTsfinWithHrCrosscheck(env, ts, tsfinRow, effFlagsIn = null, nhspShiftsIn = null) {
  const LOG = true;
  const L   = (...a) => { if (LOG) console.log('[TSFIN][HR_XCHECK]', ...a); };
  const enc = encodeURIComponent;

  const tsId = tsfinRow?.timesheet_id || ts?.timesheet_id || null;
  if (!tsId) return tsfinRow;

  // Only applies to WEEKLY timesheets
  const sheetScope = String(ts?.sheet_scope || '').toUpperCase();
  if (sheetScope !== 'WEEKLY') {
    tsfinRow.hr_crosscheck_status = null;
    tsfinRow.hr_crosscheck_issues = null;
    return tsfinRow;
  }

  // Never mutate for locked/paid
  if (tsfinRow.locked_by_invoice_id || tsfinRow.paid_at_utc) {
    return tsfinRow;
  }

  const boolish = (v) => {
    if (v === true) return true;
    if (v === false) return false;
    if (v == null) return false;
    const s = String(v).trim().toLowerCase();
    return (s === 'true' || s === '1' || s === 'yes' || s === 'y' || s === 'on');
  };

  // ✅ Use provided flags (batched) when available; fallback to per-item RPC only if missing
  let effFlags = effFlagsIn;
  if (!effFlags) {
    try {
      const ctxRows = await rpcTsfinLoadContextBatch(env, { timesheetIds: [tsId] });
      const ctx = (Array.isArray(ctxRows) && ctxRows[0]) ? ctxRows[0] : null;
      effFlags = ctx?.out_effective_flags || null;
    } catch {}
  }

  const clientAutoprocessHr = boolish(effFlags?.client_autoprocess_hr);
  const noTimesheetRequired = boolish(effFlags?.client_no_timesheet_required);

  // If not HR-autoprocess weekly OR no-timesheet-required, clear HR fields
  if (!clientAutoprocessHr || noTimesheetRequired) {
    tsfinRow.hr_crosscheck_status = null;
    tsfinRow.hr_crosscheck_issues = null;

    const ext = (tsfinRow.external_source_rows_json && typeof tsfinRow.external_source_rows_json === 'object')
      ? JSON.parse(JSON.stringify(tsfinRow.external_source_rows_json))
      : {};
    if (ext && ext.HR_WEEKLY) delete ext.HR_WEEKLY;
    tsfinRow.external_source_rows_json = ext;

    return tsfinRow;
  }

  const clientId    = tsfinRow.client_id || null;
  const candidateId = tsfinRow.candidate_id || null;
  const weekEnd     = ts?.week_ending_date || null;

  if (!clientId || !candidateId || !weekEnd) {
    tsfinRow.hr_crosscheck_status = null;
    tsfinRow.hr_crosscheck_issues = null;
    return tsfinRow;
  }

  // Compute weekStart = weekEnd - 6 days (UTC YMD math)
  const weekEndDate = new Date(`${weekEnd}T00:00:00Z`);
  if (Number.isNaN(weekEndDate.getTime())) {
    tsfinRow.hr_crosscheck_status = null;
    tsfinRow.hr_crosscheck_issues = null;
    return tsfinRow;
  }
  const weekStartDate = new Date(weekEndDate.getTime());
  weekStartDate.setUTCDate(weekStartDate.getUTCDate() - 6);

  const toYmd = (d) =>
    `${d.getUTCFullYear()}-${String(d.getUTCMonth() + 1).padStart(2,'0')}-${String(d.getUTCDate()).padStart(2,'0')}`;

  const weekStart = toYmd(weekStartDate);
  const weekEndY  = toYmd(weekEndDate);

  // DST-correct UK local HH:MM from UTC ISO
  const hhmmLondonFromIso = (iso) => {
    if (!iso) return null;
    const d = new Date(iso);
    if (Number.isNaN(d.getTime())) return null;
    try {
      return new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        hour: '2-digit',
        minute: '2-digit',
        hour12: false
      }).format(d);
    } catch {
      // fallback: UTC
      const hh = String(d.getUTCHours()).padStart(2,'0');
      const mm = String(d.getUTCMinutes()).padStart(2,'0');
      return `${hh}:${mm}`;
    }
  };

  const minutesFromHHMM = (hhmm) => {
    if (!hhmm || typeof hhmm !== 'string') return null;
    const m = hhmm.trim().match(/^(\d{1,2}):(\d{2})$/);
    if (!m) return null;
    const hh = Number(m[1]), mm = Number(m[2]);
    if (!Number.isFinite(hh) || !Number.isFinite(mm)) return null;
    if (hh < 0 || hh > 23 || mm < 0 || mm > 59) return null;
    return (hh * 60) + mm;
  };

  const diffMinsHHMM = (a, b) => {
    const am = minutesFromHHMM(a);
    const bm = minutesFromHHMM(b);
    if (am == null || bm == null) return null;
    let d = bm - am;
    if (d < 0) d += 1440; // overnight
    return d;
  };

  const computePaidMinutes = (startHHMM, endHHMM, breakMins) => {
    const s = minutesFromHHMM(startHHMM);
    const e = minutesFromHHMM(endHHMM);
    if (s == null || e == null) return null;
    let span = e - s;
    if (span < 0) span += 24 * 60; // overnight
    const br = Number(breakMins || 0) || 0;
    const paid = Math.max(0, span - br);
    return Number.isFinite(paid) ? Math.round(paid) : null;
  };

  // ─────────────────────────────────────────────
  // ✅ HR WEEKLY shifts: use preloaded list if provided; otherwise fallback to REST
  // ─────────────────────────────────────────────
  let hrShifts = [];

  if (Array.isArray(nhspShiftsIn)) {
    // Filter to this week's HR shifts for this sheet (and force source_system=HEALTHROSTER)
    hrShifts = nhspShiftsIn.filter(sh => {
      const ss = String(sh?.source_system || '').toUpperCase();
      if (ss !== 'HEALTHROSTER') return false;
      const d = String(sh?.work_date || '').trim();
      if (!/^\d{4}-\d{2}-\d{2}$/.test(d)) return false;
      return (d >= weekStart && d <= weekEndY);
    });
  } else {
    // Fallback (should become rare once caller batches)
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
          `?source_system=eq.HEALTHROSTER` +
          `&client_id=eq.${enc(clientId)}` +
          `&candidate_id=eq.${enc(candidateId)}` +
          `&work_date=gte.${enc(weekStart)}` +
          `&work_date=lte.${enc(weekEndY)}` +
          `&select=id,source_system,work_date,ward,start_utc,end_utc,break_mins,hr_request_id,assignment_code,ref_num,external_row_key` +
          `&order=work_date.asc,start_utc.asc,id.asc`
      );
      hrShifts = Array.isArray(rows) ? rows : [];
    } catch (e) {
      console.warn('[TSFIN][HR_XCHECK] failed to load HR shifts', { tsId, err: e?.message || String(e) });
      hrShifts = [];
    }
  }

  // Build HR per-day totals + snapshot
  const hrPaidByDate = {};
  const hrRowsSnapshot = [];

  for (const sh of (hrShifts || [])) {
    const d = String(sh.work_date || '').trim();
    if (!/^\d{4}-\d{2}-\d{2}$/.test(d)) continue;

    const startHHMM = hhmmLondonFromIso(sh.start_utc);
    const endHHMM   = hhmmLondonFromIso(sh.end_utc);
    const br        = Number(sh.break_mins || 0) || 0;
    const paid      = computePaidMinutes(startHHMM, endHHMM, br);

    hrRowsSnapshot.push({
      date: d,
      source_system: String(sh.source_system || 'HEALTHROSTER'),
      hr_request_id: sh.hr_request_id || null,
      nhsp_shift_id: sh.id || null,
      external_row_key: sh.external_row_key || null,
      ward: sh.ward || null,
      assignment_code: sh.assignment_code || null,
      ref_num: sh.ref_num || null,
      start: startHHMM,
      end: endHHMM,
      break_mins: br,
      paid_minutes: paid
    });

    if (paid != null) {
      hrPaidByDate[d] = (Number(hrPaidByDate[d] || 0) + Number(paid || 0));
    }
  }

  // Timesheet schedule (weekly): can be multiple segments per day
  const tsSchedule = Array.isArray(ts?.actual_schedule_json)
    ? ts.actual_schedule_json
    : (ts?.actual_schedule_json
        ? (() => { try { return JSON.parse(ts.actual_schedule_json); } catch { return []; } })()
        : []);

  const tsPaidByDate = {};

  for (const entry of (tsSchedule || [])) {
    const d = String(entry?.date || '').trim();
    if (!/^\d{4}-\d{2}-\d{2}$/.test(d)) continue;

    let startHHMM = (entry?.start != null) ? String(entry.start).trim() : '';
    let endHHMM   = (entry?.end   != null) ? String(entry.end).trim()   : '';

    if (!startHHMM && entry?.start_utc) startHHMM = hhmmLondonFromIso(entry.start_utc) || '';
    if (!endHHMM   && entry?.end_utc)   endHHMM   = hhmmLondonFromIso(entry.end_utc)   || '';

    startHHMM = startHHMM || null;
    endHHMM   = endHHMM || null;

    let br = 0;

    if (entry?.break_minutes != null) br = Number(entry.break_minutes || 0) || 0;
    else if (entry?.break_mins != null) br = Number(entry.break_mins || 0) || 0;
    else if (Array.isArray(entry?.breaks) && entry.breaks.length) {
      let sum = 0;
      for (const b of entry.breaks) {
        const bs = (b?.start != null) ? String(b.start).trim() : '';
        const be = (b?.end   != null) ? String(b.end).trim()   : '';
        const dm = diffMinsHHMM(bs, be);
        if (Number.isFinite(dm) && dm > 0) sum += dm;
      }
      br = sum;
    } else if (entry?.break_start || entry?.break_end) {
      const dm = diffMinsHHMM(String(entry.break_start || '').trim(), String(entry.break_end || '').trim());
      if (Number.isFinite(dm) && dm > 0) br = dm;
    }

    const paid = computePaidMinutes(startHHMM, endHHMM, br);
    if (paid != null) {
      tsPaidByDate[d] = (Number(tsPaidByDate[d] || 0) + Number(paid || 0));
    }
  }

  // Compare totals (per day)
  const allDates = new Set([...Object.keys(hrPaidByDate), ...Object.keys(tsPaidByDate)]);
  const issuesSet = new Set();

  if ((hrShifts || []).length === 0 && Object.keys(tsPaidByDate).length > 0) {
    issuesSet.add('HR_HOURS_MISSING');
  } else {
    for (const d of allDates) {
      const tsPaid = Number(tsPaidByDate[d] || 0);
      const hrPaid = Number(hrPaidByDate[d] || 0);

      const hasTs = tsPaid > 0;
      const hasHr = hrPaid > 0;

      if (hasTs && !hasHr) { issuesSet.add('HR_HOURS_MISSING'); continue; }
      if (!hasTs && hasHr) { issuesSet.add('HOURS_MISMATCH_HR'); continue; }

      if (hasTs && hasHr) {
        const tol = 1;
        const diff = Math.abs(tsPaid - hrPaid);
        if (diff > tol) issuesSet.add('HOURS_MISMATCH_HR');
      }
    }
  }

  const status =
    issuesSet.size === 0 ? 'OK'
    : (issuesSet.has('HR_HOURS_MISSING') ? 'HR_HOURS_MISSING' : 'HOURS_MISMATCH_HR');

  const ext = (tsfinRow.external_source_rows_json && typeof tsfinRow.external_source_rows_json === 'object')
    ? JSON.parse(JSON.stringify(tsfinRow.external_source_rows_json))
    : {};

  if (hrRowsSnapshot.length) ext.HR_WEEKLY = hrRowsSnapshot;
  else if (ext.HR_WEEKLY) delete ext.HR_WEEKLY;

  tsfinRow.hr_crosscheck_status = status;
  tsfinRow.hr_crosscheck_issues = issuesSet.size ? Array.from(issuesSet) : null;
  tsfinRow.external_source_rows_json = ext;

  L('result', { tsId, clientId, candidateId, weekStart, weekEnd: weekEndY, status, issues: tsfinRow.hr_crosscheck_issues });
  return tsfinRow;
}

// ============================================================
// Helpers for weekly changed-hours correction workflow
// (NHSP + HR weekly self-bill)
// ============================================================

/**
 * loadWeeklyChangedHoursPhase3(env, importId, systemType)
 *
 * Calls RPC weekly_import_changed_hours_phase3 and returns:
 *   { rows, byExternalKey }
 *
 * - rows: normalized objects (with stable field names + booleans/numbers coerced)
 * - byExternalKey: Map<external_row_key, row> (warns if duplicates found)
 *
 * systemType: 'NHSP' | 'HEALTHROSTER'  (accepts 'HR_WEEKLY' and maps to HEALTHROSTER defensively)
 */
async function loadWeeklyChangedHoursPhase3(env, importId, systemType) {
  const enc = encodeURIComponent;

  const rpcSystemType =
    String(systemType || '').toUpperCase() === 'NHSP' ? 'NHSP' :
    (String(systemType || '').toUpperCase() === 'HEALTHROSTER' || String(systemType || '').toUpperCase() === 'HR_WEEKLY') ? 'HEALTHROSTER' :
    null;

  if (!rpcSystemType) {
    throw new Error(`loadWeeklyChangedHoursPhase3: unsupported systemType=${systemType}`);
  }

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/rpc/weekly_import_changed_hours_phase3`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), 'content-type': 'application/json' },
      body: JSON.stringify({ p_import_id: importId, p_system_type: rpcSystemType })
    }
  );

  const txt = await res.text().catch(() => '');
  if (!res.ok) {
    throw new Error(`weekly_import_changed_hours_phase3 failed (${res.status}): ${txt || 'no body'}`);
  }

  let raw;
  try { raw = txt ? JSON.parse(txt) : []; } catch { raw = []; }
  const arr = Array.isArray(raw) ? raw : [];

  const asBool = (v) => (v === true || v === 'true' || v === 1 || v === '1');
  const asNum  = (v) => (v == null || v === '' ? null : (Number.isFinite(Number(v)) ? Number(v) : null));

  // tolerate column naming drift (defensive)
  const pick = (o, keys, dflt=null) => {
    for (const k of keys) {
      if (o && Object.prototype.hasOwnProperty.call(o, k) && o[k] != null) return o[k];
    }
    return dflt;
  };

  const rows = [];
  const byExternalKey = new Map();
  const dupKeys = new Set();

  for (const r0 of arr) {
    const ek = String(r0?.external_row_key || '').trim();
    if (!ek) continue;

    const n = {
      // identity
      hr_row_id: r0?.hr_row_id ?? null,
      external_row_key: ek,

      // ids
      shift_id: r0?.shift_id ?? null,
      candidate_id: r0?.candidate_id ?? null,
      client_id: r0?.client_id ?? null,
      contract_id: r0?.contract_id ?? null,
      timesheet_id: r0?.timesheet_id ?? null,
      week_ending_date: r0?.week_ending_date ?? null,

      // old/new time fields (names may vary)
      old_start_utc: pick(r0, ['old_start_utc','old_start','old_start_time_utc'], null),
      old_end_utc:   pick(r0, ['old_end_utc','old_end','old_end_time_utc'], null),
      old_break_mins: asNum(pick(r0, ['old_break_mins','old_break_minutes','old_break'], null)) ?? 0,

      new_start_utc: pick(r0, ['new_start_utc','new_start','new_start_time_utc'], null),
      new_end_utc:   pick(r0, ['new_end_utc','new_end','new_end_time_utc'], null),
      new_break_mins: asNum(pick(r0, ['new_break_mins','new_break_minutes','new_break'], null)) ?? 0,

      // state flags
      is_paid:     asBool(r0?.is_paid),
      is_invoiced: asBool(r0?.is_invoiced),

      // money fields (ex vat)
      old_pay_ex:   asNum(pick(r0, ['old_pay_ex','old_pay_ex_vat','old_pay'], null)),
      new_pay_ex:   asNum(pick(r0, ['new_pay_ex','new_pay_ex_vat','new_pay'], null)),
      delta_pay_ex: asNum(pick(r0, ['delta_pay_ex','delta_pay_ex_vat','delta_pay'], null)),

      old_charge_ex:   asNum(pick(r0, ['old_charge_ex','old_charge_ex_vat','old_charge'], null)),
      new_charge_ex:   asNum(pick(r0, ['new_charge_ex','new_charge_ex_vat','new_charge'], null)),
      delta_charge_ex: asNum(pick(r0, ['delta_charge_ex','delta_charge_ex_vat','delta_charge'], null)),

      // decision flags
      requires_pay_decision:     asBool(r0?.requires_pay_decision),
      requires_invoice_decision: asBool(r0?.requires_invoice_decision),
      requires_any_decision:     asBool(r0?.requires_any_decision),

      // raw (keep for debugging)
      _raw: r0
    };

    // --- shape validation (fail fast with useful message) ---
    // external_row_key already checked. For decision-needed rows we require the state flags.
    if (n.requires_any_decision && (typeof n.is_paid !== 'boolean' || typeof n.is_invoiced !== 'boolean')) {
      throw new Error(`Phase3 row missing is_paid/is_invoiced booleans for external_row_key=${ek}`);
    }

    rows.push(n);

    if (byExternalKey.has(ek)) dupKeys.add(ek);
    else byExternalKey.set(ek, n);
  }

  if (dupKeys.size) {
    console.warn('[PHASE3] duplicate external_row_key(s) returned (keeping first)', Array.from(dupKeys).slice(0, 20));
  }

  return { rows, byExternalKey };
}

/**
 * validateWeeklyImportDecisions(phase3, decisions, opts)
 *
 * Validates and normalizes decisions keyed by external_row_key.
 * - Rejects unknown keys in decisions.
 * - Requires a decision for every row where requires_any_decision=true.
 * - If PROCEED and is_invoiced=true, requires credit_week_start and reinvoice_week_start.
 * - Validates week starts are Mondays; optionally enforces ±4 Monday range from row.week_ending_date.
 *
 * Returns:
 *  {
 *    byKey: { [external_row_key]: { action:'SKIP'|'PROCEED', credit_week_start?, reinvoice_week_start? } },
 *    skipKeys: string[],
 *    forceKeys: string[],
 *    proceedRows: Array<{ row, decision }>, // convenience
 *  }
 */
function validateWeeklyImportDecisions(phase3, decisions, opts = {}) {
  const rows = Array.isArray(phase3?.rows) ? phase3.rows : [];
  const byExternal = (phase3?.byExternalKey instanceof Map) ? phase3.byExternalKey : new Map();

  const asBool = (v) => (v === true || v === 'true' || v === 1 || v === '1');

  const parseYmd = (ymd) => {
    if (!ymd || typeof ymd !== 'string') return null;
    const m = ymd.match(/^(\d{4})-(\d{2})-(\d{2})$/);
    if (!m) return null;
    const d = new Date(Date.UTC(Number(m[1]), Number(m[2]) - 1, Number(m[3])));
    return Number.isNaN(d.getTime()) ? null : d;
  };

  const isMondayYmd = (ymd) => {
    const d = parseYmd(ymd);
    return !!(d && d.getUTCDay() === 1);
  };

  const computeWeekStartFromWeekEnding = (weYmd) => {
    const d = parseYmd(weYmd);
    if (!d) return null;
    d.setUTCDate(d.getUTCDate() - 6); // Mon for a Sun week-ending
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const addDays = (ymd, days) => {
    const d = parseYmd(ymd);
    if (!d) return null;
    d.setUTCDate(d.getUTCDate() + Number(days || 0));
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const allowedKeys = new Set(rows.map(r => String(r.external_row_key || '').trim()).filter(Boolean));

  // Reject unknown keys (payload junk)
  const decisionKeys = decisions && typeof decisions === 'object' ? Object.keys(decisions) : [];
  const unknown = decisionKeys.filter(k => !allowedKeys.has(String(k).trim()));
  if (unknown.length) {
    throw new Error(`Decisions include unknown external_row_key(s): ${unknown.slice(0, 20).join(', ')}`);
  }

  const byKey = {};
  const skipKeys = [];
  const forceKeys = [];
  const proceedRows = [];

  for (const r of rows) {
    if (!r?.external_row_key) continue;
    const ek = String(r.external_row_key);

    if (!r.requires_any_decision) continue; // only validate required ones

    const d = decisions?.[ek];
    if (!d || typeof d !== 'object') {
      throw new Error(`Missing decision for decision-required external_row_key=${ek}`);
    }

    const action = asBool(d.skip) ? 'SKIP' : 'PROCEED';

    if (action === 'SKIP') {
      byKey[ek] = { action: 'SKIP' };
      skipKeys.push(ek);
      continue;
    }

    // proceed:
    const norm = { action: 'PROCEED' };

    if (r.is_invoiced) {
      const cw = d.credit_week_start || d.credit_week || d.creditWeekStart || null;
      const rw = d.reinvoice_week_start || d.reinvoice_week || d.reinvoiceWeekStart || null;

      if (!cw || !rw) {
        throw new Error(`Missing credit/reinvoice weeks for invoiced external_row_key=${ek}`);
      }
      if (!isMondayYmd(cw) || !isMondayYmd(rw)) {
        throw new Error(`credit_week_start and reinvoice_week_start must be Mondays (external_row_key=${ek})`);
      }

      if (opts.enforceMondayRange === true) {
        const base = computeWeekStartFromWeekEnding(r.week_ending_date);
        if (base) {
          const allowed = new Set();
          for (let i = -4; i <= 4; i++) allowed.add(addDays(base, i * 7));
          if (!allowed.has(cw) || !allowed.has(rw)) {
            throw new Error(`Invoice weeks must be within ±4 Mondays of base week (external_row_key=${ek}, base=${base})`);
          }
        }
      }

      norm.credit_week_start = cw;
      norm.reinvoice_week_start = rw;
    }

    byKey[ek] = norm;
    forceKeys.push(ek);
    proceedRows.push({ row: r, decision: norm });
  }

  return { byKey, skipKeys, forceKeys, proceedRows };
}

/**
 * Deterministic correction_id generator.
 * Uses import_id + external_row_key + old/new times as the “identity”
 * so retries don’t duplicate artefacts.
 */
function makeWeeklyHoursCorrectionId(importId, r) {
  const s = [
    String(importId || ''),
    String(r?.external_row_key || ''),
    String(r?.old_start_utc || ''),
    String(r?.new_start_utc || ''),
    String(r?.old_end_utc || ''),
    String(r?.new_end_utc || ''),
    String(r?.old_break_mins ?? ''),
    String(r?.new_break_mins ?? '')
  ].join('|');

  // FNV-1a 32-bit (sync, deterministic)
  let h = 0x811c9dc5;
  for (let i = 0; i < s.length; i++) {
    h ^= s.charCodeAt(i);
    h = Math.imul(h, 0x01000193);
  }
  const hex = (h >>> 0).toString(16).padStart(8, '0');
  return `chg:${importId}:${String(r?.external_row_key || '')}:${hex}`;
}

/**
 * createShiftRecoveryAdvance(env, args)
 *
 * Creates a pay_advances row for overpay recovery (schedule_json negative amount).
 * - reason enum must be OVERPAY_NHSP or OVERPAY_HR
 * - idempotent via notes containing correction_id (pay_advances has no meta_json)
 */
async function createShiftRecoveryAdvance(env, {
  candidate_id,
  client_id,
  amount,
  reason,              // 'OVERPAY_NHSP' | 'OVERPAY_HR'
  week_start,          // Monday YYYY-MM-DD
  notes,
  correction_id,
  created_by
}) {
  const enc = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  const amt = Number(amount || 0);
  if (!candidate_id || !client_id || !(amt > 0)) return null;
  if (reason !== 'OVERPAY_NHSP' && reason !== 'OVERPAY_HR') {
    throw new Error(`createShiftRecoveryAdvance: invalid reason=${reason}`);
  }

  // Idempotency probe (best-effort)
  if (correction_id) {
    try {
      const { rows: ex } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/pay_advances` +
          `?candidate_id=eq.${enc(candidate_id)}` +
          `&client_id=eq.${enc(client_id)}` +
          `&reason=eq.${enc(reason)}` +
          `&notes=ilike.${enc('%' + correction_id + '%')}` +
          `&select=id` +
          `&limit=1`
      );
      if (ex && ex[0]) return ex[0];
    } catch {
      // ignore probe failures
    }
  }

  const nowIso = new Date().toISOString();
  const ws = week_start || null;
  const schedule = ws ? [{ week_start: ws, amount: -round2(amt) }] : [];

  const payload = [{
    candidate_id,
    client_id,
    reason,
    original_amount:    round2(amt),
    outstanding_amount: round2(amt),
    linked_shift_date:  null,
    schedule_json:      schedule,
    next_due_week_start: ws || null,
    status: 'ACTIVE',
    best_guess_hours: null,
    notes: notes || null,
    created_at: nowIso,
    updated_at: nowIso,
    created_by: created_by || null
  }];

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/pay_advances`,
    { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(payload) }
  );
  const txt = await res.text().catch(() => '');
  if (!res.ok) throw new Error(`pay_advances insert failed: ${txt || res.status}`);

  let j; try { j = txt ? JSON.parse(txt) : []; } catch { j = []; }
  return Array.isArray(j) ? j[0] : j;
}

/**
 * createSingleLineCreditNoteForShift(...)
 *
 * Creates ONE negative invoice_line for old charge on the chosen credit week bucket invoice.
 * Stores traceability in invoice_lines.meta_json.
 *
 * Note: This uses self-bill weekly “bucket invoices” via findOrCreateSelfBillInvoice(...)
 * (consistent with your current self-bill invoice issuance pipeline).
 */
async function createSingleLineCreditNoteForShift(env, {
  user,
  req,
  import_id,
  system_type,
  correction_id,
  external_row_key,
  shift_id,
  timesheet_id,
  client_id,
  credit_week_start,
  old_charge_ex_vat,
  findOrCreateSelfBillInvoice,
  getInvoiceCtx
}) {
  const enc = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  const oldEx = Number(old_charge_ex_vat || 0);
  if (!Number.isFinite(oldEx)) throw new Error(`Credit: old_charge_ex_vat is not numeric (external_row_key=${external_row_key})`);

  const exists = await (async () => {
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/invoice_lines` +
          `?meta_json->>correction_id=eq.${enc(correction_id)}` +
          `&meta_json->>correction_kind=eq.${enc('CHANGED_HOURS_CREDIT')}` +
          `&select=id&limit=1`
      );
      return !!(rows && rows[0]);
    } catch { return false; }
  })();
  if (exists) return { ok: true, skipped: true };

  const ctx = getInvoiceCtx ? await getInvoiceCtx(client_id) : null;
  const invoice = ctx
    ? await ctx.findOrCreateBucket(credit_week_start)
    : await (async () => { throw new Error('createSingleLineCreditNoteForShift requires getInvoiceCtx in this codebase for VAT/header details.'); })();

  const vatRatePct = Number(invoice?.vat_rate_pct ?? ctx?.vatRatePct ?? 0);

  const chgEx = -Math.abs(oldEx);
  const vatAmt = round2(chgEx * vatRatePct / 100);
  const incAmt = round2(chgEx + vatAmt);

  const meta0 = (invoice?.header_snapshot_json && typeof invoice.header_snapshot_json === 'object')
    ? invoice.header_snapshot_json.meta
    : null;

  const bucketWarning = (meta0 && meta0.adjustment_bucket_created_due_to_issued === true)
    ? {
        type: 'ADJUSTMENT_BUCKET_CREATED',
        message: 'Adjustment invoice created because prior invoice was already issued.',
        client_id,
        week_start: credit_week_start,
        prior_invoice_id: meta0.adjustment_prior_invoice_id || null,
        prior_invoice_no: meta0.adjustment_prior_invoice_no || null,
        new_invoice_id: invoice.id,
        new_invoice_no: invoice.invoice_no || null
      }
    : null;

  const meta_json = {
    correction_id,
    correction_kind: 'CHANGED_HOURS_CREDIT',
    import_id,
    system_type,
    external_row_key,
    nhsp_shift_id: shift_id || null,
    timesheet_id: timesheet_id || null,
    client_id: client_id || null,
    credit_week_start,
    credited_old_charge_ex_vat: round2(Math.abs(oldEx)),
    credited_old_charge_inc_vat: round2(Math.abs(oldEx) + (Math.abs(oldEx) * vatRatePct / 100)),
    bucket_created_due_to_issued: !!bucketWarning,
    bucket_prior_invoice_id: bucketWarning?.prior_invoice_id || null
  };

  const line = {
    invoice_id: invoice.id,
    timesheet_id: timesheet_id || null,
    booking_id: null,
    description: `${system_type} changed-hours correction (credit old charge) – shift ${shift_id || ''}`.trim(),

    hours_day: 0, hours_night: 0, hours_sat: 0, hours_sun: 0, hours_bh: 0,
    pay_day: null, pay_night: null, pay_sat: null, pay_sun: null, pay_bh: null,
    charge_day: null, charge_night: null, charge_sat: null, charge_sun: null, charge_bh: null,

    total_pay_ex_vat: 0,
    total_charge_ex_vat: round2(chgEx),
    margin_ex_vat: round2(chgEx),
    vat_rate_pct: vatRatePct,
    vat_amount: vatAmt,
    total_inc_vat: incAmt,

    meta_json
  };

  const ins = await fetch(
    `${env.SUPABASE_URL}/rest/v1/invoice_lines`,
    { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify([line]) }
  );
  const t = await ins.text().catch(() => '');
  if (!ins.ok) throw new Error(`invoice_lines insert (CREDIT) failed: ${t || ins.status}`);

  await ctx.bumpTotals(invoice.id, round2(chgEx), vatAmt, incAmt).catch(() => {});

  await writeAudit(
    env,
    user,
    'WEEKLY_CHANGED_HOURS_CREDIT_CREATED',
    { correction_id, import_id, system_type, external_row_key, invoice_id: invoice.id, credit_week_start, old_charge_ex_vat: round2(oldEx) },
    { entity: 'invoice', subject_id: invoice.id, req }
  ).catch(() => {});

  return { ok: true, warning: bucketWarning };
}


/**
 * scheduleReinvoiceForShift(...)
 *
 * Creates ONE positive invoice_line for new charge on the chosen reinvoice week bucket invoice.
 * Stores traceability in invoice_lines.meta_json.
 */
async function scheduleReinvoiceForShift(env, {
  user,
  req,
  import_id,
  system_type,
  correction_id,
  external_row_key,
  shift_id,
  timesheet_id,
  client_id,
  reinvoice_week_start,
  new_charge_ex_vat,
  findOrCreateSelfBillInvoice,
  getInvoiceCtx
}) {
  const enc = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  const newEx = Number(new_charge_ex_vat || 0);
  if (!Number.isFinite(newEx)) throw new Error(`Reinvoice: new_charge_ex_vat is not numeric (external_row_key=${external_row_key})`);

  const exists = await (async () => {
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/invoice_lines` +
          `?meta_json->>correction_id=eq.${enc(correction_id)}` +
          `&meta_json->>correction_kind=eq.${enc('CHANGED_HOURS_REINVOICE')}` +
          `&select=id&limit=1`
      );
      return !!(rows && rows[0]);
    } catch { return false; }
  })();
  if (exists) return { ok: true, skipped: true };

  const ctx = getInvoiceCtx ? await getInvoiceCtx(client_id) : null;
  const invoice = ctx
    ? await ctx.findOrCreateBucket(reinvoice_week_start)
    : await (async () => { throw new Error('scheduleReinvoiceForShift requires getInvoiceCtx in this codebase for VAT/header details.'); })();

  const vatRatePct = Number(invoice?.vat_rate_pct ?? ctx?.vatRatePct ?? 0);

  const chgEx = Math.abs(newEx);
  const vatAmt = round2(chgEx * vatRatePct / 100);
  const incAmt = round2(chgEx + vatAmt);

  const meta0 = (invoice?.header_snapshot_json && typeof invoice.header_snapshot_json === 'object')
    ? invoice.header_snapshot_json.meta
    : null;

  const bucketWarning = (meta0 && meta0.adjustment_bucket_created_due_to_issued === true)
    ? {
        type: 'ADJUSTMENT_BUCKET_CREATED',
        message: 'Adjustment invoice created because prior invoice was already issued.',
        client_id,
        week_start: reinvoice_week_start,
        prior_invoice_id: meta0.adjustment_prior_invoice_id || null,
        prior_invoice_no: meta0.adjustment_prior_invoice_no || null,
        new_invoice_id: invoice.id,
        new_invoice_no: invoice.invoice_no || null
      }
    : null;

  const meta_json = {
    correction_id,
    correction_kind: 'CHANGED_HOURS_REINVOICE',
    import_id,
    system_type,
    external_row_key,
    nhsp_shift_id: shift_id || null,
    timesheet_id: timesheet_id || null,
    client_id: client_id || null,
    reinvoice_week_start,
    reinvoiced_new_charge_ex_vat: round2(Math.abs(newEx)),
    reinvoiced_new_charge_inc_vat: round2(Math.abs(newEx) + (Math.abs(newEx) * vatRatePct / 100)),
    bucket_created_due_to_issued: !!bucketWarning,
    bucket_prior_invoice_id: bucketWarning?.prior_invoice_id || null
  };

  const line = {
    invoice_id: invoice.id,
    timesheet_id: timesheet_id || null,
    booking_id: null,
    description: `${system_type} changed-hours correction (reinvoice new charge) – shift ${shift_id || ''}`.trim(),

    hours_day: 0, hours_night: 0, hours_sat: 0, hours_sun: 0, hours_bh: 0,
    pay_day: null, pay_night: null, pay_sat: null, pay_sun: null, pay_bh: null,
    charge_day: null, charge_night: null, charge_sat: null, charge_sun: null, charge_bh: null,

    total_pay_ex_vat: 0,
    total_charge_ex_vat: round2(chgEx),
    margin_ex_vat: round2(chgEx),
    vat_rate_pct: vatRatePct,
    vat_amount: vatAmt,
    total_inc_vat: incAmt,

    meta_json
  };

  const ins = await fetch(
    `${env.SUPABASE_URL}/rest/v1/invoice_lines`,
    { method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return-minimal' }, body: JSON.stringify([line]) }
  );
  const t = await ins.text().catch(() => '');
  if (!ins.ok) throw new Error(`invoice_lines insert (REINVOICE) failed: ${t || ins.status}`);

  await ctx.bumpTotals(invoice.id, round2(chgEx), vatAmt, incAmt).catch(() => {});

  await writeAudit(
    env,
    user,
    'WEEKLY_CHANGED_HOURS_REINVOICE_CREATED',
    { correction_id, import_id, system_type, external_row_key, invoice_id: invoice.id, reinvoice_week_start, new_charge_ex_vat: round2(newEx) },
    { entity: 'invoice', subject_id: invoice.id, req }
  ).catch(() => {});

  return { ok: true, warning: bucketWarning };
}

/**
 * applyWeeklyHoursCorrections(env, args)
 *
 * Executes pay-side + invoice-side correction actions for all PROCEED rows.
 * Idempotent using correction_id:
 *  - pay adjustments: relies on existing createShiftPayAdjustment (already in your handlers)
 *  - recoveries: uses createShiftRecoveryAdvance (idempotent via notes contains correction_id)
 *  - invoice lines: checks meta_json correction_id + correction_kind before insert
 *
 * IMPORTANT: This function ONLY processes rows explicitly returned by Phase 3 and explicitly set to PROCEED.
 */
async function applyWeeklyHoursCorrections(env, {
  user,
  req,
  import_id,
  system_type,
  phase3,
  decisionsNorm,
  createShiftPayAdjustment,
  findOrCreateSelfBillInvoice,
  getInvoiceCtx,
}) {
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  const reasonOverpay = (String(system_type).toUpperCase() === 'NHSP') ? 'OVERPAY_NHSP' : 'OVERPAY_HR';

  const nextPayWeekEnding = (() => {
    const now = new Date();
    const ymd = `${now.getUTCFullYear()}-${String(now.getUTCMonth()+1).padStart(2,'0')}-${String(now.getUTCDate()).padStart(2,'0')}`;
    const d = new Date(`${ymd}T00:00:00Z`);
    while (d.getUTCDay() !== 0) d.setUTCDate(d.getUTCDate() + 1);
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  })();

  const nextRecoveryWeekStart = (() => {
    const d = new Date();
    d.setUTCDate(d.getUTCDate() + 7);
    const day = d.getUTCDay();
    const offset = (day + 6) % 7;
    d.setUTCDate(d.getUTCDate() - offset);
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  })();

  let payAdjustmentsTouched = 0;
  let recoveriesTouched = 0;
  let invoiceCreditsTouched = 0;
  let invoiceReinvoicesTouched = 0;
  let invoiceCorrectionsBlocked = 0;

  const warnings = [];
  const warningSeen = new Set();

  const normUpper = (s) => String(s || '').trim().toUpperCase();
  const isHrSystem = normUpper(system_type) === 'HEALTHROSTER';

  // Batch-load contracts to know self_bill per contract_id (kept exactly as you provided)
  const contractSelfBillById = new Map();

  const contractIds = Array.from(new Set(
    (decisionsNorm?.proceedRows || [])
      .map(x => x?.row?.contract_id)
      .filter(Boolean)
      .map(String)
  ));

  if (contractIds.length) {
    const key =
      env.SUPABASE_SERVICE_ROLE_KEY ||
      env.SUPABASE_SERVICE_KEY ||
      env.SUPABASE_ANON_KEY;

    if (!env.SUPABASE_URL || !key) {
      throw new Error('applyWeeklyHoursCorrections: missing SUPABASE_URL or service key for contract self_bill lookup');
    }

    const inList = contractIds.map(encodeURIComponent).join(',');
    const url =
      `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?select=id,self_bill&id=in.(${inList})`;

    const r = await fetch(url, {
      method: 'GET',
      headers: {
        apikey: key,
        Authorization: `Bearer ${key}`,
        'Content-Type': 'application/json'
      }
    });

    if (!r.ok) {
      const txt = await r.text().catch(() => '');
      throw new Error(`applyWeeklyHoursCorrections: failed to load contracts (status ${r.status}) ${txt}`);
    }

    const rows = await r.json().catch(() => []);
    for (const c of (rows || [])) {
      contractSelfBillById.set(String(c.id), !!c.self_bill);
    }
  }

  const isNonSelfBillHrContract = (row) => {
    if (!isHrSystem) return false;

    const src = normUpper(row?.source_system);
    const isHrRow = (!src) ? true : (src === 'HEALTHROSTER' || src === 'HR_WEEKLY' || src === 'HR');
    if (!isHrRow) return false;

    const cid = row?.contract_id ? String(row.contract_id) : null;
    if (!cid) return true;

    const selfBill = contractSelfBillById.get(cid);
    if (typeof selfBill !== 'boolean') return true;

    return selfBill === false;
  };

  const pushWarning = (w) => {
    if (!w || typeof w !== 'object') return;
    const k = String(w.new_invoice_id || '');
    if (!k) return;
    if (warningSeen.has(k)) return;
    warningSeen.add(k);
    warnings.push(w);
  };

  for (const { row } of (decisionsNorm?.proceedRows || [])) {
    const ek = String(row.external_row_key);
    const corrId = makeWeeklyHoursCorrectionId(import_id, row);

    // Pay-side
    if (row.is_paid) {
      const deltaPay = Number(row.delta_pay_ex);
      if (Number.isFinite(deltaPay) && deltaPay !== 0) {
        if (deltaPay > 0) {
          await createShiftPayAdjustment(env, {
            timesheet_id: row.timesheet_id,
            candidate_id: row.candidate_id,
            client_id: row.client_id,
            week_ending_date: nextPayWeekEnding,
            delta_pay_ex_vat: deltaPay,
            note: `${system_type} changed-hours underpay (import ${import_id}, ek ${ek})`,
            meta_json: {
              correction_id: corrId,
              import_id,
              system_type,
              external_row_key: ek,
              shift_id: row.shift_id,
              timesheet_id: row.timesheet_id,
              candidate_id: row.candidate_id,
              client_id: row.client_id,
              old_pay_ex_vat: row.old_pay_ex != null ? round2(row.old_pay_ex) : null,
              new_pay_ex_vat: row.new_pay_ex != null ? round2(row.new_pay_ex) : null,
              delta_pay_ex_vat: round2(deltaPay)
            }
          });
          payAdjustmentsTouched++;
        } else {
          const amt = Math.abs(deltaPay);
          const notes = `${system_type} changed-hours overpay recovery (import ${import_id}, ek ${ek}, correction_id ${corrId})`;

          await createShiftRecoveryAdvance(env, {
            candidate_id: row.candidate_id,
            client_id: row.client_id,
            amount: amt,
            reason: reasonOverpay,
            week_start: nextRecoveryWeekStart,
            notes,
            correction_id: corrId,
            created_by: user?.id || null
          });
          recoveriesTouched++;
        }
      }
    }

    // Invoice-side
    if (row.is_invoiced) {
      if (isNonSelfBillHrContract(row)) {
        invoiceCorrectionsBlocked++;
        continue;
      }

      const d = decisionsNorm.byKey?.[ek];
      const credit_week_start = d?.credit_week_start;
      const reinvoice_week_start = d?.reinvoice_week_start;

      if (!credit_week_start || !reinvoice_week_start) {
        throw new Error(`applyWeeklyHoursCorrections: missing invoice weeks for invoiced ek=${ek}`);
      }

      const cr = await createSingleLineCreditNoteForShift(env, {
        user,
        req,
        import_id,
        system_type,
        correction_id: corrId,
        external_row_key: ek,
        shift_id: row.shift_id,
        timesheet_id: row.timesheet_id,
        client_id: row.client_id,
        credit_week_start,
        old_charge_ex_vat: row.old_charge_ex,
        findOrCreateSelfBillInvoice,
        getInvoiceCtx
      });
      invoiceCreditsTouched++;
      if (cr?.warning) pushWarning(cr.warning);

      const rr = await scheduleReinvoiceForShift(env, {
        user,
        req,
        import_id,
        system_type,
        correction_id: corrId,
        external_row_key: ek,
        shift_id: row.shift_id,
        timesheet_id: row.timesheet_id,
        client_id: row.client_id,
        reinvoice_week_start,
        new_charge_ex_vat: row.new_charge_ex,
        findOrCreateSelfBillInvoice,
        getInvoiceCtx
      });
      invoiceReinvoicesTouched++;
      if (rr?.warning) pushWarning(rr.warning);
    }
  }

  return {
    pay_adjustments_touched: payAdjustmentsTouched,
    recoveries_touched: recoveriesTouched,
    invoice_credits_touched: invoiceCreditsTouched,
    invoice_reinvoices_touched: invoiceReinvoicesTouched,
    invoice_corrections_blocked: invoiceCorrectionsBlocked,
    warnings
  };
}


 async function handleNhspImportConfirm(env, req, importId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) return withCORS(env, req, badRequest('import_id is required'));

  // Body may contain: { selected_group_ids: [ 'grp:...' , ... ] }
  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    body = null;
  }
  const selectedIds = Array.isArray(body?.selected_group_ids)
    ? [...new Set(body.selected_group_ids.map(String).filter(Boolean))]
    : [];

  try {
    // 1) Re-run classification to know what this import currently looks like
    const preview = await classifyWeeklyImportRows(env, importId, { source_system: 'NHSP' });

    if (preview.error === 'import_not_found') {
      return withCORS(env, req, notFound(`NHSP import ${importId} not found`));
    }
    if (preview.error === 'source_system_mismatch') {
      return withCORS(env, req, badRequest(
        `Import ${importId} has source_system=${preview.actual_source_system}, expected NHSP`
      ));
    }

    const allRows = Array.isArray(preview.rows) ? preview.rows : [];
    const groupRows = allRows.filter(r => r && r.level === 'group');

    // “Actionable” groups = NOT REJECT_* / SKIP_* / UNKNOWN
    const actionableGroups = groupRows.filter((g) => {
      const a = String(g.action || '').toUpperCase();
      if (!a) return false;
      if (a.startsWith('REJECT_')) return false;
      if (a.startsWith('SKIP_'))   return false;
      if (a === 'UNKNOWN')        return false;
      return true;
    });

    let groupsToApply = actionableGroups;

    // If FE sent selected_group_ids, intersect
    if (selectedIds.length) {
      const selSet = new Set(selectedIds);
      groupsToApply = actionableGroups.filter(g => selSet.has(String(g.preview_group_id || '')));
    }

    if (!groupsToApply.length) {
      // Nothing to do — don’t run the apply handler at all
      return withCORS(env, req, ok({
        import_id: importId,
        applied: false,
        reason: 'No actionable NHSP weekly groups for this import (after selection).',
        preview_summary: {
          total_groups: groupRows.length,
          actionable_groups: actionableGroups.length,
          selected_group_ids: selectedIds
        }
      }));
    }

    // 2) Delegate to the existing apply handler for this import
    // NOTE: handleNhspApply already returns a CORS-wrapped Response.
    return await handleNhspApply(env, req, importId);
  } catch (e) {
    return withCORS(env, req, serverError(`NHSP confirm failed: ${e?.message || e}`));
  }
}


async function handleTimesheetsSummary(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc    = encodeURIComponent;
  const urlObj = new URL(req.url);
  const q      = (k) => urlObj.searchParams.get(k);

  const pageRaw     = q('page') || '1';
  const pageSizeRaw = q('page_size') || '50';

  const page     = Math.max(1, parseInt(pageRaw, 10) || 1);
  const pageSize = Math.max(1, Math.min(200, parseInt(pageSizeRaw, 10) || 50));

  const includeTotals = String(q('include_totals') || '').toLowerCase() === 'true';

  const clientId    = q('client_id');
  const candidateId = q('candidate_id');

  // ✅ NEW: id/ids selection support (for summaryFetchCanonicalRow)
  const idExprRaw = q('id');   // accepts uuid OR "in.(uuid1,uuid2,...)"
  const idsCsvRaw = q('ids');  // accepts "uuid1,uuid2,..."

  let idList = [];
  try {
    const pushMany = (arr) => {
      (arr || []).forEach(x => {
        const s = String(x || '').trim();
        if (s) idList.push(s);
      });
    };

    if (idsCsvRaw) {
      pushMany(String(idsCsvRaw).split(','));
    }

    if (idExprRaw) {
      const s = String(idExprRaw || '').trim();
      if (/^in\.\(.+\)$/.test(s)) {
        const inner = s.replace(/^in\.\(/, '').replace(/\)$/, '');
        pushMany(inner.split(','));
      } else {
        pushMany([s]);
      }
    }

    idList = Array.from(new Set(idList.map(String))).filter(Boolean);
  } catch {
    idList = [];
  }

  const hasIdFilter = idList.length > 0;

  // ✅ NEW: canonical Tools Stage filter token (from v_timesheets_summary.tools_stage)
  const toolsStageRaw = q('tools_stage');
  const toolsStageUp  = toolsStageRaw ? String(toolsStageRaw).toUpperCase() : null;

  const routeTypeRaw = q('route_type');
  const routeType    = routeTypeRaw ? routeTypeRaw.toUpperCase() : null;

  const sheetScopeRaw = q('sheet_scope');
  const sheetScope    = sheetScopeRaw ? sheetScopeRaw.toUpperCase() : null;

  const qrStatusRaw   = q('qr_status');
  const qrStatus      = qrStatusRaw ? qrStatusRaw.toUpperCase() : null;

  // Tools checkboxes
  const candidatePaid = q('candidate_paid'); // paid_at_utc checkbox
  const isAdjusted    = q('is_adjusted');    // adjusted checkbox
  const isQr          = q('is_qr');          // legacy route checkbox

  // ✅ NEW: Issues dropdown (main summary controls)
  const issuesFilterRaw = q('issues_filter');
  const issuesFilterUp  = issuesFilterRaw ? String(issuesFilterRaw).toUpperCase() : null;

  // Legacy passthrough
  const statusCodeRaw = q('status_code');
  const statusCodeUp  = statusCodeRaw ? String(statusCodeRaw).toUpperCase() : null;

  // HR issue filter
  const hrIssueRaw = q('hr_issue');
  const hrIssue    = hrIssueRaw ? hrIssueRaw.toUpperCase() : null;

  const weFrom = q('week_ending_from');
  const weTo   = q('week_ending_to');

  const orderByParam  = (q('order_by') || '').toLowerCase();
  const orderDirParam = (q('order_dir') || '').toLowerCase();

  // Sort keys: map any request to sort by "processing_status" to processing_status_display
  const allowedSort = {
    week_ending_date:          'week_ending_date',
    client_name:               'client_name',
    candidate_name:            'candidate_name',

    // NEW: stage/signal columns
    tools_stage:               'tools_stage',
    processing_status:         'processing_status_display',
    processing_status_display: 'processing_status_display',

    route_type:                'route_type',
    sheet_scope:               'sheet_scope',

    total_pay_ex_vat:          'total_pay_ex_vat',
    total_charge_ex_vat:       'total_charge_ex_vat',
    margin_ex_vat:             'margin_ex_vat',

    pay:                       'total_pay_ex_vat',
    charge:                    'total_charge_ex_vat',
    margin:                    'margin_ex_vat'
  };

  const defaultOrderCol = 'week_ending_date';
  const orderCol = allowedSort[orderByParam] || defaultOrderCol;
  const orderDir = (orderDirParam === 'asc') ? 'asc' : 'desc';

  // Helper: apply Issues filter to the PostgREST query
  const applyIssuesFilter = (apiIn, tokenUp) => {
    let api = apiIn;
    const tok = tokenUp ? String(tokenUp).toUpperCase() : null;
    if (!tok || tok === 'ALL') return api;

    // PostgREST array-contains helper for text[]
    const cs1 = (val) => `cs.{${enc(val)}}`;

    switch (tok) {
      case 'NO_MATCH_ID':
        api += `&or=${enc('(candidate_id.is.null,client_id.is.null)')}`;
        return api;

      case 'RATE_MISSING':
        api += `&issue_codes=${cs1('Rate')}`;
        return api;

      case 'PAY_CHAN_MISS':
      case 'PAY_CHANNEL_MISSING':
        api += `&issue_codes=${cs1('Pay channel')}`;
        return api;

      case 'AWAITING_HR_VALIDATION':
      case 'AWAITING_HR_VALIDATION_REQUIRED':
        api += `&issue_codes=${cs1('HR validation')}`;
        return api;

      case 'HR_HOURS_MISMATCH':
      case 'HOURS_MISMATCH_HR':
        api += `&issue_codes=${cs1('Hours mismatch HR')}`;
        return api;

      case 'HR_HOURS_MISSING':
        api += `&issue_codes=${cs1('HR hours missing')}`;
        return api;

      case 'DUPLICATE_CONTRACTS':
        api += `&issue_codes=${cs1('Duplicate contracts')}`;
        return api;

      case 'REFERENCE_MISSING':
        api += `&issue_codes=${cs1('Reference')}`;
        return api;

      case 'VALIDATION':
        api += `&issue_codes=${cs1('Validation')}`;
        return api;

      case 'AUTHORISATION':
        api += `&issue_codes=${cs1('Authorisation')}`;
        return api;

      case 'ON_HOLD':
        api += `&issue_codes=${cs1('On hold')}`;
        return api;

      case 'QR_NOT_ISSUED':
        api += `&timesheet_id=is.not.null`;
        api += `&qr_status=eq.PENDING`;
        api += `&qr_token=is.null`;
        api += `&qr_generated_at=is.null`;
        return api;

      case 'QR_AWAITING_SIGNATURE':
      case 'QR_ISSUED_AWAITING_SIGNATURE':
        api += `&timesheet_id=is.not.null`;
        api += `&qr_status=eq.PENDING`;
        api += `&qr_token=is.not.null`;
        api += `&qr_generated_at=is.not.null`;
        api += `&qr_scanned_at=is.null`;
        return api;

      default:
        return api;
    }
  };

  // Resolve the effective issues filter
  let effectiveIssues = issuesFilterUp;
  if ((!effectiveIssues || effectiveIssues === 'ALL') && statusCodeUp && statusCodeUp !== 'ALL') {
    if (statusCodeUp === 'NO_MATCH_ID') effectiveIssues = 'NO_MATCH_ID';
    else if (statusCodeUp === 'RATE_MISSING') effectiveIssues = 'RATE_MISSING';
    else if (statusCodeUp === 'PAY_CHAN_MISS') effectiveIssues = 'PAY_CHAN_MISS';
    else if (statusCodeUp === 'READY_FOR_HR') effectiveIssues = 'AWAITING_HR_VALIDATION';
    else if (statusCodeUp === 'HR_HOURS_MISMATCH') effectiveIssues = 'HR_HOURS_MISMATCH';
  }

  const effLimit  = hasIdFilter ? Math.min(200, Math.max(1, idList.length)) : pageSize;
  const effOffset = hasIdFilter ? 0 : ((page - 1) * pageSize);

  let api =
    `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
    `?select=` + [
      '*',
      'route_type',
      'client_no_timesheet_required',
      'client_autoprocess_hr',
      'client_is_nhsp',
      'contract_id',
      'contract_week_id',
      'timesheet_id',
      'sheet_scope',
      'submission_mode',
      'basis',
      'tools_stage',
      'processing_status_display',
      'invoice_is_paid'
    ].join(',') +
    `&limit=${effLimit}&offset=${effOffset}`;

  // ✅ id/ids filter (matches either timesheet_id OR contract_week_id)
  if (hasIdFilter) {
    if (idList.length === 1) {
      const one = idList[0];
      api += `&or=${enc(`(timesheet_id.eq.${one},contract_week_id.eq.${one})`)}`;
    } else {
      const csv = idList.join(',');
      api += `&or=${enc(`(timesheet_id.in.(${csv}),contract_week_id.in.(${csv}))`)}`;
    }
  }

  if (clientId)    api += `&client_id=eq.${enc(clientId)}`;
  if (candidateId) api += `&candidate_id=eq.${enc(candidateId)}`;

  // ✅ Tools Stage filtering
  if (toolsStageUp && toolsStageUp !== 'ALL') {
    api += `&tools_stage=eq.${enc(toolsStageUp)}`;
  }

  // Route handling (aggregated)
  if (routeType && routeType !== 'ALL') {
    if (routeType === 'ELECTRONIC') {
      api += `&route_type=in.(DAILY_ELECTRONIC,WEEKLY_ELECTRONIC)`;
    } else if (routeType === 'MANUAL') {
      api += `&route_type=in.(DAILY_MANUAL,WEEKLY_MANUAL)`;
    } else if (routeType === 'NHSP') {
      api += `&route_type=in.(WEEKLY_NHSP,WEEKLY_NHSP_ADJUSTMENT)`;
    } else if (routeType === 'HEALTHROSTER') {
      api += `&route_type=eq.WEEKLY_HEALTHROSTER`;
    } else {
      api += `&route_type=eq.${enc(routeType)}`;
    }
  }

  if (sheetScope && sheetScope !== 'ALL') api += `&sheet_scope=eq.${enc(sheetScope)}`;

  if (qrStatus) api += `&qr_status=eq.${enc(qrStatus)}`;

  if (weFrom) api += `&week_ending_date=gte.${enc(weFrom)}`;
  if (weTo)   api += `&week_ending_date=lte.${enc(weTo)}`;

  if (isAdjusted === 'true')  api += `&is_adjusted=eq.true`;
  if (isAdjusted === 'false') api += `&is_adjusted=eq.false`;

  if (isQr === 'true')        api += `&is_qr=eq.true`;
  if (isQr === 'false')       api += `&is_qr=eq.false`;

  if (candidatePaid === 'true') api += `&paid_at_utc=is.not.null`;

  if (hrIssue) api += `&hr_crosscheck_issues=cs.{${enc(hrIssue)}}`;

  // Issues filter
  api = applyIssuesFilter(api, effectiveIssues);

  // Ordering (only meaningful for list pages; harmless for id-filter calls)
  if (orderByParam && allowedSort[orderByParam]) {
    api += `&order=${enc(orderCol)}.${orderDir},client_name.asc,candidate_name.asc`;
  } else {
    api += `&order=week_ending_date.desc,client_name.asc,candidate_name.asc`;
  }

  try {
    const { rows } = await sbFetch(env, api);

    const outRows = (rows || []).map(r => {
      const o = { ...(r || {}) };
      if (!Object.prototype.hasOwnProperty.call(o, 'route_type')) o.route_type = null;
      if (!Object.prototype.hasOwnProperty.call(o, 'client_no_timesheet_required')) o.client_no_timesheet_required = null;
      if (!Object.prototype.hasOwnProperty.call(o, 'client_autoprocess_hr')) o.client_autoprocess_hr = null;
      if (!Object.prototype.hasOwnProperty.call(o, 'client_is_nhsp')) o.client_is_nhsp = null;
      if (!Object.prototype.hasOwnProperty.call(o, 'tools_stage')) o.tools_stage = null;
      if (!Object.prototype.hasOwnProperty.call(o, 'processing_status_display')) o.processing_status_display = null;
      if (!Object.prototype.hasOwnProperty.call(o, 'invoice_is_paid')) o.invoice_is_paid = null;
      return o;
    });

    let totals = null;
    let totalCount = outRows.length;

    if (includeTotals) {
      if (hasIdFilter) {
        // Local totals (no RPC) for id/ids mode
        let paySum = 0;
        let marginSum = 0;
        for (const r of outRows) {
          paySum += (Number(r?.total_pay_ex_vat || 0) || 0);
          marginSum += (Number(r?.margin_ex_vat || 0) || 0);
        }
        totals = {
          count_all: outRows.length,
          total_pay_ex_vat_sum: paySum,
          margin_ex_vat_sum: marginSum
        };
        totalCount = outRows.length;
      } else {
        const filters = {
          client_id: clientId || null,
          candidate_id: candidateId || null,

          tools_stage: (toolsStageUp && toolsStageUp !== 'ALL') ? toolsStageUp : null,
          issues_filter: (effectiveIssues && effectiveIssues !== 'ALL') ? effectiveIssues : null,

          candidate_paid: candidatePaid || null,
          is_adjusted: isAdjusted || null,

          route_type: routeType || null,
          sheet_scope: sheetScope || null,
          qr_status: qrStatus || null,
          week_ending_from: weFrom || null,
          week_ending_to: weTo || null,
          is_qr: isQr || null,

          hr_issue: hrIssue || null
        };

        const totRes = await sbRpc(env, 'timesheet_list_totals', { p_filters: filters });
        const totRows = Array.isArray(totRes) ? totRes : (totRes?.data || []);
        totals = (totRows && totRows.length)
          ? totRows[0]
          : { count_all: 0, total_pay_ex_vat_sum: 0, margin_ex_vat_sum: 0 };

        totalCount = Number(totals?.count_all || 0);
      }
    }

    return withCORS(env, req, ok({
      items: outRows,
      page,
      page_size: pageSize,
      count: totalCount,
      totals: totals || undefined
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to fetch timesheets summary: ${e?.message || e}`));
  }
}




 async function handleHrAutoprocessConfirm(env, req, importId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) return withCORS(env, req, badRequest('import_id is required'));

  // Body may contain: { selected_group_ids: [ 'grp:...' , ... ] }
  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    body = null;
  }
  const selectedIds = Array.isArray(body?.selected_group_ids)
    ? [...new Set(body.selected_group_ids.map(String).filter(Boolean))]
    : [];

  try {
    // 1) Re-run classification for this HealthRoster import
    const preview = await classifyWeeklyImportRows(env, importId, { source_system: 'HEALTHROSTER' });

    if (preview.error === 'import_not_found') {
      return withCORS(env, req, notFound(`HealthRoster import ${importId} not found`));
    }
    if (preview.error === 'source_system_mismatch') {
      return withCORS(env, req, badRequest(
        `Import ${importId} has source_system=${preview.actual_source_system}, expected HEALTHROSTER`
      ));
    }

    const allRows = Array.isArray(preview.rows) ? preview.rows : [];
    const groupRows = allRows.filter(r => r && r.level === 'group');

    // “Actionable” for HR = same rule: non-REJECT / non-SKIP / non-UNKNOWN
    const actionableGroups = groupRows.filter((g) => {
      const a = String(g.action || '').toUpperCase();
      if (!a) return false;
      if (a.startsWith('REJECT_')) return false;
      if (a.startsWith('SKIP_'))   return false;
      if (a === 'UNKNOWN')        return false;
      return true;
    });

    let groupsToApply = actionableGroups;

    if (selectedIds.length) {
      const selSet = new Set(selectedIds);
      groupsToApply = actionableGroups.filter(g => selSet.has(String(g.preview_group_id || '')));
    }

    if (!groupsToApply.length) {
      // Nothing to do — don’t run the apply handler
      return withCORS(env, req, ok({
        import_id: importId,
        applied: false,
        reason: 'No actionable HealthRoster weekly groups for this import (after selection).',
        preview_summary: {
          total_groups: groupRows.length,
          actionable_groups: actionableGroups.length,
          selected_group_ids: selectedIds
        }
      }));
    }

    // 2) Delegate to the existing HealthRoster autoprocess apply handler
    return await handleHrAutoprocessApply(env, req, importId);
  } catch (e) {
    return withCORS(env, req, serverError(`HealthRoster confirm failed: ${e?.message || e}`));
  }
}

async function handleHrAutoprocessClients(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  try {
    // ✅ Contract-driven list (contracts.autoprocess_hr), return contract IDs
    const { rows: conRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?autoprocess_hr=eq.true` +
        `&select=id,client_id,role,band` +
        `&limit=10000`
    );

    const contracts = Array.isArray(conRows) ? conRows : [];
    if (!contracts.length) return withCORS(env, req, ok({ items: [] }));

    const clientIds = [...new Set(contracts.map(c => c.client_id).filter(Boolean).map(String))];
    const clientById = new Map();

    if (clientIds.length) {
      const cliParam = clientIds.map(enc).join(',');
      const { rows: cliRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients?id=in.(${cliParam})&select=id,name`
      );
      for (const c of (cliRows || [])) clientById.set(String(c.id), c);
    }

    const items = contracts.map(c => {
      const cli = c.client_id ? clientById.get(String(c.client_id)) : null;
      return {
        contract_id: c.id,
        client_id: c.client_id,
        client_name: (cli && cli.name) ? cli.name : '(unnamed client)',
        role: c.role || null,
        band: c.band || null
      };
    });

    return withCORS(env, req, ok({ items }));
  } catch (e) {
    console.error('[HR_AUTOPROC_CLIENTS] failed', { err: e?.message || String(e) });
    return withCORS(env, req, serverError('Failed to list HealthRoster autoprocess contracts'));
  }
}
async function handleTsfinUpdateSegments(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id required'));

  const body = await parseJSONBody(req).catch(() => null);

  // NEW: guarded write (optimistic concurrency) — timesheet rotation safety
  const expectedTimesheetId = body?.expected_timesheet_id || null;
  const guard = await guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId);
  if (!guard.ok) return guard.res;
  const currentTimesheetId = guard.resolved.current_timesheet_id;

  const segUpdates = Array.isArray(body?.segments) ? body.segments : [];
  if (!segUpdates.length) {
    return withCORS(env, req, badRequest('segments[] required'));
  }

  const enc = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  const computeWeekStartFromWeekEnding = (weYmd) => {
    if (!weYmd) return null;
    const d = new Date(`${weYmd}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return weYmd;
    d.setUTCDate(d.getUTCDate() - 6);
    const yyyy = d.getUTCFullYear();
    const mm = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  // 1) Load current TSFIN (is_current) + basis + client + week_ending via joined timesheet
  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=` + [
        'id',
        'client_id',
        'basis',
        'invoice_breakdown_json',
        'total_pay_ex_vat',
        'total_charge_ex_vat',
        'margin_ex_vat',
        'timesheet:timesheets(week_ending_date)'
      ].join(',')
  );
  const fin = rows?.[0] || null;
  if (!fin) {
    return withCORS(env, req, notFound('Current financial snapshot not found'));
  }

  const breakdown = fin.invoice_breakdown_json || null;
  if (!breakdown || typeof breakdown !== 'object') {
    return withCORS(env, req, badRequest('No invoice_breakdown_json present on snapshot'));
  }

  // Expect SEGMENTS mode with a segments[] array
  if (breakdown.mode !== 'SEGMENTS' || !Array.isArray(breakdown.segments)) {
    return withCORS(env, req, badRequest('This snapshot is not SEGMENTS-based; cannot update per-line settings'));
  }

  const basis = String(fin.basis || '').toUpperCase();
  const invoiceTargetAllowedBases = new Set([
    'NHSP',
    'NHSP_ADJUSTMENT',
    'HEALTHROSTER_SELF_BILL',   // NEW
    'HEALTHROSTER_ADJUSTMENT'
  ]);

  const allowInvoiceTargetChange = invoiceTargetAllowedBases.has(basis);

  const weekEnding = fin?.timesheet?.week_ending_date || null;
  const naturalWeekStart = computeWeekStartFromWeekEnding(weekEnding);

  // Build a map of updates per segment_id
  const updateMap = new Map();
  for (const u of segUpdates) {
    if (!u || typeof u !== 'object') continue;
    const sid = String(u.segment_id || '').trim();
    if (!sid) continue;
    const existing = updateMap.get(sid) || {};
    if ('exclude_from_pay' in u) {
      existing.exclude_from_pay = (u.exclude_from_pay === true);
    }
    if (typeof u.invoice_target_week_start === 'string' && u.invoice_target_week_start.trim()) {
      existing.invoice_target_week_start = u.invoice_target_week_start.trim();
    }
    updateMap.set(sid, existing);
  }

  if (!updateMap.size) {
    return withCORS(env, req, badRequest('No valid segment_id entries to update'));
  }

  // Pre-validate invoice_target_week_start changes
  if (!allowInvoiceTargetChange) {
    // If this basis isn't allowed to move invoice weeks, reject any attempt to set invoice_target_week_start
    const anyInvoiceTargetChange = Array.from(updateMap.values()).some(
      u => typeof u.invoice_target_week_start === 'string'
    );
    if (anyInvoiceTargetChange) {
      return withCORS(
        env,
        req,
        badRequest('invoice_target_week_start cannot be changed for this snapshot basis')
      );
    }
  } else {
    // Allowed bases: check locked segments and natural week floor
    const segById = new Map(
      (breakdown.segments || [])
        .filter(s => s && typeof s === 'object')
        .map(s => [String(s.segment_id || '').trim(), s])
    );

    for (const [sid, upd] of updateMap.entries()) {
      if (!upd || typeof upd.invoice_target_week_start !== 'string') continue;
      const seg = segById.get(sid);
      if (!seg) continue; // ignore unknown ids silently (matches previous behaviour)

      if (seg.invoice_locked_invoice_id) {
        // ✅ No-op tolerant: allow if caller re-sent an equivalent target (no actual change)
        const curTarget = String(seg.invoice_target_week_start || '').trim();
        const reqTarget = String(upd.invoice_target_week_start || '').trim();

        const noop =
          (reqTarget === curTarget) ||
          (!curTarget && naturalWeekStart && reqTarget === naturalWeekStart);

        if (!noop) {
          return withCORS(
            env,
            req,
            badRequest(
              `Segment ${sid} is attached to an invoice and cannot have invoice delay changed. Remove from invoice first.`
            )
          );
        }

        continue;
      }

      if (naturalWeekStart && upd.invoice_target_week_start < naturalWeekStart) {
        return withCORS(
          env,
          req,
          badRequest(
            `invoice_target_week_start for segment ${sid} cannot be earlier than natural week start ${naturalWeekStart}`
          )
        );
      }
    }
  }

  // 2) Apply changes via a LOCKED DB RPC (prevents lost updates / delay corruption)
  //    Falls back to legacy REST PATCH only if the RPC doesn't exist yet.
  const toRpcUpdates = () => {
    const out = [];
    for (const [sid, upd] of updateMap.entries()) {
      const row = { segment_id: sid };
      if (Object.prototype.hasOwnProperty.call(upd, 'exclude_from_pay')) {
        row.exclude_from_pay = (upd.exclude_from_pay === true);
      }
      if (typeof upd.invoice_target_week_start === 'string' && upd.invoice_target_week_start.trim()) {
        row.invoice_target_week_start = upd.invoice_target_week_start.trim();
      }
      out.push(row);
    }
    return out;
  };

  const unwrapRpcResult = (r) => {
    if (r == null) return null;
    if (r && typeof r === 'object' && !Array.isArray(r) && Object.prototype.hasOwnProperty.call(r, 'data')) {
      return unwrapRpcResult(r.data);
    }
    if (Array.isArray(r)) {
      if (r.length === 0) return null;
      if (r.length === 1) return r[0] || null;
      return r[0] || null;
    }
    return r;
  };

  const isMissingRpc = (err) => {
    const msg = String(err?.message || err || '');
    return (
      /Could not find the function/i.test(msg) ||
      /function .* does not exist/i.test(msg) ||
      /RPC tsfin_update_segments_locked failed 404/i.test(msg) ||
      /RPC tsfin_update_segments_locked failed 400/i.test(msg)
    );
  };

  let updated = null;
  let usedLockedRpc = false;

  try {
  const rpcRes = await sbRpc(
    env,
    'tsfin_update_segments_locked',
    {
      p_timesheet_id: currentTimesheetId,
      p_segment_updates: toRpcUpdates(),
      p_actor_user_id: (user && user.id) ? user.id : null
      // Optional future: p_expected_updated_at (if FE starts sending it)
    },
    { timeoutMs: 25000 } // ✅ avoid hanging forever on row locks
  );

  const unwrapped = unwrapRpcResult(rpcRes);
  // Allow either direct row return or {updated: row}
  updated = (unwrapped && typeof unwrapped === 'object' && Object.prototype.hasOwnProperty.call(unwrapped, 'updated'))
    ? unwrapped.updated
    : unwrapped;

  usedLockedRpc = true;
} catch (e) {
  if (!isMissingRpc(e)) throw e;
  usedLockedRpc = false;
}


  // Legacy fallback (only if the locked RPC isn't deployed yet)
  if (!usedLockedRpc) {
    // 2b) Apply changes to segments, recompute total_pay_ex_vat and margin_ex_vat
    let newTotalPay = 0;

    const segments = (breakdown.segments || []).map((seg) => {
      if (!seg || typeof seg !== 'object') return seg;
      const sid = String(seg.segment_id || '').trim();
      const upd = updateMap.get(sid) || {};

      // Exclude from pay toggle
      let exclude = !!seg.exclude_from_pay;
      if (Object.prototype.hasOwnProperty.call(upd, 'exclude_from_pay')) {
        exclude = !!upd.exclude_from_pay;
      }

      // Invoice target week start (only for allowed bases and unlocked segments)
      let invoiceTargetWeekStart = seg.invoice_target_week_start || null;
      if (
        allowInvoiceTargetChange &&
        typeof upd.invoice_target_week_start === 'string' &&
        !seg.invoice_locked_invoice_id
      ) {
        invoiceTargetWeekStart = upd.invoice_target_week_start;
      }

      const payAmt = Number(seg.pay_amount || 0);
      if (!exclude) {
        newTotalPay += payAmt;
      }

      return {
        ...seg,
        exclude_from_pay: exclude,
        invoice_target_week_start: invoiceTargetWeekStart
      };
    });

    newTotalPay = round2(newTotalPay);
    const newMargin = round2(Number(fin.total_charge_ex_vat || 0) - newTotalPay);

    const patch = {
      invoice_breakdown_json: {
        ...breakdown,
        segments
      },
      total_pay_ex_vat: newTotalPay,
      margin_ex_vat: newMargin,
      updated_at: new Date().toISOString()
    };

    // 3) Persist changes
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify(patch)
      }
    );
    if (!res.ok) {
      const t = await res.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to update segments: ${t}`));
    }
    const updatedArr = await res.json().catch(() => []);
    updated = Array.isArray(updatedArr) ? updatedArr[0] : updatedArr;
  }

  await writeAudit(
    env,
    user,
    'TSFIN_SEGMENTS_UPDATED',
    {
      timesheet_id: currentTimesheetId,
      segment_ids: Array.from(updateMap.keys())
    },
    { entity: 'timesheet', subject_id: currentTimesheetId, reason: 'PAYMENT', req }
  );

  return withCORS(env, req, ok({
    updated,
    // NEW: return resolution metadata so FE can adopt the current id if needed
    booking_id: guard.resolved.booking_id || null,
    requested_timesheet_id: guard.resolved.requested_timesheet_id || timesheetId,
    current_timesheet_id: currentTimesheetId,
    current_version: guard.resolved.current_version ?? null,
    was_stale: !!guard.resolved.was_stale
  }));
}


async function handleNhspInvoiceCandidates(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const url = new URL(req.url);
  const q   = (k) => url.searchParams.get(k);
  const enc = encodeURIComponent;

  // Parse run_at (defaults to "now")
  const runAtRaw = q('run_at');
  let runAt = new Date();
  if (runAtRaw) {
    const d = new Date(runAtRaw);
    if (!isNaN(d.getTime())) runAt = d;
  }

  // Optional explicit client_id filter
  const singleClientId = q('client_id') || null;

  // Helper: compute Monday week-start (YYYY-MM-DD) from a Date
  const toYmd = (d) => {
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const computeInvoiceWeekStart = (d) => {
    const base = new Date(Date.UTC(d.getUTCFullYear(), d.getUTCMonth(), d.getUTCDate()));
    const day  = base.getUTCDay(); // 0=Sun..6=Sat
    const offset = (day + 6) % 7;  // days since Monday
    base.setUTCDate(base.getUTCDate() - offset);
    return toYmd(base);
  };

  const invoiceWeekStart = computeInvoiceWeekStart(runAt);

  try {
    // 1) Determine which NHSP clients to invoice (CONTRACT/EFFECTIVE-DRIVEN; no client_settings.is_nhsp)
    let clientIds = [];

    if (singleClientId) {
      clientIds = [singleClientId];
    } else {
      const set = new Set();

      // A) Contract-driven discovery: contracts.is_nhsp = true
      try {
        const { rows: conRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/contracts` +
            `?is_nhsp=eq.true` +
            `&select=client_id` +
            `&limit=10000`
        );
        (conRows || []).forEach(r => { if (r?.client_id) set.add(String(r.client_id)); });
      } catch {
        // non-fatal
      }

      // B) Safety net discovery: TSFIN readiness (Policy B safe because READY_FOR_INVOICE excludes PENDING_AUTH)
      try {
        const { rows: finRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
            `?is_current=eq.true` +
            `&locked_by_invoice_id=is.null` +
            `&processing_status=eq.READY_FOR_INVOICE` +
            `&basis=in.(NHSP,NHSP_ADJUSTMENT)` +
            `&select=client_id` +
            `&limit=10000`
        );
        (finRows || []).forEach(r => { if (r?.client_id) set.add(String(r.client_id)); });
      } catch {
        // non-fatal
      }

      clientIds = Array.from(set);
    }

    if (!clientIds.length) {
      return withCORS(env, req, ok({
        run_at: runAt.toISOString(),
        invoice_week_start: invoiceWeekStart,
        clients: []
      }));
    }

    // 2) For each NHSP client, call the per-week TSFIN invoicer internally
    const results = [];
    for (const client_id of clientIds) {
      const body = JSON.stringify({
        client_id,
        invoice_week_start: invoiceWeekStart
      });

      // Build a synthetic Request that carries the same headers/auth
      const hdrs = new Headers(req.headers);
      if (!hdrs.has('content-type')) hdrs.set('content-type', 'application/json');

      const internalReq = new Request('https://internal/invoices/tsfin/by-week', {
        method: 'POST',
        headers: hdrs,
        body
      });

      let status = 'SKIPPED';
      let invoiceId = null;
      let message = null;

      try {
        const res = await handleCreateInvoiceTsfinByWeek(env, internalReq);

        if (res && typeof res.status === 'number') {
          if (res.status >= 200 && res.status < 300) {
            status = 'INVOICED';
            try {
              const json = await res.json().catch(() => null);
              invoiceId = json?.invoice_id ?? null;
              message   = null;
            } catch {
              message = 'Invoice created but response JSON could not be parsed';
            }
          } else {
            status = 'NO_INVOICE';
            try {
              const txt = await res.text().catch(() => '');
              message = txt || `HTTP ${res.status}`;
            } catch {
              message = `HTTP ${res.status}`;
            }
          }
        } else {
          status  = 'ERROR';
          message = 'Internal handler did not return a Response-like object';
        }
      } catch (e) {
        status  = 'ERROR';
        message = e?.message || String(e);
      }

      results.push({
        client_id,
        status,
        invoice_id: invoiceId,
        message
      });
    }

    return withCORS(env, req, ok({
      run_at: runAt.toISOString(),
      invoice_week_start: invoiceWeekStart,
      clients: results
    }));
  } catch (e) {
    return withCORS(
      env,
      req,
      serverError(`Failed to run NHSP invoice cycle: ${e?.message || e}`)
    );
  }
}


async function handleNhspInvoiceRun(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const body = await parseJSONBody(req).catch(() => null) || {};

  let runAt = new Date();
  if (body.run_at) {
    const d = new Date(body.run_at);
    if (!isNaN(d.getTime())) runAt = d;
  }

  const shiftIdsFilter = Array.isArray(body.shift_ids)
    ? [...new Set(body.shift_ids.map(String).filter(Boolean))]
    : null;
  const clientIdsFilter = Array.isArray(body.client_ids)
    ? [...new Set(body.client_ids.map(String).filter(Boolean))]
    : null;

  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  try {
    const runAtIso = runAt.toISOString();

    // ✅ Only NHSP source shifts (contract-driven discovery; no client_settings.is_nhsp)
    const { rows: rawShifts } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
        `?source_system=eq.NHSP` +
        `&invoice_status=eq.PENDING` +
        `&timesheet_id=not.is.null` +
        `&select=*`
    );
    let shifts = rawShifts || [];

    // Defer filter
    shifts = shifts.filter((s) => {
      if (!s.defer_until_run_after) return true;
      const d = new Date(s.defer_until_run_after);
      if (isNaN(d.getTime())) return true;
      return d < runAt;
    });

    if (shiftIdsFilter && shiftIdsFilter.length) {
      const setIds = new Set(shiftIdsFilter);
      shifts = shifts.filter(s => setIds.has(String(s.id)));
    }

    if (!shifts.length) {
      return withCORS(env, req, ok({ invoices: [], run_at: runAtIso }));
    }

    // ✅ Filter by TSFIN readiness AND basis (NHSP / NHSP_ADJUSTMENT only)
    const tsIds = [...new Set(shifts.map(s => s.timesheet_id).filter(Boolean))];
    const tsParam = tsIds.map(enc).join(',');

    const { rows: finRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=in.(${tsParam})` +
        `&is_current=eq.true` +
        `&select=timesheet_id,client_id,basis,processing_status,locked_by_invoice_id`
    );
    const finByTs = new Map();
    for (const f of finRows || []) finByTs.set(f.timesheet_id, f);

    const okBasis = new Set(['NHSP', 'NHSP_ADJUSTMENT']);

    shifts = shifts.filter((s) => {
      const fin = finByTs.get(s.timesheet_id);
      if (!fin) return false;
      if (fin.locked_by_invoice_id) return false;
      if (!okBasis.has(String(fin.basis || '').toUpperCase())) return false;
      return String(fin.processing_status || '').toUpperCase() === 'READY_FOR_INVOICE';
    });

    if (!shifts.length) {
      return withCORS(env, req, ok({ invoices: [], run_at: runAtIso }));
    }

    // Optional client_ids filter
    if (clientIdsFilter && clientIdsFilter.length) {
      const setFilter = new Set(clientIdsFilter.map(String));
      shifts = shifts.filter(s => setFilter.has(String(s.client_id)));
    }
    if (!shifts.length) {
      return withCORS(env, req, ok({ invoices: [], run_at: runAtIso }));
    }

       // Load defaults & clients for VAT/header info
    // ✅ settings_defaults is NON-FINANCE ONLY (VAT default is now in finance windows)
    const { rows: defRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=bank_name,bank_sort_code,bank_account_number,vat_registration_number`
    );

    // ✅ VAT default = finance window in force when invoice is created/amended
    // Anchor = runAt in Europe/London (NOT shift date)
    const anchorYmd = (() => {
      try {
        const s = new Intl.DateTimeFormat('en-GB', {
          timeZone: 'Europe/London',
          year: 'numeric',
          month: '2-digit',
          day: '2-digit'
        }).format(runAt);
        const [dd, mm, yyyy] = s.split('/');
        return `${yyyy}-${mm}-${dd}`;
      } catch {
        const d = new Date(runAt);
        const y = d.getUTCFullYear();
        const m = String(d.getUTCMonth() + 1).padStart(2, '0');
        const day = String(d.getUTCDate()).padStart(2, '0');
        return `${y}-${m}-${day}`;
      }
    })();

    let defaultVat = 20; // safe fallback
    try {
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify({ p_date: anchorYmd || null })
        }
      );
      const txt = await res.text().catch(() => '');
      if (res.ok) {
        const j = txt ? JSON.parse(txt) : null;
        const row = Array.isArray(j) ? j[0] : j;
        const v = Number(row?.vat_rate_pct);
        if (Number.isFinite(v)) defaultVat = v;
      }
    } catch {
      // keep fallback
    }

    const uniqClientIds = [...new Set(shifts.map(s => s.client_id).filter(Boolean))];
    const { rows: cliRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/clients` +
        `?id=in.(${uniqClientIds.map(enc).join(',')})` +
        `&select=id,name,invoice_address,primary_invoice_email,vat_chargeable,payment_terms_days`
    );
    const clientMap = new Map();
    for (const c of cliRows || []) clientMap.set(String(c.id), c);

    // VAT rate per client from client_settings (VAT is client-level)
    // ✅ Prevent future-dated rows being applied early: effective_from <= anchorYmd
    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
        `?client_id=in.(${uniqClientIds.map(enc).join(',')})` +
        `&effective_from=lte.${enc(anchorYmd)}` +
        `&select=client_id,vat_rate_pct,effective_from` +
        `&order=client_id.asc,effective_from.desc`
    );
    const vatCfgByClient = new Map();
    for (const s of csRows || []) {
      const cid = String(s.client_id);
      if (!vatCfgByClient.has(cid)) {
        vatCfgByClient.set(cid, Number(s.vat_rate_pct ?? defaultVat));
      }
    }


    const DEFAULT_STATIONERY_KEY =
      env.INVOICE_STATIONERY_KEY || 'Assets/Stationery/Letterhead/A4/Letterhead_v1@300dpi.png';
    const DEFAULT_STATIONERY_MARGINS_MM = { top: 32, right: 12, bottom: 20, left: 12 };
    const DEFAULT_HIDE_BANK_FOOTER = true;

    // Group shifts by client
    const byClient = new Map();
    for (const sh of shifts) {
      const cid = String(sh.client_id);
      if (!byClient.has(cid)) byClient.set(cid, []);
      byClient.get(cid).push(sh);
    }

    const invoicesOut = [];

    for (const [cid, clientShifts] of byClient.entries()) {
      const client = clientMap.get(cid);
      if (!client) continue;

      const vatRatePct = client.vat_chargeable === false
        ? 0
        : (vatCfgByClient.get(cid) ?? defaultVat);

      const issuedAt = runAtIso;
      const termsDays = Number(client.payment_terms_days ?? 30);
      const dueAt = new Date(runAt.getTime() + termsDays * 86400000).toISOString();

      const header_snapshot_json = {
        client_id: client.id,
        client_name: client.name,
        client_invoice_address: client.invoice_address ?? null,
        client_primary_invoice_email: client.primary_invoice_email ?? null,
        vat_chargeable: !!client.vat_chargeable,
        applied_vat_rate_pct: vatRatePct,
        payment_terms_days: termsDays,
        issued_at_utc: issuedAt,
        due_at_utc: dueAt,
        stationery_key: DEFAULT_STATIONERY_KEY,
        stationery_margins_mm: DEFAULT_STATIONERY_MARGINS_MM,
        hide_bank_footer: DEFAULT_HIDE_BANK_FOOTER,
        bank: {
          name: defRows?.[0]?.bank_name ?? null,
          sort_code: defRows?.[0]?.bank_sort_code ?? null,
          account_number: defRows?.[0]?.bank_account_number ?? null,
        },
        vat_registration_number: defRows?.[0]?.vat_registration_number ?? null,
        meta: { source: 'NHSP', run_at: issuedAt, shift_count: clientShifts.length },
        attach_policy: { requires_hr: false, hr_attach_to_invoice: false, ts_attach_to_invoice: false }
      };

      const invRes = await fetch(`${env.SUPABASE_URL}/rest/v1/invoices`, {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify({
          client_id: client.id,
          status: 'DRAFT',
          issued_at_utc: issuedAt,
          due_at_utc: dueAt,
          subtotal_ex_vat: 0,
          vat_amount: 0,
          total_inc_vat: 0,
          header_snapshot_json
        })
      });
      if (!invRes.ok) {
        const t = await invRes.text().catch(() => '');
        return withCORS(env, req, serverError(`Failed to create NHSP invoice for client ${cid}: ${t}`));
      }
      const invJson = await invRes.json().catch(() => []);
      const invoice = Array.isArray(invJson) ? invJson[0] : invJson;
      if (!invoice?.id) continue;

      let sumEx = 0, sumVat = 0, sumInc = 0;
      const lines = [];

      const byTimesheet = new Map();
      const bumpTs = (tsId, workDate, chargeEx) => {
        if (!tsId) return;
        const k = String(tsId);
        let v = byTimesheet.get(k);
        if (!v) v = { shift_count: 0, charge_ex_vat: 0, first_date: null, last_date: null };
        v.shift_count += 1;
        v.charge_ex_vat += Number(chargeEx || 0);
        if (workDate) {
          const wd = String(workDate);
          if (!v.first_date || wd < v.first_date) v.first_date = wd;
          if (!v.last_date  || wd > v.last_date)  v.last_date  = wd;
        }
        byTimesheet.set(k, v);
      };

      for (const sh of clientShifts) {
        const chargeEx = Number(sh.charge_amount_snapshot || 0);
        const vatAmt   = round2(chargeEx * (vatRatePct / 100));
        const incAmt   = round2(chargeEx + vatAmt);

        sumEx  += chargeEx;
        sumVat += vatAmt;
        sumInc += incAmt;

        bumpTs(sh.timesheet_id || null, sh.work_date || null, chargeEx);

        const desc = `NHSP shift ${sh.work_date} ${sh.start_utc}–${sh.end_utc}${sh.ward ? ' (' + sh.ward + ')' : ''}`;

        lines.push({
          invoice_id: invoice.id,
          timesheet_id: sh.timesheet_id || null,
          booking_id: null,
          description: desc,
          hours_day: 0, hours_night: 0, hours_sat: 0, hours_sun: 0, hours_bh: 0,
          pay_day: null, pay_night: null, pay_sat: null, pay_sun: null, pay_bh: null,
          charge_day: null, charge_night: null, charge_sat: null, charge_sun: null, charge_bh: null,
          total_pay_ex_vat: 0,
          total_charge_ex_vat: chargeEx,
          margin_ex_vat: chargeEx,
          vat_rate_pct: vatRatePct,
          vat_amount: vatAmt,
          total_inc_vat: incAmt,
          meta_json: {
            line_type: 'NHSP_SHIFT',
            nhsp_shift_id: sh.id,
            work_date: sh.work_date,
            ward: sh.ward,
            start_utc: sh.start_utc,
            end_utc: sh.end_utc,
            break_mins: sh.break_mins
          }
        });
      }

      if (lines.length) {
        const liRes = await fetch(`${env.SUPABASE_URL}/rest/v1/invoice_lines`, {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify(lines)
        });
        if (!liRes.ok) {
          const t = await liRes.text().catch(() => '');
          return withCORS(env, req, serverError(`Failed to insert NHSP invoice lines: ${t}`));
        }
      }

      const updRes = await fetch(
        `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoice.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-representation' },
          body: JSON.stringify({
            subtotal_ex_vat: round2(sumEx),
            vat_amount: round2(sumVat),
            total_inc_vat: round2(sumInc),
            updated_at: runAtIso
          })
        }
      );
      if (!updRes.ok) {
        const t = await updRes.text().catch(() => '');
        return withCORS(env, req, serverError(`Failed to update NHSP invoice totals: ${t}`));
      }

      const shiftIdList = clientShifts.map(s => s.id);
      const shiftParam  = shiftIdList.map(enc).join(',');
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/nhsp_shifts?id=in.(${shiftParam})`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            invoice_status: 'INCLUDED',
            invoice_id: invoice.id,
            updated_at: runAtIso
          })
        }
      ).catch(() => {});

      try {
        for (const [tsId, agg] of byTimesheet.entries()) {
          await writeAudit(
            env,
            user,
            'TIMESHEET_NHSP_INVOICED',
            {
              timesheet_id: tsId,
              invoice_id: invoice.id,
              client_id: client.id,
              run_at: issuedAt,
              shift_count: agg.shift_count,
              total_charge_ex_vat: round2(agg.charge_ex_vat),
              work_date_from: agg.first_date,
              work_date_to: agg.last_date
            },
            { entity: 'timesheets', subject_id: tsId, req }
          );
        }
      } catch {}

      invoicesOut.push({ invoice_id: invoice.id, client_id: client.id, shift_count: clientShifts.length });
    }

    await writeAudit(
      env,
      user,
      'NHSP_INVOICE_RUN_COMPLETED',
      { run_at: runAtIso, invoices: invoicesOut },
      { entity: 'invoice', subject_id: null, req }
    );

    return withCORS(env, req, ok({ run_at: runAtIso, invoices: invoicesOut }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to run NHSP invoice batch: ${e?.message || e}`));
  }
}



 async function handleNhspShiftDefer(env, req, shiftId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!shiftId) return withCORS(env, req, badRequest('shift id required'));

  const body = await parseJSONBody(req).catch(() => null) || {};
  const runAtRaw = body.run_at;
  let runAt = new Date();
  if (runAtRaw) {
    const d = new Date(runAtRaw);
    if (!isNaN(d.getTime())) runAt = d;
  }

  const enc = encodeURIComponent;
  const nowIso = new Date().toISOString();

  try {
    // Ensure shift exists
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts?id=eq.${enc(shiftId)}&select=id,invoice_status`
    );
    const shift = rows?.[0] || null;
    if (!shift) return withCORS(env, req, notFound('NHSP shift not found'));

    const patch = {
      invoice_status: 'PENDING',
      defer_until_run_after: runAt.toISOString(),
      invoice_id: null,
      updated_at: nowIso
    };

    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts?id=eq.${enc(shiftId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify(patch)
      }
    );
    if (!res.ok) {
      const t = await res.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to defer NHSP shift: ${t}`));
    }
    const updatedArr = await res.json().catch(() => []);
    const updated = Array.isArray(updatedArr) ? updatedArr[0] : updatedArr;

    await writeAudit(
      env,
      user,
      'NHSP_SHIFT_DEFERRED',
      { shift_id: shiftId, defer_until: patch.defer_until_run_after },
      { entity: 'nhsp_shifts', subject_id: shiftId, req }
    );

    return withCORS(env, req, ok({ shift: updated }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to defer NHSP shift: ${e?.message || e}`));
  }
}

async function handleInvoiceRemoveTimesheet(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!invoiceId) return withCORS(env, req, badRequest('invoice_id required'));

  const body = await parseJSONBody(req).catch(() => null) || {};
  const shiftIds = Array.isArray(body.shift_ids)
    ? [...new Set(body.shift_ids.map(String).filter(Boolean))]
    : [];

  if (!shiftIds.length) return withCORS(env, req, badRequest('shift_ids[] required'));

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_remove_nhsp_shifts', {
      p_invoice_id: invoiceId,
      p_shift_ids: shiftIds,
      p_actor_user_id: actorUserId
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x) return withCORS(env, req, serverError('Remove shifts RPC returned no result'));

    // Return a minimal invoice shape for FE compatibility
    return withCORS(env, req, ok({
      invoice: {
        id: x.invoice_id || invoiceId,
        subtotal_ex_vat: Number(x.subtotal_ex_vat || 0),
        vat_amount: Number(x.vat_amount || 0),
        total_inc_vat: Number(x.total_inc_vat || 0)
      }
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to remove NHSP shifts from invoice: ${e?.message || e}`));
  }
}

function getCandidateIdFromPath(req) {
  const url = new URL(req.url);
  const parts = url.pathname.split('/').filter(Boolean);
  const idx = parts.indexOf('candidates');
  if (idx >= 0 && parts[idx + 1]) return parts[idx + 1];
  return null;
}

function getAdvanceIdFromPath(req) {
  const url = new URL(req.url);
  const parts = url.pathname.split('/').filter(Boolean);
  const idx = parts.indexOf('advances');
  if (idx >= 0 && parts[idx + 1]) return parts[idx + 1];
  return null;
}

function computeNextDueFromSchedule(schedule) {
  if (!Array.isArray(schedule)) return null;
  let next = null;
  for (const e of schedule) {
    if (!e || typeof e !== 'object') continue;
    const amt = Number(e.amount || 0);
    const ws = typeof e.week_start === 'string' ? e.week_start : null;
    if (!ws || !amt || amt >= 0) continue; // only negative entries (repayments)
    if (!next || ws < next) next = ws;
  }
  return next;
}

 async function handlePayAdvancesList(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);

  const candidateId = getCandidateIdFromPath(req);
  if (!candidateId) {
    return withCORS(env, req, badRequest('candidate_id missing in path'));
  }

  const status = q('status'); // optional: ACTIVE | PAUSED | PAID_OFF | null

  let url =
    `${env.SUPABASE_URL}/rest/v1/pay_advances` +
    `?candidate_id=eq.${enc(candidateId)}` +
    `&select=id,candidate_id,client_id,reason,original_amount,outstanding_amount,` +
    `linked_shift_date,schedule_json,next_due_week_start,status,best_guess_hours,notes,created_at` +
    `&order=created_at.asc`;

  if (status) {
    url += `&status=eq.${enc(status)}`;
  }

  const { rows } = await sbFetch(env, url);
  const advances = rows || [];

  return withCORS(env, req, ok({ advances }));
}

 async function handlePayAdvancesCreateMissingShift(env, req, candidateIdParam) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const candidateId = candidateIdParam || getCandidateIdFromPath(req);
  if (!candidateId) {
    return withCORS(env, req, badRequest('candidate_id missing in path'));
  }

  const body = await parseJSONBody(req).catch(() => null);
  const client_id = body?.client_id || null;
  const shift_date = body?.shift_date || null;
  const amountRaw = body?.amount;
  const best_guess_hours = body?.best_guess_hours || null;
  const notes = body?.notes || null;

  const amount = Number(amountRaw || 0);
  if (!client_id) {
    return withCORS(env, req, badRequest('client_id is required'));
  }
  if (!shift_date) {
    return withCORS(env, req, badRequest('shift_date is required'));
  }
  if (!amount || amount <= 0) {
    return withCORS(env, req, badRequest('amount must be > 0'));
  }

  const nowIso = new Date().toISOString();

  const payload = [{
    candidate_id: candidateId,
    client_id,
    reason: 'MISSING_SHIFT',
    original_amount: round2(amount),
    outstanding_amount: round2(amount),
    linked_shift_date: shift_date,
    schedule_json: [],  // no schedule yet; repays when matching shift is paid
    next_due_week_start: null,
    status: 'ACTIVE',
    best_guess_hours: best_guess_hours || null,
    notes: notes || null,
    created_at: nowIso,
    updated_at: nowIso,
    created_by: user.id || null
  }];

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/pay_advances`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload)
    }
  );
  if (!res.ok) {
    const t = await res.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create missing-shift advance: ${t}`));
  }
  const json = await res.json().catch(() => []);
  const advance = Array.isArray(json) ? json[0] : json;

  await writeAudit(
    env,
    user,
    'PAY_ADVANCE_MISSING_SHIFT_CREATED',
    { candidate_id: candidateId, client_id, shift_date, amount: round2(amount) },
    { entity: 'candidate', subject_id: candidateId, reason: 'PAYMENT', req }
  );

  return withCORS(env, req, ok({ advance }));
}

 async function handlePayAdvancesCreateManual(env, req, candidateIdParam) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const candidateId = candidateIdParam || getCandidateIdFromPath(req);
  if (!candidateId) {
    return withCORS(env, req, badRequest('candidate_id missing in path'));
  }

  const body = await parseJSONBody(req).catch(() => null);
  const client_id = body?.client_id || null;
  const amountRaw = body?.amount;
  const start_week_start = body?.start_week_start || null;
  const weeks = Array.isArray(body?.weeks) ? body.weeks : [];
  const custom_schedule = Array.isArray(body?.custom_schedule) ? body.custom_schedule : null;
  const notes = body?.notes || null;

  const amount = Number(amountRaw || 0);
  if (!amount || amount <= 0) {
    return withCORS(env, req, badRequest('amount must be > 0'));
  }

  let schedule = [];

  if (custom_schedule && custom_schedule.length) {
    // Use custom schedule as-is, but ensure numeric amounts
    schedule = custom_schedule
      .map((e) => ({
        week_start: String(e.week_start || '').trim(),
        amount: Number(e.amount || 0)
      }))
      .filter((e) => e.week_start);
  } else if (weeks.length) {
    const N = weeks.length;
    const perWeek = round2(-amount / N);
    schedule = weeks.map((weekStart, i) => {
      const ws = String(weekStart || '').trim();
      if (!ws) return null;
      const base = (i === N - 1)
        ? round2(-amount - perWeek * (N - 1))
        : perWeek;
      return { week_start: ws, amount: base };
    }).filter(Boolean);
  } else if (start_week_start) {
    // Fallback: single repayment in the specified start week
    schedule = [{
      week_start: String(start_week_start).trim(),
      amount: round2(-amount)
    }];
  } else {
    return withCORS(env, req, badRequest('Either weeks[] or start_week_start is required'));
  }

  const nowIso = new Date().toISOString();
  const nextDue = computeNextDueFromSchedule(schedule);

  const payload = [{
    candidate_id: candidateId,
    client_id,
    reason: 'MANUAL_ADVANCE',
    original_amount: round2(amount),
    outstanding_amount: round2(amount),
    linked_shift_date: null,
    schedule_json: schedule,
    next_due_week_start: nextDue,
    status: 'ACTIVE',
    best_guess_hours: null,
    notes: notes || null,
    created_at: nowIso,
    updated_at: nowIso,
    created_by: user.id || null
  }];

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/pay_advances`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload)
    }
  );
  if (!res.ok) {
    const t = await res.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create manual advance: ${t}`));
  }
  const json = await res.json().catch(() => []);
  const advance = Array.isArray(json) ? json[0] : json;

  await writeAudit(
    env,
    user,
    'PAY_ADVANCE_MANUAL_CREATED',
    { candidate_id: candidateId, client_id, amount: round2(amount) },
    { entity: 'candidate', subject_id: candidateId, reason: 'PAYMENT', req }
  );

  return withCORS(env, req, ok({ advance }));
}

 async function handlePayAdvancesUpdate(env, req, advanceIdParam) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const advanceId = advanceIdParam || getAdvanceIdFromPath(req);
  if (!advanceId) {
    return withCORS(env, req, badRequest('advance id missing in path'));
  }

  const body = await parseJSONBody(req).catch(() => null);
  if (!body || typeof body !== 'object') {
    return withCORS(env, req, badRequest('Invalid JSON body'));
  }

  const patch = {};
  if ('notes' in body) patch.notes = body.notes;
  if ('status' in body && body.status) patch.status = body.status;

  if (Array.isArray(body.schedule_json)) {
    const schedule = body.schedule_json.map((e) => ({
      week_start: String(e.week_start || '').trim(),
      amount: Number(e.amount || 0)
    })).filter((e) => e.week_start);
    patch.schedule_json = schedule;
    patch.next_due_week_start = computeNextDueFromSchedule(schedule);
  }

  if (!Object.keys(patch).length) {
    return withCORS(env, req, badRequest('Nothing to update'));
  }

  patch.updated_at = new Date().toISOString();

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/pay_advances?id=eq.${enc(advanceId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(patch)
    }
  );
  if (!res.ok) {
    const t = await res.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to update advance: ${t}`));
  }
  const json = await res.json().catch(() => []);
  const advance = Array.isArray(json) ? json[0] : json;

  await writeAudit(
    env,
    user,
    'PAY_ADVANCE_UPDATED',
    { advance_id: advanceId, patch },
    { entity: 'pay_advance', subject_id: advanceId, reason: 'PAYMENT', req }
  );

  return withCORS(env, req, ok({ advance }));
}
 async function handlePayAdvancesPause(env, req, advanceIdParam) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const advanceId = advanceIdParam || getAdvanceIdFromPath(req);
  if (!advanceId) {
    return withCORS(env, req, badRequest('advance id missing in path'));
  }

  const patch = {
    status: 'PAUSED',
    updated_at: new Date().toISOString()
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/pay_advances?id=eq.${enc(advanceId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(patch)
    }
  );
  if (!res.ok) {
    const t = await res.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to pause advance: ${t}`));
  }
  const json = await res.json().catch(() => []);
  const advance = Array.isArray(json) ? json[0] : json;

  await writeAudit(
    env,
    user,
    'PAY_ADVANCE_PAUSED',
    { advance_id: advanceId },
    { entity: 'pay_advance', subject_id: advanceId, reason: 'PAYMENT', req }
  );

  return withCORS(env, req, ok({ advance }));
}

 async function handlePayAdvancesResume(env, req, advanceIdParam) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const advanceId = advanceIdParam || getAdvanceIdFromPath(req);
  if (!advanceId) {
    return withCORS(env, req, badRequest('advance id missing in path'));
  }

  // Load current schedule so we can recompute next_due_week_start
  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/pay_advances` +
      `?id=eq.${enc(advanceId)}` +
      `&select=id,schedule_json`
  );
  const adv = rows?.[0] || null;
  if (!adv) {
    return withCORS(env, req, notFound('advance not found'));
  }

  const schedule = Array.isArray(adv.schedule_json) ? adv.schedule_json : [];
  const nextDue = computeNextDueFromSchedule(schedule);

  const patch = {
    status: 'ACTIVE',
    next_due_week_start: nextDue,
    updated_at: new Date().toISOString()
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/pay_advances?id=eq.${enc(advanceId)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(patch)
    }
  );
  if (!res.ok) {
    const t = await res.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to resume advance: ${t}`));
  }
  const json = await res.json().catch(() => []);
  const advance = Array.isArray(json) ? json[0] : json;

  await writeAudit(
    env,
    user,
    'PAY_ADVANCE_RESUMED',
    { advance_id: advanceId },
    { entity: 'pay_advance', subject_id: advanceId, reason: 'PAYMENT', req }
  );

  return withCORS(env, req, ok({ advance }));
}

 async function handlePayAdvancesSummary(env, req, candidateIdParam) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;
  const candidateId = candidateIdParam || getCandidateIdFromPath(req);
  if (!candidateId) {
    return withCORS(env, req, badRequest('candidate_id missing in path'));
  }

  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/pay_advances` +
      `?candidate_id=eq.${enc(candidateId)}` +
      `&select=reason,outstanding_amount,original_amount,status` +
      `&order=created_at.asc`
  );
  const advances = rows || [];

  let totalOwedByCandidate = 0;
  let totalMissingShift = 0;

  for (const a of advances) {
    const out = Number(a.outstanding_amount || 0);
    if (a.status === 'ACTIVE' || a.status === 'PAUSED') {
      totalOwedByCandidate += out;
      if (a.reason === 'MISSING_SHIFT') {
        totalMissingShift += out;
      }
    }
  }

  const summary = {
    total_owed_by_candidate: round2(totalOwedByCandidate),
    total_advances_not_offset: round2(totalMissingShift)
  };

  return withCORS(env, req, ok(summary));
}

async function loadScheduledAdvanceEntries(env, candidateId, weekStart) {
  const enc = encodeURIComponent;

  // Fetch ACTIVE advances where there's something due on or before weekStart
  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/pay_advances` +
      `?candidate_id=eq.${enc(candidateId)}` +
      `&status=eq.ACTIVE` +
      `&next_due_week_start.lte.${enc(weekStart)}` +
      `&select=id,reason,original_amount,outstanding_amount,schedule_json`
  );

  const advances = rows || [];
  const entries = [];

  for (const adv of advances) {
    const schedule = Array.isArray(adv.schedule_json) ? adv.schedule_json : [];
    for (const e of schedule) {
      if (!e || typeof e !== 'object') continue;
      const ws = String(e.week_start || '').trim();
      if (!ws || ws !== weekStart) continue;

      const amount = Number(e.amount || 0);
      if (!amount) continue; // skip zeroes

      entries.push({
        advance_id: adv.id,
        amount,
        reason: adv.reason,
        original_amount: Number(adv.original_amount || 0),
        outstanding_amount: Number(adv.outstanding_amount || 0)
      });
    }
  }

  // We return both the flattened entries and the raw advances for convenience
  return { entries, advances };
}

async function applyAdvanceScheduleEntriesForWeek(env, candidateId, weekStart, initialGross, scheduleEntries) {
  let G = Number(initialGross || 0);
  const updates = [];

  for (const e of scheduleEntries || []) {
    if (!e || typeof e !== 'object') continue;
    const advId = e.advance_id;
    if (!advId) continue;

    const amt = Number(e.amount || 0);
    if (!amt) continue;

    if (amt > 0) {
      // Extra pay to worker this week
      G += amt;
      updates.push({
        advance_id: advId,
        amount: amt,
        actual: amt,
        remainder: 0,
        deltaOutstanding: -amt, // per brief
        reason: e.reason
      });
      continue;
    }

    // Repayment (negative)
    const planned = -amt;                // positive
    const maxAllowed = Math.max(0, G);   // must not push G below 0
    const actual = Math.min(planned, maxAllowed);
    G -= actual;
    const remainder = planned - actual;  // > 0 if we couldn't take it all

    updates.push({
      advance_id: advId,
      amount: amt,              // original scheduled amount (negative)
      actual,                   // amount actually taken this week (>= 0)
      remainder,                // still to recover in future weeks
      deltaOutstanding: -actual,
      reason: e.reason
    });
  }

  return {
    newGross: round2(G),
    updates
  };
}
async function persistAdvanceRepayments(env, updates, weekStart) {
  const enc = encodeURIComponent;

  if (!Array.isArray(updates) || !updates.length) return;

  // Group updates by advance_id
  const grouped = new Map();
  for (const u of updates) {
    if (!u || !u.advance_id) continue;
    const actual = Number(u.actual || 0);
    const remainder = Number(u.remainder || 0);

    if (!grouped.has(u.advance_id)) {
      grouped.set(u.advance_id, { totalActual: 0, totalRemainder: 0 });
    }
    const g = grouped.get(u.advance_id);
    g.totalActual += actual;
    g.totalRemainder += remainder;
  }

  if (!grouped.size) return;

  // Helper: add 7 days to a YYYY-MM-DD weekStart
  const add7Days = (ws) => {
    if (!ws) return null;
    const d = new Date(`${ws}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return ws;
    d.setUTCDate(d.getUTCDate() + 7);
    const yyyy = d.getUTCFullYear();
    const mm = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  for (const [advanceId, agg] of grouped.entries()) {
    const { totalActual, totalRemainder } = agg;
    if (!totalActual && !totalRemainder) continue;

    // Load current advance row
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/pay_advances` +
        `?id=eq.${enc(advanceId)}` +
        `&select=id,outstanding_amount,schedule_json,status`
    );
    const adv = rows?.[0] || null;
    if (!adv) continue;

    let outstanding = Number(adv.outstanding_amount || 0);
    const oldSchedule = Array.isArray(adv.schedule_json) ? adv.schedule_json : [];

    // Remove all entries for this weekStart
    const newSchedule = [];
    for (const e of oldSchedule) {
      if (!e || typeof e !== 'object') continue;
      const ws = String(e.week_start || '').trim();
      if (ws === weekStart) continue; // consumed in this run
      newSchedule.push(e);
    }

    // If there's any leftover to recover, schedule it for next week
    if (totalRemainder > 0) {
      const futureWeekStart = add7Days(weekStart);
      newSchedule.push({
        week_start: futureWeekStart,
        amount: -round2(totalRemainder) // negative = future repayment
      });
    }

    // Adjust outstanding balance by actual taken this week
    outstanding = round2(outstanding - totalActual);

    // Recompute next_due_week_start based on new schedule
    const nextDue = computeNextDueFromSchedule(newSchedule);

    // If no negative entries remain or outstanding <= 0 → mark as PAID_OFF
    const hasNegative = newSchedule.some(
      (e) => e && typeof e === 'object' && Number(e.amount || 0) < 0
    );
    let status = adv.status;
    if (!hasNegative || outstanding <= 0) {
      outstanding = 0;
      status = 'PAID_OFF';
    }

    const patch = {
      outstanding_amount: round2(outstanding),
      schedule_json: newSchedule,
      next_due_week_start: nextDue,
      status,
      updated_at: new Date().toISOString()
    };

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/pay_advances?id=eq.${enc(advanceId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(patch)
      }
    ).catch((e) => {
      console.warn('[pay_advances] persistAdvanceRepayments patch failed', {
        advance_id: advanceId,
        err: e?.message || String(e)
      });
    });
  }
}
async function createMissingShiftRepayEntriesForTs(env, candidateId, clientId, tsfinRow, weekStart) {
  const enc = encodeURIComponent;

  if (!candidateId || !clientId || !tsfinRow) return;

  const breakdown = tsfinRow.invoice_breakdown_json || {};
  if (breakdown.mode !== 'SEGMENTS' || !Array.isArray(breakdown.segments)) {
    return;
  }

  // Collect distinct shift dates from segments
  const dateSet = new Set();
  for (const seg of breakdown.segments) {
    if (!seg || typeof seg !== 'object') continue;
    const d = String(seg.date || '').trim();
    if (!d) continue;
    dateSet.add(d);
  }

  const dates = Array.from(dateSet);
  if (!dates.length) return;

  const datesParam = dates.map(enc).join(',');

  // Find ACTIVE MISSING_SHIFT advances for these dates
  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/pay_advances` +
      `?reason=eq.MISSING_SHIFT` +
      `&candidate_id=eq.${enc(candidateId)}` +
      `&client_id=eq.${enc(clientId)}` +
      `&status=eq.ACTIVE` +
      `&linked_shift_date=in.(${datesParam})` +
      `&select=id,linked_shift_date,outstanding_amount,schedule_json`
  );
  const advances = rows || [];
  if (!advances.length) return;

  for (const adv of advances) {
    const outstanding = Number(adv.outstanding_amount || 0);
    if (outstanding <= 0) continue;

    const schedule = Array.isArray(adv.schedule_json) ? adv.schedule_json : [];

    // Append a repayment entry for this pay week
    schedule.push({
      week_start: weekStart,
      amount: -round2(outstanding)   // try to recover full outstanding this week
    });

    const nextDue = computeNextDueFromSchedule(schedule);

    const patch = {
      schedule_json: schedule,
      next_due_week_start: nextDue,
      updated_at: new Date().toISOString()
    };

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/pay_advances?id=eq.${enc(adv.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(patch)
      }
    ).catch((e) => {
      console.warn('[pay_advances] createMissingShiftRepayEntriesForTs patch failed', {
        advance_id: adv.id,
        err: e?.message || String(e)
      });
    });
  }
}















async function buildHrRotaValidationContext(env, importId) {
  const enc  = encodeURIComponent;
  const norm = (s) => String(s || '').trim().toLowerCase();
  const LOG  = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const ctx = {
    import_id: importId,
    imp: null,
    error: null,
    hrRows: [],
    // caches
    candidateByNameTrust: new Map(), // `${staffNorm}|${trustNorm}` -> candidate_id|null
    clientByTrust: new Map(),        // trustNorm -> client_id|null
    timesheetsByCand: new Map()      // candidate_id -> [timesheets...]
  };

  // Load hr_imports
  const { rows: impRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_imports` +
      `?id=eq.${enc(importId)}` +
      `&select=id,source_system,client_id,parse_summary_json` +
      `&limit=1`
  );
  const imp = impRows?.[0] || null;
  if (!imp) {
    ctx.error = 'import_not_found';
    if (LOG) {
      console.warn('[HR_ROTA_CTX]', JSON.stringify({
        stage: 'import_not_found',
        import_id: importId
      }));
    }
    return ctx;
  }
  ctx.imp = imp;
  const src = String(imp.source_system || '').toUpperCase();
  if (src !== 'HEALTHROSTER_DAILY') {
    ctx.error = 'source_system_mismatch';
    if (LOG) {
      console.warn('[HR_ROTA_CTX]', JSON.stringify({
        stage: 'source_system_mismatch',
        import_id: importId,
        actual_source_system: src
      }));
    }
    return ctx;
  }

  // Load hr_rows (daily)
  const { rows: hrRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_rows` +
      `?import_id=eq.${enc(importId)}` +
      `&select=id,hr_request_id,date_local,start_time_local,end_time_local,` +
      `staff_raw,staff_norm,unit_raw,assignment_grade_norm,hours_worked,payload_json` +
      `&order=id.asc`
  );
  ctx.hrRows = hrRows || [];

  if (LOG) {
    console.log('[HR_ROTA_CTX]', JSON.stringify({
      stage: 'loaded',
      import_id: importId,
      hr_row_count: ctx.hrRows.length
    }));
  }

  return ctx;
}

async function classifyHrRotaRow(env, hrRow, context) {
  const enc   = encodeURIComponent;
  const norm  = (s) => String(s || '').trim().toLowerCase();

  const importId = context.import_id;

  // helper: candidate + trust cache
  async function resolveCandidateByNameTrustCached(staffRaw, staffNorm, trustNorm) {
    const nameKey = `${staffNorm || norm(staffRaw)}|${trustNorm || ''}`;
    if (context.candidateByNameTrust.has(nameKey)) {
      return context.candidateByNameTrust.get(nameKey);
    }
    let candidateId = null;
    try {
      candidateId = await findCandidateByImportName(env, staffRaw || staffNorm, { trustNorm });
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] candidate resolve failed (non-fatal)', {
        import_id: importId,
        staff: staffRaw,
        trustNorm,
        err: e?.message || String(e)
      });
    }
    context.candidateByNameTrust.set(nameKey, candidateId || null);
    return candidateId || null;
  }

  async function resolveClientIdCached(hospRaw) {
    const t = String(hospRaw || '').trim();
    const trustNorm = norm(t);
    if (!trustNorm) return null;
    if (context.clientByTrust.has(trustNorm)) return context.clientByTrust.get(trustNorm);

    let clientId = null;
    try {
      clientId = await resolveClientId(env, hospRaw);
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] client resolve failed (non-fatal)', {
        import_id: importId,
        hospital: hospRaw,
        err: e?.message || String(e)
      });
    }
    context.clientByTrust.set(trustNorm, clientId || null);
    return clientId || null;
  }

  async function getDailyTimesheetsForCandidateCached(candidateId) {
    if (!candidateId) return [];
    if (context.timesheetsByCand.has(candidateId)) {
      return context.timesheetsByCand.get(candidateId);
    }
    let tsRows = [];
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?candidate_id=eq.${enc(candidateId)}` +
          `&sheet_scope=eq.DAILY` +
          `&is_current=eq.true` +
          `&select=timesheet_id,worked_start_iso,hospital_norm,contract_id,job_title_norm,band`
      );
      tsRows = rows || [];
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] timesheets lookup failed (non-fatal)', {
        import_id: importId,
        candidate_id: candidateId,
        err: e?.message || String(e)
      });
      tsRows = [];
    }
    context.timesheetsByCand.set(candidateId, tsRows);
    return tsRows;
  }

  // extract HR row fields
  const hrRowId       = hrRow.id;
  const hrRequestId   = hrRow.hr_request_id || null;
  const dateLocal     = hrRow.date_local || null;
  const staffRaw      = hrRow.staff_raw || hrRow.payload_json?.staff_name || '';
  const staffNorm     = hrRow.staff_norm || norm(staffRaw);
  const hospRaw       = hrRow.unit_raw || hrRow.payload_json?.unit || hrRow.payload_json?.ward || '';
  const hospNorm      = norm(hospRaw);
  const gradeRaw      = hrRow.assignment_grade_norm || hrRow.payload_json?.grade_raw || hrRow.payload_json?.Request_Grade || null;
  const hoursWorked   = hrRow.hours_worked ?? hrRow.payload_json?.actual_hours ?? null;
  const startLocal    = hrRow.start_time_local || hrRow.payload_json?.start_local || null;
  const endLocal      = hrRow.end_time_local || hrRow.payload_json?.end_local || null;

  const baseResult = {
    hr_row_id: hrRowId,
    import_id: importId,
    source_system: 'HEALTHROSTER_DAILY',
    hr_request_id: hrRequestId,
    staff_name: staffRaw || null,
    staff_norm: staffNorm || null,
    hospital_or_trust: hospRaw || null,
    trust_norm: hospNorm || null,
    date_local: dateLocal,
    timesheet_id: null,
    status: 'UNMATCHED',
    reason_code: 'timesheet_not_found_or_ambiguous',
    can_email: false,
    details: {
      start_local: startLocal,
      end_local: endLocal,
      hours_worked: hoursWorked
    }
  };

  // candidate
  let candidateId = null;
  if (staffNorm) {
    candidateId = await resolveCandidateByNameTrustCached(staffRaw, staffNorm, hospNorm);
  }

  // client
  let clientId = null;
  if (hospRaw) {
    clientId = await resolveClientIdCached(hospRaw);
  }

  if (!candidateId || !clientId || !dateLocal) {
    return { baseResult, classification: { ...baseResult } };
  }

  // timesheet
  let ts = null;
  const tsRows = await getDailyTimesheetsForCandidateCached(candidateId);
  const candidates = [];
  for (const t of tsRows || []) {
    const wsIso = t.worked_start_iso || null;
    if (!wsIso) continue;
    let ymd = null;
    try {
      const parts = toLocalParts(wsIso, null);
      ymd = parts && parts.ymd ? parts.ymd : String(wsIso).slice(0, 10);
    } catch {
      ymd = String(wsIso).slice(0, 10);
    }
    if (ymd !== dateLocal) continue;
    if (hospNorm && t.hospital_norm) {
      const tsHospNorm = norm(t.hospital_norm);
      if (tsHospNorm !== hospNorm) {
        continue;
      }
    }
    candidates.push(t);
  }

  if (candidates.length === 1) {
    ts = candidates[0];
  } else {
    return { baseResult, classification: { ...baseResult } };
  }

  const timesheetId = ts?.timesheet_id || null;
  if (!timesheetId) {
    return { baseResult, classification: { ...baseResult } };
  }

  // map grade to roleForRates
  let roleForRates = null;
  try {
    const gradeUse = gradeRaw || null;
    roleForRates = await mapRequestGradeToRole(env, {
      client_id: clientId,
      candidate_id: candidateId,
      gradeRaw: gradeUse,
      dateYmd: dateLocal
    });
  } catch (e) {
    console.warn('[HR_ROTA_CLASSIFY] mapRequestGradeToRole failed (non-fatal)', {
      import_id: importId,
      hr_row_id: hrRowId,
      err: e?.message || String(e)
    });
  }

  const hrRowForValidation = {
    id: hrRowId,
    hr_request_id: hrRequestId,
    date_local: dateLocal,
    start_time_local: startLocal,
    end_time_local: endLocal,
    staff_raw: staffRaw,
    staff_norm: staffNorm,
    hospital_or_trust: hospRaw,
    assignment_grade_norm: gradeRaw,
    hours_worked: hoursWorked,
    payload_json: hrRow.payload_json || {}
  };

  let validationRes = { ok: false, reason_code: 'internal_error', detail: null };
  try {
    validationRes = await validateDailyRotaRowAgainstTimesheet(
      env,
      ts,
      hrRowForValidation,
      { roleForRates }
    );
  } catch (e) {
    console.warn('[HR_ROTA_CLASSIFY] validateDailyRotaRowAgainstTimesheet failed (non-fatal)', {
      import_id: importId,
      hr_row_id: hrRowId,
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
  }

  const ok = !!validationRes.ok;
  const reasonCode = validationRes.reason_code || null;
  const canEmail =
    !!timesheetId &&
    !!reasonCode &&
    ['actual_hours_mismatch', 'start_end_mismatch', 'break_minutes_mismatch'].includes(
      String(reasonCode).toLowerCase()
    );

  const classification = {
    ...baseResult,
    timesheet_id: timesheetId,
    status: ok ? 'VALIDATION_OK' : 'FAILED',
    reason_code: reasonCode || (ok ? null : 'validation_failed'),
    can_email: canEmail,
    details: validationRes.detail || baseResult.details
  };

  return { baseResult, classification };
}



async function buildWeeklyImportContext(env, importId, sourceSystem) {
  const enc  = encodeURIComponent;
  const norm = (s) => String(s || '').trim().toLowerCase();
  const LOG  = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const ctx = {
    import_id: importId,
    expected_source_system: String(sourceSystem || '').toUpperCase(),
    imp: null,
    source_system: null,
    hrRows: [],
    settings: null,

    // caches for batching
    candidateByNi: new Map(),
    candidateById: new Map(),
    candidateByNameTrust: new Map(), // `${name_norm}|${trust_norm}` -> candidate_id|null
    clientByTrust: new Map(),        // trust_norm -> {client_id,name}|null
    clientById: new Map(),           // client_id -> row
    contractsByCandClient: new Map(),// `${cand_id}__${client_id}` -> [contracts]
    clientSettingsByClient: new Map(),// client_id -> client_settings row
    timesheetsById: new Map(),
    tsfinById: new Map()
  };

  // Load settings
  ctx.settings = await loadSettingsDefaults(env);

  // Load hr_imports row
  const { rows: impRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_imports` +
      `?id=eq.${enc(importId)}` +
      `&select=id,source_system,client_id,filename,parse_summary_json` +
      `&limit=1`
  );
  const imp = impRows?.[0] || null;
  if (!imp) {
    ctx.error = 'import_not_found';
    if (LOG) {
      console.warn('[WEEKLY_CTX]', JSON.stringify({
        stage: 'import_not_found',
        import_id: importId
      }));
    }
    return ctx;
  }
  ctx.imp = imp;
  ctx.source_system = String(imp.source_system || '').toUpperCase();

  if (ctx.source_system !== ctx.expected_source_system) {
    ctx.error = 'source_system_mismatch';
    if (LOG) {
      console.warn('[WEEKLY_CTX]', JSON.stringify({
        stage: 'source_system_mismatch',
        import_id: importId,
        expected: ctx.expected_source_system,
        actual: ctx.source_system
      }));
    }
    return ctx;
  }

  // Load hr_rows
  const { rows: hrRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_rows` +
      `?import_id=eq.${enc(importId)}` +
      `&select=id,external_row_key,payload_json` +
      `&order=id.asc`
  );
  ctx.hrRows = hrRows || [];

  if (LOG) {
    console.log('[WEEKLY_CTX]', JSON.stringify({
      stage: 'loaded',
      import_id: importId,
      source_system: ctx.source_system,
      hr_row_count: ctx.hrRows.length
    }));
  }

  return ctx;
}

async function resolveClientForWeeklyRow(env, payload, context) {
  const enc  = encodeURIComponent;
  const norm = (s) => String(s || '').trim().toLowerCase();

  const trustRaw = String(
    payload.trust ||
    payload.hospital_or_trust ||
    payload.client ||
    ''
  ).trim();
  const trustNorm = norm(trustRaw);

  if (!trustNorm) return null;

  if (context.clientByTrust.has(trustNorm)) {
    const row = context.clientByTrust.get(trustNorm);
    return row ? row.client_id : null;
  }

  let clientId = null;
  let clientName = null;

  try {
    const aliasJson = JSON.stringify([trustNorm]);
    const { rows: hospRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
        `?hospital_name_norm=cs.${enc(aliasJson)}` +
        `&select=client_id&limit=1`
    );
    if (hospRows?.[0]?.client_id) {
      clientId = hospRows[0].client_id;
    } else {
      const { rows: cliRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients` +
          `?name=eq.${enc(trustRaw)}` +
          `&select=id,name&limit=1`
      );
      if (cliRows?.[0]?.id) {
        clientId   = cliRows[0].id;
        clientName = cliRows[0].name;
      }
    }
  } catch {
    if (!clientId) {
      const { rows: cliRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients` +
          `?name=eq.${enc(trustRaw)}` +
          `&select=id,name&limit=1`
      );
      if (cliRows?.[0]?.id) {
        clientId   = cliRows[0].id;
        clientName = cliRows[0].name;
      }
    }
  }

  if (clientId && !clientName) {
    const { rows: cliRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/clients` +
        `?id=eq.${enc(clientId)}&select=id,name&limit=1`
    );
    const cli = cliRows?.[0] || null;
    clientName = cli?.name || null;
  }

  const row = clientId ? { client_id: clientId, name: clientName } : null;
  context.clientByTrust.set(trustNorm, row);
  if (row) context.clientById.set(clientId, row);
  return clientId;
}

async function groupWeeklyRows(env, hrRows, context, sourceSystem) {
  const norm = (s) => String(s || '').trim().toLowerCase();
  const upper = (s) => String(s || '').trim().toUpperCase();

  const groupMap = new Map(); // key -> group object

  for (const hrRow of hrRows || []) {
    const payload = hrRow.payload_json || {};
    const id      = hrRow.id;

    let staffName = '';
    let workDate  = '';
    let ward      = '';
    let trustRaw  = '';
    let startIso  = null;
    let endIso    = null;
    let breakMins = 0;
    let finalised = '';
    let assignmentCode = '';

    if (sourceSystem === 'NHSP') {
      staffName = String(payload.worker_name || payload.name || '').trim();
      workDate  = String(payload.work_date || payload.date || '').trim();
      ward      = String(payload.ward || payload.unit || '').trim();
      trustRaw  = String(payload.trust || payload.hospital_or_trust || '').trim();
      startIso  = payload.start_utc || payload.actual_start_iso || payload.actual_start || null;
      endIso    = payload.end_utc   || payload.actual_end_iso   || payload.actual_end   || null;
      breakMins = Number(payload.break_mins ?? payload.break_minutes ?? payload.actual_break_minutes ?? 0) || 0;
      assignmentCode = String(payload.assignment || payload.assignment_code || '').trim();
    } else {
      // HEALTHROSTER
      staffName = String(payload.staff_name || payload.worker_name || '').trim();
      workDate  = String(payload.work_date || payload.date || '').trim();
      ward      = String(payload.ward || payload.unit || '').trim();
      trustRaw  = String(payload.trust || payload.hospital_or_trust || '').trim();
      startIso  = payload.start_utc || null;
      endIso    = payload.end_utc   || null;
      breakMins = Number(payload.break_mins ?? 0) || 0;
      finalised = String(payload.finalised_date || payload.finalized_date || '').trim();
    }

    if (!workDate || !startIso || !endIso) {
      // skip bad rows at grouping time; row-level rejection can still be added by caller
      continue;
    }

    const staffNorm = norm(staffName);
    const trustNorm = norm(trustRaw);

    const candidateId = await resolveCandidateForWeeklyRow(env, payload, context);
    const clientId    = await resolveClientForWeeklyRow(env, payload, context);

    if (!candidateId || !clientId) {
      // cannot group; caller can treat as row-level REJECT
      continue;
    }

    // Contracts & week-ending are best handled by the main classifier.
    // Here we'll just collect raw shifts keyed by candidate/client/date.
    const key = `${candidateId}__${clientId}__${workDate}`;
    let g = groupMap.get(key);
    if (!g) {
      g = {
        candidate_id: candidateId,
        candidate_name: staffName,
        client_id: clientId,
        client_name: null, // caller can populate from context.clientById
        work_date: workDate,
        shifts: [],
        hr_row_ids: [],
        has_unfinalised: sourceSystem === 'HEALTHROSTER' && !finalised,
        assignment_code: (sourceSystem === 'NHSP' ? assignmentCode : null)
      };
      groupMap.set(key, g);
    }

    g.shifts.push({
      hr_row_id: id,
      staff_name: staffName,
      work_date: workDate,
      ward,
      start_utc: startIso,
      end_utc: endIso,
      break_mins: breakMins,
      assignment_code: (sourceSystem === 'NHSP' ? assignmentCode : null),
      is_unfinalised: (sourceSystem === 'HEALTHROSTER' && !finalised)
    });
    g.hr_row_ids.push(id);
  }

  return groupMap;
}

async function classifyWeeklyGroup(env, group, context, sourceSystem) {
  // This is a *skeleton* that you can fill with your existing classifyGroup logic.
  // For now, we return an UNKNOWN action, so it is safe but not yet fully wired.

  const result = {
    level: 'group',
    preview_group_id: `grp:${group.contract_id || 'UNK'}:${group.week_ending_date || group.work_date}:${group.candidate_id}`,
    import_id: context.import_id,
    source_system: sourceSystem,
    candidate_id: group.candidate_id,
    candidate_name: group.candidate_name || null,
    client_id: group.client_id,
    client_name: group.client_name || null,
    contract_id: group.contract_id || null,
    week_ending_date: group.week_ending_date || group.work_date || null,
    assignment_code: group.assignment_code || null,
    self_bill: null,
    has_unfinalised: !!group.has_unfinalised,
    hr_row_ids: group.hr_row_ids ? group.hr_row_ids.slice() : [],
    truth_pay_ex_vat: null,
    truth_charge_ex_vat: null,
    current_pay_ex_vat: null,
    current_charge_ex_vat: null,
    delta_pay_ex_vat: null,
    delta_charge_ex_vat: null,
    base_timesheet_id: null,
    latest_adjustment_timesheet_id: null,
    action: 'UNKNOWN',
    reason: 'classifyWeeklyGroup is not yet wired with full group logic',
    default_selected: false
  };

  return result;
}





















 async function handleNhspImportsList(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const url = new URL(req.url);
  const q = (k) => url.searchParams.get(k);
  const enc = encodeURIComponent;

  const page     = Math.max(1, parseInt(q('page') || '1', 10));
  const pageSize = Math.max(1, Math.min(200, parseInt(q('page_size') || '50', 10)));

  const order   = q('order') || 'uploaded_at_utc.desc';
  const orderEnc = enc(order);

  try {
    // 1) Load NHSP imports
    let api =
      `${env.SUPABASE_URL}/rest/v1/hr_imports` +
      `?source_system=eq.NHSP` +
      `&select=id,filename,uploaded_by,uploaded_at_utc,tz_assumption,parse_summary_json,file_r2_key,source_system` +
      `&order=${orderEnc}` +
      `&limit=${pageSize}&offset=${(page-1)*pageSize}`;

    const { rows: imports } = await sbFetch(env, api, false);
    const list = imports || [];
    if (!list.length) {
      return withCORS(env, req, ok({ items: [], page, page_size: pageSize, count: 0 }));
    }

    const ids = list.map(r => r.id);
    const idParam = ids.map(enc).join(',');

    // 2) Aggregates: row_count from hr_rows, shift_count from nhsp_shifts
    const { rows: rowAgg } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_rows` +
        `?import_id=in.(${idParam})` +
        `&select=import_id,count:id` +
        `&group=import_id`
    );
    const rowCountMap = Object.fromEntries(
      (rowAgg || []).map(r => [r.import_id, Number(r.count || 0)])
    );

    const { rows: shiftAgg } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
        `?latest_import_id=in.(${idParam})` +
        `&select=latest_import_id,count:id` +
        `&group=latest_import_id`
    );
    const shiftCountMap = Object.fromEntries(
      (shiftAgg || []).map(r => [r.latest_import_id, Number(r.count || 0)])
    );

    const items = list.map(r => ({
      ...r,
      row_count: rowCountMap[r.id] || 0,
      shift_count: shiftCountMap[r.id] || 0
    }));

    return withCORS(env, req, ok({
      items,
      page,
      page_size: pageSize,
      count: items.length
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to list NHSP imports: ${e?.message || e}`));
  }
}
 async function handleNhspImportSummary(env, req, importId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) return withCORS(env, req, badRequest('import_id required'));

  const enc = encodeURIComponent;

  try {
    // 1) Confirm import is NHSP
    const { rows: impRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_imports` +
        `?id=eq.${enc(importId)}` +
        `&select=id,source_system,filename,uploaded_at_utc,parse_summary_json` +
        `&limit=1`
    );
    const imp = impRows?.[0] || null;
    if (!imp) return withCORS(env, req, notFound('NHSP import not found'));
    if (imp.source_system !== 'NHSP') {
      return withCORS(env, req, badRequest(`Import ${importId} is not NHSP (source_system=${imp.source_system})`));
    }

    // 2) Row count from hr_rows
    const { rows: rowAgg } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_rows` +
        `?import_id=eq.${enc(importId)}` +
        `&select=count:id`
    );
    const rowCount = Number(rowAgg?.[0]?.count || 0);

    // 3) Shifts for this import
    const { rows: shiftRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/nhsp_shifts` +
        `?latest_import_id=eq.${enc(importId)}` +
        `&select=id,external_row_key,candidate_id,client_id,timesheet_id`
    );
    const shifts = shiftRows || [];
    const shiftCount = shifts.length;

    const shiftsMappedTimesheets = shifts.filter(s => !!s.timesheet_id).length;
    const shiftsUnmatched = shifts.filter(s => !s.candidate_id || !s.client_id).length;

    // 4) Created vs updated shifts by external_row_key (across imports)
    const keys = [...new Set(shifts.map(s => s.external_row_key).filter(Boolean))];
    let createdCount = 0;
    let updatedCount = 0;

    if (keys.length) {
      const keyParam = keys.map(enc).join(',');
      const { rows: otherRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/hr_rows` +
          `?external_row_key=in.(${keyParam})` +
          `&import_id=neq.${enc(importId)}` +
          `&select=external_row_key`
      );
      const otherKeys = new Set((otherRows || []).map(r => r.external_row_key).filter(Boolean));

      for (const k of keys) {
        if (otherKeys.has(k)) updatedCount++;
        else createdCount++;
      }
    }

    // 5) Adjustments created (TSFIN basis = 'NHSP_ADJUSTMENT' and nhsp_import_id = import_id)
    const { rows: adjRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?nhsp_import_id=eq.${enc(importId)}` +
        `&basis=eq.NHSP_ADJUSTMENT` +
        `&select=count:id`
    );
    const adjustmentsCreated = Number(adjRows?.[0]?.count || 0);

    return withCORS(env, req, ok({
      import_id: importId,
      filename: imp.filename,
      uploaded_at_utc: imp.uploaded_at_utc,
      row_count: rowCount,
      shift_count: shiftCount,
      shifts_mapped_timesheets: shiftsMappedTimesheets,
      shifts_unmatched: shiftsUnmatched,
      shifts_created: createdCount,
      shifts_updated: updatedCount,
      adjustments_created: adjustmentsCreated
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to summarise NHSP import: ${e?.message || e}`));
  }
}
async function handleTimesheetCreateManualNhspShift(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await parseJSONBody(req).catch(() => null) || {};

  const candidateId = body.candidate_id && String(body.candidate_id).trim();
  const clientId    = body.client_id && String(body.client_id).trim();
  const workDate    = body.work_date && String(body.work_date).trim();
  const startUtc    = body.start_utc && String(body.start_utc).trim();
  const endUtc      = body.end_utc && String(body.end_utc).trim();
  const breakMins   = Number(body.break_mins || 0) || 0;
  const ward        = body.ward && String(body.ward).trim();

  // NEW: optional per-day reference for this shift (e.g. NHSP ref / manual ref)
  // If the caller includes day_reference, we will merge it into timesheets.day_references_json[workDate].
  const hasDayReferenceField = Object.prototype.hasOwnProperty.call(body, 'day_reference');
  const dayReferenceRaw      = hasDayReferenceField ? (body.day_reference ?? '') : undefined;
  const dayReference         = hasDayReferenceField ? String(dayReferenceRaw || '').trim() : undefined;

  if (!candidateId || !clientId || !workDate || !startUtc || !endUtc) {
    return withCORS(env, req, badRequest('candidate_id, client_id, work_date, start_utc and end_utc are required'));
  }

  const enc = encodeURIComponent;
  const nowIso = new Date().toISOString();

  try {
    // 1) Validate candidate
    const { rows: cRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?id=eq.${enc(candidateId)}&select=id,display_name` +
        `&limit=1`
    );
    const cand = cRows?.[0] || null;
    if (!cand) return withCORS(env, req, notFound('Candidate not found'));

    // 2) Validate client and ensure is_nhsp
    const { rows: cliRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/clients` +
        `?id=eq.${enc(clientId)}&select=id,name` +
        `&limit=1`
    );
    const client = cliRows?.[0] || null;
    if (!client) return withCORS(env, req, notFound('Client not found'));

    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
        `?client_id=eq.${enc(clientId)}&select=is_nhsp,week_ending_weekday` +
        `&order=effective_from.desc&limit=1`
    );
    const cs = csRows?.[0] || null;
    if (!cs || cs.is_nhsp !== true) {
      return withCORS(env, req, badRequest('Client is not marked as NHSP in client_settings'));
    }

    const weekEndingWeekday = Number.isInteger(Number(cs.week_ending_weekday))
      ? Number(cs.week_ending_weekday)
      : 0; // default Sunday

    // 3) Find contract covering this date
    const { rows: contractRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?candidate_id=eq.${enc(candidateId)}` +
        `&client_id=eq.${enc(clientId)}` +
        `&select=*`
    );
    const allContracts = contractRows || [];
    const dateObj = new Date(`${workDate}T00:00:00Z`);
    if (isNaN(dateObj.getTime())) {
      return withCORS(env, req, badRequest('Invalid work_date'));
    }

    let chosen = null;
    for (const c of allContracts) {
      const start = c.start_date ? new Date(`${c.start_date}T00:00:00Z`) : null;
      const end   = c.end_date   ? new Date(`${c.end_date}T00:00:00Z`)   : null;
      if (start && dateObj < start) continue;
      if (end   && dateObj > end)   continue;
      if (!chosen) chosen = c;
      else {
        // pick the contract with the latest start_date
        const prevStart = chosen.start_date ? new Date(`${chosen.start_date}T00:00:00Z`) : null;
        if (prevStart && start && start > prevStart) chosen = c;
      }
    }

    if (!chosen) {
      return withCORS(env, req, badRequest('No contract covers this candidate/client/work_date'));
    }

    const contract = chosen;

    // 4) Compute week_ending_date based on client week_ending_weekday
    const d = new Date(dateObj);
    // Find next week_ending_weekday ON or AFTER work_date
    while (d.getUTCDay() !== weekEndingWeekday) {
      d.setUTCDate(d.getUTCDate() + 1);
    }
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    const weekEndingDate = `${yyyy}-${mm}-${dd}`;

    // 5) Find or create contract_week for this contract/week
    const { rows: cwRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(contract.id)}` +
        `&week_ending_date=eq.${enc(weekEndingDate)}` +
        `&additional_seq=eq.0` +
        `&select=*` +
        `&limit=1`
    );
    let cw = cwRows?.[0] || null;

    if (!cw) {
      const cwPayload = {
        contract_id: contract.id,
        week_ending_date: weekEndingDate,
        additional_seq: 0,
        is_adjustment: false,
        status: 'OPEN',
        created_at: nowIso,
        updated_at: nowIso
      };
      const insCw = await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'return=representation' },
          body: JSON.stringify(cwPayload)
        }
      );
      if (!insCw.ok) {
        const t = await insCw.text().catch(() => '');
        return withCORS(env, req, serverError(`Failed to create contract_week: ${t}`));
      }
      const cwJson = await insCw.json().catch(() => []);
      cw = Array.isArray(cwJson) ? cwJson[0] : cwJson;
    }

    // 6) Find or create a weekly timesheet for this week
    let ts = null;
    if (cw.timesheet_id) {
      const { rows: tsRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(cw.timesheet_id)}&select=*`
      );
      ts = tsRows?.[0] || null;
    }

    if (!ts) {
      const occNorm  = (cand.display_name || String(cand.id)).toLowerCase();
      const hospNorm = (contract.display_site || client.name || String(client.id)).toLowerCase();
      const wardNorm = (ward || contract.ward_hint || 'nhsp-manual').toLowerCase();
      const jobTitleNorm = (contract.role || 'nhsp-weekly').toLowerCase();

      // We assume a helper makeWeeklyBookingId exists; if not, you can substitute your own booking id logic.
      const bookingId = makeWeeklyBookingId
        ? makeWeeklyBookingId(cand.id, contract, cw)
        : `NHSP:${candidateId}:${clientId}:${weekEndingDate}`;

      const tsPayload = [{
        booking_id: bookingId,
        version: 1,
        is_current: true,
        status: 'SUBMITTED',
        occupant_key_norm: occNorm,
        hospital_norm: hospNorm,
        ward_norm: wardNorm,
        job_title_norm: jobTitleNorm,
        shift_label_norm: 'weekly',
        week_ending_date: weekEndingDate,
        r2_nurse_key: null,
        r2_auth_key: null,
        contract_id: contract.id,
        submission_mode: 'MANUAL',
        manual_pdf_r2_key: null,
        line_type: 'HOURS',
        actual_schedule_json: [],
        authorised_at_server: null,
        created_at: nowIso,
        updated_at: nowIso
      }];

      const insTs = await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'return=representation' },
          body: JSON.stringify(tsPayload)
        }
      );
      if (!insTs.ok) {
        const t = await insTs.text().catch(() => '');
        return withCORS(env, req, serverError(`Failed to create weekly NHSP timesheet: ${t}`));
      }
      const tsJson = await insTs.json().catch(() => []);
      ts = Array.isArray(tsJson) ? tsJson[0] : tsJson;

      // Link week → timesheet
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({ timesheet_id: ts.timesheet_id, status: 'SUBMITTED', updated_at: nowIso })
        }
      ).catch(() => {});
    }

    // 7) Append shift segment to actual_schedule_json
    const existingSched = Array.isArray(ts.actual_schedule_json)
      ? ts.actual_schedule_json
      : [];

    existingSched.push({
      date: workDate,
      ward: ward || null,
      start_utc: startUtc,
      end_utc: endUtc,
      break_mins: breakMins
    });

    // NEW: merge per-day reference into timesheets.day_references_json (if supplied)
    let patchBody = {
      actual_schedule_json: existingSched,
      updated_at: nowIso
    };

    if (hasDayReferenceField) {
      // Start from any existing day_references_json on the timesheet
      let dayRefs = {};
      if (ts.day_references_json && typeof ts.day_references_json === 'object') {
        dayRefs = { ...ts.day_references_json };
      }

      if (dayReference) {
        // Set/overwrite the reference for this workDate
        dayRefs[workDate] = dayReference;
      } else {
        // Empty string/null in the request means "clear this date's reference"
        if (dayRefs.hasOwnProperty(workDate)) {
          delete dayRefs[workDate];
        }
      }

      patchBody.day_references_json = Object.keys(dayRefs).length ? dayRefs : null;
    }

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(patchBody)
      }
    ).catch(() => {});

    // 8) Optionally enqueue TSFIN recompute (worker will handle basis, hours, etc.)
    try {
      // ✅ FIX: enqueue_ts_financials signature uses (_timesheet_id, _reason)
      await sbRpc(env, 'enqueue_ts_financials', { _timesheet_id: ts.timesheet_id, _reason: 'MANUAL_NHSP_SHIFT_ADDED' });
    } catch {
      // best-effort; triggers may already handle it
    }

    await writeAudit(
      env,
      user,
      'NHSP_MANUAL_SHIFT_CREATED',
      {
        candidate_id: candidateId,
        client_id: clientId,
        work_date: workDate,
        start_utc: startUtc,
        end_utc: endUtc,
        break_mins: breakMins,
        timesheet_id: ts.timesheet_id,
        contract_week_id: cw.id,
        // Include reference info in the audit if provided
        ...(hasDayReferenceField ? { day_reference: dayReference || null } : {})
      },
      { entity: 'timesheet', subject_id: ts.timesheet_id, req }
    );

    return withCORS(env, req, ok({
      timesheet_id: ts.timesheet_id,
      contract_week_id: cw.id,
      work_date: workDate,
      appended: true
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to create manual NHSP shift: ${e?.message || e}`));
  }
}

// Helper: normalise a value (string / CSV / JSON / array) into a
// lower-cased, de-duplicated array of aliases.
function normaliseAliasList(val) {
  if (val == null) return [];

  if (Array.isArray(val)) {
    return val
      .map((x) => String(x || '').trim().toLowerCase())
      .filter(Boolean);
  }

  if (typeof val === 'string') {
    const s = val.trim();
    if (!s) return [];

    // If it's a JSON array string
    if (s.startsWith('[')) {
      try {
        const arr = JSON.parse(s);
        if (Array.isArray(arr)) {
          return arr
            .map((x) => String(x || '').trim().toLowerCase())
            .filter(Boolean);
        }
      } catch {
        // fall through to CSV/single handling
      }
    }

    // Treat as CSV or single value
    return s
      .split(',')
      .map((x) => x.trim().toLowerCase())
      .filter(Boolean);
  }

  // Fallback: single value
  return [String(val).trim().toLowerCase()].filter(Boolean);
}

// Helper: resolve a staff name from NHSP/HealthRoster to a candidate.
// 1) Try candidates.nhsp_hr_name_aliases (JSONB aliases).
// 2) Fall back to hr_name_mappings (existing behaviour).

// ─────────────────────────────────────────────────────────────
// resolveClientId: now uses JSONB aliases on client_hospitals.hospital_name_norm
// ─────────────────────────────────────────────────────────────
async function resolveClientId(env, hospital_norm) {
  if (!hospital_norm) return null;

  const base = `${env.SUPABASE_URL}/rest/v1/client_hospitals`;
  const enc  = encodeURIComponent;

  try {
    // hospital_name_norm is jsonb array of aliases: ["uhb", "university hospitals birmingham", ...]
    // We want "array contains hospital_norm".
    const aliasJson = JSON.stringify([hospital_norm]); // ["qeqm paeds"]
    const { rows } = await sbFetch(
      env,
      `${base}` +
      `?hospital_name_norm=cs.${enc(aliasJson)}` +
      `&select=client_id` +
      `&limit=1`
    );
    if (rows?.[0]?.client_id) {
      return rows[0].client_id;
    }
  } catch {
    // fall through to null
  }

  return null;
}

// ─────────────────────────────────────────────────────────────
// handleCreateHospital: now writes hospital_name_norm as JSON alias array
// ─────────────────────────────────────────────────────────────
async function handleCreateHospital(env, req, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  try {
    // hospital_name_norm is now JSONB: store as an array of lower-cased aliases.
    const rawName =
      typeof data.hospital_name_norm !== 'undefined'
        ? data.hospital_name_norm
        : (data.name || data.hospital || '');

    let hospitalAliases = [];

    if (Array.isArray(rawName)) {
      hospitalAliases = rawName
        .map((x) => String(x || '').trim().toLowerCase())
        .filter(Boolean);
    } else if (typeof rawName === 'string') {
      const s = rawName.trim();
      hospitalAliases = s ? [s.toLowerCase()] : [];
    } else if (rawName != null) {
      const s = String(rawName).trim();
      hospitalAliases = s ? [s.toLowerCase()] : [];
    }

    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/client_hospitals`, {
      method: "POST",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify({
        ...data,
        client_id: clientId,
        hospital_name_norm: hospitalAliases, // JSONB array
        created_at: new Date().toISOString()
      })
    });
    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Hospital creation failed: ${err}`));
    }
    const json = await res.json().catch(() => ({}));
    const hospital = Array.isArray(json) ? json[0] : json;
    return withCORS(env, req, ok({ hospital }));
  } catch {
    return withCORS(env, req, serverError("Failed to create client hospital"));
  }
}


// ─────────────────────────────────────────────────────────────
// classifyWeeklyImportRows: updated to use JSON aliases for hospital→client,
// and candidate aliases for staff name→candidate.
// ─────────────────────────────────────────────────────────────

async function classifyWeeklyImportRows(env, importId, { source_system }) {
  const enc   = encodeURIComponent;
  const norm  = (s) => String(s || '').trim().toLowerCase();
  const upper = (s) => String(s || '').trim().toUpperCase();
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);

  const chunk = (arr, n) => {
    const out = [];
    for (let i = 0; i < (arr || []).length; i += n) out.push(arr.slice(i, i + n));
    return out;
  };

  console.log('[WEEKLY_CLASSIFY] start', { importId, source_system });

  // ─────────────────────────────────────────────────────────────
  // 0) Build shared context (import + hr_rows + settings)
  // ─────────────────────────────────────────────────────────────
  const ctx = await buildWeeklyImportContext(env, importId, source_system);
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  if (ctx.error === 'import_not_found') {
    if (LOG) {
      console.warn('[WEEKLY_CLASSIFY]', JSON.stringify({
        stage: 'import_not_found',
        import_id: importId
      }));
    }
    return { error: 'import_not_found', import_id: importId, source_system, rows: [] };
  }
  if (ctx.error === 'source_system_mismatch') {
    if (LOG) {
      console.warn('[WEEKLY_CLASSIFY]', JSON.stringify({
        stage: 'source_system_mismatch',
        import_id: importId,
        expected: ctx.expected_source_system,
        actual: ctx.source_system
      }));
    }
    return {
      error: 'source_system_mismatch',
      import_id: importId,
      expected_source_system: source_system,
      actual_source_system: ctx.source_system,
      rows: []
    };
  }

  // ─────────────────────────────────────────────────────────────
  // 0.5) Decide batched vs legacy based on settings
  // ─────────────────────────────────────────────────────────────
  const useBatched =
    !!(ctx.settings &&
       ctx.settings.importConfig &&
       ctx.settings.importConfig.useBatchedClassification);

  if (LOG) {
    console.log('[WEEKLY_CLASSIFY]', JSON.stringify({
      stage: 'context_loaded',
      import_id: importId,
      source_system: ctx.source_system,
      hr_row_count: (ctx.hrRows || []).length,
      use_batched_classification: useBatched
    }));
  }

  if (!useBatched) {
    return await classifyWeeklyImportRowsLegacy(env, importId, { source_system });
  }

  // From here down is the batched implementation
  const imp    = ctx.imp;
  const hrRows = ctx.hrRows || [];

  if (!hrRows.length) {
    console.log('[WEEKLY_CLASSIFY] no hr_rows', { import_id: importId });
    return { import_id: importId, source_system, rows: [] };
  }

  // ─────────────────────────────────────────────────────────────
  // 1) Phase1 SQL mapping calls (KEEP, as requested)
  //     - NHSP: nhsp_preview_mappings_phase1
  //     - HR weekly: hr_weekly_preview_mappings_phase1
  // ─────────────────────────────────────────────────────────────
  let nhspMappingByHrRowId = null;
  let hrPreviewMappingByHrRowId = null;

  if (source_system === 'NHSP') {
    try {
      const rpcBody = { p_import_id: importId };
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/nhsp_preview_mappings_phase1`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify(rpcBody)
        }
      );

      const txt = await res.text().catch(() => '');
      let json;
      try { json = txt ? JSON.parse(txt) : []; } catch { json = []; }

      if (Array.isArray(json) && json.length) {
        nhspMappingByHrRowId = new Map();
        for (const row of json) {
          if (row && row.hr_row_id) nhspMappingByHrRowId.set(String(row.hr_row_id), row);
        }
      }

      if (LOG) {
        console.log('[WEEKLY_CLASSIFY]', JSON.stringify({
          stage: 'nhsp_preview_mappings_loaded',
          import_id: importId,
          rows: Array.isArray(json) ? json.length : 0
        }));
      }
    } catch (e) {
      console.warn('[WEEKLY_CLASSIFY] nhsp_preview_mappings_phase1 failed (non-fatal)', e);
      nhspMappingByHrRowId = null;
    }
  }

  if (source_system === 'HEALTHROSTER') {
    try {
      const rpcBody = { p_import_id: importId };
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/hr_weekly_preview_mappings_phase1`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify(rpcBody)
        }
      );

      const txt = await res.text().catch(() => '');
      let json;
      try { json = txt ? JSON.parse(txt) : []; } catch { json = []; }

      if (Array.isArray(json) && json.length) {
        hrPreviewMappingByHrRowId = new Map();
        for (const row of json) {
          if (row && row.hr_row_id) hrPreviewMappingByHrRowId.set(String(row.hr_row_id), row);
        }
      }

      if (LOG) {
        console.log('[WEEKLY_CLASSIFY]', JSON.stringify({
          stage: 'hr_preview_mappings_loaded',
          import_id: importId,
          rows: Array.isArray(json) ? json.length : 0
        }));
      }
    } catch (e) {
      console.warn('[WEEKLY_CLASSIFY] hr_weekly_preview_mappings_phase1 failed (non-fatal)', e);
      hrPreviewMappingByHrRowId = null;
    }
  }

  // ─────────────────────────────────────────────────────────────
  // 2) Phase2 SQL (existing): candidate/client/contract + band/grade mapping + week ending
  //     weekly_import_phase2(p_import_id uuid, p_system_type text)
  // ─────────────────────────────────────────────────────────────
  const systemType =
    (source_system === 'NHSP') ? 'NHSP' :
    (source_system === 'HEALTHROSTER') ? 'HR_WEEKLY' :
    null;

  if (!systemType) {
    return {
      error: 'unsupported_source_system',
      import_id: importId,
      source_system,
      rows: [{
        level: 'row',
        preview_row_id: 'row:unsupported',
        hr_row_id: null,
        import_id: importId,
        source_system,
        action: 'REJECT_UNSUPPORTED_SOURCE',
        reason: `Unsupported source_system=${source_system}`,
        default_selected: false
      }]
    };
  }

  let phase2ByHrRowId = null;
  try {
    const rpcBody = { p_import_id: importId, p_system_type: systemType };
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/rpc/weekly_import_phase2`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), 'content-type': 'application/json' },
        body: JSON.stringify(rpcBody)
      }
    );

    const txt = await res.text().catch(() => '');
    let json;
    try { json = txt ? JSON.parse(txt) : []; } catch { json = []; }

    if (Array.isArray(json) && json.length) {
      phase2ByHrRowId = new Map();
      for (const row of json) {
        if (row && row.hr_row_id) phase2ByHrRowId.set(String(row.hr_row_id), row);
      }
    } else {
      phase2ByHrRowId = new Map(); // empty but non-null
    }

    if (LOG) {
      console.log('[WEEKLY_CLASSIFY]', JSON.stringify({
        stage: 'phase2_loaded',
        import_id: importId,
        system_type: systemType,
        rows: Array.isArray(json) ? json.length : 0
      }));
    }
  } catch (e) {
    console.error('[WEEKLY_CLASSIFY] weekly_import_phase2 failed (FATAL)', e);
    return {
      error: 'phase2_rpc_failed',
      import_id: importId,
      source_system,
      message: 'weekly_import_phase2 RPC failed; cannot perform SQL-first weekly classification.',
      rows: []
    };
  }

  // ─────────────────────────────────────────────────────────────
  // 2.5) Phase3 SQL (NEW): changed hours detection + paid/invoiced flags + deltas
  //     weekly_import_changed_hours_phase3(p_import_id uuid, p_system_type text)
  //
  // IMPORTANT: Phase3 expects p_system_type in {'NHSP','HEALTHROSTER'} (NOT 'HR_WEEKLY')
  // ─────────────────────────────────────────────────────────────
  const phase3SystemType =
    (source_system === 'NHSP') ? 'NHSP' :
    (source_system === 'HEALTHROSTER') ? 'HEALTHROSTER' :
    null;

  let changedShifts = [];
  let changedByExternalRowKey = new Map();
  let changedAggByGroupKey = new Map();

  const safeBool = (v) => (v === true || v === 'true' || v === 1 || v === '1');

  const loadPhase3 = async () => {
    if (!phase3SystemType) return [];
    try {
      const rpcBody = { p_import_id: importId, p_system_type: phase3SystemType };
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/weekly_import_changed_hours_phase3`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify(rpcBody)
        }
      );

      const txt = await res.text().catch(() => '');
      let json;
      try { json = txt ? JSON.parse(txt) : []; } catch { json = []; }

      if (!Array.isArray(json)) json = [];

      if (LOG) {
        console.log('[WEEKLY_CLASSIFY]', JSON.stringify({
          stage: 'phase3_loaded',
          import_id: importId,
          phase3_system_type: phase3SystemType,
          rows: json.length
        }));
      }

      return json;
    } catch (e) {
      console.warn('[WEEKLY_CLASSIFY] weekly_import_changed_hours_phase3 failed (non-fatal)', e);
      return [];
    }
  };

  // Fetch Phase 3 once (SQL is authoritative for "changed hours")
  changedShifts = await loadPhase3();

  // Normalise + index Phase3 output (keyed by external_row_key)
  if (Array.isArray(changedShifts) && changedShifts.length) {
    const normRow = (r) => {
      const out = { ...(r || {}) };

      // Normalise booleans (RPC should return booleans but be defensive)
      out.is_paid = safeBool(out.is_paid ?? out.paid ?? out.paid_at_utc);
      out.is_invoiced = safeBool(out.is_invoiced ?? out.invoiced ?? out.locked_by_invoice_id);

      out.requires_pay_decision = safeBool(out.requires_pay_decision);
      out.requires_invoice_decision = safeBool(out.requires_invoice_decision);
      out.requires_any_decision = safeBool(out.requires_any_decision);

      // Common alias keys (keep raw too)
      if (!out.external_row_key && out.external_row_key !== '') out.external_row_key = null;
      if (!out.hr_row_id) out.hr_row_id = null;

      return out;
    };

    changedShifts = changedShifts.map(normRow);

    changedByExternalRowKey = new Map();
    for (const r of changedShifts) {
      const k = r && r.external_row_key ? String(r.external_row_key) : '';
      if (!k) continue;
      if (!changedByExternalRowKey.has(k)) changedByExternalRowKey.set(k, []);
      changedByExternalRowKey.get(k).push(r);
    }

    // Pre-compute group aggregates keyed by candidate_id__client_id__contract_id__week_ending_date
    changedAggByGroupKey = new Map();
    for (const r of changedShifts) {
      const cid = r?.candidate_id || null;
      const cli = r?.client_id || null;
      const con = r?.contract_id || null;
      const we  = r?.week_ending_date || null;
      const ek  = r?.external_row_key ? String(r.external_row_key) : null;

      if (!cid || !cli || !con || !we) continue;
      const gk = `${cid}__${cli}__${con}__${we}`;

      const agg = changedAggByGroupKey.get(gk) || {
        changed_shifts_count: 0,
        changed_shifts_decision_needed_count: 0,
        external_row_keys: []
      };

      agg.changed_shifts_count += 1;
      if (r?.requires_any_decision) agg.changed_shifts_decision_needed_count += 1;
      if (ek) {
        if (!agg.external_row_keys.includes(ek)) agg.external_row_keys.push(ek);
      }

      changedAggByGroupKey.set(gk, agg);
    }
  }

  // ─────────────────────────────────────────────────────────────
  // 3) Row-level classification using Phase2 results
  //    - If Phase2 says REJECT_... => emit row preview and skip
  //    - Else => group by (candidate_id, client_id, contract_id, week_ending_date)
  // ─────────────────────────────────────────────────────────────
  const previewRows = [];
  const groupMap = new Map();

  const pushUnique = (arr, v) => {
    if (v == null) return;
    const s = String(v);
    if (!arr.includes(s)) arr.push(s);
  };

  for (const hrRow of hrRows) {
    const payload = hrRow.payload_json || {};
    const preview_row_id = `row:${hrRow.id}`;

    // Extract display fields (for UI)
    let staffName = '';
    let workDate  = '';
    let ward      = '';
    let startIso  = null;
    let endIso    = null;
    let breakMins = 0;

    let finalised = '';         // HR weekly only
    let requestId = '';         // HR weekly
    let refNum    = '';         // NHSP
    let trustRaw  = '';         // NHSP trust/hospital string

    let assignmentCode = '';    // NHSP
    let gradeRaw = '';          // HR weekly

    if (source_system === 'NHSP') {
      staffName = String(payload.worker_name || payload.name || payload.staff_name || '').trim();
      workDate  = String(payload.work_date || payload.date || '').trim();
      ward      = String(payload.ward || payload.unit || '').trim();
      trustRaw  = String(payload.trust || payload.hospital_or_trust || payload.client || '').trim();
      startIso  = payload.start_utc || payload.actual_start_iso || payload.actual_start || null;
      endIso    = payload.end_utc   || payload.actual_end_iso   || payload.actual_end   || null;
      breakMins = Number(payload.break_mins ?? payload.break_minutes ?? payload.actual_break_minutes ?? 0) || 0;
      assignmentCode = String(payload.assignment_code || payload.assignment || '').trim();
      refNum    = String(payload.ref_num || payload.reference || '').trim();
    } else {
      // HEALTHROSTER weekly
      staffName = String(payload.staff_name || payload.worker_name || '').trim();
      workDate  = String(payload.work_date || payload.date || '').trim();
      ward      = String(payload.ward || payload.unit || '').trim();
      startIso  = payload.start_utc || null;
      endIso    = payload.end_utc   || null;
      breakMins = Number(payload.break_mins ?? 0) || 0;
      finalised = String(payload.finalised_date || payload.finalized_date || '').trim();
      requestId = String(payload.request_id || '').trim();
      gradeRaw  = String(payload.grade_raw || '').trim();
    }

    const isUnfinalised = (source_system === 'HEALTHROSTER' && !finalised);

    // Basic field sanity (we still reject BAD_ROW here for clarity)
    if (!workDate || !startIso || !endIso) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? gradeRaw : null),
        incoming_code: (source_system === 'NHSP' ? assignmentCode : gradeRaw),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_BAD_ROW',
        reason: 'Missing date or start/end times in payload',
        default_selected: false
      });
      continue;
    }

    // Phase2 lookup (SQL does candidate/client/contract/week ending + band/grade mapping)
    const p2 = (phase2ByHrRowId instanceof Map) ? (phase2ByHrRowId.get(String(hrRow.id)) || null) : null;

    if (!p2) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? gradeRaw : null),
        incoming_code: (source_system === 'NHSP' ? assignmentCode : gradeRaw),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_PHASE2_MISSING',
        reason: 'No Phase2 row returned for hr_row_id (weekly_import_phase2)',
        default_selected: false
      });
      continue;
    }

    const action = String(p2.action || '').toUpperCase();
    const reason = String(p2.reason || '').trim();

    // If Phase2 rejected it, emit a row-level preview and skip grouping
    if (action.startsWith('REJECT_')) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        trust_raw: (source_system === 'NHSP' ? trustRaw : null),

        candidate_id: p2.candidate_id || null,
        client_id: p2.client_id || null,
        contract_id: p2.contract_id || null,
        week_ending_date: p2.week_ending_date || null,

        assignment_code: (source_system === 'NHSP' ? (p2.incoming_code || assignmentCode) : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? (p2.incoming_code || gradeRaw) : null),
        incoming_code: p2.incoming_code || (source_system === 'NHSP' ? assignmentCode : gradeRaw),

        request_id: requestId || null,
        ref_num: refNum || null,
        action,
        reason: reason || 'Rejected by Phase2',
        default_selected: false
      });
      continue;
    }

    // Otherwise Phase2 gives the chosen contract/week, group it
    const candidateId = p2.candidate_id || null;
    const clientId    = p2.client_id || null;
    const contractId  = p2.contract_id || null;
    const we          = p2.week_ending_date || null;
    const incomingCode = String(p2.incoming_code || (source_system === 'NHSP' ? assignmentCode : gradeRaw) || '').trim();

    if (!candidateId || !clientId || !contractId || !we) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? gradeRaw : null),
        incoming_code: incomingCode,
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_PHASE2_INCOMPLETE',
        reason: 'Phase2 returned incomplete mapping (missing candidate/client/contract/week_ending_date)',
        default_selected: false
      });
      continue;
    }

    const groupKey = `${candidateId}__${clientId}__${contractId}__${we}`;
    let g = groupMap.get(groupKey);
    if (!g) {
      // Use Phase1 names when available (nice for UI)
      let candidateName = null;
      let clientName = null;

      if (source_system === 'NHSP' && nhspMappingByHrRowId instanceof Map) {
        const m1 = nhspMappingByHrRowId.get(String(hrRow.id)) || null;
        if (m1) {
          candidateName = m1.candidate_name || null;
          clientName = m1.client_name || null;
        }
      } else if (source_system === 'HEALTHROSTER' && hrPreviewMappingByHrRowId instanceof Map) {
        const m1 = hrPreviewMappingByHrRowId.get(String(hrRow.id)) || null;
        if (m1) {
          candidateName = m1.candidate_name || null;
          clientName = m1.client_name || null;
        }
      }

      g = {
        candidate_id: candidateId,
        candidate_name: candidateName,
        client_id: clientId,
        client_name: clientName,
        contract_id: contractId,
        week_ending_date: we,

        // store multiple incoming codes if they vary within group
        incoming_codes: [],

        // NHSP only (kept for UI consistency)
        assignment_code: (source_system === 'NHSP' ? incomingCode : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? incomingCode : null),

        shifts: [],
        hr_row_ids: [],
        has_unfinalised: false
      };
      groupMap.set(groupKey, g);
    }

    pushUnique(g.incoming_codes, incomingCode);

    if (isUnfinalised && source_system === 'HEALTHROSTER') {
      g.has_unfinalised = true;
    }

    g.shifts.push({
      hr_row_id: hrRow.id,
      staff_name: staffName,
      work_date: workDate,
      ward,
      start_utc: startIso,
      end_utc: endIso,
      break_mins: breakMins,
      assignment_code: (source_system === 'NHSP' ? incomingCode : null),
      grade_raw: (source_system === 'HEALTHROSTER' ? incomingCode : null),
      request_id: requestId || null,
      ref_num: refNum || null,
      is_unfinalised: isUnfinalised
    });
    g.hr_row_ids.push(hrRow.id);
  }

  console.log('[WEEKLY_CLASSIFY] grouping complete', {
    import_id: importId,
    source_system,
    group_count: groupMap.size,
    preview_row_count: previewRows.length
  });

  // ─────────────────────────────────────────────────────────────
  // 4) Batch fetch contracts (rates_json required for payChargeFromContract)
  // ─────────────────────────────────────────────────────────────
  const groups = Array.from(groupMap.values());
  const contractIds = Array.from(new Set(groups.map(g => g.contract_id)));

  const contractById = new Map();
  if (contractIds.length) {
    // keep URL lengths safe
    for (const cids of chunk(contractIds, 150)) {
      const url =
        `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?id=in.(${cids.map(enc).join(',')})` +
        `&select=id,candidate_id,client_id,role,band,pay_method_snapshot,self_bill,rates_json`;

      const { rows: cRows } = await sbFetch(env, url);
      for (const c of (cRows || [])) contractById.set(c.id, c);
    }
  }

  // ─────────────────────────────────────────────────────────────
  // 5) Batch fetch contract_weeks for all relevant contract_ids + week_ending_dates
  //    (We fetch superset and filter in JS to avoid OR explosion)
  // ─────────────────────────────────────────────────────────────
  const weekEndingDates = Array.from(new Set(groups.map(g => g.week_ending_date)));
  const weeksByPair = new Map(); // key=contract_id__week_ending_date -> weeks[]

  if (contractIds.length && weekEndingDates.length) {
    for (const cids of chunk(contractIds, 150)) {
      for (const weds of chunk(weekEndingDates, 150)) {
        const url =
          `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?contract_id=in.(${cids.map(enc).join(',')})` +
          `&week_ending_date=in.(${weds.map(enc).join(',')})` +
          `&select=contract_id,week_ending_date,id,timesheet_id,additional_seq,is_adjustment` +
          `&order=additional_seq.asc`;

        const { rows: cwRows } = await sbFetch(env, url);
        for (const w of (cwRows || [])) {
          const key = `${w.contract_id}__${w.week_ending_date}`;
          const arr = weeksByPair.get(key) || [];
          arr.push(w);
          weeksByPair.set(key, arr);
        }
      }
    }
  }

  // Batch fetch timesheets + current financials
  const allTsIds = [];
  for (const arr of weeksByPair.values()) {
    for (const w of arr) {
      if (w.timesheet_id) allTsIds.push(w.timesheet_id);
    }
  }
  const tsIds = Array.from(new Set(allTsIds));

  let tsById = new Map();
  if (tsIds.length) {
    for (const tidChunk of chunk(tsIds, 200)) {
      const { rows: tsRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=in.(${tidChunk.map(enc).join(',')})` +
        `&select=timesheet_id,submission_mode,status`
      );
      for (const t of (tsRows || [])) tsById.set(t.timesheet_id, t);
    }
  }

  let finByTsId = new Map();
  if (tsIds.length) {
    for (const tidChunk of chunk(tsIds, 200)) {
      const { rows: finRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=in.(${tidChunk.map(enc).join(',')})` +
        `&is_current=eq.true` +
        `&select=timesheet_id,total_pay_ex_vat,total_charge_ex_vat,basis,paid_at_utc,locked_by_invoice_id`
      );
      for (const f of (finRows || [])) finByTsId.set(f.timesheet_id, f);
    }
  }

  // ─────────────────────────────────────────────────────────────
  // 6) Group-level classification (existing)
  // ─────────────────────────────────────────────────────────────
  const policyCache = new Map(); // key=client_id__dateYmd -> policy
  const getPolicyCached = async (client_id, dateYmd) => {
    const k = `${client_id}__${dateYmd}`;
    if (policyCache.has(k)) return policyCache.get(k);
    const p = await loadPolicy(env, client_id, dateYmd);
    policyCache.set(k, p);
    return p;
  };

  const classifyGroup = async (g) => {
    const { candidate_id, client_id, contract_id, week_ending_date } = g;

    const contract = contractById.get(contract_id) || null;
    if (!contract) {
      return {
        level: 'group',
        preview_group_id: `grp:${contract_id}:${week_ending_date}:${candidate_id}`,
        import_id: importId,
        source_system,
        candidate_id,
        candidate_name: g.candidate_name,
        client_id,
        client_name: g.client_name,
        contract_id,
        week_ending_date,
        incoming_code: (g.incoming_codes.length === 1 ? g.incoming_codes[0] : g.incoming_codes.join(', ')),
        assignment_code: (source_system === 'NHSP' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
        self_bill: null,
        has_unfinalised: !!g.has_unfinalised,
        hr_row_ids: g.hr_row_ids.slice(),
        truth_pay_ex_vat: 0,
        truth_charge_ex_vat: 0,
        current_pay_ex_vat: 0,
        current_charge_ex_vat: 0,
        delta_pay_ex_vat: 0,
        delta_charge_ex_vat: 0,
        base_timesheet_id: null,
        latest_adjustment_timesheet_id: null,
        action: 'REJECT_NO_CONTRACT',
        reason: 'Contract not found (batch fetch) at classify stage',
        default_selected: false
      };
    }

    // Resolve pay/charge from contract rates_json (weekly rule)
    const pc = payChargeFromContract(contract);
    const pay = pc?.pay || null;
    const chg = pc?.charge || null;

    if (!pay || !chg) {
      return {
        level: 'group',
        preview_group_id: `grp:${contract_id}:${week_ending_date}:${candidate_id}`,
        import_id: importId,
        source_system,
        candidate_id,
        candidate_name: g.candidate_name,
        client_id,
        client_name: g.client_name,
        contract_id,
        week_ending_date,
        incoming_code: (g.incoming_codes.length === 1 ? g.incoming_codes[0] : g.incoming_codes.join(', ')),
        assignment_code: (source_system === 'NHSP' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
        self_bill: (source_system === 'HEALTHROSTER') ? !!contract.self_bill : null,
        has_unfinalised: !!g.has_unfinalised,
        hr_row_ids: g.hr_row_ids.slice(),
        truth_pay_ex_vat: 0,
        truth_charge_ex_vat: 0,
        current_pay_ex_vat: 0,
        current_charge_ex_vat: 0,
        delta_pay_ex_vat: 0,
        delta_charge_ex_vat: 0,
        base_timesheet_id: null,
        latest_adjustment_timesheet_id: null,
        action: 'REJECT_RATE_MISSING_CONTRACT',
        reason: 'Contract rates_json is missing or pay/charge buckets could not be derived (payChargeFromContract).',
        default_selected: false
      };
    }

    // Load contract_weeks for this contract/week (from batched map)
    const pairKey = `${contract_id}__${week_ending_date}`;
    const weeks = (weeksByPair.get(pairKey) || []).slice();

    const baseWeek = weeks.find(w => !w.is_adjustment && Number(w.additional_seq || 0) === 0) || null;
    const adjWeeks = weeks.filter(w => !!w.is_adjustment);

    const tsIdsLocal = weeks.map(w => w.timesheet_id).filter(Boolean);

    // Compute truth totals from import shifts using contract rates
    let truthPay = 0;
    let truthChg = 0;

    const missingPayBuckets = new Set();
    const missingChgBuckets = new Set();

    for (const sh of g.shifts) {
      const policy = await getPolicyCached(client_id, sh.work_date);

      let segs = [[sh.start_utc, sh.end_utc]];
      segs = subtractBreak(segs, null, null, sh.break_mins || 0);

      const hours = classifyMinutes(env, policy, segs);

      const used = {
        day:   (hours.hours_day   || 0),
        night: (hours.hours_night || 0),
        sat:   (hours.hours_sat   || 0),
        sun:   (hours.hours_sun   || 0),
        bh:    (hours.hours_bh    || 0),
      };

      // Missing bucket detection (strict for weekly imports)
      for (const k of ['day','night','sat','sun','bh']) {
        if ((used[k] || 0) > 0) {
          const pv = pay[k];
          const cv = chg[k];
          if (pv == null || pv === '' || !Number.isFinite(Number(pv))) missingPayBuckets.add(k);
          if (cv == null || cv === '' || !Number.isFinite(Number(cv))) missingChgBuckets.add(k);
        }
      }

      const segPay = round2(
        (used.day   || 0) * asNumberLocal(pay.day)   +
        (used.night || 0) * asNumberLocal(pay.night) +
        (used.sat   || 0) * asNumberLocal(pay.sat)   +
        (used.sun   || 0) * asNumberLocal(pay.sun)   +
        (used.bh    || 0) * asNumberLocal(pay.bh)
      );
      const segChg = round2(
        (used.day   || 0) * asNumberLocal(chg.day)   +
        (used.night || 0) * asNumberLocal(chg.night) +
        (used.sat   || 0) * asNumberLocal(chg.sat)   +
        (used.sun   || 0) * asNumberLocal(chg.sun)   +
        (used.bh    || 0) * asNumberLocal(chg.bh)
      );

      truthPay += segPay;
      truthChg += segChg;
    }

    if (missingPayBuckets.size || missingChgBuckets.size) {
      const mp = Array.from(missingPayBuckets);
      const mc = Array.from(missingChgBuckets);
      return {
        level: 'group',
        preview_group_id: `grp:${contract_id}:${week_ending_date}:${candidate_id}`,
        import_id: importId,
        source_system,
        candidate_id,
        candidate_name: g.candidate_name,
        client_id,
        client_name: g.client_name,
        contract_id,
        week_ending_date,
        incoming_code: (g.incoming_codes.length === 1 ? g.incoming_codes[0] : g.incoming_codes.join(', ')),
        assignment_code: (source_system === 'NHSP' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
        grade_raw: (source_system === 'HEALTHROSTER' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
        self_bill: (source_system === 'HEALTHROSTER') ? !!contract.self_bill : null,
        has_unfinalised: !!g.has_unfinalised,
        hr_row_ids: g.hr_row_ids.slice(),
        truth_pay_ex_vat: 0,
        truth_charge_ex_vat: 0,
        current_pay_ex_vat: 0,
        current_charge_ex_vat: 0,
        delta_pay_ex_vat: 0,
        delta_charge_ex_vat: 0,
        base_timesheet_id: baseWeek?.timesheet_id || null,
        latest_adjustment_timesheet_id: null,
        action: 'REJECT_RATE_MISSING_CONTRACT',
        reason: `Contract rates_json missing required buckets for this week's shifts. Missing pay buckets: ${mp.join(', ') || 'none'}; missing charge buckets: ${mc.join(', ') || 'none'}.`,
        default_selected: false
      };
    }

    truthPay = round2(truthPay);
    truthChg = round2(truthChg);

    // Current totals from existing TSFIN (missing TSFIN rows count as 0)
    let currentPay = 0;
    let currentChg = 0;

    for (const tsId of tsIdsLocal) {
      const fin = finByTsId.get(tsId);
      if (!fin) continue;
      currentPay += Number(fin.total_pay_ex_vat || 0);
      currentChg += Number(fin.total_charge_ex_vat || 0);
    }
    currentPay = round2(currentPay);
    currentChg = round2(currentChg);

    const deltaPay = round2(truthPay - currentPay);
    const deltaChg = round2(truthChg - currentChg);
    const tol = 0.01;

    const baseTsId = baseWeek?.timesheet_id || null;
    const baseTs   = baseTsId ? tsById.get(baseTsId) : null;
    const baseFin  = baseTsId ? finByTsId.get(baseTsId) : null;

    let latestAdjWeek = null;
    if (adjWeeks.length) {
      latestAdjWeek = adjWeeks.reduce((m, w) =>
        Number(w.additional_seq || 0) > Number(m.additional_seq || 0) ? w : m,
        adjWeeks[0]
      );
    }
    const latestAdjTsId = latestAdjWeek?.timesheet_id || null;
    const latestAdjFin  = latestAdjTsId ? finByTsId.get(latestAdjTsId) : null;

    const anyAdj = !!latestAdjWeek;

    // ✅ IMPORTANT FIX:
    // If base timesheet exists but there is NO current TSFIN row, treat the base as
    // "unpaid + uninvoiced + safe to rebuild" for classification purposes.
    const baseFinMissing = !!baseTsId && !baseFin;

    const baseUnpaidUnlocked =
      baseFinMissing ||
      !!(baseFin && !baseFin.paid_at_utc && !baseFin.locked_by_invoice_id);

    // Keep adjustment-unpaid logic strict: only consider it "unpaid/unlocked" if its TSFIN exists and is unlocked.
    const latestAdjUnpaidUnlocked =
      !!(latestAdjFin && !latestAdjFin.paid_at_utc && !latestAdjFin.locked_by_invoice_id);

    const isPaid     = !!(baseFin && baseFin.paid_at_utc);
    const isInvoiced = !!(baseFin && baseFin.locked_by_invoice_id);

    const selfBill   = (source_system === 'HEALTHROSTER') ? !!contract.self_bill : null;
    const hasUnfinal = !!g.has_unfinalised;

    let result = {
      level: 'group',
      preview_group_id: `grp:${contract_id}:${week_ending_date}:${candidate_id}`,
      import_id: importId,
      source_system,
      candidate_id,
      candidate_name: g.candidate_name,
      client_id,
      client_name: g.client_name,
      contract_id,
      week_ending_date,
      incoming_code: (g.incoming_codes.length === 1 ? g.incoming_codes[0] : g.incoming_codes.join(', ')),
      assignment_code: (source_system === 'NHSP' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
      grade_raw: (source_system === 'HEALTHROSTER' ? (g.incoming_codes.length === 1 ? g.incoming_codes[0] : null) : null),
      self_bill: selfBill,
      has_unfinalised: hasUnfinal,
      hr_row_ids: g.hr_row_ids.slice(),
      truth_pay_ex_vat: truthPay,
      truth_charge_ex_vat: truthChg,
      current_pay_ex_vat: currentPay,
      current_charge_ex_vat: currentChg,
      delta_pay_ex_vat: deltaPay,
      delta_charge_ex_vat: deltaChg,
      base_timesheet_id: baseTsId,
      latest_adjustment_timesheet_id: latestAdjTsId,
      action: 'UNKNOWN',
      reason: 'Unable to classify this weekly group – please review manually.',
      default_selected: false,

      // NEW: placeholders for Phase3 aggregates (filled post-pass)
      changed_shifts_count: 0,
      changed_shifts_decision_needed_count: 0,
      changed_shifts_external_row_keys: []
    };

    // No base timesheet yet
    if (!baseTsId) {
      if (Math.abs(truthPay) < tol && Math.abs(truthChg) < tol) {
        result.action = 'SKIP_ALREADY_PROCESSED';
        result.reason = 'No weekly timesheet yet and truth totals are zero – nothing to create.';
        result.default_selected = false;
      } else {
        result.action = 'NEW_AUTOPROC_TIMESHEET';
        result.reason = 'No existing weekly timesheet – a new weekly timesheet will be created from the import.';
        result.default_selected = !hasUnfinal;
      }
      return result;
    }

    // Base TS exists: if totals already match, skip
    // NOTE: If TSFIN is missing, current totals are 0 so this condition won't trigger; we'll classify as UPDATE_* and rebuild.
    if (Math.abs(deltaPay) < tol && Math.abs(deltaChg) < tol) {
      result.action = 'SKIP_ALREADY_PROCESSED';
      result.reason = 'Timesheet and existing adjustments already match NHSP/HealthRoster – nothing further to do.';
      result.default_selected = false;
      return result;
    }

    // ─────────────────────────────────────────────────────────────
    // DECISION: manual vs autoproc
    // ─────────────────────────────────────────────────────────────
    const submissionMode = String(baseTs?.submission_mode || '').toUpperCase();
    const treatAsManualWeek = (submissionMode === 'MANUAL' && !baseFinMissing);

    // Manual base (true manual workflow)
    if (treatAsManualWeek) {
      if (baseUnpaidUnlocked && !anyAdj) {
        result.action = 'UPDATE_MANUAL_WEEK';
        result.reason = 'Existing manual weekly timesheet (unpaid/uninvoiced) will be overwritten with updated import hours for this week.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      if (latestAdjUnpaidUnlocked) {
        result.action = 'UPDATE_ADJUSTMENT_TS';
        result.reason = 'Existing unpaid/uninvoiced adjustment timesheet will be updated to reflect the new changes.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      result.action = 'CREATE_ADJUSTMENT_TS';
      result.reason = 'Existing timesheet/adjustments appear paid or invoiced; a new sequential adjustment timesheet will be created for the changes.';
      result.default_selected = !hasUnfinal;
      return result;
    }

    // Autoproc/import base (NHSP and HR_WEEKLY import routes)
    if (source_system === 'NHSP' || (source_system === 'HEALTHROSTER' && selfBill)) {
      if (baseUnpaidUnlocked && !anyAdj) {
        result.action = 'UPDATE_AUTOPROC_TS';
        result.reason =
          baseFinMissing
            ? 'Base timesheet exists but has no current financial snapshot (TSFIN). Snapshot will be rebuilt from import shifts (safe/unpaid/uninvoiced).'
            : 'Existing weekly timesheet (unpaid/uninvoiced) will be updated with corrected import hours for this week.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      if (latestAdjUnpaidUnlocked) {
        result.action = 'UPDATE_ADJUSTMENT_TS';
        result.reason = 'Existing unpaid/uninvoiced adjustment timesheet will be updated to reflect the new changes.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      result.action = 'CREATE_ADJUSTMENT_TS';
      result.reason = 'Timesheet and previous adjustments appear paid/invoiced; a new sequential adjustment timesheet will be created for the amended hours.';
      result.default_selected = !hasUnfinal;
      return result;
    }

    // HEALTHROSTER, self_bill = false → special HR logic
    if (source_system === 'HEALTHROSTER' && selfBill === false) {
      // If TSFIN is missing, we must treat it as not-paid/not-invoiced so we can rebuild it (this is the fix).
      if (!isPaid && !isInvoiced) {
        result.action = 'UPDATE_AUTOPROC_TS';
        result.reason =
          baseFinMissing
            ? 'Base timesheet exists but has no current financial snapshot (TSFIN). Snapshot will be rebuilt from import shifts (safe/unpaid/uninvoiced).'
            : 'HR weekly timesheet will be overwritten with modified hours for this week (unpaid/uninvoiced).';
        result.default_selected = !hasUnfinal;
        return result;
      }

      if (isInvoiced) {
        result.action = 'BLOCK_INVOICE_ISSUED';
        result.reason = 'HR Timesheet invoice already issued – unissue the invoice before applying these HR changes.';
        result.default_selected = false;
        return result;
      }

      if (isPaid && !isInvoiced) {
        result.action = 'CREATE_PAY_ADJUSTMENT_ONLY';
        result.reason = 'HR - Candidate already paid (not invoiced yet) – a pay-only adjustment will be created; invoice will reflect full HR hours.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      result.action = 'UNKNOWN';
      result.reason = 'HR weekly (self-bill=false): unhandled state – please review manually.';
      result.default_selected = false;
      return result;
    }

    result.action = 'UNKNOWN';
    result.reason = 'Unable to classify this weekly group – please review manually.';
    result.default_selected = !hasUnfinal;
    return result;
  };

  for (const g of groupMap.values()) {
    const gp = await classifyGroup(g);
    previewRows.push(gp);
  }

  // ─────────────────────────────────────────────────────────────
  // 6.5) Attach Phase3 aggregates to group rows (optional but helpful UX)
  // ─────────────────────────────────────────────────────────────
  if (changedAggByGroupKey instanceof Map && changedAggByGroupKey.size) {
    for (const pr of previewRows) {
      if (!pr || String(pr.level || '').toLowerCase() !== 'group') continue;

      const cid = pr.candidate_id || null;
      const cli = pr.client_id || null;
      const con = pr.contract_id || null;
      const we  = pr.week_ending_date || null;
      if (!cid || !cli || !con || !we) continue;

      const gk = `${cid}__${cli}__${con}__${we}`;
      const agg = changedAggByGroupKey.get(gk);
      if (!agg) continue;

      pr.changed_shifts_count = Number(agg.changed_shifts_count || 0) || 0;
      pr.changed_shifts_decision_needed_count = Number(agg.changed_shifts_decision_needed_count || 0) || 0;
      pr.changed_shifts_external_row_keys = Array.isArray(agg.external_row_keys) ? agg.external_row_keys.slice() : [];
    }
  }

  console.log('[WEEKLY_CLASSIFY] done', {
    import_id: importId,
    source_system,
    preview_rows: previewRows.length
  });

  // ─────────────────────────────────────────────────────────────
  // 7) Post-process previewRows with mapping fields for FE
  // ─────────────────────────────────────────────────────────────
  for (const pr of previewRows) {
    const lvl = String(pr.level || '').toLowerCase();

    if (lvl === 'row') {
      const staffRaw = pr.staff_name || '';
      const ward     = pr.ward || '';
      const trust    = pr.trust_raw || pr.trust || pr.hospital_or_trust || '';
      const hosp     = ward || trust;

      pr.staff_raw         = staffRaw;
      pr.staff_norm        = norm(staffRaw);
      pr.hospital_or_trust = hosp;
      pr.trust_norm        = norm(hosp);

      if (!Object.prototype.hasOwnProperty.call(pr, 'candidate_id')) pr.candidate_id = null;
      if (!Object.prototype.hasOwnProperty.call(pr, 'client_id')) pr.client_id = null;

      const act = String(pr.action || '').toUpperCase();
      if (!pr.resolution_status) {
        if (act === 'REJECT_NO_CANDIDATE') pr.resolution_status = 'NO_CANDIDATE';
        else if (act === 'REJECT_NO_CLIENT') pr.resolution_status = 'NO_CLIENT';
        else if (act === 'REJECT_BAD_ROW' || act === 'REJECT_BAD_ROW2') pr.resolution_status = 'BAD_ROW';
        else if (act.startsWith('REJECT_')) pr.resolution_status = act;
        else pr.resolution_status = 'OK';
      }
    } else if (lvl === 'group') {
      if (!Object.prototype.hasOwnProperty.call(pr, 'staff_raw')) pr.staff_raw = null;
      if (!Object.prototype.hasOwnProperty.call(pr, 'staff_norm')) pr.staff_norm = null;
      if (!Object.prototype.hasOwnProperty.call(pr, 'hospital_or_trust')) pr.hospital_or_trust = null;
      if (!Object.prototype.hasOwnProperty.call(pr, 'trust_norm')) pr.trust_norm = null;
      if (!pr.resolution_status) pr.resolution_status = pr.action || 'UNKNOWN';
    }
  }

  // ─────────────────────────────────────────────────────────────
  // 8) Return payload: include Phase3 output in BOTH top-level and summary
  // ─────────────────────────────────────────────────────────────
  const changedCount = Array.isArray(changedShifts) ? changedShifts.length : 0;
  const decisionNeededCount = Array.isArray(changedShifts)
    ? changedShifts.reduce((a, r) => a + (r && r.requires_any_decision ? 1 : 0), 0)
    : 0;

  const summary = {
    total_hr_rows: hrRows.length,
    preview_rows: previewRows.length,
    changed_shifts_count: changedCount,
    changed_shifts_decision_needed_count: decisionNeededCount,

    // IMPORTANT: put the full list here too so FE survives summary-only render paths
    changed_shifts: Array.isArray(changedShifts) ? changedShifts : []
  };

  return {
    import_id: importId,
    source_system,

    // IMPORTANT: top-level list as well (FE can read either)
    changed_shifts: Array.isArray(changedShifts) ? changedShifts : [],

    summary,
    rows: previewRows
  };
}



async function classifyWeeklyImportRowsLegacy(env, importId, { source_system }) {
  const enc   = encodeURIComponent;
  const norm  = (s) => String(s || '').trim().toLowerCase();
  const upper = (s) => String(s || '').trim().toUpperCase();
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);

  console.log('[WEEKLY_CLASSIFY] start', { importId, source_system });

  // ─────────────────────────────────────────────────────────────
  // 0) Sanity check import
  // ─────────────────────────────────────────────────────────────
  const { rows: impRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_imports` +
    `?id=eq.${enc(importId)}` +
    `&select=id,source_system,client_id,filename,parse_summary_json` +
    `&limit=1`
  );
  const imp = impRows?.[0] || null;
  if (!imp) {
    console.warn('[WEEKLY_CLASSIFY] import_not_found', { importId });
    return { error: 'import_not_found', import_id: importId, source_system, rows: [] };
  }
  if (String(imp.source_system || '').toUpperCase() !== String(source_system || '').toUpperCase()) {
    console.warn('[WEEKLY_CLASSIFY] source_system_mismatch', {
      importId,
      expected: source_system,
      actual: imp.source_system
    });
    return {
      error: 'source_system_mismatch',
      import_id: importId,
      expected_source_system: source_system,
      actual_source_system: imp.source_system,
      rows: []
    };
  }

  // ─────────────────────────────────────────────────────────────
  // 1) Load hr_rows
  // ─────────────────────────────────────────────────────────────
  const { rows: hrRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_rows` +
    `?import_id=eq.${enc(importId)}` +
    `&select=id,external_row_key,payload_json` +
    `&order=id.asc`
  );

  if (!hrRows?.length) {
    console.log('[WEEKLY_CLASSIFY] no hr_rows', { import_id: importId });
    return { import_id: importId, source_system, rows: [] };
  }

  console.log('[WEEKLY_CLASSIFY] loaded hr_rows', { import_id: importId, count: hrRows.length });

  // ─────────────────────────────────────────────────────────────
  // 2) Preload client_settings for week-ending day (per client)
  // ─────────────────────────────────────────────────────────────
  const clientIds = [];
  if (source_system === 'HEALTHROSTER' && imp.client_id) {
    clientIds.push(imp.client_id);
  }

  const clientSettingsMap = new Map();
  if (clientIds.length) {
    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
      `?client_id=in.(${clientIds.map(enc).join(',')})` +
      `&select=client_id,week_ending_weekday` +
      `&order=effective_from.desc,created_at.desc`
    );
    for (const cs of csRows || []) {
      if (!clientSettingsMap.has(cs.client_id)) clientSettingsMap.set(cs.client_id, cs);
    }
  }

  const weekEndingFor = async (client_id, workDateYmd) => {
    let weDow = 0;
    if (!clientSettingsMap.has(client_id)) {
      const { rows: csRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_settings` +
        `?client_id=eq.${enc(client_id)}` +
        `&select=client_id,week_ending_weekday` +
        `&order=effective_from.desc,created_at.desc&limit=1`
      );
      const cs = csRows?.[0] || null;
      if (cs) clientSettingsMap.set(client_id, cs);
    }
    const cs = clientSettingsMap.get(client_id);
    if (cs && Number.isInteger(Number(cs.week_ending_weekday))) {
      weDow = Number(cs.week_ending_weekday);
    }

    const d = new Date(`${workDateYmd}T00:00:00Z`);
    if (isNaN(d.getTime())) return null;
    while (d.getUTCDay() !== weDow) {
      d.setUTCDate(d.getUTCDate() + 1);
    }
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  // ─────────────────────────────────────────────────────────────
  // 3) Row-level classification first: parse + candidate/client/contract mapping
  // ─────────────────────────────────────────────────────────────
  const previewRows = [];
  const groupMap = new Map(); // key -> { candidate_id, client_id, contract_id, week_ending_date, shifts: [], context... }

  for (const hrRow of hrRows) {
    const payload = hrRow.payload_json || {};
    const preview_row_id = `row:${hrRow.id}`;

    let staffName = '';
    let workDate  = '';
    let ward      = '';
    let startIso  = null;
    let endIso    = null;
    let breakMins = 0;
    let finalised = '';
    let assignmentCode = '';
    let requestId = '';
    let refNum    = '';
    let trustRaw  = '';

    if (source_system === 'NHSP') {
      staffName = String(payload.worker_name || payload.name || '').trim();
      workDate  = String(payload.work_date || payload.date || '').trim();
      ward      = String(payload.ward || payload.unit || '').trim();
      trustRaw  = String(payload.trust || payload.hospital_or_trust || '').trim();
      startIso  = payload.start_utc || payload.actual_start_iso || payload.actual_start || null;
      endIso    = payload.end_utc   || payload.actual_end_iso   || payload.actual_end   || null;
      breakMins = Number(payload.break_mins ?? payload.break_minutes ?? payload.actual_break_minutes ?? 0) || 0;
      assignmentCode = String(payload.assignment || payload.assignment_code || '').trim();
      refNum    = String(payload.ref_num || payload.reference || '').trim();
    } else if (source_system === 'HEALTHROSTER') {
      staffName = String(payload.staff_name || payload.worker_name || '').trim();
      workDate  = String(payload.work_date || payload.date || '').trim();
      ward      = String(payload.ward || payload.unit || '').trim();
      trustRaw  = String(payload.trust || payload.hospital_or_trust || '').trim();
      startIso  = payload.start_utc || null;
      endIso    = payload.end_utc   || null;
      breakMins = Number(payload.break_mins ?? 0) || 0;
      finalised = String(payload.finalised_date || payload.finalized_date || payload.finalized_date || '').trim();
      requestId = String(payload.request_id || '').trim();
    } else {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_UNSUPPORTED_SOURCE',
        reason: `Unsupported source_system=${source_system}`,
        default_selected: false
      });
      continue;
    }

    const isUnfinalised = (source_system === 'HEALTHROSTER' && !finalised);

    // Basic field sanity
    if (!workDate || !startIso || !endIso) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_BAD_ROW',
        reason: 'Missing date or start/end times in payload',
        default_selected: false
      });
      continue;
    }

    // Candidate mapping
    let candidateId = null;
    let candidateName = null;

    if (source_system === 'NHSP') {
      const uniqueId = String(
        payload.unique_id ||
        payload.worker_unique_id ||
        payload.agency_worker_unique_id ||
        ''
      ).trim();

      if (uniqueId) {
        const { rows: candByNi } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?ni_number=eq.${enc(uniqueId)}` +
          `&select=id,display_name` +
          `&limit=1`
        );
        if (candByNi?.[0]?.id) {
          candidateId   = candByNi[0].id;
          candidateName = candByNi[0].display_name || null;
        }
      }
    }

    if (!candidateId && staffName) {
      const trustNorm = norm(trustRaw);
      const foundCandidateId = await findCandidateByImportName(env, staffName, { trustNorm });
      if (foundCandidateId) {
        candidateId = foundCandidateId;
      }
    }

    if (!candidateId) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_NO_CANDIDATE',
        reason: 'No candidate found for this staff (no NI match and no alias/HR name mapping)',
        default_selected: false
      });
      continue;
    }

    if (!candidateName) {
      const cand = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?id=eq.${enc(candidateId)}&select=id,display_name&limit=1`
      );
      candidateName = cand?.display_name || null;
    }

    // Client mapping
    let clientId = null;
    let clientName = null;

    if (source_system === 'HEALTHROSTER') {
      clientId = imp.client_id || null;
      if (!clientId) {
        previewRows.push({
          level: 'row',
          preview_row_id,
          hr_row_id: hrRow.id,
          import_id: importId,
          source_system,
          staff_name: staffName,
          work_date: workDate,
          ward,
          request_id: requestId || null,
          ref_num: null,
          action: 'REJECT_NO_CLIENT',
          reason: 'HealthRoster import has no client_id configured',
          default_selected: false
        });
        continue;
      }
      const cli = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients` +
        `?id=eq.${enc(clientId)}&select=id,name&limit=1`
      );
      if (!cli) {
        previewRows.push({
          level: 'row',
          preview_row_id,
          hr_row_id: hrRow.id,
          import_id: importId,
          source_system,
          staff_name: staffName,
          work_date: workDate,
          ward,
          request_id: requestId || null,
          ref_num: null,
          action: 'REJECT_NO_CLIENT',
          reason: 'HealthRoster client_id not found in clients table',
          default_selected: false
        });
        continue;
      }
      clientName = cli.name;
    } else {
      const trustNorm = norm(trustRaw);

      if (trustNorm) {
        try {
          const aliasJson = JSON.stringify([trustNorm]);
          const { rows: hospRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
            `?hospital_name_norm=cs.${enc(aliasJson)}` +
            `&select=client_id&limit=1`
          );
          if (hospRows?.[0]?.client_id) {
            clientId = hospRows[0].client_id;
          } else {
            const { rows: cliRows } = await sbFetch(
              env,
              `${env.SUPABASE_URL}/rest/v1/clients` +
              `?name=eq.${enc(trustRaw)}` +
              `&select=id,name&limit=1`
            );
            if (cliRows?.[0]?.id) {
              clientId   = cliRows[0].id;
              clientName = cliRows[0].name;
            }
          }
        } catch {
          if (!clientId) {
            const { rows: cliRows } = await sbFetch(
              env,
              `${env.SUPABASE_URL}/rest/v1/clients` +
              `?name=eq.${enc(trustRaw)}` +
              `&select=id,name&limit=1`
            );
            if (cliRows?.[0]?.id) {
              clientId   = cliRows[0].id;
              clientName = cliRows[0].name;
            }
          }
        }
      }

      if (!clientId) {
        previewRows.push({
          level: 'row',
          preview_row_id,
          hr_row_id: hrRow.id,
          import_id: importId,
          source_system,
          staff_name: staffName,
          work_date: workDate,
          ward,
          assignment_code: assignmentCode || null,
          request_id: null,
          ref_num: refNum || null,
          action: 'REJECT_NO_CLIENT',
          reason: `No client mapping for trust/hospital '${trustRaw}'`,
          default_selected: false
        });
        continue;
      }

      if (!clientName) {
        const cli = await sbGetOne(
          env,
          `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=eq.${enc(clientId)}&select=id,name&limit=1`
        );
        clientName = cli?.name || null;
      }
    }

    // ─────────────────────────────────────────────────────────────
    // Contract mapping with NHSP assignment ↔ band matching
    // ─────────────────────────────────────────────────────────────
    const { rows: contractRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?candidate_id=eq.${enc(candidateId)}` +
      `&client_id=eq.${enc(clientId)}` +
      `&select=id,start_date,end_date,role,band,pay_method_snapshot,self_bill` +
      `&order=start_date.asc`
    );
    const allContracts = contractRows || [];

    const workDateObj = new Date(`${workDate}T00:00:00Z`);
    if (isNaN(workDateObj.getTime())) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_BAD_ROW',
        reason: 'Invalid work_date in payload',
        default_selected: false
      });
      continue;
    }

    const inRange = [];
    for (const c of allContracts) {
      const s = c.start_date ? new Date(`${c.start_date}T00:00:00Z`) : null;
      const e = c.end_date   ? new Date(`${c.end_date}T00:00:00Z`)   : null;
      if (s && workDateObj < s) continue;
      if (e && workDateObj > e) continue;
      inRange.push(c);
    }

    if (!inRange.length) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_NO_CONTRACT',
        reason: 'No active contract for this candidate/client on this date',
        default_selected: false
      });
      continue;
    }

    let candidateContracts = inRange;
    if (source_system === 'NHSP' && assignmentCode) {
      const assignNorm = upper(assignmentCode);
      const bandMatches = [];

      for (const c of inRange) {
        const bandStr = upper(c.band || '');
        if (!bandStr) continue;
        const tokens = bandStr.split(/[,\s]+/).filter(Boolean);
        if (tokens.includes(assignNorm)) {
          bandMatches.push(c);
        }
      }

      if (!bandMatches.length) {
        previewRows.push({
          level: 'row',
          preview_row_id,
          hr_row_id: hrRow.id,
          import_id: importId,
          source_system,
          staff_name: staffName,
          work_date: workDate,
          ward,
          assignment_code: assignmentCode,
          request_id: requestId || null,
          ref_num: refNum || null,
          action: 'REJECT_NO_CONTRACT_BAND_MISMATCH',
          reason: `No contract band contains assignment '${assignmentCode}' for this candidate/client on this date`,
          default_selected: false
        });
        continue;
      }
      candidateContracts = bandMatches;
    }

    let chosenContract = null;
    for (const c of candidateContracts) {
      if (!chosenContract) {
        chosenContract = c;
        continue;
      }
      const prevStart = chosenContract.start_date ? new Date(`${chosenContract.start_date}T00:00:00Z`) : null;
      const thisStart = c.start_date            ? new Date(`${c.start_date}T00:00:00Z`)            : null;
      if (thisStart && prevStart && thisStart > prevStart) {
        chosenContract = c;
      }
    }

    if (!chosenContract) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_NO_CONTRACT',
        reason: 'No active contract for this candidate/client on this date (after band/assignment filtering)',
        default_selected: false
      });
      continue;
    }

    const we = await weekEndingFor(clientId, workDate);
    if (!we) {
      previewRows.push({
        level: 'row',
        preview_row_id,
        hr_row_id: hrRow.id,
        import_id: importId,
        source_system,
        staff_name: staffName,
        work_date: workDate,
        ward,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        request_id: requestId || null,
        ref_num: refNum || null,
        action: 'REJECT_BAD_ROW',
        reason: 'Unable to derive week-ending date',
        default_selected: false
      });
      continue;
    }

    // Group key: candidate + client + contract + week-ending
    const groupKey = `${candidateId}__${clientId}__${chosenContract.id}__${we}`;
    let g = groupMap.get(groupKey);
    if (!g) {
      g = {
        candidate_id: candidateId,
        candidate_name: candidateName,
        client_id: clientId,
        client_name: clientName,
        contract_id: chosenContract.id,
        week_ending_date: we,
        pay_method_snapshot: chosenContract.pay_method_snapshot,
        assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
        shifts: [],
        hr_row_ids: [],
        has_unfinalised: false
      };
      groupMap.set(groupKey, g);
    }

    if (isUnfinalised && source_system === 'HEALTHROSTER') {
      g.has_unfinalised = true;
    }

    g.shifts.push({
      hr_row_id: hrRow.id,
      staff_name: staffName,
      work_date: workDate,
      ward,
      start_utc: startIso,
      end_utc: endIso,
      break_mins: breakMins,
      assignment_code: (source_system === 'NHSP' ? assignmentCode : null),
      request_id: requestId || null,
      ref_num: refNum || null,
      is_unfinalised: isUnfinalised
    });
    g.hr_row_ids.push(hrRow.id);
  }

  console.log('[WEEKLY_CLASSIFY] grouping complete', {
    import_id: importId,
    source_system,
    group_count: groupMap.size,
    preview_row_count: previewRows.length
  });

  // ─────────────────────────────────────────────────────────────
  // 4) Group-level classification: base/adjustment TSFIN, delta, action
  // ─────────────────────────────────────────────────────────────
  const classifyGroup = async (g) => {
    const { candidate_id, client_id, contract_id, week_ending_date } = g;

    // Load contract (incl self_bill)
    const contract = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?id=eq.${enc(contract_id)}&select=id,role,band,pay_method_snapshot,self_bill&limit=1`
    );
    if (!contract) {
      return {
        level: 'group',
        preview_group_id: `grp:${contract_id}:${week_ending_date}:${candidate_id}`,
        import_id: importId,
        source_system,
        candidate_id,
        candidate_name: g.candidate_name,
        client_id,
        client_name: g.client_name,
        contract_id,
        week_ending_date,
        assignment_code: g.assignment_code || null,
        self_bill: null,
        has_unfinalised: !!g.has_unfinalised,
        hr_row_ids: g.hr_row_ids.slice(),
        truth_pay_ex_vat: 0,
        truth_charge_ex_vat: 0,
        current_pay_ex_vat: 0,
        current_charge_ex_vat: 0,
        delta_pay_ex_vat: 0,
        delta_charge_ex_vat: 0,
        base_timesheet_id: null,
        latest_adjustment_timesheet_id: null,
        action: 'REJECT_NO_CONTRACT',
        reason: 'Contract not found at apply stage',
        default_selected: false
      };
    }

    // Load contract_weeks for this contract/week
    const { rows: cwRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(contract_id)}` +
      `&week_ending_date=eq.${enc(week_ending_date)}` +
      `&select=id,timesheet_id,additional_seq,is_adjustment` +
      `&order=additional_seq.asc`
    );
    const weeks = cwRows || [];
    const baseWeek   = weeks.find(w => !w.is_adjustment && Number(w.additional_seq || 0) === 0) || null;
    const adjWeeks   = weeks.filter(w => !!w.is_adjustment);

    const tsIds = weeks.map(w => w.timesheet_id).filter(Boolean);
    let tsById = new Map();
    if (tsIds.length) {
      const { rows: tsRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=in.(${tsIds.map(enc).join(',')})` +
        `&select=timesheet_id,submission_mode,status`
      );
      tsById = new Map((tsRows || []).map(t => [t.timesheet_id, t]));
    }

    let finByTsId = new Map();
    if (tsIds.length) {
      const { rows: finRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=in.(${tsIds.map(enc).join(',')})` +
        `&is_current=eq.true` +
        `&select=timesheet_id,total_pay_ex_vat,total_charge_ex_vat,basis,paid_at_utc,locked_by_invoice_id`
      );
      finByTsId = new Map((finRows || []).map(f => [f.timesheet_id, f]));
    }

    // Compute truth totals from import shifts
    let truthPay = 0;
    let truthChg = 0;

    for (const sh of g.shifts) {
      const policy = await loadPolicy(env, client_id, sh.work_date);
      let segs = [[sh.start_utc, sh.end_utc]];
      segs = subtractBreak(segs, null, null, sh.break_mins || 0);

      const hours = classifyMinutes(env, policy, segs);
      const rates = await resolveRates(env, {
        candidate_id,
        client_id,
        role: contract.role || null,
        band: contract.band || null,
        dateYmd: sh.work_date,
      });
      const pay = rates.pay || {};
      const chg = rates.charge || {};

      const segPay = round2(
        (hours.hours_day   || 0) * asNumberLocal(pay.day)   +
        (hours.hours_night || 0) * asNumberLocal(pay.night) +
        (hours.hours_sat   || 0) * asNumberLocal(pay.sat)   +
        (hours.hours_sun   || 0) * asNumberLocal(pay.sun)   +
        (hours.hours_bh    || 0) * asNumberLocal(pay.bh)
      );
      const segChg = round2(
        (hours.hours_day   || 0) * asNumberLocal(chg.day)   +
        (hours.hours_night || 0) * asNumberLocal(chg.night) +
        (hours.hours_sat   || 0) * asNumberLocal(chg.sat)   +
        (hours.hours_sun   || 0) * asNumberLocal(chg.sun)   +
        (hours.hours_bh    || 0) * asNumberLocal(chg.bh)
      );
      truthPay += segPay;
      truthChg += segChg;
    }
    truthPay = round2(truthPay);
    truthChg = round2(truthChg);

    let currentPay = 0;
    let currentChg = 0;

    for (const w of weeks) {
      const tsId = w.timesheet_id;
      if (!tsId) continue;
      const fin = finByTsId.get(tsId);
      if (!fin) continue;
      currentPay += Number(fin.total_pay_ex_vat || 0);
      currentChg += Number(fin.total_charge_ex_vat || 0);
    }
    currentPay = round2(currentPay);
    currentChg = round2(currentChg);

    const deltaPay = round2(truthPay - currentPay);
    const deltaChg = round2(truthChg - currentChg);
    const tol = 0.01;

    const baseTsId    = baseWeek?.timesheet_id || null;
    const baseTs      = baseTsId ? tsById.get(baseTsId) : null;
    const baseFin     = baseTsId ? finByTsId.get(baseTsId) : null;

    let latestAdjWeek = null;
    if (adjWeeks.length) {
      latestAdjWeek = adjWeeks.reduce((m, w) =>
        Number(w.additional_seq || 0) > Number(m.additional_seq || 0) ? w : m,
        adjWeeks[0]
      );
    }
    const latestAdjTsId = latestAdjWeek?.timesheet_id || null;
    const latestAdjFin  = latestAdjTsId ? finByTsId.get(latestAdjTsId) : null;

    const anyAdj = !!latestAdjWeek;
    const latestAdjUnpaidUnlocked =
      !!(latestAdjFin && !latestAdjFin.paid_at_utc && !latestAdjFin.locked_by_invoice_id);
    const baseUnpaidUnlocked =
      !!(baseFin && !baseFin.paid_at_utc && !baseFin.locked_by_invoice_id);

    const isPaid     = !!(baseFin && baseFin.paid_at_utc);
    const isInvoiced = !!(baseFin && baseFin.locked_by_invoice_id);
    const selfBill   = (source_system === 'HEALTHROSTER') ? !!contract.self_bill : null;
    const hasUnfinal = !!g.has_unfinalised;

    let result = {
      level: 'group',
      preview_group_id: `grp:${contract_id}:${week_ending_date}:${candidate_id}`,
      import_id: importId,
      source_system,
      candidate_id,
      candidate_name: g.candidate_name,
      client_id,
      client_name: g.client_name,
      contract_id,
      week_ending_date,
      assignment_code: g.assignment_code || null,
      self_bill: selfBill,
      has_unfinalised: hasUnfinal,
      hr_row_ids: g.hr_row_ids.slice(),
      truth_pay_ex_vat: truthPay,
      truth_charge_ex_vat: truthChg,
      current_pay_ex_vat: currentPay,
      current_charge_ex_vat: currentChg,
      delta_pay_ex_vat: deltaPay,
      delta_charge_ex_vat: deltaChg,
      base_timesheet_id: baseTsId,
      latest_adjustment_timesheet_id: latestAdjTsId,
      action: 'UNKNOWN',
      reason: 'Unable to classify this weekly group – please review manually.',
      default_selected: false
    };

    // No base timesheet yet
    if (!baseTsId) {
      if (Math.abs(truthPay) < tol && Math.abs(truthChg) < tol) {
        result.action = 'SKIP_ALREADY_PROCESSED';
        result.reason = 'No weekly timesheet yet and truth totals are zero – nothing to create.';
        result.default_selected = false;
      } else {
        result.action = 'NEW_AUTOPROC_TIMESHEET';
        result.reason = 'No existing weekly timesheet – a new weekly TS will be created from these shifts.';
        result.default_selected = !hasUnfinal;
      }
      return result;
    }

    // Base TS exists: if totals already match, skip
    if (Math.abs(deltaPay) < tol && Math.abs(deltaChg) < tol) {
      result.action = 'SKIP_ALREADY_PROCESSED';
      result.reason = 'Base timesheet and existing adjustments already match NHSP/HealthRoster totals – nothing further to do.';
      result.default_selected = false;
      return result;
    }

    const submissionMode = String(baseTs?.submission_mode || '').toUpperCase();

    // Manual base: unchanged logic
    if (submissionMode === 'MANUAL') {
      if (baseUnpaidUnlocked && !anyAdj) {
        result.action = 'UPDATE_MANUAL_WEEK';
        result.reason = 'Existing manual weekly timesheet (unpaid/uninvoiced) will be overwritten with NHSP/HR hours for this week.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      if (latestAdjUnpaidUnlocked) {
        result.action = 'UPDATE_ADJUSTMENT_TS';
        result.reason = 'Existing unpaid/uninvoiced adjustment timesheet will be updated to reflect the new delta.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      result.action = 'CREATE_ADJUSTMENT_TS';
      result.reason = 'Base and previous adjustments are paid/invoiced; a new sequential adjustment timesheet will be created for the new delta.';
      result.default_selected = !hasUnfinal;
      return result;
    }

    // Autoproc base
    if (submissionMode !== 'MANUAL') {
      // NHSP and HR self_bill=true → standard NHSP-style logic
      if (source_system === 'NHSP' || (source_system === 'HEALTHROSTER' && selfBill)) {
        if (baseUnpaidUnlocked && !anyAdj) {
          result.action = 'UPDATE_AUTOPROC_TS';
          result.reason = 'Existing autoproc weekly timesheet (unpaid/uninvoiced) will be updated with corrected NHSP/HR hours for this week.';
          result.default_selected = !hasUnfinal;
          return result;
        }

        if (latestAdjUnpaidUnlocked) {
          result.action = 'UPDATE_ADJUSTMENT_TS';
          result.reason = 'Existing unpaid/uninvoiced adjustment timesheet will be updated to reflect the new delta.';
          result.default_selected = !hasUnfinal;
          return result;
        }

        result.action = 'CREATE_ADJUSTMENT_TS';
        result.reason = 'Autoproc base and previous adjustments are paid/invoiced; a new sequential adjustment timesheet will be created for the new delta.';
        result.default_selected = !hasUnfinal;
        return result;
      }

      // HEALTHROSTER, self_bill = false → special HR logic
      if (source_system === 'HEALTHROSTER' && selfBill === false) {
        if (!isPaid && !isInvoiced) {
          result.action = 'UPDATE_AUTOPROC_TS';
          result.reason = 'HR weekly (self-bill=false): base timesheet will be overwritten with HR hours for this week; no new adjustment weeks will be created.';
          result.default_selected = !hasUnfinal;
          return result;
        }

        if (isInvoiced) {
          result.action = 'BLOCK_INVOICE_ISSUED';
          result.reason = 'HR weekly (self-bill=false): invoice already issued – unissue the invoice before applying these HR changes.';
          result.default_selected = false;
          return result;
        }

        if (isPaid && !isInvoiced) {
          result.action = 'CREATE_PAY_ADJUSTMENT_ONLY';
          result.reason = 'HR weekly (self-bill=false): candidate already paid – a pay-only adjustment will be created; invoice will reflect full HR hours.';
          result.default_selected = !hasUnfinal;
          return result;
        }

        // Fallback
        result.action = 'UNKNOWN';
        result.reason = 'HR weekly (self-bill=false): unhandled state – please review manually.';
        result.default_selected = false;
        return result;
      }

      // Fallback for other autoproc routes
      result.action = 'UNKNOWN';
      result.reason = 'Unable to classify this weekly group – please review manually.';
      result.default_selected = !hasUnfinal;
      return result;
    }

    // Fallback
    return result;
  };

  for (const g of groupMap.values()) {
    const gp = await classifyGroup(g);
    previewRows.push(gp);
  }

  console.log('[WEEKLY_CLASSIFY] done', {
    import_id: importId,
    source_system,
    preview_rows: previewRows.length
  });

  // ─────────────────────────────────────────────────────────────
  // 5) Post-process previewRows with mapping fields for FE
  // ─────────────────────────────────────────────────────────────
  for (const pr of previewRows) {
    const lvl = String(pr.level || '').toLowerCase();

    if (lvl === 'row') {
      // staff / hospital for row-level entries
      const staffRaw = pr.staff_name || '';
      const ward     = pr.ward || '';
      const trust    = pr.trust || pr.hospital_or_trust || '';
      const hosp     = ward || trust;

      pr.staff_raw        = staffRaw;
      pr.staff_norm       = norm(staffRaw);
      pr.hospital_or_trust = hosp;
      pr.trust_norm       = norm(hosp);

      // candidate/client ids for row-level entries are not tracked here
      if (!Object.prototype.hasOwnProperty.call(pr, 'candidate_id')) {
        pr.candidate_id = null;
      }
      if (!Object.prototype.hasOwnProperty.call(pr, 'client_id')) {
        pr.client_id = null;
      }

      // resolution_status derived from action
      const act = String(pr.action || '').toUpperCase();
      if (!pr.resolution_status) {
        if (act === 'REJECT_NO_CANDIDATE') pr.resolution_status = 'NO_CANDIDATE';
        else if (act === 'REJECT_NO_CLIENT') pr.resolution_status = 'NO_CLIENT';
        else if (act === 'REJECT_BAD_ROW' || act === 'REJECT_BAD_ROW2') pr.resolution_status = 'BAD_ROW';
        else if (act === 'REJECT_NO_CONTRACT' || act === 'REJECT_NO_CONTRACT_BAND_MISMATCH') pr.resolution_status = act;
        else if (act.startsWith('REJECT_')) pr.resolution_status = act;
        else pr.resolution_status = 'OK';
      }

    } else if (lvl === 'group') {
      // group-level: ensure resolution_status and mapping fields exist
      if (!Object.prototype.hasOwnProperty.call(pr, 'staff_raw')) {
        pr.staff_raw = null;
      }
      if (!Object.prototype.hasOwnProperty.call(pr, 'staff_norm')) {
        pr.staff_norm = null;
      }
      if (!Object.prototype.hasOwnProperty.call(pr, 'hospital_or_trust')) {
        pr.hospital_or_trust = null;
      }
      if (!Object.prototype.hasOwnProperty.call(pr, 'trust_norm')) {
        pr.trust_norm = null;
      }
      // candidate_id / client_id already present on group result
      if (!pr.resolution_status) {
        pr.resolution_status = pr.action || 'UNKNOWN';
      }
    }
  }

  return {
    import_id: importId,
    source_system,
    rows: previewRows
  };
}

async function handleNhspImport(env, req) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await parseJSONBody(req).catch(() => null);
  const filename = (body?.original_name || body?.file_key || '').trim();
  const fileKey  = (body?.file_key || '').trim();

  if (!filename) {
    return withCORS(env, req, badRequest("original_name or file_key is required"));
  }
  if (!fileKey) {
    return withCORS(env, req, badRequest("file_key is required for NHSP import (to parse the Excel)."));
  }

  if (LOG) {
    console.log('[NHSP_IMPORT]', JSON.stringify({
      stage: 'start',
      filename,
      file_key: fileKey,
      tz_assumption: body?.tz_assumption || 'Europe/London'
    }));
  }

  try {
    const nowIso = new Date().toISOString();
    const tzAssumption = body?.tz_assumption || 'Europe/London';

    // 1) Create hr_imports row for this NHSP file
    const payload = {
      filename,
      uploaded_by: user.id,
      uploaded_at_utc: nowIso,
      tz_assumption: tzAssumption,
      source_system: 'NHSP',
      file_r2_key: fileKey,
      parse_summary_json: {
        status: 'PENDING_PARSE',
        rows_total: 0,
        rows_parsed: 0,
        rows_skipped: 0,
        notes: null,
        header_columns: []
      }
    };

    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/hr_imports`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload),
    });

    if (!res.ok) {
      const err = await res.text();
      if (LOG) {
        console.error('[NHSP_IMPORT]', JSON.stringify({
          stage: 'hr_imports_insert_failed',
          filename,
          file_key: fileKey,
          error: err
        }));
      }
      return withCORS(env, req, badRequest(`NHSP import record create failed: ${err}`));
    }

    const json = await res.json().catch(() => ([]));
    const rec = Array.isArray(json) ? json[0] : json;

    if (!rec || !rec.id) {
      if (LOG) {
        console.error('[NHSP_IMPORT]', JSON.stringify({
          stage: 'no_import_id',
          filename,
          file_key: fileKey
        }));
      }
      return withCORS(env, req, serverError("NHSP import record create returned no id"));
    }

    const importId = rec.id;

    // 2) Parse the NHSP workbook into hr_rows (one row per shift)
    let summary = {
      rows_total: 0,
      rows_parsed: 0,
      rows_skipped: 0,
      notes: null,
      header_columns: [],
      error: false
    };

    try {
      if (typeof parseNhspWorkbookIntoHrRows === 'function') {
        const parsed = await parseNhspWorkbookIntoHrRows(env, {
          import_id: importId,
          file_key: fileKey,
          tz: tzAssumption
        });

        if (parsed && typeof parsed === 'object') {
          summary = {
            ...summary,
            ...parsed,
            header_columns: Array.isArray(parsed.header_columns) ? parsed.header_columns : []
          };
        }
      } else {
        summary.error = true;
        summary.notes = 'parseNhspWorkbookIntoHrRows helper is not implemented.';
      }
    } catch (e) {
      summary.error = true;
      summary.notes = `Parsing failed: ${e?.message || String(e)}`;
      if (LOG) {
        console.error('[NHSP_IMPORT]', JSON.stringify({
          stage: 'parse_failed',
          import_id: importId,
          filename,
          file_key: fileKey,
          error: e?.message || String(e)
        }));
      }
    }

    const prev = (rec.parse_summary_json && typeof rec.parse_summary_json === 'object')
      ? rec.parse_summary_json
      : {};

    const headerCols = Array.isArray(summary.header_columns)
      ? summary.header_columns.map(x => String(x ?? ''))
      : [];

    const patchBody = {
      parse_summary_json: {
        ...prev,
        status: summary.error ? 'PARSE_FAILED' : 'PARSED',
        rows_total: Number(summary.rows_total || 0),
        rows_parsed: Number(summary.rows_parsed || 0),
        rows_skipped: Number(summary.rows_skipped || 0),
        notes: summary.notes || null,
        header_columns: headerCols
      }
    };

    // 3) Update hr_imports.parse_summary_json with the real summary (INCLUDING header_columns)
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/hr_imports?id=eq.${encodeURIComponent(importId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
        body: JSON.stringify(patchBody)
      }
    ).catch(() => { /* best effort */ });

    if (LOG) {
      console.log('[NHSP_IMPORT]', JSON.stringify({
        stage: 'after_parse',
        import_id: importId,
        filename,
        file_key: fileKey,
        tz_assumption: tzAssumption,
        parse_summary: patchBody.parse_summary_json
      }));
    }

    // 4) Audit
    await writeAudit(
      env,
      user,
      'NHSP_IMPORT_CREATED',
      {
        import_id: importId,
        filename,
        parse_summary: patchBody.parse_summary_json
      },
      { entity: 'hr_imports', subject_id: importId, req }
    );

    return withCORS(env, req, ok({
      import_id: importId,
      parse_summary: patchBody.parse_summary_json
    }));
  } catch (e) {
    if (LOG) {
      console.error('[NHSP_IMPORT]', JSON.stringify({
        stage: 'unexpected_error',
        filename,
        file_key: fileKey,
        error: e?.message || String(e)
      }));
    }
    return withCORS(env, req, serverError("Failed to create NHSP import"));
  }
}


 async function handleNhspImportPreview(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!importId) {
    return withCORS(env, req, badRequest('import_id is required'));
  }

  try {
    const result = await classifyWeeklyImportRows(env, importId, { source_system: 'NHSP' });

    if (result.error === 'import_not_found') {
      if (LOG) {
        console.warn('[NHSP_PREVIEW]', JSON.stringify({
          import_id: importId,
          error: 'import_not_found'
        }));
      }
      return withCORS(env, req, notFound(`NHSP import ${importId} not found`));
    }
    if (result.error === 'source_system_mismatch') {
      if (LOG) {
        console.warn('[NHSP_PREVIEW]', JSON.stringify({
          import_id: importId,
          error: 'source_system_mismatch',
          actual_source_system: result.actual_source_system
        }));
      }
      return withCORS(env, req, badRequest(
        `Import ${importId} has source_system=${result.actual_source_system}, expected NHSP`
      ));
    }

    if (LOG) {
      const groups = Array.isArray(result.groups)
        ? result.groups
        : (Array.isArray(result.rows)
            ? result.rows.filter(r => r && r.level === 'group')
            : []);

      const sampleProblems = groups
        .filter(g => g.action && g.action !== 'APPLY_OK')
        .slice(0, 10)
        .map(g => ({
          preview_group_id: g.preview_group_id,
          action: g.action,
          reason: g.reason || null,
          candidate_id: g.candidate_id,
          client_id: g.client_id,
          week_ending: g.week_ending_date
        }));

      console.log('[NHSP_PREVIEW]', JSON.stringify({
        import_id: importId,
        summary: result.summary || null,
        total_groups: groups.length,
        sample_problem_groups: sampleProblems
      }));
    }

    return withCORS(env, req, ok(result));
  } catch (e) {
    if (LOG) {
      console.error('[NHSP_PREVIEW]', JSON.stringify({
        import_id: importId,
        stage: 'unexpected_error',
        error: e?.message || e
      }));
    }
    return withCORS(env, req, serverError(`NHSP preview failed: ${e?.message || e}`));
  }
}

 async function handleHrAutoprocessPreview(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!importId) {
    return withCORS(env, req, badRequest('import_id is required'));
  }

  try {
    const result = await classifyWeeklyImportRows(env, importId, { source_system: 'HEALTHROSTER' });

    if (result.error === 'import_not_found') {
      if (LOG) {
        console.warn('[HR_WEEKLY_PREVIEW]', JSON.stringify({
          import_id: importId,
          error: 'import_not_found'
        }));
      }
      return withCORS(env, req, notFound(`HealthRoster import ${importId} not found`));
    }
    if (result.error === 'source_system_mismatch') {
      if (LOG) {
        console.warn('[HR_WEEKLY_PREVIEW]', JSON.stringify({
          import_id: importId,
          error: 'source_system_mismatch',
          actual_source_system: result.actual_source_system
        }));
      }
      return withCORS(env, req, badRequest(
        `Import ${importId} has source_system=${result.actual_source_system}, expected HEALTHROSTER`
      ));
    }

    if (LOG) {
      const groups = Array.isArray(result.groups)
        ? result.groups
        : (Array.isArray(result.rows)
            ? result.rows.filter(r => r && r.level === 'group')
            : []);

      const sampleProblems = groups
        .filter(g => g.action && g.action !== 'APPLY_OK')
        .slice(0, 10)
        .map(g => ({
          preview_group_id: g.preview_group_id,
          action: g.action,
          reason: g.reason || null,
          candidate_id: g.candidate_id,
          client_id: g.client_id,
          week_ending: g.week_ending_date
        }));

      console.log('[HR_WEEKLY_PREVIEW]', JSON.stringify({
        import_id: importId,
        summary: result.summary || null,
        total_groups: groups.length,
        sample_problem_groups: sampleProblems
      }));
    }

    return withCORS(env, req, ok(result));
  } catch (e) {
    if (LOG) {
      console.error('[HR_WEEKLY_PREVIEW]', JSON.stringify({
        import_id: importId,
        stage: 'unexpected_error',
        error: e?.message || String(e)
      }));
    }
    return withCORS(env, req, serverError(`HealthRoster preview failed: ${e?.message || e}`));
  }
}

async function findCandidateByImportName(env, staffName, { trustNorm } = {}) {
  const enc  = encodeURIComponent;
  const norm = (s) => String(s || '').trim().toLowerCase();

  const nameNorm = norm(staffName);
  if (!nameNorm) return null;

  // 1) Candidate-level alias JSONB: candidates.nhsp_hr_name_aliases contains nameNorm
  try {
    const aliasJson = JSON.stringify([nameNorm]); // ["john smith"]
    const { rows: candRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?nhsp_hr_name_aliases=cs.${enc(aliasJson)}` +
        `&active=eq.true` +
        `&select=id` +
        `&limit=2`
    );
    // Only accept if exactly one match to avoid ambiguity
    if (candRows?.length === 1 && candRows[0]?.id) {
      return candRows[0].id;
    }
  } catch {
    // If this fails for any reason, just fall through to hr_name_mappings
  }

  // 2) hr_name_mappings: single query for all active mappings for this name
  let mapRows = [];
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_name_mappings` +
        `?hr_name_norm=eq.${enc(nameNorm)}` +
        `&active=eq.true` +
        `&select=candidate_id,hospital_or_trust`
      // no limit: table is small; this is one subrequest either way
    );
    mapRows = rows || [];
  } catch {
    return null;
  }

  if (!mapRows.length) {
    return null;
  }

  const tNorm = norm(trustNorm);

  // Prefer mappings that match this hospital_or_trust
  if (tNorm) {
    const matches = mapRows.filter((r) => norm(r.hospital_or_trust) === tNorm);
    const ids = [...new Set(matches.map((r) => r.candidate_id).filter(Boolean))];
    if (ids.length === 1) {
      return ids[0];
    }
    // if >1 candidate_id for the same site, treat as ambiguous and fall back to name-only
  }

  // Name-only fallback: if all mappings for this name point to the same candidate, use it
  const allIds = [...new Set(mapRows.map((r) => r.candidate_id).filter(Boolean))];
  if (allIds.length === 1) {
    return allIds[0];
  }

  // Ambiguous (multiple candidates for same name); require manual resolve
  return null;
}


// ───────────────────────────────────────────────────────────────────────────────
// SEARCH — Invoices (richer filters + csv/print)
// ───────────────────────────────────────────────────────────────────────────────
async function handleSearchInvoices(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q  = (k) => urlObj.searchParams.get(k);
  const qa = (k) => urlObj.searchParams.getAll(k);
  const page     = Math.max(1, parseInt(q('page') || '1', 10));
  const pageSize = Math.max(1, Math.min(200, parseInt(q('page_size') || '50', 10)));

  const format = (q('format') || 'json').toLowerCase(); // 'json'|'csv'|'print'

  // explicit-ID selection support
  const idInExpr = q('id');
  const idsRaw   = q('ids');
  let idFilterExpr = null;
  if (idInExpr && /^in\.\(.+\)$/.test(idInExpr)) {
    idFilterExpr = idInExpr;
  } else if (idsRaw) {
    const list = idsRaw.split(',').map(s => s.trim()).filter(Boolean);
    if (list.length) idFilterExpr = `in.(${list.join(',')})`;
  }

  // Filters
  const statuses   = qa('status');
  const clientId   = q('client_id');
  const invNo      = q('invoice_no');
  const invQ       = q('q');
  const issuedFrom = q('issued_from');
  const issuedTo   = q('issued_to');
  const dueFrom    = q('due_from');
  const dueTo      = q('due_to');
  const createdFrom = q('created_from');
  const createdTo   = q('created_to');

  const orderBy = (q('order_by') || 'issued_at_utc').toLowerCase();
  const orderDir = (q('order_dir') || 'desc').toLowerCase() === 'asc' ? 'asc' : 'desc';
  const orderAllowed = new Set(['issued_at_utc','invoice_no','total_inc_vat','subtotal_ex_vat','created_at','due_at_utc','status_date_utc']);

  let url = `${env.SUPABASE_URL}/rest/v1/invoices` +
    `?select=` +
    [
      'id','invoice_no','client_id','status','status_date_utc',
      'issued_at_utc','due_at_utc','created_at',
      'total_inc_vat','subtotal_ex_vat','vat_amount',
      'on_hold_reason',
      'client:clients(name)'
    ].join(',') +
    `&limit=${pageSize}&offset=${(page-1)*pageSize}`;

  if (Array.isArray(statuses) && statuses.length) {
    const inList = statuses.map(s => String(s).toUpperCase().replace(/[(),]/g,'')).join(',');
    url += `&status=in.(${inList})`;
  }
  if (clientId) url += `&client_id=eq.${enc(clientId)}`;
  if (invNo)    url += `&invoice_no=eq.${enc(invNo)}`;
  if (invQ)     url += `&invoice_no=ilike.*${enc(invQ)}*`;
  if (issuedFrom) url += `&issued_at_utc=gte.${enc(issuedFrom)}`;
  if (issuedTo)   url += `&issued_at_utc=lte.${enc(issuedTo)}`;
  if (dueFrom)    url += `&due_at_utc=gte.${enc(dueFrom)}`;
  if (dueTo)      url += `&due_at_utc=lte.${enc(dueTo)}`;
  if (createdFrom) url += `&created_at=gte.${enc(createdFrom)}`;
  if (createdTo)   url += `&created_at=lte.${enc(createdTo)}`;

  if (idFilterExpr) url += `&id=${enc(idFilterExpr)}`;

  url += `&order=${orderAllowed.has(orderBy) ? enc(orderBy) : 'issued_at_utc'}.${orderDir}`;

  let rows = [];
  try {
    ({ rows } = await sbFetch(env, url));
  } catch (err) {
    return withCORS(env, req, ok({ error: String(err?.message || err), rows: [], page, page_size: pageSize, count: 0 }));
  }

  if (format === 'csv') {
    const header = ['InvoiceNo','Client','Status','StatusDate','IssuedAt','DueAt','CreatedAt','SubtotalExVAT','VAT','TotalIncVAT','OnHoldReason'];
    const out = [csvJoin(header)];
    for (const r of rows || []) {
      out.push(csvJoin([
        r.invoice_no || '',
        r.client?.name || '',
        r.status || '',
        r.status_date_utc || '',
        r.issued_at_utc || '',
        r.due_at_utc || '',
        r.created_at || '',
        round2(r.subtotal_ex_vat || 0).toFixed(2),
        round2(r.vat_amount || 0).toFixed(2),
        round2(r.total_inc_vat || 0).toFixed(2),
        r.on_hold_reason || ''
      ]));
    }
    return withCORS(env, req, ok({ csv: out.join('\n'), count: rows?.length || 0, page, page_size: pageSize }));
  }

  if (format === 'print') {
    const rowsHtml = (rows || []).map(r => `
      <tr>
        <td>${r.invoice_no || ''}</td>
        <td>${(r.client && r.client.name) ? r.client.name : ''}</td>
        <td>${r.status || ''}</td>
        <td>${r.status_date_utc || ''}</td>
        <td>${r.issued_at_utc || ''}</td>
        <td>${r.due_at_utc || ''}</td>
        <td>${r.created_at || ''}</td>
        <td style="text-align:right">${round2(r.subtotal_ex_vat || 0).toFixed(2)}</td>
        <td style="text-align:right">${round2(r.vat_amount || 0).toFixed(2)}</td>
        <td style="text-align:right">${round2(r.total_inc_vat || 0).toFixed(2)}</td>
        <td>${r.on_hold_reason || ''}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Invoices — Search Results</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5">
            <th>Invoice No</th><th>Client</th><th>Status</th><th>Status Date</th><th>Issued At</th><th>Due At</th><th>Created At</th>
            <th>Subtotal ex VAT</th><th>VAT</th><th>Total inc VAT</th><th>On hold reason</th>
          </tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;
    return withCORS(env, req, ok({ html, count: rows?.length || 0, page, page_size: pageSize }));
  }

  return withCORS(env, req, ok({ rows, page, page_size: pageSize, count: rows?.length || 0 }));
}





// ───────────────────────────────────────────────────────────────────────────────
// SEARCH — Candidates (richer filters + csv/print)
// ───────────────────────────────────────────────────────────────────────────────




// ───────────────────────────────────────────────────────────────────────────────
// SEARCH — Clients (richer filters + csv/print)
// ───────────────────────────────────────────────────────────────────────────────

 async function handleSearchClients(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const page     = Math.max(1, parseInt(q('page') || '1', 10));
  const pageSize = Math.max(1, Math.min(200, parseInt(q('page_size') || '50', 10)));
  const format   = (q('format') || 'json').toLowerCase(); // 'json'|'csv'|'print'

  // Sorting
  const orderByParam = (q('order_by') || '').toLowerCase();
  const orderDirParam = (q('order_dir') || '').toLowerCase();

  const allowedSort = {
    name:                  'name',
    cli_ref:               'cli_ref',
    primary_invoice_email: 'primary_invoice_email',
    ap_phone:              'ap_phone',
    vat_chargeable:        'vat_chargeable',
    payment_terms_days:    'payment_terms_days',
    created_at:            'created_at',
    updated_at:            'updated_at'
  };
  const defaultOrderCol = 'name';
  const orderCol = allowedSort[orderByParam] || defaultOrderCol;
  const orderDir = (orderDirParam === 'desc') ? 'desc' : 'asc';

  // explicit-ID selection support
  const idInExpr = q('id');    // 'in.(...)'
  const idsRaw   = q('ids');   // 'uuid1,uuid2,...'
  let idFilterExpr = null;
  if (idInExpr && /^in\.\(.+\)$/.test(idInExpr)) {
    idFilterExpr = idInExpr;
  } else if (idsRaw) {
    const list = idsRaw.split(',').map(s => s.trim()).filter(Boolean);
    if (list.length) idFilterExpr = `in.(${list.join(',')})`;
  }

  // Filters expanded to match FE
  const text          = q('q'); // name partial
  const cliRef        = q('cli_ref');
  const primaryEmail  = q('primary_invoice_email');
  const invoiceAddr   = q('invoice_address');
  const postcode      = q('postcode');              // kept as a query param, but no DB column yet
  const apPhone       = q('ap_phone');
  const vatChargeable = q('vat_chargeable');        // 'true'|'false'|null
  const paymentTerms  = q('payment_terms_days');
  const mileageRate   = q('mileage_charge_rate');
  const tsQueries     = q('ts_queries_email');
  const createdFrom   = q('created_from');
  const createdTo     = q('created_to');
  const updatedFrom   = q('updated_from');
  const updatedTo     = q('updated_to');

  let url =
    `${env.SUPABASE_URL}/rest/v1/clients` +
    `?select=id,cli_ref,name,invoice_address,primary_invoice_email,ap_phone,vat_chargeable,payment_terms_days,mileage_charge_rate,ts_queries_email,created_at,updated_at` +
    `&order=${enc(orderCol)}.${orderDir}` +
    `&limit=${pageSize}&offset=${(page-1)*pageSize}`;

  if (idFilterExpr) url += `&id=${enc(idFilterExpr)}`;
  if (text)         url += `&name=ilike.*${enc(text)}*`;
  if (cliRef)       url += `&cli_ref=ilike.*${enc(cliRef)}*`;
  if (primaryEmail) url += `&primary_invoice_email=ilike.*${enc(primaryEmail)}*`;
  if (invoiceAddr)  url += `&invoice_address=ilike.*${enc(invoiceAddr)}*`;
  // NOTE: postcode is not a real column on clients table yet, so we don't add a filter here
  if (apPhone)      url += `&ap_phone=ilike.*${enc(apPhone)}*`;

  if (vatChargeable === 'true')  url += `&vat_chargeable=eq.true`;
  if (vatChargeable === 'false') url += `&vat_chargeable=eq.false`;

  if (paymentTerms) url += `&payment_terms_days=eq.${enc(paymentTerms)}`;
  if (mileageRate)  url += `&mileage_charge_rate=eq.${enc(mileageRate)}`;
  if (tsQueries)    url += `&ts_queries_email=ilike.*${enc(tsQueries)}*`;

  if (createdFrom)  url += `&created_at=gte.${enc(createdFrom)}`;
  if (createdTo)    url += `&created_at=lte.${enc(createdTo)}`;
  if (updatedFrom)  url += `&updated_at=gte.${enc(updatedFrom)}`;
  if (updatedTo)    url += `&updated_at=lte.${enc(updatedTo)}`;

  let rows = [];
  try {
    ({ rows } = await sbFetch(env, url));
  } catch (err) {
    return withCORS(env, req, ok({ error: String(err?.message || err), rows: [], page, page_size: pageSize, count: 0 }));
  }

  if (format === 'csv') {
    const header = [
      'ClientId',
      'Name',
      'ClientRef',
      'InvoiceAddress',
      'Postcode',
      'VATChargeable',
      'PaymentTermsDays',
      'PrimaryInvoiceEmail',
      'APPhone',
      'MileageChargeRate',
      'TSQueriesEmail',
      'CreatedAt',
      'UpdatedAt'
    ];
    const out = [csvJoin(header)];
    for (const r of rows || []) {
      out.push(csvJoin([
        r.id,
        r.name || '',
        r.cli_ref || '',
        r.invoice_address || '',
        '', // postcode placeholder (no DB column yet)
        r.vat_chargeable ? 'Y' : 'N',
        Number(r.payment_terms_days ?? ''),
        r.primary_invoice_email || '',
        r.ap_phone || '',
        r.mileage_charge_rate != null ? String(r.mileage_charge_rate) : '',
        r.ts_queries_email || '',
        r.created_at || '',
        r.updated_at || ''
      ]));
    }
    return withCORS(env, req, ok({ csv: out.join('\n'), count: rows?.length || 0, page, page_size: pageSize }));
  }

  if (format === 'print') {
    const rowsHtml = (rows || []).map(r => `
      <tr>
        <td>${r.name || ''}</td>
        <td>${r.cli_ref || ''}</td>
        <td>${r.invoice_address || ''}</td>
        <td></td>
        <td>${r.vat_chargeable ? 'Y' : 'N'}</td>
        <td>${Number(r.payment_terms_days ?? '')}</td>
        <td>${r.primary_invoice_email || ''}</td>
        <td>${r.ap_phone || ''}</td>
        <td>${r.mileage_charge_rate != null ? String(r.mileage_charge_rate) : ''}</td>
        <td>${r.ts_queries_email || ''}</td>
        <td>${r.created_at || ''}</td>
        <td>${r.updated_at || ''}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Clients — Search Results</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5">
            <th>Name</th><th>Client Ref</th><th>Invoice Address</th><th>Postcode</th>
            <th>VAT Chargeable</th><th>Payment Terms (days)</th>
            <th>Primary Invoice Email</th><th>A/P Phone</th>
            <th>Mileage Charge Rate</th><th>TS Queries Email</th>
            <th>Created At</th><th>Updated At</th>
          </tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;
    return withCORS(env, req, ok({ html, count: rows?.length || 0, page, page_size: pageSize }));
  }

  return withCORS(env, req, ok({ rows, page, page_size: pageSize, count: rows?.length || 0 }));
}


// ───────────────────────────────────────────────────────────────────────────────
// SEARCH — Umbrellas (richer filters + csv/print)
// ───────────────────────────────────────────────────────────────────────────────
 async function handleSearchUmbrellas(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q = (k) => urlObj.searchParams.get(k);
  const page     = Math.max(1, parseInt(q('page') || '1', 10));
  const pageSize = Math.max(1, Math.min(200, parseInt(q('page_size') || '50', 10)));
  const format   = (q('format') || 'json').toLowerCase(); // 'json'|'csv'|'print'

  // Sorting
  const orderByParam = (q('order_by') || '').toLowerCase();
  const orderDirParam = (q('order_dir') || '').toLowerCase();

  const allowedSort = {
    name:           'name',
    enabled:        'enabled',
    vat_chargeable: 'vat_chargeable',
    bank_name:      'bank_name',
    sort_code:      'sort_code',
    account_number: 'account_number',
    created_at:     'created_at'
  };
  const defaultOrderCol = 'name';
  const orderCol = allowedSort[orderByParam] || defaultOrderCol;
  const orderDir = (orderDirParam === 'desc') ? 'desc' : 'asc';

  // explicit-ID selection support
  const idInExpr = q('id');    // 'in.(...)'
  const idsRaw   = q('ids');   // 'uuid1,uuid2,...'
  let idFilterExpr = null;
  if (idInExpr && /^in\.\(.+\)$/.test(idInExpr)) {
    idFilterExpr = idInExpr;
  } else if (idsRaw) {
    const list = idsRaw.split(',').map(s => s.trim()).filter(Boolean);
    if (list.length) idFilterExpr = `in.(${list.join(',')})`;
  }

  // Expanded filters to match FE
  const text          = q('q'); // name partial
  const bankName      = q('bank_name');
  const sortCode      = q('sort_code');
  const accountNo     = q('account_number');
  const enabled       = q('enabled');        // 'true'|'false'|null
  const vatChargeable = q('vat_chargeable'); // 'true'|'false'|null
  const createdFrom   = q('created_from');
  const createdTo     = q('created_to');

  let url = `${env.SUPABASE_URL}/rest/v1/umbrellas` +
            `?select=id,name,vat_chargeable,enabled,bank_name,sort_code,account_number,created_at` +
            `&order=${enc(orderCol)}.${orderDir}` +
            `&limit=${pageSize}&offset=${(page-1)*pageSize}`;

  if (idFilterExpr) url += `&id=${enc(idFilterExpr)}`;
  if (text)      url += `&name=ilike.*${enc(text)}*`;
  if (bankName)  url += `&bank_name=ilike.*${enc(bankName)}*`;
  if (sortCode)  url += `&sort_code=ilike.*${enc(sortCode)}*`;
  if (accountNo) url += `&account_number=ilike.*${enc(accountNo)}*`;
  if (enabled === 'true')  url += `&enabled=eq.true`;
  if (enabled === 'false') url += `&enabled=eq.false`;
  if (vatChargeable === 'true')  url += `&vat_chargeable=eq.true`;
  if (vatChargeable === 'false') url += `&vat_chargeable=eq.false`;
  if (createdFrom) url += `&created_at=gte.${enc(createdFrom)}`;
  if (createdTo)   url += `&created_at=lte.${enc(createdTo)}`;

  let rows = [];
  try {
    ({ rows } = await sbFetch(env, url));
  } catch (err) {
    return withCORS(env, req, ok({ error: String(err?.message || err), rows: [], page, page_size: pageSize, count: 0 }));
  }

  if (format === 'csv') {
    const header = ['UmbrellaId','Name','Enabled','VATChargeable','Bank','SortCode','AccountNumber','CreatedAt'];
    const out = [csvJoin(header)];
    for (const r of rows || []) {
      out.push(csvJoin([
        r.id,
        r.name || '',
        r.enabled ? 'Y' : 'N',
        r.vat_chargeable ? 'Y' : 'N',
        r.bank_name || '',
        r.sort_code || '',
        r.account_number || '',
        r.created_at || ''
      ]));
    }
    return withCORS(env, req, ok({ csv: out.join('\n'), count: rows?.length || 0, page, page_size: pageSize }));
  }

  if (format === 'print') {
    const rowsHtml = (rows || []).map(r => `
      <tr>
        <td>${r.name || ''}</td>
        <td>${r.enabled ? 'Y' : 'N'}</td>
        <td>${r.vat_chargeable ? 'Y' : 'N'}</td>
        <td>${r.bank_name || ''}</td>
        <td>${r.sort_code || ''}</td>
        <td>${r.account_number || ''}</td>
        <td>${r.created_at || ''}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Umbrellas — Search Results</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5">
            <th>Name</th><th>Enabled</th><th>VAT Chargeable</th>
            <th>Bank</th><th>Sort code</th><th>Account number</th><th>Created At</th>
          </tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;
    return withCORS(env, req, ok({ html, count: rows?.length || 0, page, page_size: pageSize }));
  }

  return withCORS(env, req, ok({ rows, page, page_size: pageSize, count: rows?.length || 0 }));
}



async function buildHealthRosterPdf(env, invoiceId) {
  // Placeholder implementation:
  //
  // In future this should:
  //  - Look up which HealthRoster import(s) and validation results apply
  //    to this invoice’s timesheets (by client/candidate/week),
  //  - Build a filtered HR report (only rows covering the shifts being invoiced),
  //  - Render that to a PDF (via browser / html → pdf or pre-generated),
  //  - Return a Uint8Array of the PDF bytes.
  //
  // For now we return null so nothing breaks and no HR attachment is added.
  try {
    // TODO: implement real HR PDF generation.
    return null;
  } catch {
    return null;
  }
}



// ───────────────────────────────────────────────────────────────────────────────
// REPORT PRESETS — Create / List / Update / Delete
// Table: report_presets (id, user_id, section, name, filters_json, is_default, is_shared, created_at, updated_at)
// ───────────────────────────────────────────────────────────────────────────────
// BACKEND — UPDATED
// handleReportPresetsList: default sort name.asc; include user join; mine first then shared.

 async function handleReportPresetsList(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    const urlObj = new URL(req.url);
    const q  = (k) => urlObj.searchParams.get(k);
    const page      = Math.max(1, parseInt(q('page') || '1', 10));
    const pageSize  = Math.max(1, Math.min(200, parseInt(q('page_size') || '50', 10)));
    const section   = q('section');
    const kind      = q('kind');
    const text      = q('q');
    const includeShared = q('include_shared') === 'true';
    const orderBy   = (q('order_by') || 'name').toLowerCase(); // created_at|name|updated_at
    const orderDir  = (q('order_dir') || 'asc').toLowerCase() === 'desc' ? 'desc' : 'asc';

    const orderAllowed = new Set(['created_at','name','updated_at']);
    const orderExpr = `&order=${orderAllowed.has(orderBy) ? enc(orderBy) : 'name'}.${orderDir}`;
    const pageExpr  = `&limit=${pageSize}&offset=${(page-1)*pageSize}`;

    // include selection_json so FE can save/load selections with filters
    const sel = `id,user_id,section,kind,name,filters_json,selection_json,is_default,is_shared,created_at,updated_at,` +
                `user:tms_users(id,display_name,email)`;

    // 1) My presets
    let urlMine = `${env.SUPABASE_URL}/rest/v1/report_presets` +
      `?select=${enc(sel)}` +
      `&user_id=eq.${enc(user.id)}`;
    if (section) urlMine += `&section=eq.${enc(section)}`;
    if (kind)    urlMine += `&kind=eq.${enc(kind)}`;
    if (text)    urlMine += `&name=ilike.*${enc(text)}*`;
    urlMine += orderExpr + pageExpr;

    const { rows: mine = [] } = await sbFetch(env, urlMine);

    // 2) Shared presets (not mine)
    let shared = [];
    if (includeShared) {
      let urlShared = `${env.SUPABASE_URL}/rest/v1/report_presets` +
        `?select=${enc(sel)}` +
        `&is_shared=eq.true` +
        `&user_id=neq.${enc(user.id)}`;
      if (section) urlShared += `&section=eq.${enc(section)}`;
      if (kind)    urlShared += `&kind=eq.${enc(kind)}`;
      if (text)    urlShared += `&name=ilike.*${enc(text)}*`;
      urlShared += orderExpr + pageExpr;
      const { rows } = await sbFetch(env, urlShared);
      shared = rows || [];
    }

    return withCORS(env, req, ok({
      rows: (mine || []).concat(shared || []),
      page, page_size: pageSize,
      count: (mine?.length || 0) + (shared?.length || 0)
    }));
  } catch (err) {
    return withCORS(env, req, serverError('Failed to list report presets'));
  }
}
 async function handleReportPresetsCreate(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    let body;
    try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

    const section   = (body?.section || '').trim();
    const name      = (body?.name || '').trim();
    const filters   = body?.filters || {};
    const selection = body?.selection; // may be undefined or an object
    const isDefault = !!body?.is_default;
    const isShared  = !!body?.is_shared;
    const kindRaw   = (body?.kind ?? 'search');
    const kind      = String(kindRaw).trim().toLowerCase();

    // ⬅️ include 'selection' kind
    const KIND_ALLOWED = new Set(['search','report','dashboard','selection']);

    if (!section) return withCORS(env, req, badRequest('section is required'));
    if (!name)    return withCORS(env, req, badRequest('name is required'));
    if (typeof filters !== 'object') return withCORS(env, req, badRequest('filters must be an object'));
    if (!KIND_ALLOWED.has(kind))     return withCORS(env, req, badRequest('kind must be one of search|report|dashboard|selection'));

    if (isDefault) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/report_presets` +
        `?user_id=eq.${enc(user.id)}` +
        `&section=eq.${enc(section)}` +
        `&kind=eq.${enc(kind)}` +
        `&is_default=eq.true`,
        { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return=minimal' }, body: JSON.stringify({ is_default: false }) }
      );
    }

    const payload = {
      user_id: user.id,
      section,
      kind,
      name,
      filters_json: filters,                          // for searches
      ...(typeof selection === 'object' ? { selection_json: selection } : {}), // for selections
      is_default: isDefault,
      is_shared: isShared
    };

    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/report_presets`,
      true,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify(payload)
      }
    );

    return withCORS(env, req, ok({ row: rows?.[0] || null }));
  } catch (err) {
    return withCORS(env, req, serverError('Failed to create report preset'));
  }
}

 async function handleReportPresetsUpdate(env, req, routeId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    const urlObj  = new URL(req.url);
    const qsId    = urlObj.searchParams.get('id');
    let body;
    try { body = await parseJSONBody(req); } catch { body = {}; }

    const id = routeId || qsId || body?.id;
    if (!id) return withCORS(env, req, badRequest('id is required'));

    const { rows: existingRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/report_presets?select=id,user_id,section,kind,is_default&id=eq.${enc(id)}`
    );
    const existing = existingRows?.[0];
    if (!existing) return withCORS(env, req, notFound('Preset not found'));
    if (existing.user_id !== user.id) return withCORS(env, req, unauthorized());

    // ⬅️ include 'selection' kind
    const KIND_ALLOWED = new Set(['search','report','dashboard','selection']);

    const patch = {};
    if (typeof body.name === 'string')    patch.name = body.name.trim();
    if (typeof body.section === 'string') patch.section = body.section.trim();
    if (body.filters && typeof body.filters === 'object') patch.filters_json = body.filters;

    // allow updating/clearing selection
    if ('selection' in body) {
      if (body.selection === null) patch.selection_json = null;
      else if (typeof body.selection === 'object') patch.selection_json = body.selection;
      else return withCORS(env, req, badRequest('selection must be an object or null'));
    }

    if (typeof body.is_shared === 'boolean')  patch.is_shared = body.is_shared;
    if (typeof body.is_default === 'boolean') patch.is_default = body.is_default;
    if (typeof body.kind === 'string') {
      const k = body.kind.trim().toLowerCase();
      if (!KIND_ALLOWED.has(k)) return withCORS(env, req, badRequest('kind must be one of search|report|dashboard|selection'));
      patch.kind = k;
    }

    if (patch.is_default === true) {
      const sectionEff = patch.section || existing.section;
      const kindEff    = patch.kind    || existing.kind;
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/report_presets` +
        `?user_id=eq.${enc(user.id)}` +
        `&section=eq.${enc(sectionEff)}` +
        `&kind=eq.${enc(kindEff)}` +
        `&is_default=eq.true` +
        `&id=neq.${enc(id)}`,
        { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return=minimal' }, body: JSON.stringify({ is_default: false }) }
      );
    }

    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/report_presets?id=eq.${enc(id)}`,
      true,
      { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return=representation' }, body: JSON.stringify(patch) }
    );

    return withCORS(env, req, ok({ row: rows?.[0] || null }));
  } catch (err) {
    return withCORS(env, req, serverError('Failed to update report preset'));
  }
}


 async function handleReportPresetsDelete(env, req, routeId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const qsId   = urlObj.searchParams.get('id'); // optional ?id=...

  // Prefer route param, then query
  const id = routeId || qsId;
  if (!id) return withCORS(env, req, badRequest('id is required'));

  // Ownership check
  const { rows: existingRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/report_presets?select=id,user_id&id=eq.${enc(id)}`
  );
  const existing = existingRows?.[0];
  if (!existing) return withCORS(env, req, notFound('Preset not found'));
  if (existing.user_id !== user.id) return withCORS(env, req, unauthorized());

  await fetch(
    `${env.SUPABASE_URL}/rest/v1/report_presets?id=eq.${enc(id)}`,
    { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return=minimal' } }
  );

  return withCORS(env, req, ok({ deleted_id: id }));
}
function buildHTML(payload) {
  const {
    header = {},
    meta: payloadMeta = {},
    invoice_no = "",
    issued_at_utc,
    due_at_utc,
    totals = { subtotal_ex_vat: 0, vat_amount: 0, total_inc_vat: 0 },
    items = [],
    reference_rows = []
  } = payload || {};

  // Snapshot fields (populated by your issuing worker)
  const clientName = pick(header, "client_name", "");
  const clientAddress = (pick(header, "client_invoice_address", "") || "")
    .split("\n")
    .map((l) => l.trim())
    .filter(Boolean);

  const vatChargeable = !!pick(header, "vat_chargeable", true);
  const appliedVatPct = Number(pick(header, "applied_vat_rate_pct", 0)); // NOTE: never displayed
  const termsDays = pick(header, "payment_terms_days", null);
  const bank = pick(header, "bank", {}) || {};

  // VAT reg: use settings value if present; otherwise fallback to hard-wired number
  const DEFAULT_VAT_REG = "363 6805 80";
  const vatReg = pick(header, "vat_registration_number", "") || DEFAULT_VAT_REG;

  // Stationery (letterhead) — expects PNG/JPG URL (signed) + safe-area margins (mm)
  const stationeryUrl = pick(header, "stationery_url", ""); // PNG/JPG URL or data: URI
  const defaultMargins = stationeryUrl
    ? { top: 32, right: 12, bottom: 20, left: 12 } // safe defaults with artwork
    : { top: 18, right: 12, bottom: 34, left: 12 }; // plain layout defaults
  const mgIn = pick(header, "stationery_margins_mm", {}) || {};
  const mg = {
    top: Number(pick(mgIn, "top", defaultMargins.top)),
    right: Number(pick(mgIn, "right", defaultMargins.right)),
    bottom: Number(pick(mgIn, "bottom", defaultMargins.bottom)),
    left: Number(pick(mgIn, "left", defaultMargins.left))
  };

  // Hide transactional footer if your artwork already includes it
  const hideBankFooter = !!pick(header, "hide_bank_footer", false);

  // Header-level PO only if a single unique PO exists across header + all items
  const headerPo = pick(header, "po_number", null);
  const itemPos = items.map((i) => i?.meta?.po_number).filter(Boolean);
  const uniquePos = Array.from(new Set([...(headerPo ? [headerPo] : []), ...itemPos]));
  const poNo = uniquePos.length === 1 ? uniquePos[0] : "";

  const showVatCols = vatChargeable && (appliedVatPct > 0 || Number(totals.vat_amount) > 0);

  // ─────────────────────────────────────────────────────────────
  // Helpers for breakdown rendering (keeps styling consistent)
  // ─────────────────────────────────────────────────────────────
  const num = (v) => {
    const n = Number(v);
    return Number.isFinite(n) ? n : 0;
  };
  const round2 = (v) => Math.round(num(v) * 100) / 100;
  const fmtQty = (v, decimals = 2) => {
    const n = num(v);
    if (Math.abs(n - Math.round(n)) < 1e-9) return String(Math.round(n));
    return n.toFixed(decimals);
  };
  const eqRate = (a, b) => {
    // Compare to 2dp to avoid tiny float drift; rates are normally stored as numeric
    return round2(a) === round2(b);
  };

 const getLineTypeNorm = (it) => {
  const m = it?.meta || {};
  const s = String(m.line_type_norm || m.line_type || "").toUpperCase();
  return s;
};

const isHoursLineType = (t) => {
  const s = String(t || "").toUpperCase();
  return (s === "HOURS" || s.startsWith("HOURS_"));
};


  const getTimesheetId = (it) => {
    return (it && it.timesheet_id != null) ? String(it.timesheet_id)
      : (it?.meta?.timesheet_id != null ? String(it.meta.timesheet_id) : null);
  };

  const isAdjustmentItem = (it) => {
    const t = getLineTypeNorm(it);
    const tsId = getTimesheetId(it);
    return (!tsId || t === "ADJUSTMENT");
  };

  // Labels (use per-line labels if provided; fallback to defaults)
  const DEFAULT_LABELS = { day: "Day", night: "Night", sat: "Sat", sun: "Sun", bh: "BH" };
  const bucketLabelOf = (labels, key) => String((labels && labels[key]) || DEFAULT_LABELS[key] || key);

  // ─────────────────────────────────────────────────────────────
  // Group items by timesheet_id, keep adjustments separate
  // ─────────────────────────────────────────────────────────────
  const groupMap = new Map(); // tsId -> { items: [], metaHint: {} }
  const adjustments = [];

  for (const it of (items || [])) {
    if (isAdjustmentItem(it)) {
      adjustments.push(it);
      continue;
    }
    const tsId = getTimesheetId(it);
    if (!tsId) {
      adjustments.push(it);
      continue;
    }
    if (!groupMap.has(tsId)) groupMap.set(tsId, { tsId, items: [] });
    groupMap.get(tsId).items.push(it);
  }

  // Sort groups deterministically by week ending then candidate
 const groups = Array.from(groupMap.values()).sort((a, b) => {
  const aMeta = (a.items.find(x => isHoursLineType(getLineTypeNorm(x)))?.meta) || a.items[0]?.meta || {};
  const bMeta = (b.items.find(x => isHoursLineType(getLineTypeNorm(x)))?.meta) || b.items[0]?.meta || {};
  const awe = String(aMeta.week_ending_date || aMeta.week_ending || aMeta.weekEnding || "");
  const bwe = String(bMeta.week_ending_date || bMeta.week_ending || bMeta.weekEnding || "");
  if (awe !== bwe) return awe < bwe ? 1 : -1; // desc
  const ac = String(aMeta.candidate_display || aMeta.candidate || "");
  const bc = String(bMeta.candidate_display || bMeta.candidate || "");
  if (ac !== bc) return ac.localeCompare(bc);
  return String(a.tsId).localeCompare(String(b.tsId));
});


  // ─────────────────────────────────────────────────────────────
  // Build breakdown rows for a single timesheet group
  // Unit Description | Quantity | Unit Charge (ex VAT) | Charge (ex VAT)
  // ─────────────────────────────────────────────────────────────
 const groupBreakdownTableHtml = (grp) => {
  const its = grp.items || [];
  const hoursItem = its.find((x) => isHoursLineType(getLineTypeNorm(x))) || null;
// meta for display/header
  const metaBase = (hoursItem?.meta || its[0]?.meta || {}) || {};
  const labels = (metaBase.bucket_labels && typeof metaBase.bucket_labels === "object") ? metaBase.bucket_labels : DEFAULT_LABELS;
    // Pull bucket hours/rates from meta (these are merged by _renderInvoiceBundleAndStore)
    const hDay = num(metaBase.hours_day);
    const hNgt = num(metaBase.hours_night);
    const hSat = num(metaBase.hours_sat);
    const hSun = num(metaBase.hours_sun);
    const hBh  = num(metaBase.hours_bh);

    const rDay = num(metaBase.charge_day);
    const rNgt = num(metaBase.charge_night);
    const rSat = num(metaBase.charge_sat);
    const rSun = num(metaBase.charge_sun);
    const rBh  = num(metaBase.charge_bh);

    const groupFlag = !!pick(payloadMeta, "group_nightsat_sunbh", false);
    const canMerge = groupFlag && eqRate(rNgt, rSat) && eqRate(rSun, rBh);

    const rows = [];

    const pushRow = (desc, qty, unit, charge) => {
      const q = num(qty);
      const u = num(unit);
      const c = round2(charge);
      // Requirement: hide zero-subtotal rows, but show positive and negative rows.
      if (c === 0) return;
      rows.push({ desc: String(desc || ""), qty: q, unit: u, charge: c });
    };

    // HOURS breakdown
    if (hoursItem) {
      if (canMerge) {
        const nightSatQty = hNgt + hSat;
        const sunBhQty = hSun + hBh;
        pushRow(bucketLabelOf(labels, "day"), hDay, rDay, hDay * rDay);
        pushRow(`${bucketLabelOf(labels, "night")}/${bucketLabelOf(labels, "sat")}`, nightSatQty, rNgt, nightSatQty * rNgt);
        pushRow(`${bucketLabelOf(labels, "sun")}/${bucketLabelOf(labels, "bh")}`, sunBhQty, rSun, sunBhQty * rSun);
      } else {
        pushRow(bucketLabelOf(labels, "day"), hDay, rDay, hDay * rDay);
        pushRow(bucketLabelOf(labels, "night"), hNgt, rNgt, hNgt * rNgt);
        pushRow(bucketLabelOf(labels, "sat"), hSat, rSat, hSat * rSat);
        pushRow(bucketLabelOf(labels, "sun"), hSun, rSun, hSun * rSun);
        pushRow(bucketLabelOf(labels, "bh"), hBh, rBh, hBh * rBh);
      }
    }
// Additional rates / mileage / expenses (non-hours)
  for (const it of its) {
    const t = getLineTypeNorm(it);
    if (isHoursLineType(t)) continue;
    if (t === "ADJUSTMENT") continue;

      const m = it.meta || {};
      const totalEx = num(it.total_ex_vat);

      // Default label (keep the human-friendly SQL-generated description where available)
      const unitLabel = String(m.unit_label || it.description || t || "").trim() || t;

      let qty = null;
      let unitCharge = null;

      // Mileage (miles + rate)
      if (t === "MILEAGE") {
        if (m?.mileage && m.mileage.mileage_units != null) qty = num(m.mileage.mileage_units);
        else if (m.mileage_units != null) qty = num(m.mileage_units);
        else if (m.qty != null) qty = num(m.qty);

        if (m?.mileage && m.mileage.charge_rate != null) unitCharge = num(m.mileage.charge_rate);
        else if (m.unit_charge_ex_vat != null) unitCharge = num(m.unit_charge_ex_vat);
      }

      // Additional units/rates
      else if (t.startsWith("ADDITIONAL_RATE")) {
        if (m?.units && m.units.unit_count != null) qty = num(m.units.unit_count);
        else if (m.unit_count != null) qty = num(m.unit_count);
        else if (m.qty != null) qty = num(m.qty);

        if (m?.units && m.units.charge_rate != null) unitCharge = num(m.units.charge_rate);
        else if (m.unit_charge_ex_vat != null) unitCharge = num(m.unit_charge_ex_vat);
      }

      // Expenses (travel / accommodation / other etc.)
      else if (t.startsWith("EXPENSE")) {
        qty = (m.qty != null) ? num(m.qty) : 1;
        unitCharge = (m.unit_charge_ex_vat != null)
          ? num(m.unit_charge_ex_vat)
          : (qty !== 0 ? totalEx / qty : totalEx);
      }

      // Generic fallback
      else {
        qty = (m.qty != null) ? num(m.qty) : 1;
        unitCharge = (m.unit_charge_ex_vat != null)
          ? num(m.unit_charge_ex_vat)
          : (qty !== 0 ? totalEx / qty : totalEx);
      }

      if (qty == null) qty = 1;

      // Requirement: skip zero-qty rows (but DO show negative qty/charges)
      if (round2(qty) === 0) continue;

      if (unitCharge == null) {
        unitCharge = (qty !== 0) ? (totalEx / qty) : totalEx;
      }

      pushRow(unitLabel, qty, unitCharge, totalEx);
    }

    if (!rows.length) return "";

    const head = `
      <table class="breakdown">
        <thead>
          <tr>
            <th class="b-desc">Unit Description</th>
            <th class="b-qty">Quantity</th>
            <th class="b-unit">Unit Charge (ex VAT)</th>
            <th class="b-charge">Charge (ex VAT)</th>
          </tr>
        </thead>
        <tbody>
    `;

    const body = rows.map(r => `
      <tr>
        <td class="b-desc">${escapeHtml(r.desc)}</td>
        <td class="b-qty mono">${fmtQty(r.qty, 2)}</td>
        <td class="b-unit mono">${fmtGBP(r.unit)}</td>
        <td class="b-charge mono">${fmtGBP(r.charge)}</td>
      </tr>
    `).join("");

    const tail = `
        </tbody>
      </table>
    `;

    return head + body + tail;
  };

  // ─────────────────────────────────────────────────────────────

  // ─────────────────────────────────────────────────────────────
  // Booking reference rows (manifest.reference_rows)
  // Rendered under each timesheet group (never show timesheet_id)
  // ─────────────────────────────────────────────────────────────
  const refsByTsId = new Map();
  for (const r of (reference_rows || [])) {
    const tsId = (r && r.timesheet_id != null) ? String(r.timesheet_id) : null;
    if (!tsId) continue;
    if (!refsByTsId.has(tsId)) refsByTsId.set(tsId, []);
    refsByTsId.get(tsId).push(r);
  }

  const refsTableHtmlForTs = (tsId) => {
    const refs = refsByTsId.get(String(tsId || "")) || [];
    if (!refs.length) return "";

    const rowsHtml = refs.map((r) => {
      const day = r?.day_ymd ? fmtDateGB(r.day_ymd) : "";
      const st = r?.start_utc ? fmtUKTime(r.start_utc) : "";
      const en = r?.end_utc ? fmtUKTime(r.end_utc) : "";

      const hasRef = (r?.current_reference != null) && String(r.current_reference).trim();
      const refTxt = hasRef ? String(r.current_reference).trim() : (r?.is_required ? "MISSING" : "—");
      const refCls = (!hasRef && r?.is_required) ? "ref-missing" : "";

      return `
        <tr>
          <td class="r-day mono">${escapeHtml(day)}</td>
          <td class="r-time mono">${escapeHtml(st)}</td>
          <td class="r-time mono">${escapeHtml(en)}</td>
          <td class="r-ref mono ${refCls}">${escapeHtml(refTxt)}</td>
        </tr>
      `;
    }).join("");

    return `
      <div class="refs-wrap">
        <div class="refs-title">Booking references</div>
        <table class="refs">
          <thead>
            <tr>
              <th class="r-day">Day</th>
              <th class="r-time">Start</th>
              <th class="r-time">End</th>
              <th class="r-ref">Reference</th>
            </tr>
          </thead>
          <tbody>
            ${rowsHtml}
          </tbody>
        </table>
      </div>
    `;
  };

  // Build main table rows:
  // - One row per timesheet group (with nested breakdown table)
  // - Optional adjustments section at the end
  // ─────────────────────────────────────────────────────────────
  const groupRowsHtml = groups.map((grp, idx) => {
    const its = grp.items || [];
    const metaFirst = (its.find(x => getLineTypeNorm(x) === "HOURS")?.meta) || its[0]?.meta || {};
    const we = metaFirst.week_ending_date || metaFirst.week_ending || metaFirst.weekEnding || null;

    const sublineParts = [
      metaFirst.candidate_display || metaFirst.candidate || null,
      metaFirst.role || metaFirst.job_title || null,
      metaFirst.hospital || metaFirst.hospital_norm || null,
      metaFirst.ward || metaFirst.ward_norm || null,
      we ? `W/E ${fmtDateGB(we)}` : null,
      metaFirst.po_number ? `PO ${metaFirst.po_number}` : null
    ].filter(Boolean).join(" • ");

    const grpEx = round2(its.reduce((a, it) => a + num(it.total_ex_vat), 0));
    const grpVat = round2(its.reduce((a, it) => a + num(it.vat_amount), 0));
    const grpInc = round2(its.reduce((a, it) => a + num(it.total_inc_vat), 0));

    const title = escapeHtml(metaFirst.candidate_display || metaFirst.candidate || `Timesheet ${idx + 1}`);
    const breakdown = groupBreakdownTableHtml(grp);
    const refsHtml = refsTableHtmlForTs(grp.tsId);

    return `
      <tr class="line">
        <td class="desc">
          <div class="desc-title">${title}</div>
          <div class="desc-meta">
            ${escapeHtml(sublineParts)}
            ${breakdown ? `<div class="breakdown-wrap">${breakdown}</div>` : ""}
            ${refsHtml || ""}
          </div>
        </td>
        <td class="money exvat">${fmtGBP(grpEx)}</td>
        ${showVatCols ? `<td class="money vat">${fmtGBP(grpVat)}</td>` : ""}
        <td class="money totalinc">${fmtGBP(grpInc)}</td>
      </tr>
    `;
  }).join("");

  const adjustmentsRowsHtml = (adjustments && adjustments.length)
    ? (() => {
        const head = `
          <tr class="section-row">
            <td class="desc" colspan="${showVatCols ? 4 : 3}">
              <div class="section-title">Adjustments</div>
            </td>
          </tr>
        `;

        const rows = adjustments.map((it, idx) => {
          const meta = it.meta || {};
          const desc = escapeHtml(it.description || meta.unit_label || `Adjustment ${idx + 1}`);
          const sub = [
            meta.po_number ? `PO ${meta.po_number}` : null
          ].filter(Boolean).join(" • ");

          return `
            <tr class="line">
              <td class="desc">
                <div class="desc-title">${desc}</div>
                ${sub ? `<div class="desc-meta">${escapeHtml(sub)}</div>` : ""}
              </td>
              <td class="money exvat">${fmtGBP(it.total_ex_vat)}</td>
              ${showVatCols ? `<td class="money vat">${fmtGBP(it.vat_amount)}</td>` : ""}
              <td class="money totalinc">${fmtGBP(it.total_inc_vat)}</td>
            </tr>
          `;
        }).join("");

        return head + rows;
      })()
    : "";

  const lineRows = (groupRowsHtml || adjustmentsRowsHtml)
    ? (groupRowsHtml + adjustmentsRowsHtml)
    : "";

  // Build full HTML (stationery background + reserved margins + fixed footer)
  return `<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Invoice ${escapeHtml(invoice_no || "")}</title>
  <style>
    /* Reserve safe areas so content never overlaps header/footer artwork */
    @page { size: A4; margin: ${mg.top}mm ${mg.right}mm ${mg.bottom}mm ${mg.left}mm; }

    html, body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif;
      color: #111;
      font-size: 11px; /* fixed size per spec */
      line-height: 1.35;
      -webkit-print-color-adjust: exact;
    }

    /* Stationery (full page) */
    .stationery {
      position: fixed;
      inset: 0;
      z-index: 0;
      background-repeat: no-repeat;
      background-position: center;
      background-size: cover; /* A4 PNG should fill edge-to-edge */
      opacity: 1;
      pointer-events: none;
    }

    .wrap { position: relative; z-index: 1; width: 100%; }

    .header {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 16px;
      margin-bottom: 16px;
    }
    .title { font-size: 20px; font-weight: 700; letter-spacing: .5px; }
    .muted { color: #666; }
    .mono { font-variant-numeric: tabular-nums; }
    .panel { border: 1px solid #e5e7eb; border-radius: 8px; padding: 10px; }
    .billto-title { font-weight: 600; margin-bottom: 4px; }
    .billto { white-space: pre-wrap; }

    .meta-table { width: 100%; border-collapse: collapse; }
    .meta-table th { text-align: left; font-weight: 600; padding: 0 0 2px 0; }
    .meta-table td { padding: 2px 0; }

    .lines {
      width: 100%;
      border-collapse: collapse;
      border: 1px solid #e5e7eb;
      border-radius: 10px;
      overflow: hidden;
    }
    .lines thead th {
      background: #f9fafb;
      padding: 8px 10px;
      text-align: left;
      font-weight: 600;
    }
    .lines th, .lines td {
      border: 1px solid #e5e7eb;  /* full grid */
      padding: 8px 10px;
      vertical-align: top;
    }
    .lines thead th.money, .lines td.money { text-align: right; }
    .desc-title { font-weight: 600; margin-bottom: 2px; }
    .desc-meta { color: #555; }
    .money { font-variant-numeric: tabular-nums; }

    .lines tfoot td { background: #fcfcfd; font-weight: 600; }
    .lines tfoot .label { text-align: right; color: #333; font-weight: 600; }

    /* New: neat nested breakdown table (keeps existing styling palette) */
    .breakdown-wrap { margin-top: 6px; }
    table.breakdown {
      width: 100%;
      border-collapse: collapse;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      overflow: hidden;
      font-size: 10px;
      background: #fff;
    }
    table.breakdown th, table.breakdown td {
      border: 1px solid #e5e7eb;
      padding: 6px 8px;
      vertical-align: top;
    }
    table.breakdown thead th {
      background: #f9fafb;
      font-weight: 600;
      text-align: left;
    }
    table.breakdown .b-qty,
    table.breakdown .b-unit,
    table.breakdown .b-charge { text-align: right; white-space: nowrap; }
    table.breakdown .b-desc { text-align: left; }

    /* Booking references table */
    .refs-wrap { margin-top: 6px; }
    .refs-title { font-weight: 600; margin: 2px 0 4px; color: #333; }
    table.refs {
      width: 100%;
      border-collapse: collapse;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      overflow: hidden;
      font-size: 10px;
      background: #fff;
    }
    table.refs th, table.refs td {
      border: 1px solid #e5e7eb;
      padding: 6px 8px;
      vertical-align: top;
    }
    table.refs thead th {
      background: #f9fafb;
      font-weight: 600;
      text-align: left;
    }
    table.refs .r-day { width: 90px; white-space: nowrap; }
    table.refs .r-time { width: 60px; white-space: nowrap; text-align: right; }
    table.refs .r-ref { text-align: left; }
    table.refs td.r-time { text-align: right; }
    .ref-missing { color: #b91c1c; font-weight: 700; }

    /* New: adjustments section header */
    .section-row td {
      background: #f9fafb;
      border-left: 1px solid #e5e7eb;
      border-right: 1px solid #e5e7eb;
    }
    .section-title { font-weight: 700; color: #333; }

    /* Transactional footer pinned above bottom margin */
    .footer {
      position: fixed;
      left: ${mg.left}mm; right: ${mg.right}mm; bottom: ${mg.bottom}mm;
      font-size: 10px; color: #333;
      display: ${hideBankFooter ? "none" : "grid"};
      grid-template-columns: 2fr 1fr; gap: 12px;
    }
    .right { text-align: right; }
  </style>
</head>
<body>
  ${stationeryUrl ? `<div class="stationery" style="background-image:url('${escapeUrl(stationeryUrl)}');"></div>` : ""}

  <div class="wrap">
    <div class="header">
      <div>
        <div class="title">INVOICE ${invoice_no ? `<span class="muted mono">#${escapeHtml(invoice_no)}</span>` : ""}</div>
        <div class="panel" style="margin-top:8px;">
          <div class="billto-title">Bill To</div>
          <div class="billto"><b>${escapeHtml(clientName)}</b>${clientAddress.length ? `<br>${clientAddress.map(escapeHtml).join("<br>")}` : ""}</div>
        </div>
      </div>
      <div class="panel">
        <table class="meta-table">
          <tr><th>Issue date</th><td class="mono">${fmtDateGB(issued_at_utc)}</td></tr>
          <tr><th>Due date</th><td class="mono">${fmtDateGB(due_at_utc)}</td></tr>
          ${termsDays != null ? `<tr><th>Payment terms</th><td class="mono">${termsDays} days</td></tr>` : ""}
          ${poNo ? `<tr><th>PO Number</th><td class="mono">${escapeHtml(poNo)}</td></tr>` : ""}
          <!-- VAT % intentionally NOT displayed -->
        </table>
      </div>
    </div>

    <table class="lines">
      <thead>
        <tr>
          <th>Description</th>
          <th class="money">Ex VAT</th>
          ${showVatCols ? `<th class="money">VAT</th>` : ""}
          <th class="money">Total</th>
        </tr>
      </thead>
      <tbody>
        ${lineRows || `<tr><td colspan="${showVatCols ? 4 : 3}">No lines.</td></tr>`}
      </tbody>
      <tfoot>
        <tr>
          <td class="label">Subtotal (ex VAT)</td>
          <td class="money mono">${fmtGBP(totals.subtotal_ex_vat)}</td>
          ${showVatCols ? `<td></td>` : ""}
          <td></td>
        </tr>
        ${showVatCols ? `
        <tr>
          <td class="label">VAT</td>
          <td></td>
          <td class="money mono">${fmtGBP(totals.vat_amount)}</td>
          <td></td>
        </tr>` : ""}
        <tr>
          <td class="label"><b>Total due</b></td>
          <td></td>
          ${showVatCols ? `<td></td>` : ""}
          <td class="money mono"><b>${fmtGBP(totals.total_inc_vat)}</b></td>
        </tr>
      </tfoot>
    </table>
  </div>

  <div class="footer">
    <div>
      <div><b>BACS Payment Details</b></div>
      <div>Banker: <span class="mono">${escapeHtml(pick(bank, "name", ""))}</span></div>
      <div>Sort Code: <span class="mono">${escapeHtml(pick(bank, "sort_code", ""))}</span> &nbsp;&nbsp; Account No.: <span class="mono">${escapeHtml(pick(bank, "account_number", ""))}</span></div>
    </div>
    <div class="right">
      ${vatReg ? `<div>VAT Reg: <b class="mono">${escapeHtml(vatReg)}</b></div>` : ""}
    </div>
  </div>
</body>
</html>`;
}



/*
  Email Outbox Broker – queue + drain + provider integration (Power Automate)
  ---------------------------------------------------------------------------
  Drop this file into your Worker codebase (or merge the functions into your existing
  handler module). It uses your existing helper utilities and DB conventions.

  Assumptions / dependencies already present in your codebase (as seen in snippets):
    - requireUser(env, req, roles?) -> returns user or null
    - withCORS(env, req, response)
    - ok/json helpers: ok(data), badRequest(msg), unauthorized(), notFound(msg), serverError(msg)
    - sbHeaders(env) -> { 'apikey': ..., 'Authorization': 'Bearer ...', 'Content-Type': 'application/json' }
    - sbFetch(env, url, single = false, init?) -> { rows } JSON wrapper for Supabase REST
    - writeAudit(env, user, action, afterJson, opts) -> writes audit_events
    - handleInvoiceRender(env, req, invoiceId) -> returns Response JSON { pdf_url }

  New ed handlers in this module:
    - handleOutboxDrain
    - handleEmailSend
    - handleQueueTsoFailureEmail
    - handleOutboxRetry
    - handleListOutbox
    - handleGetOutboxItem
    - handleOutboxMarkSent
    - handleOutboxMarkFailed

  Helpers (pure logic or provider-facing):
    - drainEmailOutboxOnce
    - buildEmailPayloadFromOutboxRow
    - postToPowerAutomate
    - fetchAttachmentBase64FromR2
    - limitOrLinkAttachments
    - normalizeEmailPayload, validateEmailPayload, estimatePayloadSizeBytes
    - resolveTsoRecipientForTimesheet
    - recordEmailAudit (thin wrapper over writeAudit)
    - signDownloadUrlForR2Key

  Revised functions from your snippets:
    - handleRemittanceEmailForCandidate (queues REMITTANCE table row)
    - handleInvoiceEmail (queues INVOICE row; ensures PDF exists; audit)

  Router wiring helper:
    - wireEmailRoutes(router)

  Scheduled drain (optional):
    - scheduled(event, env, ctx) example at bottom – call drainEmailOutboxOnce periodically.
*/

// ------------------------------
// Config knobs (override via env if you like)
// ------------------------------
const DEFAULT_DRAIN_LIMIT = 10;                 // how many queued rows to pick per drain
const EMAIL_MAX_PAYLOAD_BYTES = 18 * 1024 * 1024; // 18MB safety cap before trimming/links
const SIGNED_LINK_TTL_SECS = 7 * 24 * 60 * 60;  // 7 days

// ------------------------------
// Small utilities
// ------------------------------

// best-effort byte size estimate for JSON payload
function estimatePayloadSizeBytes(obj) {
  try {
    return new TextEncoder().encode(JSON.stringify(obj)).byteLength;
  } catch {
    return 0;
  }
}

function isNonEmptyString(x) {
  return typeof x === 'string' && x.trim().length > 0;
}

function toArray(x) {
  if (!x) return [];
  if (Array.isArray(x)) return x;
  return [x];
}

function splitCsvMaybe(s) {
  if (!isNonEmptyString(s)) return [];
  return s.split(',').map((p) => p.trim()).filter(Boolean);
}

// robust base64 from ArrayBuffer for Workers (avoid large String.fromCharCode spread)
function base64FromArrayBuffer(buf) {
  let binary = '';
  const bytes = new Uint8Array(buf);
  const chunk = 0x8000;
  for (let i = 0; i < bytes.length; i += chunk) {
    binary += String.fromCharCode(...bytes.subarray(i, i + chunk));
  }
  return btoa(binary);
}

// ------------------------------
// Provider integration (Power Automate)
// ------------------------------
async function postToPowerAutomate(env, payload) {
  // Primary source: settings_defaults.finance_email_settings.webhook_url (cached via loadSettingsDefaults)
  let url = null;
  let extraHeaders = null;

  try {
    const s = await loadSettingsDefaults(env);
    const fes = s?.finance_email_settings;
    if (fes && typeof fes === 'object') {
      const u = (typeof fes.webhook_url === 'string') ? fes.webhook_url.trim() : '';
      if (u) url = u;

      // optional: allow a headers object (e.g. future auth headers)
      if (fes.headers && typeof fes.headers === 'object') extraHeaders = fes.headers;
    }
  } catch {}

  // Fallback: env
  if (!url) url = env.POWER_AUTOMATE_EMAIL_WEBHOOK_URL;

  if (!isNonEmptyString(url)) {
    return { ok: false, status: 0, body: 'Power Automate webhook URL not configured (settings_defaults.finance_email_settings.webhook_url or env.POWER_AUTOMATE_EMAIL_WEBHOOK_URL)' };
  }

  const headers = { 'Content-Type': 'application/json' };
  if (extraHeaders && typeof extraHeaders === 'object') {
    for (const [k, v] of Object.entries(extraHeaders)) {
      if (typeof k === 'string' && k.trim() && v != null) headers[k] = String(v);
    }
  }

  const res = await fetch(url, {
    method: 'POST',
    headers,
    body: JSON.stringify(payload),
  });

  let body;
  try { body = await res.text(); } catch { body = ''; }

  const ok = res.ok;

  let provider_message_id = undefined;
  try {
    const j = JSON.parse(body);
    provider_message_id = j.provider_message_id || j.id || j.messageId || undefined;
  } catch {}

  return { ok, status: res.status, body, provider_message_id };
}

// ------------------------------
// Attachments
// ------------------------------
async function fetchAttachmentBase64FromR2(env, r2Key) {
  // Try common binding names – adjust if your binding name differs.
  const bucket = env.DOCS_BUCKET || env.R2 || env.R2_BUCKET || env.FILES_BUCKET;
  if (!bucket || typeof bucket.get !== 'function') {
    throw new Error('R2 binding not available on env (expected DOCS_BUCKET or R2)');
  }
  const obj = await bucket.get(r2Key);
  if (!obj) throw new Error(`R2 object not found for key: ${r2Key}`);
  const arrBuf = await obj.arrayBuffer();
  const base64 = base64FromArrayBuffer(arrBuf);
  // if the filename is not known here, caller should supply display name
  return base64;
}

function normalizeEmailPayload(raw) {
  const to = Array.isArray(raw.to) ? raw.to : splitCsvMaybe(raw.to);
  const cc = Array.isArray(raw.cc) ? raw.cc : splitCsvMaybe(raw.cc);
  const bcc = Array.isArray(raw.bcc) ? raw.bcc : splitCsvMaybe(raw.bcc);
  const replyTo = Array.isArray(raw.replyTo) ? raw.replyTo : splitCsvMaybe(raw.replyTo);

  const html = raw.html || raw.body_html || undefined;
  const text = raw.text || raw.body_text || undefined;

  let attachments = [];
  // Support two shapes:
  //  1) legacy: [{ r2_key, filename }]
  //  2) direct: [{ name, contentBase64 }]
  for (const a of toArray(raw.attachments)) {
    if (!a) continue;
    if (a.contentBase64 && a.name) {
      attachments.push({ name: String(a.name), contentBase64: String(a.contentBase64) });
    } else if (a.r2_key) {
      attachments.push({ r2_key: String(a.r2_key), name: a.filename || 'attachment' });
    }
  }

  return { to, cc, bcc, replyTo, subject: raw.subject, html, text, attachments, reference: raw.reference };
}



function validateEmailPayload(p) {
  if (!Array.isArray(p.to) || p.to.length === 0) return 'Missing recipient(s)';
  if (!isNonEmptyString(p.subject)) return 'Missing subject';
  if (!isNonEmptyString(p.html) && !isNonEmptyString(p.text)) return 'Missing html/text body';
  return null;
}

async function buildEmailPayloadFromOutboxRow(env, outboxRow) {
  const base = normalizeEmailPayload({
    to: outboxRow.to,
    cc: outboxRow.cc,
    subject: outboxRow.subject,
    body_html: outboxRow.body_html,
    body_text: outboxRow.body_text,
    attachments: outboxRow.attachments,
    reference: outboxRow.reference,
  });

  const err = validateEmailPayload(base);
  if (err) throw new Error(err);

  // Pull finance sender config (for invoices/remittances)
  let financeEmail = null;
  try {
    const s = await loadSettingsDefaults(env);
    financeEmail = (typeof s?.finance_email === 'string') ? s.finance_email.trim() : null;
  } catch {}

  // Resolve attachments:
  // - { contentBase64, name } -> pass-through
  // - { r2_key, name } -> fetch bytes from R2
  // - { invoice_id, filename } -> ensureInvoicePdf -> fetch from R2
  const resolved = [];

  for (const a of base.attachments) {
    if (!a) continue;

    if (a.contentBase64 && a.name) {
      resolved.push(a);
      continue;
    }

    // invoice placeholder
    if (a.invoice_id) {
      const invId = String(a.invoice_id).trim();
      if (!invId) throw new Error('Invalid invoice_id attachment');

      // Ensure PDF exists (internal helper, no HTTP)
      const ensured = await ensureInvoicePdf(env, invId, { req: outboxRow?._req || undefined, user: null });
      if (!ensured?.ok || !ensured.invoice_pdf_r2_key) {
        throw new Error(`PDF_NOT_READY: invoice ${invId}`);
      }

      const key = String(ensured.invoice_pdf_r2_key).trim();
      const contentBase64 = await fetchAttachmentBase64FromR2(env, key);
      resolved.push({ name: a.filename || a.name || `Invoice_${invId}.pdf`, contentBase64 });
      continue;
    }

    // r2_key attachment
    if (a.r2_key) {
      const key = String(a.r2_key).trim();
      if (!key) throw new Error('Invalid r2_key attachment');

      const contentBase64 = await fetchAttachmentBase64FromR2(env, key);
      resolved.push({ name: a.name || a.filename || 'attachment', contentBase64 });
      continue;
    }
  }

  // Compose canonical payload expected by the Flow
  let payload = {
    to: base.to,
    cc: base.cc,
    bcc: base.bcc,
    replyTo: base.replyTo,
    subject: base.subject,
    html: base.html,
    text: base.text,
    attachments: resolved,
    reference: base.reference,
    meta: {
      type: outboxRow.type,
      outbox_id: outboxRow.id,
      // finance emails use the finance mailbox (Flow can use this if configured)
      fromMailbox: (outboxRow.type === 'INVOICE' || outboxRow.type === 'REMITTANCE') ? (financeEmail || null) : null
    }
  };

  // Trim or link heavy payloads (kept)
  const sized = await limitOrLinkAttachments(env, payload);
  return sized.payload;
}


async function limitOrLinkAttachments(env, payload) {
  const limitBytes = Number(env.EMAIL_MAX_PAYLOAD_BYTES) || EMAIL_MAX_PAYLOAD_BYTES;
  let currentBytes = estimatePayloadSizeBytes(payload);
  if (currentBytes <= limitBytes) return { payload, trimmed: false };

  // Prefer to keep a PDF invoice if present, trim the rest and inject links.
  const kept = [];
  const trimmed = [];
  for (const a of payload.attachments) {
    const isInvoice = /invoice/i.test(a.name || '') && /\.pdf$/i.test(a.name || '');
    if (isInvoice && kept.length === 0) { kept.push(a); } else { trimmed.push(a); }
  }
  if (kept.length === 0 && payload.attachments.length > 0) {
    // keep the first as a compromise
    kept.push(payload.attachments[0]);
    trimmed.splice(0, 1);
  }

  let linksHtml = '';
  let linksText = '';

  // If original attachments came from R2 we may have lost their original keys.
  // Encourage callers to include `r2_key` in attachments for graceful linking.
  for (const a of trimmed) {
    const key = a.r2_key || (a.meta && a.meta.r2_key) || null;
    if (!key) continue;
    const url = await signDownloadUrlForR2Key(env, key, { ttlSecs: SIGNED_LINK_TTL_SECS });
    linksHtml += `<li><a href="${url}">${a.name || key}</a></li>`;
    linksText += `\n- ${a.name || key}: ${url}`;
  }

  let html = payload.html || '';
  let text = payload.text || '';

  if (linksHtml) {
    html += `\n<hr/><p>Some large attachments were replaced with links:</p><ul>${linksHtml}</ul>`;
  }
  if (linksText) {
    text += `\n\nSome large attachments were replaced with links:${linksText}`;
  }

  const newPayload = { ...payload, attachments: kept, html, text };
  return { payload: newPayload, trimmed: true };
}

async function signDownloadUrlForR2Key(env, r2Key, { ttlSecs }) {
  // If you already expose a download endpoint like /files?key=...
  // prefer to sign that instead of S3-style presign here.
  // Configure env.PUBLIC_DOWNLOAD_BASE_URL to your existing endpoint.
  const base = env.PUBLIC_DOWNLOAD_BASE_URL;
  if (isNonEmptyString(base)) {
    const u = new URL(base);
    u.searchParams.set('key', r2Key);
    u.searchParams.set('exp', String(Math.floor(Date.now() / 1000) + ttlSecs));
    // Optionally: include a dummy HMAC if you already verify it your side
    return u.toString();
  }
  // Fallback: return plain key token – your Flow can resolve it.
  return `r2://${r2Key}`;
}

// ------------------------------
// Queue drain logic
// ------------------------------
async function drainEmailOutboxOnce(env, { limit, types } = {}) {
  const take = Math.max(1, Math.min(Number(limit) || Number(env.EMAIL_DRAIN_LIMIT_DEFAULT) || DEFAULT_DRAIN_LIMIT, 100));
  const typeFilter = Array.isArray(types) && types.length ? types : null;

  let url = `${env.SUPABASE_URL}/rest/v1/mail_outbox?select=*` +
            `&status=eq.QUEUED` +
            `&order=created_at_utc.asc` +
            `&limit=${take}`;
  if (typeFilter) {
    const t = typeFilter.map((t) => `"${enc(t)}"`).join(',');
    url += `&type=in.(${t})`;
  }

  const { rows } = await sbFetch(env, url, false);
  const picked = rows || [];
  if (picked.length === 0) {
    return { picked: 0, sent: 0, failed: 0, deferred: 0, errors: [] };
  }

  let sent = 0;
  let failed = 0;
  let deferred = 0;
  const errors = [];

  const nowPlusMinutesIso = (mins) => {
    const ms = Date.now() + (Math.max(1, Number(mins) || 5) * 60 * 1000);
    return new Date(ms).toISOString();
  };

  for (const row of picked) {
    try {
      const payload = await buildEmailPayloadFromOutboxRow(env, row);
      const res = await postToPowerAutomate(env, payload);

      if (res.ok) {
        const upd = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${enc(row.id)}`, {
          method: 'PATCH',
          headers: sbHeaders(env),
          body: JSON.stringify({
            status: 'SENT',
            sent_at: nowIso(),
            provider_message_id: res.provider_message_id || null,
            last_error: null,
            failed_at: null
          })
        });
        if (!upd.ok) {
          const errTxt = await upd.text();
          throw new Error(`Sent but failed to update status: ${errTxt}`);
        }
        sent += 1;
        await recordEmailAudit(env, null, 'EMAIL_SENT', { outbox_id: row.id, provider_message_id: res.provider_message_id, type: row.type });
      } else {
        const upd = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${enc(row.id)}`, {
          method: 'PATCH', headers: sbHeaders(env),
          body: JSON.stringify({ status: 'FAILED', failed_at: nowIso(), last_error: String(res.body || res.status) })
        });
        if (!upd.ok) {
          const errTxt = await upd.text();
          throw new Error(`Provider fail and update fail: ${errTxt}`);
        }
        failed += 1;
        errors.push({ id: row.id, error: res.body || `HTTP ${res.status}` });
        await recordEmailAudit(env, null, 'EMAIL_FAILED', { outbox_id: row.id, error: res.body || `HTTP ${res.status}`, type: row.type });
      }
    } catch (e) {
      const msg = String(e?.message || e);

      // ✅ RETRYABLE DEFERRAL: PDFs not ready yet
      if (msg.startsWith('PDF_NOT_READY:')) {
        try {
          await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${enc(row.id)}`, {
            method: 'PATCH',
            headers: sbHeaders(env),
            body: JSON.stringify({
              // keep QUEUED so it retries later
              status: 'QUEUED',
              last_error: msg,
              // push it back in the queue to avoid hot-looping
              created_at_utc: nowPlusMinutesIso(10)
            })
          });
        } catch {}
        deferred += 1;
        errors.push({ id: row.id, error: msg, deferred: true });
        await recordEmailAudit(env, null, 'EMAIL_DEFERRED', { outbox_id: row.id, reason: msg, type: row.type });
        continue;
      }

      // defensive failure (non-retryable)
      try {
        await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${enc(row.id)}`, {
          method: 'PATCH', headers: sbHeaders(env),
          body: JSON.stringify({ status: 'FAILED', failed_at: nowIso(), last_error: msg })
        });
      } catch {}
      failed += 1;
      errors.push({ id: row.id, error: msg });
      await recordEmailAudit(env, null, 'EMAIL_FAILED', { outbox_id: row.id, error: msg, type: row.type });
    }
  }

  return { picked: picked.length, sent, failed, deferred, errors };
}

// ------------------------------
// HTTP handlers – Outbox ops
// ------------------------------
 async function handleOutboxDrain(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body = {};
  try { body = await parseJSONBody(req); } catch {}

  try {
    const report = await drainEmailOutboxOnce(env, { limit: body?.limit, types: body?.types });
    return withCORS(env, req, ok(report));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}

 async function handleEmailSend(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const normalized = normalizeEmailPayload(body);
  const err = validateEmailPayload(normalized);
  if (err) return withCORS(env, req, badRequest(err));

  // If caller asks to queue instead of immediate send
  if (body?.queue === true) {
    const insert = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
      method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({
        type: body?.type || 'BROADCAST',
        to: normalized.to.join(','), cc: normalized.cc?.join(',') || null,
        subject: normalized.subject,
        body_html: normalized.html || null,
        body_text: normalized.text || null,
        attachments: body.attachments || null,
        status: 'QUEUED',
        reference: body?.reference || null,
        created_by: user?.id || null,
      })
    });
    if (!insert.ok) {
      return withCORS(env, req, serverError(`Failed to queue: ${await insert.text()}`));
    }
    const rows = await insert.json().catch(() => []);
    const row = Array.isArray(rows) ? rows[0] : rows;

    await recordEmailAudit(env, user, 'EMAIL_QUEUED', { outbox_id: row?.id, type: body?.type || 'BROADCAST' });
    return withCORS(env, req, ok({ queued: true, id: row?.id }));
  }

  // Immediate send via provider
  // Resolve any R2 attachments
  const resolved = [];
  for (const a of normalized.attachments) {
    if (a.contentBase64 && a.name) { resolved.push(a); }
    else if (a.r2_key) {
      const contentBase64 = await fetchAttachmentBase64FromR2(env, a.r2_key);
      resolved.push({ name: a.name || 'attachment', contentBase64 });
    }
  }

  const outgoing = await limitOrLinkAttachments(env, { payload: { ...normalized, attachments: resolved } });
  const resp = await postToPowerAutomate(env, outgoing.payload);
  if (!resp.ok) {
    return withCORS(env, req, serverError(`Provider rejected: ${resp.status} ${resp.body || ''}`));
  }

  await recordEmailAudit(env, user, 'EMAIL_SENT', { ad_hoc: true, provider_message_id: resp.provider_message_id });
  return withCORS(env, req, ok({ sent: true, provider_message_id: resp.provider_message_id }));
}

 async function handleOutboxRetry(env, req, outboxId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    const upd = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${enc(outboxId)}`, {
      method: 'PATCH', headers: sbHeaders(env),
      body: JSON.stringify({ status: 'QUEUED', failed_at: null, last_error: null })
    });
    if (!upd.ok) return withCORS(env, req, serverError(`Failed to retry: ${await upd.text()}`));
    await recordEmailAudit(env, user, 'EMAIL_RETRY', { outbox_id: outboxId });
    return withCORS(env, req, ok({ queued: true }));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}

 async function handleListOutbox(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const url = new URL(req.url);
  const status = url.searchParams.get('status');
  const limit = Math.min(parseInt(url.searchParams.get('limit') || '50', 10), 200);
  const type = url.searchParams.get('type');

  let q = `${env.SUPABASE_URL}/rest/v1/mail_outbox?select=*`;
  if (status) q += `&status=eq.${enc(status)}`;
  if (type) q += `&type=eq.${enc(type)}`;
  q += `&order=created_at_utc.desc&limit=${limit}`;

  const { rows } = await sbFetch(env, q, false);
  return withCORS(env, req, ok({ items: rows }));
}

 async function handleGetOutboxItem(env, req, outboxId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const { rows } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/mail_outbox?select=*&id=eq.${enc(outboxId)}`, false);
  if (!rows?.length) return withCORS(env, req, notFound('Outbox item not found'));
  return withCORS(env, req, ok(rows[0]));
}

 async function handleOutboxMarkSent(env, req) {
  // Optional callback for provider -> system reconciliation
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }
  const { id, provider_message_id } = body || {};
  if (!isNonEmptyString(id)) return withCORS(env, req, badRequest('id is required'));

  const upd = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${enc(id)}`, {
    method: 'PATCH', headers: sbHeaders(env),
    body: JSON.stringify({ status: 'SENT', sent_at: nowIso(), provider_message_id: provider_message_id || null, last_error: null, failed_at: null })
  });
  if (!upd.ok) return withCORS(env, req, serverError(`Failed to mark sent: ${await upd.text()}`));

  await recordEmailAudit(env, user, 'EMAIL_MARK_SENT', { outbox_id: id, provider_message_id });
  return withCORS(env, req, ok({ ok: true }));
}

 async function handleOutboxMarkFailed(env, req) {
  // Optional callback for provider -> system reconciliation
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }
  const { id, error } = body || {};
  if (!isNonEmptyString(id)) return withCORS(env, req, badRequest('id is required'));

  const upd = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${enc(id)}`, {
    method: 'PATCH', headers: sbHeaders(env),
    body: JSON.stringify({ status: 'FAILED', failed_at: nowIso(), last_error: String(error || 'Unknown error') })
  });
  if (!upd.ok) return withCORS(env, req, serverError(`Failed to mark failed: ${await upd.text()}`));

  await recordEmailAudit(env, user, 'EMAIL_MARK_FAILED', { outbox_id: id, error: String(error || 'Unknown error') });
  return withCORS(env, req, ok({ ok: true }));
}

// ------------------------------
// HTTP handler – TSO failure email queueing
// ------------------------------
 async function handleQueueTsoFailureEmail(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const timesheet_id = body?.timesheet_id || null;
  const booking_id = body?.booking_id || null;
  if (!timesheet_id && !booking_id) return withCORS(env, req, badRequest('Provide { timesheet_id } or { booking_id }'));

  try {
    const { to, client_id } = await resolveTsoRecipientForTimesheet(env, { timesheet_id, booking_id });
    if (!to) return withCORS(env, req, badRequest('Client TS queries email not configured'));

    const subject = body?.subject || 'Timesheet Query (TSO Failure)';
    const text = body?.body_text || 'A timesheet requires your attention.';
    const html = body?.body_html || `<p>${text}</p>`;

    // Optional attachments supplied by caller – we just pass through to the queue
    const attachments = Array.isArray(body?.attachments) ? body.attachments : null;

    const insert = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
      method: 'POST', headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({
        type: 'TSO_FAILURE',
        to,
        cc: null,
        subject,
        body_html: html,
        body_text: text,
        attachments,
        status: 'QUEUED',
        reference: booking_id ? `tso_failure:booking:${booking_id}` : `tso_failure:timesheet:${timesheet_id}`,
        created_by: user?.id || null,
      })
    });
    if (!insert.ok) return withCORS(env, req, serverError(`Failed to queue: ${await insert.text()}`));

    const rows = await insert.json().catch(() => []);
    const row = Array.isArray(rows) ? rows[0] : rows;
    await recordEmailAudit(env, user, 'EMAIL_QUEUED', { outbox_id: row?.id, type: 'TSO_FAILURE', client_id });

    return withCORS(env, req, ok({ queued: true, id: row?.id }));
  } catch (e) {
    return withCORS(env, req, badRequest(String(e?.message || e)));
  }
}

// ------------------------------
// Recipient resolution for TSO mails
// ------------------------------
 async function resolveTsoRecipientForTimesheet(env, { timesheet_id, booking_id }) {
  // Prefer to resolve via current financials -> client_id
  if (timesheet_id) {
    const url = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
                `?select=client_id,timesheet:timesheets(hospital_norm)` +
                `&timesheet_id=eq.${enc(timesheet_id)}` +
                `&is_current=eq.true` +
                `&limit=1`;
    const { rows } = await sbFetch(env, url, false);
    if (rows?.length) {
      const row = rows[0];
      if (row.client_id) {
        const to = await fetchTsQueriesEmailForClient(env, row.client_id);
        if (!to) throw new Error('NO_EMAIL_CONFIGURED');
        return { to, client_id: row.client_id };
      }
      // fallback: try hospital mapping
      const hosp = row?.timesheet?.hospital_norm || null;
      return await resolveRecipientViaHospital(env, hosp);
    }
  }

  if (booking_id) {
    // resolve via hospital mapping from the timesheets table (current version)
    const url = `${env.SUPABASE_URL}/rest/v1/timesheets` +
                `?select=hospital_norm` +
                `&booking_id=eq.${enc(booking_id)}` +
                `&is_current=eq.true` +
                `&limit=1`;
    const { rows } = await sbFetch(env, url, false);
    const hosp = rows?.[0]?.hospital_norm || null;
    return await resolveRecipientViaHospital(env, hosp);
  }

  throw new Error('CLIENT_UNKNOWN');
}

async function resolveRecipientViaHospital(env, hospital_norm) {
  if (!isNonEmptyString(hospital_norm)) throw new Error('CLIENT_UNKNOWN');
  const url = `${env.SUPABASE_URL}/rest/v1/client_hospitals?select=client_id&hospital_name_norm=eq.${enc(hospital_norm)}`;
  const { rows } = await sbFetch(env, url, false);
  if (!rows?.length) throw new Error('CLIENT_UNKNOWN');
  if (rows.length > 1) throw new Error('AMBIGUOUS_HOSPITAL');
  const client_id = rows[0].client_id;
  const to = await fetchTsQueriesEmailForClient(env, client_id);
  if (!to) throw new Error('NO_EMAIL_CONFIGURED');
  return { to, client_id };
}

async function fetchTsQueriesEmailForClient(env, client_id) {
  const url = `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${enc(client_id)}&select=ts_queries_email`;
  const { rows } = await sbFetch(env, url, false);
  const to = rows?.[0]?.ts_queries_email || null;
  if (!isNonEmptyString(to)) return null;
  return to;
}

// ------------------------------
// Audit helper
// ------------------------------
async function recordEmailAudit(env, userOrNull, action, meta) {
  try {
    await writeAudit(env, userOrNull, action, meta, {
      entity: 'email', subject_id: (meta && meta.outbox_id) || null, reason: 'MAIL_OUTBOX'
    });
  } catch {}
}

// ------------------------------
// REVISED: Remittance & Invoice email queueing
// ------------------------------
 async function handleRemittanceEmailForCandidate(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const timesheetIds = Array.isArray(body?.timesheet_ids) ? body.timesheet_ids.filter(Boolean) : [];
  const candidateId = body?.candidate_id || null;
  const startDate = body?.period_start || null; // YYYY-MM-DD
  const endDate   = body?.period_end   || null; // YYYY-MM-DD

  if (!timesheetIds.length && !(candidateId && startDate && endDate)) {
    return withCORS(env, req, badRequest('Provide either timesheet_ids[] OR { candidate_id, period_start, period_end }'));
  }

  // helpers
  const nowIso = new Date().toISOString();
  const esc = (s) => String(s ?? '').replace(/[&<>"']/g, (c) => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;','\'':'&#39;'}[c]));
  const fmt = (n) => (n == null ? '' : Number(n).toFixed(2));
  const toNum = (v) => (v == null ? 0 : Number(v) || 0);

  try {
    // 1) Pull current ts-fin snapshots (+ joined timesheet + client) with the new fields we need
     let url = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
              `?select=` + [
                'id','timesheet_id','candidate_id','client_id','pay_method',
                'hours_day','hours_night','hours_sat','hours_sun','hours_bh',
                'pay_day','pay_night','pay_sat','pay_sun','pay_bh',
                'total_hours','total_pay_ex_vat',
                'expenses_pay_ex_vat','mileage_pay_ex_vat',
                'pay_wtr_rate_pct_snapshot','policy_snapshot_json',
                'pay_vat_rate_pct_snapshot','pay_vat_amount_snapshot','pay_total_inc_vat_snapshot',

                // ✅ NEW: anchor finance window to pay date for deterministic resend
                'paid_at_utc',

                'remittance_send_count',
                'timesheet:timesheets(timesheet_id,booking_id,week_ending_date,hospital_norm,ward_norm,shift_label_norm)',
                'client:clients(name)'
              ].join(',') +
              `&is_current=eq.true`;


    if (timesheetIds.length) {
      const ids = timesheetIds.map((id) => enc(id)).join(',');
      url += `&timesheet_id=in.(${ids})`;
    } else {
      url += `&candidate_id=eq.${enc(candidateId)}`;
      url += `&timesheet.week_ending_date=gte.${enc(startDate)}`;
      url += `&timesheet.week_ending_date=lte.${enc(endDate)}`;
    }
    url += `&order=timesheet.week_ending_date.asc`;

    const { rows: finRows } = await sbFetch(env, url, false);
    if (!finRows?.length) return withCORS(env, req, notFound('No timesheets found for the selection'));

    const candIds = [...new Set(finRows.map((r) => r.candidate_id).filter(Boolean))];
    if (candIds.length !== 1) return withCORS(env, req, badRequest('Selection spans multiple candidates; send one remittance per candidate.'));
    const candId = candIds[0];

    // Candidate details
    const { rows: candRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candId)}&select=id,email,display_name,first_name,last_name`,
      false
    );
    if (!candRows?.length) return withCORS(env, req, notFound('Candidate not found'));

    const cand = candRows[0];
    const toEmail = (cand.email || '').trim();
    if (!toEmail) return withCORS(env, req, badRequest('Candidate email is missing'));

    const candName = cand.display_name || [cand.first_name, cand.last_name].filter(Boolean).join(' ') || 'Candidate';
    const dates = finRows.map((r) => r?.timesheet?.week_ending_date).filter(Boolean).sort();

    let periodLabel = '', periodKey = '';
    if (startDate && endDate) {
      periodLabel = `${startDate} to ${endDate}`;
      periodKey = `${startDate}_${endDate}`;
    } else if (dates.length) {
      const first = dates[0]; const last = dates[dates.length - 1];
      periodLabel = first === last ? `WE ${first}` : `WE ${first}–${last}`;
      periodKey = first === last ? `${first}` : `${first}_${last}`;
    } else {
      periodLabel = 'Selected timesheets';
      periodKey = 'selected';
    }

    const reference = `remit:candidate:${candId}:${periodKey}`;

    // Determine if selection is PAYE and/or UMBRELLA (in theory a candidate is one channel, but be robust)
    const hasPAYE = finRows.some((r) => String(r.pay_method || '').toUpperCase() === 'PAYE');
    const hasUmbrella = finRows.some((r) => String(r.pay_method || '').toUpperCase() === 'UMBRELLA');

       // Finance fallback for WTR (Holiday pay %) must be anchored to PAY DATE:
    // - If row.paid_at_utc exists => use that (Europe/London date)
    // - Else => use today's date (Europe/London)
    //
    // This ensures resending remittances later uses the same WTR split for paid rows.
    const londonTodayYmd = (() => {
      try {
        const s = new Intl.DateTimeFormat('en-GB', {
          timeZone: 'Europe/London',
          year: 'numeric',
          month: '2-digit',
          day: '2-digit'
        }).format(new Date());
        const [dd, mm, yyyy] = s.split('/');
        return `${yyyy}-${mm}-${dd}`;
      } catch {
        const d = new Date();
        const y = d.getUTCFullYear();
        const m = String(d.getUTCMonth() + 1).padStart(2,'0');
        const day = String(d.getUTCDate()).padStart(2,'0');
        return `${y}-${m}-${day}`;
      }
    })();

    const toLondonYmdFromIso = (isoLike) => {
      const raw = String(isoLike || '').trim();
      if (!raw) return null;

      // If already YYYY-MM-DD, accept
      const ymd = raw.slice(0, 10);
      if (/^\d{4}-\d{2}-\d{2}$/.test(ymd)) {
        // If it's a full ISO, interpret as date in London:
        // (Intl handles the timezone conversion)
        if (raw.length > 10) {
          try {
            const s = new Intl.DateTimeFormat('en-GB', {
              timeZone: 'Europe/London',
              year: 'numeric',
              month: '2-digit',
              day: '2-digit'
            }).format(new Date(raw));
            const [dd, mm, yyyy] = s.split('/');
            return `${yyyy}-${mm}-${dd}`;
          } catch {
            return ymd;
          }
        }
        return ymd;
      }

      // If it's ISO with time but parseable, use London date
      try {
        const d = new Date(raw);
        if (!Number.isNaN(d.getTime())) {
          const s = new Intl.DateTimeFormat('en-GB', {
            timeZone: 'Europe/London',
            year: 'numeric',
            month: '2-digit',
            day: '2-digit'
          }).format(d);
          const [dd, mm, yyyy] = s.split('/');
          return `${yyyy}-${mm}-${dd}`;
        }
      } catch {}
      return null;
    };

    const anchorYmdForRow = (row) => {
      const paidAt = row?.paid_at_utc || null;
      return toLondonYmdFromIso(paidAt) || londonTodayYmd;
    };

    // Cache finance windows per anchor date so we do at most 1 RPC per unique anchorYmd.
    const financeByDate = new Map(); // anchorYmd -> { holiday_pay_pct, apply_holiday_to }
    const loadFinanceForAnchor = async (anchorYmd) => {
      const k = String(anchorYmd || '').slice(0, 10);
      if (financeByDate.has(k)) return financeByDate.get(k);

      // Safe fallback if RPC not available
      let out = { holiday_pay_pct: 0, apply_holiday_to: 'PAYE_ONLY' };

      try {
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
          {
            method: 'POST',
            headers: { ...sbHeaders(env), 'content-type': 'application/json' },
            body: JSON.stringify({ p_date: k || null })
          }
        );
        const txt = await res.text().catch(() => '');
        if (res.ok) {
          const j = txt ? JSON.parse(txt) : null;
          const row = Array.isArray(j) ? j[0] : j;

          const hp = Number(row?.holiday_pay_pct);
          const ap = String(row?.apply_holiday_to || 'PAYE_ONLY').toUpperCase();

          out = {
            holiday_pay_pct: Number.isFinite(hp) ? hp : 0,
            apply_holiday_to: ap || 'PAYE_ONLY'
          };
        }
      } catch {
        // keep fallback
      }

      financeByDate.set(k, out);
      return out;
    };

    // Preload finance windows for all anchors we will use (minimise subcalls)
    const uniqueAnchors = [...new Set(finRows.map(anchorYmdForRow).filter(Boolean))];
    for (const a of uniqueAnchors) {
      await loadFinanceForAnchor(a);
    }

    // WTR helper — prefer snapshot, else policy snapshot, else finance window by pay date
    function resolveWtrPct(row) {
      const snap = row?.pay_wtr_rate_pct_snapshot;
      if (snap !== null && snap !== undefined && Number.isFinite(Number(snap))) return Number(snap);

      // If policy snapshot has explicit rules, keep respecting it (it may be frozen by TSFIN)
      const pol = row?.policy_snapshot_json || {};
      const polApply = String(pol.apply_holiday_to || '').toUpperCase();
      if (polApply === 'NONE') return 0;

      const polPct = Number(pol.holiday_pay_pct ?? NaN);
      if (Number.isFinite(polPct)) return polPct;

      // Finance-window fallback (anchored to paid date)
      const anchor = anchorYmdForRow(row);
      const fin = financeByDate.get(anchor) || { holiday_pay_pct: 0, apply_holiday_to: 'PAYE_ONLY' };

      const applyTo = String(fin.apply_holiday_to || 'PAYE_ONLY').toUpperCase();
      if (applyTo === 'NONE') return 0;

      // This handler is a remittance: WTR applies only to PAYE pay in the UI anyway,
      // but we still honour apply_holiday_to for completeness.
      return Number(fin.holiday_pay_pct || 0);
    }


    // 2) Build table rows with:
    // - Per band hours/rates (as before)
    // - PAYE: Basic/WTR informational split (included in pay) using WTR%
    // - UMBRELLA: VAT & inc-VAT using snapshot (or derived from rate if snapshot missing)
    let totalPayEx = 0, totalExpEx = 0, totalMilEx = 0, totalEx = 0;
    let totalWtrBasic = 0, totalWtrElem = 0;
    let totalVat = 0, totalInc = 0;

    const rowsHtml = finRows.map((r) => {
      const ts = r.timesheet || {}; const cli = r.client || {};
      const payMethod = String(r.pay_method || '').toUpperCase();

      // Ex-VAT components
      const payEx = toNum(r.total_pay_ex_vat);
      const expEx = toNum(r.expenses_pay_ex_vat);
      const milEx = toNum(r.mileage_pay_ex_vat);
      let rowEx = payEx + expEx + milEx;

      totalPayEx += payEx;
      totalExpEx += expEx;
      totalMilEx += milEx;
      totalEx += rowEx;

      // PAYE WTR split (informational)
      let wtrInfoHtml = '—';
      if (payMethod === 'PAYE') {
        const wtrPct = resolveWtrPct(r);
        const base = rowEx > 0 ? (payEx / (1 + (wtrPct / 100))) : 0; // split only the hourly pay portion
        const wtr = payEx - base;
        totalWtrBasic += base;
        totalWtrElem += wtr;
             wtrInfoHtml = `${fmt(base)} basic + ${fmt(wtr)} holiday pay @ ${fmt(wtrPct)}% = ${fmt(payEx)}`;

      }

      // Umbrella VAT (from snapshot if present)
      let vatHtml = '';
      let incHtml = '';
      if (payMethod === 'UMBRELLA') {
        let vatAmt = toNum(r.pay_vat_amount_snapshot);
        let incAmt = toNum(r.pay_total_inc_vat_snapshot);
        const rate = r.pay_vat_rate_pct_snapshot == null ? null : Number(r.pay_vat_rate_pct_snapshot);

        // If snapshot absent, derive from ex + rate (if available)
        if (!incAmt && rate && rate > 0) {
          vatAmt = (rowEx * rate) / 100;
          incAmt = rowEx + vatAmt;
        }
        // Prefer snapshot-consistent ex for display where possible
        if (incAmt && vatAmt) {
          // Recompute rowEx for display consistency
          const snapshotEx = incAmt - vatAmt;
          if (snapshotEx > 0) rowEx = snapshotEx;
        }

        totalVat += vatAmt;
        totalInc += incAmt;

        vatHtml = `${fmt(vatAmt)}${(rate || rate === 0) ? ` @ ${fmt(rate)}%` : ''}`;
        incHtml = `${fmt(incAmt)}`;
      }

      return `
        <tr>
          <td>${esc(ts.week_ending_date || '')}</td>
          <td>${esc(cli.name || '')}</td>
          <td>${esc(ts.hospital_norm || '')}</td>
          <td>${esc(ts.ward_norm || '')}</td>
          <td>${esc(ts.shift_label_norm || '')}</td>

          <td style="text-align:right">${fmt(r.hours_day)}</td>
          <td style="text-align:right">${fmt(r.pay_day)}</td>
          <td style="text-align:right">${fmt(r.hours_night)}</td>
          <td style="text-align:right">${fmt(r.pay_night)}</td>
          <td style="text-align:right">${fmt(r.hours_sat)}</td>
          <td style="text-align:right">${fmt(r.pay_sat)}</td>
          <td style="text-align:right">${fmt(r.hours_sun)}</td>
          <td style="text-align:right">${fmt(r.pay_sun)}</td>
          <td style="text-align:right">${fmt(r.hours_bh)}</td>
          <td style="text-align:right">${fmt(r.pay_bh)}</td>

          <td style="text-align:right">${fmt(payEx)}</td>
          <td style="text-align:right">${fmt(expEx)}</td>
          <td style="text-align:right">${fmt(milEx)}</td>
          <td style="text-align:right"><strong>${fmt(rowEx)}</strong></td>

          ${hasPAYE ? `<td style="text-align:right">${wtrInfoHtml}</td>` : ''}

          ${hasUmbrella ? `<td style="text-align:right">${vatHtml || '—'}</td>` : ''}
          ${hasUmbrella ? `<td style="text-align:right"><strong>${incHtml || '—'}</strong></td>` : ''}
        </tr>`;
    }).join('');

    // 3) Build HTML (header adapts to PAYE/Umbrella columns)
    const extraPAYECol = hasPAYE ? '<th align="right">Basic + WTR (info)</th>' : '';
    const extraUmbCols = hasUmbrella
      ? '<th align="right">VAT</th><th align="right">Total (inc VAT)</th>'
      : '';

    const periodTitleSuffix = hasUmbrella ? ' – Umbrella' : (hasPAYE ? ' – PAYE' : '');

    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif;font-size:14px;line-height:1.4">
        <h2 style="margin:0 0 8px">Remittance Advice${periodTitleSuffix}</h2>
        <p style="margin:0 0 12px"><strong>${esc(candName)}</strong></p>
        <p style="margin:0 0 12px">Period: ${esc(periodLabel)}</p>
        <p style="margin:0 0 16px;color:#666">Generated: ${esc(nowIso)}</p>

        <table width="100%" border="0" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead>
            <tr style="background:#f5f5f5">
              <th align="left">Week Ending</th>
              <th align="left">Client</th>
              <th align="left">Hospital</th>
              <th align="left">Ward</th>
              <th align="left">Shift</th>

              <th align="right">Hrs Day</th>
              <th align="right">Pay Day</th>
              <th align="right">Hrs Night</th>
              <th align="right">Pay Night</th>
              <th align="right">Hrs Sat</th>
              <th align="right">Pay Sat</th>
              <th align="right">Hrs Sun</th>
              <th align="right">Pay Sun</th>
              <th align="right">Hrs BH</th>
              <th align="right">Pay BH</th>

              <th align="right">Pay (ex VAT)</th>
              <th align="right">Expenses</th>
              <th align="right">Mileage</th>
              <th align="right">Total (ex VAT)</th>

              ${extraPAYECol}
              ${extraUmbCols}
            </tr>
          </thead>
          <tbody>${rowsHtml}</tbody>
          <tfoot>
            <tr>
              <td colspan="${hasPAYE ? 19 : 18}${hasUmbrella ? '' : ''}" align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>Totals:</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${fmt(totalPayEx)}</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${fmt(totalExpEx)}</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${fmt(totalMilEx)}</strong></td>
              <td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${fmt(totalEx)}</strong></td>

              ${hasPAYE ? `<td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${fmt(totalWtrBasic)} basic + ${fmt(totalWtrElem)} WTR</strong></td>` : ''}

              ${hasUmbrella ? `<td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${fmt(totalVat)}</strong></td>` : ''}
              ${hasUmbrella ? `<td align="right" style="padding-top:10px;border-top:1px solid #e5e5e5"><strong>${fmt(totalInc)}</strong></td>` : ''}
            </tr>
          </tfoot>
        </table>

        ${hasPAYE ? `<p style="margin-top:12px;color:#666">Note: For PAYE, the pay rate is WTR-inclusive. The “Basic + WTR” split is informational only and is included in your payment.</p>` : ''}
        ${hasUmbrella ? `<p style="margin-top:8px;color:#666">Note: For Umbrella assignments where VAT applies, totals show ex VAT and inc VAT amounts using the VAT rate captured at the time of payment/lock.</p>` : ''}
      </div>`;

    // 4) Plain-text version (short, but with the new info)
    const textLines = [];
    textLines.push(`Remittance Advice${periodTitleSuffix}`);
    textLines.push(`${candName}`);
    textLines.push(`Period: ${periodLabel}`);
    textLines.push(`Generated: ${nowIso}`);
    textLines.push('');

    for (const r of finRows) {
      const ts = r.timesheet || {}; const cli = r.client || {};
      const pm = String(r.pay_method || '').toUpperCase();

      const payEx = toNum(r.total_pay_ex_vat);
      const expEx = toNum(r.expenses_pay_ex_vat);
      const milEx = toNum(r.mileage_pay_ex_vat);
      const rowEx = payEx + expEx + milEx;

      textLines.push(`WE ${ts.week_ending_date || ''} — ${cli.name || ''} / ${ts.hospital_norm || ''} / ${ts.ward_norm || ''} / ${ts.shift_label_norm || ''}`);
      textLines.push(`Day: ${fmt(r.hours_day)} @ ${fmt(r.pay_day)}, Night: ${fmt(r.hours_night)} @ ${fmt(r.pay_night)}, Sat: ${fmt(r.hours_sat)} @ ${fmt(r.pay_sat)}, Sun: ${fmt(r.hours_sun)} @ ${fmt(r.pay_sun)}, BH: ${fmt(r.hours_bh)} @ ${fmt(r.pay_bh)}`);
      textLines.push(`Pay ex VAT: ${fmt(payEx)}  |  Expenses: ${fmt(expEx)}  |  Mileage: ${fmt(milEx)}  |  Total ex VAT: ${fmt(rowEx)}`);

      if (pm === 'PAYE') {
        const wtrPct = resolveWtrPct(r);
        const base = payEx / (1 + (wtrPct / 100));
        const wtr = payEx - base;
        textLines.push(`(PAYE) Basic + WTR (info): ${fmt(base)} basic + ${fmt(wtr)} WTR @ ${fmt(wtrPct)}% (included)`);
      } else if (pm === 'UMBRELLA') {
        const vatAmt = toNum(r.pay_vat_amount_snapshot);
        const incAmt = toNum(r.pay_total_inc_vat_snapshot);
        const rate = r.pay_vat_rate_pct_snapshot == null ? null : Number(r.pay_vat_rate_pct_snapshot);
        const vatStr = rate || rate === 0 ? `VAT: ${fmt(vatAmt)} @ ${fmt(rate)}%  |  Total inc VAT: ${fmt(incAmt)}` : `VAT: ${fmt(vatAmt)}  |  Total inc VAT: ${fmt(incAmt)}`;
        textLines.push(`(Umbrella) ${vatStr}`);
      }
      textLines.push('');
    }

    textLines.push(`Totals — Pay ex VAT: ${fmt(totalPayEx)}, Expenses: ${fmt(totalExpEx)}, Mileage: ${fmt(totalMilEx)}, Total ex VAT: ${fmt(totalEx)}`);
    if (hasPAYE) textLines.push(`PAYE Basic + WTR (info totals): ${fmt(totalWtrBasic)} basic + ${fmt(totalWtrElem)} WTR`);
    if (hasUmbrella) textLines.push(`Umbrella VAT Total: ${fmt(totalVat)}  |  Total inc VAT: ${fmt(totalInc)}`);

    const text = textLines.join('\n');

    // 5) Queue email in mail_outbox
    const outRes = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({
        type: 'REMITTANCE', to: toEmail, cc: null,
        subject: `Remittance Advice – ${periodLabel}`,
        body_html: html, body_text: text,
        attachments: null,
        status: 'QUEUED', reference,
        created_by: user?.id || null,
      })
    });

    if (!outRes.ok) {
      const err = await outRes.text();
      return withCORS(env, req, serverError(`Failed to queue remittance email: ${err}`));
    }

    const outJson = await outRes.json().catch(() => []);
    const mail = Array.isArray(outJson) ? outJson[0] : outJson;
    const mailId = mail?.id || null;

    // 6) Audit logs
    await writeAudit(
      env, user, 'EMAIL_QUEUED',
      {
        to: toEmail,
        subject: `Remittance Advice – ${periodLabel}`,
        period: { start: startDate || dates[0] || null, end: endDate || dates[dates.length - 1] || null },
        mail_id: mailId,
        timesheets: finRows.map((r) => r.timesheet_id)
      },
      { entity: 'candidate', subject_id: candId, reason: 'REMITTANCE', correlation_id: mailId, req }
    );
    for (const r of finRows) {
      await writeAudit(
        env, user, 'EMAIL_QUEUED',
        { to: toEmail, subject: `Remittance Advice – ${periodLabel}`, mail_id: mailId },
        { entity: 'timesheet', subject_id: r.timesheet_id, reason: 'REMITTANCE', correlation_id: mailId, req }
      );
    }

    // 7) Update remittance counters on the snapshots (timestamp + increment count)
    //    Do per-row patch to safely increment the counter value we just read.
    for (const r of finRows) {
      const newCount = (Number(r.remittance_send_count || 0) + 1);
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(r.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
          body: JSON.stringify({
            remittance_last_sent_at_utc: nowIso,
            remittance_send_count: newCount
          })
        }
      );
    }

    return withCORS(env, req, ok({ queued: true, mail_id: mailId, items: finRows.length }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to build/queue remittance email'));
  }
}


// ─────────────────────────────────────────────────────────────────────────────
// CANDIDATES: snapshot / delta / id-list
// Assumes candidates table has columns: id, first_name, last_name, display_name, email, active, rev (optional)
// If rev not present, we fallback to updated_at (timestamp number).
// roles_display: either materialized, or computed in FE from roles array.
// ─────────────────────────────────────────────────────────────────────────────
async function handlePickerCandidatesSnapshot(env, req){
  const user = await requireUser(env, req, ['admin']); if (!user) return unauthorized();
  // minimal projection; we prefer selecting explicit columns
  const sel = 'id,first_name,last_name,display_name,email,active,rev,updated_at,roles';
  const url = `${env.SUPABASE_URL}/rest/v1/candidates?select=${encodeURIComponent(sel)}&active=is.true`;
  const { rows } = await sbFetch(env, url);
  // Project to minimal (roles_display can be computed client-side; include roles for FE to format)
  const items = (rows||[]).map(r => ({
    id: r.id,
    first_name: r.first_name || '',
    last_name:  r.last_name  || '',
    display_name: r.display_name || '',
    email: r.email || '',
    active: r.active !== false,
    roles: r.roles || null,   // FE will format to roles_display
    rev: (r.rev ?? null),
    updated_at: r.updated_at || null
  }));
  const since = computeSinceFromRows(items); // prefer max rev else max updated_at epoch
  return okJSON({ items, since });
}

async function handlePickerCandidatesDelta(env, req){
  const user = await requireUser(env, req, ['admin']); if (!user) return unauthorized();
  const u = new URL(req.url);
  const sinceRaw = u.searchParams.get('since');
  if (!sinceRaw) return badJSON(400, 'missing since');

  // Try rev-based first
  let urlAdd = `${env.SUPABASE_URL}/rest/v1/candidates?select=id,first_name,last_name,display_name,email,active,rev,updated_at,roles&rev=gt.${encodeURIComponent(sinceRaw)}`;
  let { rows } = await sbFetch(env, urlAdd);
  // Fallback to updated_at timestamp (when rev not present); clients can pass timestamp numbers
  if (!Array.isArray(rows)) rows = [];
  let updates = rows;

  // Hard deletes: optional tombstones
  let removed = [];
  try {
    const tombUrl = `${env.SUPABASE_URL}/rest/v1/candidates_tombstones?select=id,deleted_rev&deleted_rev=gt.${encodeURIComponent(sinceRaw)}`;
    const del = await sbFetch(env, tombUrl);
    removed = (del?.rows||[]).map(r => r.id);
  } catch {}

  const added = updates.filter(r => r.active !== false); // new/updated active rows
  const updated = updates.filter(r => r.active === false ? false : true); // treat all as updated on client (we don't distinguish)

  const since = computeSinceFromRows(updates); // max rev/updated_at
  return okJSON({ added, updated, removed, since });
}

async function handlePickerCandidatesIdList(env, req){
  const user = await requireUser(env, req, ['admin']); if (!user) return unauthorized();
  const u = new URL(req.url);
  // Map passed filters to PostgREST query. Keep it minimal (ids, role, q, active, etc.)
  const qs = new URLSearchParams();

  // Example mappings:
  const ids  = (u.searchParams.get('ids')||'').trim(); if (ids)  qs.set('id', `in.(${ids.split(',').map(x=>`"${x.trim()}"`).join(',')})`);
  const role = (u.searchParams.get('role')||'').trim(); if (role) qs.set('roles::text', `ilike.*${role}*`);
  const band = (u.searchParams.get('band')||'').trim(); if (band) qs.set('band', `eq.${band}`);
  const q    = (u.searchParams.get('q')||'').trim();    if (q)    qs.set('display_name', `ilike.*${q}*`);
  const active = u.searchParams.get('active');          if (active!=null) qs.set('active', `eq.${active==='true'}`);

  // Return only ids sorted by display_name (server-side consistent ordering)
  const sel = 'id';
  const url = `${env.SUPABASE_URL}/rest/v1/candidates?select=${sel}&${qs.toString()}&order=display_name.asc&limit=20000`;
  const { rows } = await sbFetch(env, url);
  const idsOut = (rows||[]).map(r => r.id);
  return okJSON({ fingerprint: u.searchParams.toString(), ids: idsOut, total: idsOut.length });
}
// ─────────────────────────────────────────────────────────────────────────────
// CLIENTS: snapshot / delta / id-list
// ─────────────────────────────────────────────────────────────────────────────
async function handlePickerClientsSnapshot(env, req){
  const user = await requireUser(env, req, ['admin']); 
  if (!user) return unauthorized();

  // Pull NHSP / HR autoproc flags from client_settings via nested select
  const sel = 'id,name,primary_invoice_email,rev,updated_at,client_settings(is_nhsp,autoprocess_hr)';
  const url = `${env.SUPABASE_URL}/rest/v1/clients?select=${encodeURIComponent(sel)}`;
  const { rows } = await sbFetch(env, url);

  const items = (rows || []).map(r => {
    // client_settings is usually an array from PostgREST when nested
    const raw = r.client_settings;
    let cs;
    if (Array.isArray(raw)) {
      cs = raw[0] || {};
    } else {
      cs = raw || {};
    }

    return {
      id:   r.id,
      name: r.name || '',
      primary_invoice_email: r.primary_invoice_email || '',
      is_nhsp:        !!cs.is_nhsp,
      autoprocess_hr: !!cs.autoprocess_hr,
      rev:            (r.rev ?? null),
      updated_at:     r.updated_at || null
    };
  });

  const since = computeSinceFromRows(items);
  return okJSON({ items, since });
}

async function handlePickerClientsDelta(env, req){
  const user = await requireUser(env, req, ['admin']); 
  if (!user) return unauthorized();

  const u        = new URL(req.url);
  const sinceRaw = u.searchParams.get('since');
  if (!sinceRaw) return badJSON(400, 'missing since');

  const sel = 'id,name,primary_invoice_email,rev,updated_at,client_settings(is_nhsp,autoprocess_hr)';
  const urlAdd =
    `${env.SUPABASE_URL}/rest/v1/clients` +
    `?select=${encodeURIComponent(sel)}` +
    `&rev=gt.${encodeURIComponent(sinceRaw)}`;

  let { rows } = await sbFetch(env, urlAdd);
  if (!Array.isArray(rows)) rows = [];

  const items = (rows || []).map(r => {
    const raw = r.client_settings;
    let cs;
    if (Array.isArray(raw)) {
      cs = raw[0] || {};
    } else {
      cs = raw || {};
    }

    return {
      id:   r.id,
      name: r.name || '',
      primary_invoice_email: r.primary_invoice_email || '',
      is_nhsp:        !!cs.is_nhsp,
      autoprocess_hr: !!cs.autoprocess_hr,
      rev:            (r.rev ?? null),
      updated_at:     r.updated_at || null
    };
  });

  // Hard deletes: optional tombstones
  let removed = [];
  try {
    const tombUrl =
      `${env.SUPABASE_URL}/rest/v1/clients_tombstones` +
      `?select=id,deleted_rev&deleted_rev=gt.${encodeURIComponent(sinceRaw)}`;
    const del = await sbFetch(env, tombUrl);
    removed = (del?.rows || []).map(r => r.id);
  } catch {}

  // For clients we just treat all as "updated" on the FE side.
  const added   = [];
  const updated = items;

  const since = computeSinceFromRows(items);
  return okJSON({ added, updated, removed, since });
}


async function handlePickerClientsIdList(env, req){
  const user = await requireUser(env, req, ['admin']); if (!user) return unauthorized();
  const u = new URL(req.url);
  const qs = new URLSearchParams();

  const ids = (u.searchParams.get('ids')||'').trim();
  if (ids) qs.set('id', `in.(${ids.split(',').map(x=>`"${x.trim()}"`).join(',')})`);

  const q = (u.searchParams.get('q')||'').trim();
  if (q) qs.set('name', `ilike.*${q}*`);

  const sel = 'id';
  const url = `${env.SUPABASE_URL}/rest/v1/clients?select=${sel}${qs.toString() ? `&${qs.toString()}` : ''}&order=name.asc&limit=20000`;
  const { rows } = await sbFetch(env, url);
  const idsOut = (rows||[]).map(r => r.id);
  return okJSON({ fingerprint: u.searchParams.toString(), ids: idsOut, total: idsOut.length });
}

// ─────────────────────────────────────────────────────────────────────────────
// Utility: computeSinceFromRows(rows)
// Picks max rev if available else max updated_at (as numeric timestamp)
// ─────────────────────────────────────────────────────────────────────────────
function computeSinceFromRows(rows){
  let maxRev = null, maxTs = 0;
  for (const r of (rows||[])) {
    if (r.rev != null) maxRev = (maxRev==null) ? r.rev : Math.max(maxRev, r.rev);
    if (r.updated_at) {
      const t = Date.parse(r.updated_at); if (!isNaN(t)) maxTs = Math.max(maxTs, t);
    }
  }
  return (maxRev!=null) ? String(maxRev) : (maxTs ? String(maxTs) : null);
}

// ─────────────────────────────────────────────────────────────────────────────
// HELPERS (backend)
// ─────────────────────────────────────────────────────────────────────────────
function okJSON(body){ return new Response(JSON.stringify(body), { status:200, headers: { 'content-type':'application/json' } }); }
function badJSON(status, msg){ return new Response(JSON.stringify({ error: msg || 'Bad Request' }), { status, headers: { 'content-type':'application/json' } }); }

function ok(data, headers = {}) {
  return new Response(JSON.stringify(data), { status: 200, headers: { ...JSON_HEADERS, ...headers } });
}
function badRequest(msg, details) {
  return new Response(JSON.stringify({ error: msg, details }), { status: 400, headers: JSON_HEADERS });
}
function unauthorized(msg = "Unauthorized") {
  return new Response(JSON.stringify({ error: msg }), { status: 401, headers: JSON_HEADERS });
}
function forbidden(msg = "Forbidden") {
  return new Response(JSON.stringify({ error: msg }), { status: 403, headers: JSON_HEADERS });
}
function notFound(msg = "Not found") {
  return new Response(JSON.stringify({ error: msg }), { status: 404, headers: JSON_HEADERS });
}
function conflict(msg = "Conflict") {
  return new Response(JSON.stringify({ error: msg }), { status: 409, headers: JSON_HEADERS });
}
function tooLarge(msg = "Payload too large") {
  return new Response(JSON.stringify({ error: msg }), { status: 413, headers: JSON_HEADERS });
}
function unsupported(msg = "Unsupported Media Type") {
  return new Response(JSON.stringify({ error: msg }), { status: 415, headers: JSON_HEADERS });
}
function unprocessable(msg = "Unprocessable Entity") {
  return new Response(JSON.stringify({ error: msg }), { status: 422, headers: JSON_HEADERS });
}
function serverError(msg = "Internal Server Error") {
  return new Response(JSON.stringify({ error: msg }), { status: 500, headers: JSON_HEADERS });
}

function parseJSONBody(req) {
  return req.json().catch(() => null);
}
function splitCsv(s) {
  return String(s || "")
    .split(",")
    .map((x) => x.trim())
    .filter(Boolean);
}
// BACKEND — UPDATED
// buildCORSHeaders: allow PATCH, DELETE so overwrite & bin work.
function buildCORSHeaders(env, reqOrigin) {
  const allowed = splitCsv(env.ALLOWED_ORIGINS || "");
  const h = {
    "Access-Control-Allow-Credentials": "true",
    "Access-Control-Allow-Headers": "authorization,content-type,content-md5,x-requested-with,idempotency-key,x-idempotency-key",
    "Access-Control-Allow-Methods": "GET,POST,PUT,PATCH,DELETE,OPTIONS",
    "Vary": "Origin",
  };
  if (!allowed.length) return h;
  if (reqOrigin && allowed.includes(reqOrigin)) h["Access-Control-Allow-Origin"] = reqOrigin;
  return h;
}

function withCORS(env, req, res) {
  const origin = req.headers.get("origin");
  const headers = buildCORSHeaders(env, origin);
  const newHeaders = new Headers(res.headers);
  for (const [k, v] of Object.entries(headers)) newHeaders.set(k, v);
  return new Response(res.body, { status: res.status, headers: newHeaders });
}
// BACKEND — UPDATED
// preflightIfNeeded: unchanged logic; leverages updated buildCORSHeaders. (kept for completeness)
function preflightIfNeeded(env, req) {
  if (req.method === "OPTIONS") return withCORS(env, req, new Response(null, { status: 204 }));
  return null;
}


// ---------------------- Crypto helpers ----------------------
async function hmacSign(secret, data) {
  const key = await crypto.subtle.importKey(
    "raw",
    new TextEncoder().encode(secret),
    { name: "HMAC", hash: "SHA-256" },
    false,
    ["sign", "verify"]
  );
  const sig = await crypto.subtle.sign("HMAC", key, new TextEncoder().encode(data));
  return bufToBase64Url(sig);
}
async function hmacVerify(secret, data, signatureB64url) {
  const key = await crypto.subtle.importKey(
    "raw",
    new TextEncoder().encode(secret),
    { name: "HMAC", hash: "SHA-256" },
    false,
    ["sign", "verify"]
  );
  const sig = base64UrlToUint8(signatureB64url);
  return crypto.subtle.verify("HMAC", key, sig, new TextEncoder().encode(data));
}
async function sha256Hex(s) {
  const d = await crypto.subtle.digest("SHA-256", new TextEncoder().encode(s));
  const arr = Array.from(new Uint8Array(d));
  return arr.map((b) => b.toString(16).padStart(2, "0")).join("");
}
function bufToBase64Url(buf) {
  let binary = "";
  const bytes = new Uint8Array(buf);
  for (let i = 0; i < bytes.byteLength; i++) binary += String.fromCharCode(bytes[i]);
  return btoa(binary).replace(/\+/g, "-").replace(/\//g, "_").replace(/=+$/g, "");
}
function base64UrlToUint8(b64url) {
  const b64 = b64url.replace(/-/g, "+").replace(/_/g, "/") + "==".slice((2 - (b64url.length * 3) % 4) % 4);
  const bin = atob(b64);
  const arr = new Uint8Array(bin.length);
  for (let i = 0; i < bin.length; i++) arr[i] = bin.charCodeAt(i);
  return arr;
}

// Tokens (compact): base64url(JSON).base64url(HMAC) with exp
async function createToken(secret, payload) {
  const data = bufToBase64Url(new TextEncoder().encode(JSON.stringify(payload)));
  const sig = await hmacSign(secret, data);
  return `${data}.${sig}`;
}
async function verifyToken(secret, token) {
  const [data, sig] = String(token || "").split(".");
  if (!data || !sig) return { ok: false, error: "Malformed token" };
  const ok = await hmacVerify(secret, data, sig);
  if (!ok) return { ok: false, error: "Invalid signature" };
  const payload = JSON.parse(new TextDecoder().decode(base64UrlToUint8(data)));
  const now = Math.floor(Date.now() / 1000);
  if (typeof payload.exp === "number" && now > payload.exp) return { ok: false, error: "Token expired" };
  return { ok: true, payload };
}

// ---------------------- Date / Time ----------------------
const LONDON_TZ = "Europe/London";
function londonDate(isoOrDate) {
  const d = new Date(isoOrDate);
  const fmt = new Intl.DateTimeFormat("en-GB", { timeZone: LONDON_TZ, year: "numeric", month: "2-digit", day: "2-digit" });
  const parts = fmt.formatToParts(d).reduce((acc, p) => ((acc[p.type] = p.value), acc), {});
  return `${parts.year}-${parts.month}-${parts.day}`;
}
function weekEndingSunday(dateYmd) {
  const [y, m, d] = dateYmd.split("-").map((x) => parseInt(x, 10));
  const dt = new Date(Date.UTC(y, m - 1, d));
  const dow = new Intl.DateTimeFormat("en-GB", { timeZone: LONDON_TZ, weekday: "short" }).format(dt).toLowerCase();
  const dayNum = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"].indexOf(dow.slice(0, 3));
  const add = 6 - (dayNum === -1 ? 0 : dayNum);
  const sunday = new Date(dt);
  sunday.setUTCDate(sunday.getUTCDate() + add);
  return londonDate(sunday);
}

// ---------------------- Booking ID ----------------------
function norm(s) {
  return String(s || "")
    .trim()
    .toLowerCase()
    .replace(/\s+/g, " ")
    .replace(/[^\w\s\-@&\/,.:]/g, "");
}
async function makeBookingId(candidate_id, date_of_shift, hospital, ward, job_title, shift_label = "") {
  const base = `${norm(candidate_id)}|${date_of_shift}|${norm(hospital)}|${norm(ward)}|${norm(job_title)}|${norm(shift_label)}`;
  const hash = await sha256Hex(base);
  return `bk_${hash.slice(0, 16)}`;
}

// ---------------------- R2 helpers ----------------------
async function r2Head(env, key) {
  try { return await env.R2.head(key); } catch { return null; }
}



async function r2Get(env, key) {
  try {
    const k = String(key || '').trim().replace(/^\/+/, ''); // ✅ strip leading slashes
    return await env.R2.get(k);
  } catch {
    return null;
  }
}

async function handleSignGet(env, req, url) {
  const canon = (s) => String(s || "").trim().replace(/^\/+/, ""); // ✅ canonical key

  const key_raw    = url.searchParams.get("key") || "";
  const booking_id = url.searchParams.get("booking_id") || "";
  const role       = url.searchParams.get("role") || "";
  const token      = url.searchParams.get("token") || "";

  const key = canon(key_raw);

  const secret = env.UPLOAD_TOKEN_SECRET;
  const ver = await verifyToken(secret, token);
  if (!ver.ok) return unauthorized("Invalid token");

  const p = ver.payload || {};

  // ✅ compare canonical keys, not raw strings
  if (
    p.typ !== "dl" ||
    String(p.booking_id || "") !== String(booking_id || "") ||
    String(p.role || "") !== String(role || "") ||
    canon(p.key) !== key
  ) {
    return unauthorized("Token mismatch");
  }

  const obj = await r2Get(env, key);
  if (!obj) return notFound("Not found");

  // ✅ better: use stored content-type if present (otherwise default png)
  const ct = (obj.httpMetadata && obj.httpMetadata.contentType) ? obj.httpMetadata.contentType : "image/png";

  const headers = new Headers({
    "content-type": ct,
    "cache-control": "private, max-age=300"
  });

  return new Response(obj.body, { status: 200, headers });
}


// ---------------------- Supabase REST ----------------------
function sbHeaders(env) {
  const key = env.SUPABASE_SERVICE_ROLE_KEY;
  return { "apikey": key, "Authorization": `Bearer ${key}`, "Content-Type": "application/json" };
}

async function sbUpsertTimesheet(env, row) {
  const url = `${env.SUPABASE_URL}/rest/v1/timesheets?on_conflict=booking_id,version`;
  const res = await fetch(url, {
    method: "POST",
    headers: { ...sbHeaders(env), "Prefer": "resolution=merge-duplicates,return=representation" },
    body: JSON.stringify(row),
  });
  if (!res.ok) throw new Error(`Supabase upsert timesheet failed ${res.status}`);
  const json = await res.json().catch(() => ({}));
  return Array.isArray(json) ? json[0] : json;
}

// Helpers to read timesheets
async function sbGetTimesheetCurrent(env, booking_id) {
  const url = `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=eq.${encodeURIComponent(booking_id)}&is_current=eq.true&select=*`;
  const { rows } = await sbFetch(env, url);
  return rows[0] || null;
}
async function sbGetTimesheetByVersion(env, booking_id, version) {
  const url = `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=eq.${encodeURIComponent(booking_id)}&version=eq.${encodeURIComponent(version)}&select=*`;
  const { rows } = await sbFetch(env, url);
  return rows[0] || null;
}
async function sbMaxVersion(env, booking_id) {
  const url = `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=eq.${encodeURIComponent(booking_id)}&select=version&order=version.desc&limit=1`;
  const { rows } = await sbFetch(env, url);
  return rows.length ? rows[0].version : 0;
}

// ---------------------- Business rules ----------------------
function isEligibleWindow(worked_end_iso) {
  // Shift must be happening now OR finished within last 4 hours.
  const now = Date.now();
  const end = new Date(worked_end_iso).getTime();
  return now >= end - 1000 * 60 * 60 * 12 && now <= end + 1000 * 60 * 60 * 4;
}
function minutesBetween(aIso, bIso) {
  const a = new Date(aIso).getTime();
  const b = new Date(bIso).getTime();
  return Math.round((b - a) / 60000);
}
function isPng(contentType) {
  return /^image\/png(?:;|$)/i.test(contentType || "");
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// AUTH SECTION (login/forgot/reset/refresh/logout)
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// ENV expected (Option A: Cloudflare Pages frontend + Worker API):
// - SUPABASE_URL
// - SUPABASE_SERVICE_ROLE_KEY
// - ALLOWED_ORIGINS                 (CSV of exact origins for CORS, e.g. "https://tms.example.com")
// - SESSION_TOKEN_SECRET            (HMAC secret for access/refresh tokens)
// - COOKIE_NAME                     (default 'ctms_refresh')
// - COOKIE_DOMAIN                   (e.g. '.example.com' for same-site subdomains)
// - COOKIE_SAME_SITE                ('Lax' recommended for same-site; 'None' if truly cross-site)
// - ACCESS_TTL_SECONDS              (default 900 = 15m)
// - REFRESH_TTL_SECONDS             (default 1209600 = 14d)
// - PASSWORD_RESET_TTL_SECONDS      (default 3600)
// - UPLOAD_TOKEN_SECRET             (HMAC secret for upload/download token mint/verify)
// Bindings:
// - SESSIONS (KV namespace)         (KV for refresh sessions)
// - R2 (bucket for signatures)

const AUTH = {
  USERS_TABLE: 'tms_users',
  RESETS_TABLE: 'tms_password_resets',
};

function pickCookieSameSite(env) {
  const v = String(env.COOKIE_SAME_SITE || 'Lax');
  return (v === 'None' || v === 'Lax' || v === 'Strict') ? v : 'Lax';
}
function cookieName(env){ return String(env.COOKIE_NAME || 'ctms_refresh'); }

function setCookie(headers, name, value, { maxAgeSec, domain, sameSite='Lax', secure=true, httpOnly=true, path='/' } = {}) {
  const parts = [`${name}=${value || ''}`];
  if (path) parts.push(`Path=${path}`);
  if (domain) parts.push(`Domain=${domain}`);
  if (Number.isFinite(maxAgeSec)) parts.push(`Max-Age=${Math.max(0, maxAgeSec|0)}`);
  if (sameSite) parts.push(`SameSite=${sameSite}`);
  if (secure) parts.push('Secure');
  if (httpOnly) parts.push('HttpOnly');
  headers.append('Set-Cookie', parts.join('; '));
}
function parseCookies(req) {
  const raw = req.headers.get('cookie') || '';
  const out = {};
  raw.split(';').map(s => s.trim()).filter(Boolean).forEach(p=>{
    const i = p.indexOf('=');
    const k = i>=0 ? p.slice(0,i).trim() : p;
    const v = i>=0 ? p.slice(i+1) : '';
    out[k] = v;
  });
  return out;
}

// ── Password hashing (PBKDF2-SHA256) ─────────────────────────
const MAX_PBKDF2_ITER = 100000; // Cloudflare limit

async function pbkdf2Hash(password, iterations = 100000) {
  const iters = Math.min(Number(iterations) || 100000, MAX_PBKDF2_ITER);
  const salt = crypto.getRandomValues(new Uint8Array(16));
  const key = await crypto.subtle.importKey('raw', new TextEncoder().encode(password), { name:'PBKDF2' }, false, ['deriveBits']);
  const bits = await crypto.subtle.deriveBits({ name:'PBKDF2', hash:'SHA-256', salt, iterations: iters }, key, 256);
  const hashB64 = bufToBase64Url(bits);
  const saltB64 = bufToBase64Url(salt);
  return `pbkdf2:sha256$${iters}$${saltB64}$${hashB64}`;
}

async function pbkdf2Verify(password, stored) {
  // format: pbkdf2:sha256$ITER$SALT$HASH
  const m = /^pbkdf2:sha256\$(\d+)\$([A-Za-z0-9\-_]+)\$([A-Za-z0-9\-_]+)$/.exec(String(stored||''));
  if (!m) return false;
  const iterations = parseInt(m[1],10);
  const salt = base64UrlToUint8(m[2]);
  const want = base64UrlToUint8(m[3]);
  if (!Number.isFinite(iterations) || iterations <= 0 || iterations > MAX_PBKDF2_ITER) {
    // Iteration count not supported on this platform → treat as mismatch (avoids 500)
    console.warn('PBKDF2 iteration count not supported:', iterations);
    return false;
  }
  try {
    const key = await crypto.subtle.importKey('raw', new TextEncoder().encode(password), { name:'PBKDF2' }, false, ['deriveBits']);
    const bits = await crypto.subtle.deriveBits({ name:'PBKDF2', hash:'SHA-256', salt, iterations }, key, want.byteLength*8);
    const got = new Uint8Array(bits);
    if (got.byteLength !== want.byteLength) return false;
    let diff = 0;
    for (let i=0;i<got.byteLength;i++) diff |= (got[i]^want[i]);
    return diff === 0;
  } catch (e) {
    console.warn('PBKDF2 verify failed:', e);
    return false;
  }
}

// â”€â”€ Supabase helpers for users / resets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function sbAuthHeaders(env){
  const k = env.SUPABASE_SERVICE_ROLE_KEY;
  return { 'apikey': k, 'Authorization': `Bearer ${k}`, 'Content-Type': 'application/json' };
}
async function sbGetUserByEmail(env, email) {
  const url = `${env.SUPABASE_URL}/rest/v1/${AUTH.USERS_TABLE}?email=eq.${encodeURIComponent(email)}&select=id,email,role,is_active,password_hash,session_version`;
  const res = await fetch(url, { headers: sbAuthHeaders(env) });
  const json = await res.json().catch(()=>[]);
  return Array.isArray(json) && json[0] ? json[0] : null;
}
async function sbGetUserById(env, id) {
  const url = `${env.SUPABASE_URL}/rest/v1/${AUTH.USERS_TABLE}?id=eq.${encodeURIComponent(id)}&select=id,email,role,is_active,password_hash,session_version`;
  const res = await fetch(url, { headers: sbAuthHeaders(env) });
  const json = await res.json().catch(()=>[]);
  return Array.isArray(json) && json[0] ? json[0] : null;
}
async function sbUpdateUserPassword(env, user_id, newHash) {
  const url = `${env.SUPABASE_URL}/rest/v1/${AUTH.USERS_TABLE}?id=eq.${encodeURIComponent(user_id)}`;
  const res = await fetch(url, { method:'PATCH', headers: { ...sbAuthHeaders(env), 'Prefer':'return=representation' }, body: JSON.stringify({ password_hash: newHash }) });
  if (!res.ok) throw new Error(`password update failed ${res.status}`);
  // bump session_version:
  const current = await sbGetUserById(env, user_id);
  const svRes = await fetch(url, { method:'PATCH', headers: { ...sbAuthHeaders(env), 'Prefer':'return=representation' }, body: JSON.stringify({ session_version: (current.session_version|0) + 1 }) });
  if (!svRes.ok) throw new Error(`session_version bump failed ${svRes.status}`);
  const j = await svRes.json().catch(()=>[]);
  return Array.isArray(j) && j[0] ? j[0] : null;
}
async function sbInsertResetToken(env, user_id, ttlSec) {
  const token = bufToBase64Url(crypto.getRandomValues(new Uint8Array(32)));
  const expires_at = new Date(Date.now() + (ttlSec*1000)).toISOString();
  const url = `${env.SUPABASE_URL}/rest/v1/${AUTH.RESETS_TABLE}`;
  const row = { user_id, token, expires_at, used_at: null };
  const res = await fetch(url, { method:'POST', headers: { ...sbAuthHeaders(env), 'Prefer':'return=representation' }, body: JSON.stringify(row) });
  if (!res.ok) throw new Error(`insert reset token failed ${res.status}`);
  return token;
}
async function sbConsumeResetToken(env, token) {
  const selUrl = `${env.SUPABASE_URL}/rest/v1/${AUTH.RESETS_TABLE}?token=eq.${encodeURIComponent(token)}&select=id,user_id,expires_at,used_at`;
  const r = await fetch(selUrl, { headers: sbAuthHeaders(env) });
  const arr = await r.json().catch(()=>[]);
  const row = Array.isArray(arr) ? arr[0] : null;
  if (!row) return { ok:false, error:'INVALID_OR_EXPIRED_RESET' };
  if (row.used_at) return { ok:false, error:'INVALID_OR_EXPIRED_RESET' };
  if (new Date(row.expires_at).getTime() < Date.now()) return { ok:false, error:'INVALID_OR_EXPIRED_RESET' };
  const updUrl = `${env.SUPABASE_URL}/rest/v1/${AUTH.RESETS_TABLE}?id=eq.${encodeURIComponent(row.id)}`;
  const u = await fetch(updUrl, { method:'PATCH', headers: { ...sbAuthHeaders(env), 'Prefer':'return=representation' }, body: JSON.stringify({ used_at: new Date().toISOString() }) });
  if (!u.ok) return { ok:false, error:'RESET_CONSUME_FAILED' };
  return { ok:true, user_id: row.user_id };
}

// â”€â”€ Access/Refresh tokens (HMAC) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function accessTtl(env){ return parseInt(env.ACCESS_TTL_SECONDS || '900', 10) || 900; }          // 15m
function refreshTtl(env){ return parseInt(env.REFRESH_TTL_SECONDS || '1209600', 10) || 1209600; } // 14d
function resetTtl(env){ return parseInt(env.PASSWORD_RESET_TTL_SECONDS || '3600', 10) || 3600; }   // 60m
function sessionSecret(env){ return String(env.SESSION_TOKEN_SECRET); }

async function mintAccessToken(env, { user_id, email, role, sv, sid }) {
  const exp = Math.floor(Date.now()/1000) + accessTtl(env);
  const payload = { typ:'access', sub:user_id, email, role, sv, sid, iat: Math.floor(Date.now()/1000), exp };
  const token = await createToken(sessionSecret(env), payload);
  return { token, exp };
}
async function mintRefreshToken(env, { sid, sv }) {
  const exp = Math.floor(Date.now()/1000) + refreshTtl(env);
  const payload = { typ:'refresh', sid, sv, iat: Math.floor(Date.now()/1000), exp };
  const token = await createToken(sessionSecret(env), payload);
  return { token, exp };
}

// Bearer access-token guard for /api/* routes
async function requireUser(env, req, allowedRoles = []) {
  const hdr = req.headers.get('authorization') || '';
  const m = hdr.match(/^Bearer\s+(.+)$/i);
  if (!m) return null;

  const ver = await verifyToken(sessionSecret(env), m[1]);
  if (!ver.ok) return null;

  const p = ver.payload || {};
  if (p.typ !== 'access' || !p.sub) return null;

  // Ensure the user still exists, is active, and session_version matches
  const user = await sbGetUserById(env, p.sub);
  if (!user || user.is_active !== true) return null;
  if ((user.session_version|0) !== (p.sv|0)) return null;

  if (Array.isArray(allowedRoles) && allowedRoles.length && !allowedRoles.includes(user.role)) return null;
  return { id: user.id, email: user.email, role: user.role, sv: user.session_version|0, sid: p.sid };
}

// KV session helpers (store sid → { user_id, sv, exp })
async function kvPutSession(env, sid, data, ttlSec) {

  await env.SESSIONS.put(`sid:${sid}`, JSON.stringify(data), { expirationTtl: ttlSec });
}
async function kvGetSession(env, sid) {
  const t = await env.SESSIONS.get(`sid:${sid}`);
  return t ? JSON.parse(t) : null;
}
async function kvDelSession(env, sid) {
  await env.SESSIONS.delete(`sid:${sid}`);
}

// â”€â”€ Auth handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function handleAuthLogin(env, req) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;
  const body = await parseJSONBody(req);
  if (!body) return badRequest('invalid_json');

  const email = String((body.email||'')).trim().toLowerCase();
  const pw    = String(body.password||'');
  if (!email || !pw) return badRequest('email_and_password_required');

  const user = await sbGetUserByEmail(env, email);
  if (!user || user.is_active !== true) return unauthorized('Invalid credentials');

  const okPw = await pbkdf2Verify(pw, user.password_hash || '');
  if (!okPw) return unauthorized('Invalid credentials');

  // ✅ Best-effort: stamp last_login_at_utc (non-fatal if column not deployed yet)
  try {
    const nowIso = new Date().toISOString();
    const url = `${env.SUPABASE_URL}/rest/v1/${AUTH.USERS_TABLE}?id=eq.${encodeURIComponent(user.id)}`;
    await fetch(url, {
      method: 'PATCH',
      headers: { ...sbAuthHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({
        last_login_at_utc: nowIso,
        updated_at: nowIso
      })
    }).catch(() => {});
  } catch (_) {
    // ignore: never block login on telemetry update
  }

  // Create KV session + tokens
  const sid = bufToBase64Url(crypto.getRandomValues(new Uint8Array(16)));
  const sv  = user.session_version|0 || 1;
  const refresh = await mintRefreshToken(env, { sid, sv });
  const access  = await mintAccessToken(env, { user_id: user.id, email: user.email, role: user.role, sv, sid });

  await kvPutSession(env, sid, { user_id: user.id, sv, exp: refresh.exp }, refreshTtl(env));

  const headers = new Headers(JSON_HEADERS);
  setCookie(headers, cookieName(env), refresh.token, {
    maxAgeSec: refreshTtl(env),
    domain: env.COOKIE_DOMAIN || undefined,
    sameSite: pickCookieSameSite(env),
    secure: true,
    httpOnly: true,
    path: '/'
  });

  return new Response(JSON.stringify({
    ok: true,
    access_token: access.token,
    expires_in: accessTtl(env),
    user: { id: user.id, email: user.email, role: user.role }
  }), { status: 200, headers });
}

async function handleAuthRefresh(env, req) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;
  const cookies = parseCookies(req);
  const raw = cookies[cookieName(env)];
  if (!raw) return unauthorized('No refresh cookie');

  const ver = await verifyToken(sessionSecret(env), raw);
  if (!ver.ok) return unauthorized('Invalid refresh token');
  const { typ, sid, sv, exp } = ver.payload || {};
  if (typ !== 'refresh' || !sid) return unauthorized('Invalid refresh claims');
  if ((exp|0) <= Math.floor(Date.now()/1000)) return unauthorized('Refresh expired');

  const sess = await kvGetSession(env, sid);
  if (!sess) return unauthorized('Session not found');

  // Check session_version still valid
  const user = await sbGetUserById(env, sess.user_id);
  if (!user || user.is_active !== true) return unauthorized('User disabled');
  if ((user.session_version|0) !== (sv|0)) {
    await kvDelSession(env, sid);
    return unauthorized('Session version changed');
  }

  const access = await mintAccessToken(env, {
    user_id: user.id, email: user.email, role: user.role, sv, sid
  });

  const headers = new Headers(JSON_HEADERS);
  // Optional: rotate refresh if near expiry (<3d)
  const secondsLeft = exp - Math.floor(Date.now()/1000);
  if (secondsLeft < (3*24*60*60)) {
    const next = await mintRefreshToken(env, { sid, sv });
    await kvPutSession(env, sid, { user_id: user.id, sv, exp: next.exp }, refreshTtl(env));
    setCookie(headers, cookieName(env), next.token, {
      maxAgeSec: refreshTtl(env),
      domain: env.COOKIE_DOMAIN || undefined,
      sameSite: pickCookieSameSite(env),
      secure: true, httpOnly: true, path:'/'
    });
  }

  return new Response(JSON.stringify({
    access_token: access.token,
    expires_in: accessTtl(env),
    user: { id: user.id, email: user.email, role: user.role }
  }), { status: 200, headers });
}

async function handleAuthLogout(env, req) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;
  const cookies = parseCookies(req);
  const raw = cookies[cookieName(env)];
  if (raw) {
    const ver = await verifyToken(sessionSecret(env), raw);
    if (ver.ok && ver.payload && ver.payload.sid) {
      await kvDelSession(env, ver.payload.sid);
    }
  }
  const headers = new Headers(JSON_HEADERS);
  setCookie(headers, cookieName(env), '', {
    maxAgeSec: 0, domain: env.COOKIE_DOMAIN || undefined, sameSite: pickCookieSameSite(env), secure:true, httpOnly:true, path:'/'
  });
  return new Response(JSON.stringify({ ok:true }), { status:200, headers });
}

async function handleAuthForgot(env, req) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;
  const body = await parseJSONBody(req);
  if (!body) return badRequest('invalid_json');
  const email = String((body.email||'')).trim().toLowerCase();
  if (!email) return badRequest('email_required');

  const user = await sbGetUserByEmail(env, email);
  if (user && user.is_active === true) {
    await sbInsertResetToken(env, user.id, resetTtl(env));
    // Send email via your mailer with a link containing ?k=<token> (not implemented here)
  }
  return ok({ ok:true }); // privacy-safe
}

async function handleAuthReset(env, req) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;
  const body = await parseJSONBody(req);
  if (!body) return badRequest('invalid_json');

  const token = String(body.token||'');
  const newPw = String(body.new_password||'');
  if (!token || !newPw) return badRequest('token_and_new_password_required');

  const strong = newPw.length>=8 && /[a-z]/.test(newPw) && /[A-Z]/.test(newPw) && /[0-9]/.test(newPw);
  if (!strong) return new Response(JSON.stringify({ ok:false, error:'WEAK_PASSWORD' }), { status:400, headers: JSON_HEADERS });

  const consumed = await sbConsumeResetToken(env, token);
  if (!consumed.ok) return new Response(JSON.stringify({ ok:false, error: consumed.error }), { status:400, headers: JSON_HEADERS });

  const hash = await pbkdf2Hash(newPw);
  await sbUpdateUserPassword(env, consumed.user_id, hash);

  return ok({ ok:true });
}

// ---------------------- UK timezone check ----------------------
async function handleUKTimeCheck(env, req) {
  const body = await parseJSONBody(req);
  if (!body) return withCORS(env, req, badRequest('invalid_json'));

  const phone_tz = String(body.phone_tz || '');
  const phone_epoch_ms = Number(body.phone_epoch_ms);
  const tolerance_ms = Math.max(0, Number(env.UK_TZ_SKEW_MS ?? 180000));

  const broker_epoch_ms = Date.now();
  const broker_tz = 'Europe/London';

  const tzOk = phone_tz === broker_tz;
  const skew_ms = Number.isFinite(phone_epoch_ms)
    ? Math.abs(broker_epoch_ms - phone_epoch_ms)
    : NaN;
  const skewOk = Number.isFinite(skew_ms) && skew_ms <= tolerance_ms;

  const valid = tzOk && skewOk;
  const reason = valid
    ? 'ok'
    : (!tzOk ? 'tz_mismatch' : (!Number.isFinite(skew_ms) ? 'invalid_phone_epoch' : 'clock_skew'));

  return withCORS(env, req, ok({
    valid,
    reason,
    tolerance_ms,
    skew_ms,
    broker_epoch_ms,
    broker_tz,
  }));
}

// ---------------------- Query builder for list ----------------------
function buildTimesheetsQuery(env, q) {
  const url = new URL(`${env.SUPABASE_URL}/rest/v1/timesheets`);
  url.searchParams.set("select", "*");

  const add = (k, v) => url.searchParams.set(k, v);

  if (q.booking_id) add("booking_id", `eq.${q.booking_id}`);
  if (q.booking_ids && q.booking_ids.length) add("booking_id", `in.(${q.booking_ids.map(encodeURIComponent).join(",")})`);

  if (q.candidate_id) add("occupant_key_norm", `eq.${q.candidate_id}`);
  if (q.candidate_ids && q.candidate_ids.length) add("occupant_key_norm", `in.(${q.candidate_ids.map(encodeURIComponent).join(",")})`);

  if (q.week_ending) add("week_ending_date", `eq.${q.week_ending}`);
  if (q.week_endings && q.week_endings.length) add("week_ending_date", `in.(${q.week_endings.map(encodeURIComponent).join(",")})`);

  if (q.status) add("status", `eq.${q.status}`);
  if (q.statuses && q.statuses.length) add("status", `in.(${q.statuses.map(encodeURIComponent).join(",")})`);

  if (q.job_title) add("job_title_norm", `eq.${q.job_title}`);
  if (q.job_titles && q.job_titles.length) add("job_title_norm", `in.(${q.job_titles.map(encodeURIComponent).join(",")})`);

  const hospMode = q.hospital_match || "contains";
  if (q.hospital) {
    if (hospMode === "exact") add("hospital_norm", `eq.${q.hospital.toLowerCase()}`);
    else if (hospMode === "prefix") add("hospital_norm", `like.${q.hospital.toLowerCase()}%`);
    else add("hospital_norm", `like.%${q.hospital.toLowerCase()}%`);
  }
  const wardMode = q.ward_match || "contains";
  if (q.ward) {
    if (wardMode === "exact") add("ward_norm", `eq.${q.ward.toLowerCase()}`);
    else if (wardMode === "prefix") add("ward_norm", `like.${q.ward.toLowerCase()}%`);
    else add("ward_norm", `like.%${q.ward.toLowerCase()}%`);
  }

  if (q.version) add("version", `eq.${q.version}`);
  else if (String(q.current_only ?? "true").toLowerCase() !== "false") add("is_current", "eq.true");

  if (q.sort) {
    const col = q.sort;
    const ord = q.order === "asc" ? "asc" : "desc";
    url.searchParams.set("order", `${col}.${ord}`);
  }
  const limit = Math.min(parseInt(q.limit || "50", 10) || 50, 200);
  const offset = parseInt(q.offset || "0", 10) || 0;
  url.searchParams.set("limit", String(limit));
  url.searchParams.set("offset", String(offset));

  return url.toString();
}

// ---------------------- Upload/submit/presign ----------------------
async function handlePresign(env, req) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;

  const body = await parseJSONBody(req);
  if (!body) return withCORS(env, req, badRequest("Invalid JSON"));

  const {
    occupant_key: candidate_id,
    date_start_local,  // YYYY-MM-DD (local)
    hospital,
    ward,
    job_title,
    shift_label = "",
    resubmission_of,
  } = body;

  if (!candidate_id || !date_start_local || !hospital || !ward || !job_title) {
    return withCORS(env, req, badRequest("Missing required fields"));
  }

  const booking_id = resubmission_of || await makeBookingId(candidate_id, date_start_local, hospital, ward, job_title, shift_label);
  const week_ending_date = weekEndingSunday(date_start_local);
  const weCompact = week_ending_date.replace(/-/g, "");

  const maxV = await sbMaxVersion(env, booking_id);
  const version = maxV > 0 ? maxV + 1 : 1;

   const nurseKey = `Signatures/we=${weCompact}/${booking_id}/v${version}/nurse.png`;
  const authKey  = `Signatures/we=${weCompact}/${booking_id}/v${version}/authoriser.png`;


  const maxBytes = parseInt(env.UPLOAD_MAX_BYTES || "300000", 10);
  const expiresSec = parseInt(env.PRESIGN_EXPIRES_SECONDS || "600", 10);
  const exp = Math.floor(Date.now() / 1000) + expiresSec;
  const secret = env.UPLOAD_TOKEN_SECRET;

  const nurseToken = await createToken(secret, { typ: "upload", booking_id, version, role: "nurse", key: nurseKey, exp });
  const authToken  = await createToken(secret, { typ: "upload", booking_id, version, role: "authoriser", key: authKey, exp });

  const uploadBase = new URL(req.url);
  uploadBase.pathname = "/upload";
  const mkUrl = (key, token, role) => {
    const u = new URL(uploadBase);
    u.searchParams.set("key", key);
    u.searchParams.set("booking_id", booking_id);
    u.searchParams.set("version", String(version));
    u.searchParams.set("role", role);
    u.searchParams.set("token", token);
    return u.toString();
  };

  return withCORS(env, req, ok({
    booking_id,
    version,
    week_ending_date,
    upload: {
      content_type: "image/png",
      max_bytes: maxBytes,
      expires_at: new Date(exp * 1000).toISOString(),
      nurse: { key: nurseKey, put_url: mkUrl(nurseKey, nurseToken, "nurse"), token: nurseToken },
      authoriser: { key: authKey, put_url: mkUrl(authKey, authToken, "authoriser"), token: authToken },
    },
  }));
}

async function handleUpload(env, req, url) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;

  const key = url.searchParams.get("key") || "";
  const booking_id = url.searchParams.get("booking_id") || "";
  const role = url.searchParams.get("role") || "";
  const token = url.searchParams.get("token") || "";

  const secret = env.UPLOAD_TOKEN_SECRET;
  const ver = await verifyToken(secret, token);
  if (!ver.ok) return withCORS(env, req, unauthorized("Invalid token"));
  const p = ver.payload;
  if (p.typ !== "upload" || p.booking_id !== booking_id || p.role !== role || p.key !== key) {
    return withCORS(env, req, unauthorized("Token mismatch"));
  }

  const keyOk = /^Signatures\/we=\d{8}\/bk_[a-f0-9]{16}(?:\/v\d+)?\/(nurse|authoriser)\.png$/.test(key);
  if (!keyOk) return withCORS(env, req, badRequest("Invalid key"));


  const ct = req.headers.get("content-type") || "";
  if (!isPng(ct)) return withCORS(env, req, unsupported("Only image/png allowed"));

  const maxBytes = parseInt(env.UPLOAD_MAX_BYTES || "300000", 10);
  const contentLength = parseInt(req.headers.get("content-length") || "0", 10);
  if (contentLength > maxBytes) return withCORS(env, req, tooLarge(`Max ${maxBytes} bytes`));

  const requireMd5 = String(env.REQUIRE_MD5 || "false").toLowerCase() === "true";
  const md5 = req.headers.get("content-md5");
  if (requireMd5 && !md5) return withCORS(env, req, badRequest("Content-MD5 required"));

  const we = (key.match(/^Signatures\/we=(\d{8})\//) || [])[1];
  const versionMatch = key.match(/\/v(\d+)\//);
  const version = versionMatch ? parseInt(versionMatch[1], 10) : 1;
  const week_ending_date = we ? `${we.slice(0,4)}-${we.slice(4,6)}-${we.slice(6,8)}` : undefined;

  const putRes = await r2Put(env, key, req.body, {
    httpMetadata: { contentType: "image/png" },
    customMetadata: {
      bookingid: booking_id,
      weekending: week_ending_date || "",
      role,
      version: String(version),
    },
  });
  const size = contentLength || undefined;
  return withCORS(env, req, ok({ ok: true, role, key, etag: putRes?.etag, size, version }));
}


async function handleSubmit(env, req) {
  const pre = preflightIfNeeded(env, req);
  if (pre) return pre;

  const body = await parseJSONBody(req);
  if (!body) return withCORS(env, req, badRequest("Invalid JSON"));

  const required = [
    "booking_id", "scheduled_start_iso", "scheduled_end_iso",
    "worked_start_iso", "worked_end_iso",
    "break_start_iso", "break_end_iso",
    "auth_name", "auth_job_title", "nurse_key", "authoriser_key", "idempotency_key"
  ];
  for (const k of required) if (!body[k]) return withCORS(env, req, badRequest(`Missing ${k}`));

  if (!isEligibleWindow(body.worked_end_iso)) {
    return withCORS(env, req, new Response(JSON.stringify({
      error: "Shift not in eligible window (must be ongoing or ended ≤ 4h)",
      code: "INELIGIBLE"
    }), { status: 422, headers: JSON_HEADERS }));
  }

  const nurseHead = await r2Head(env, body.nurse_key);
  const authHead  = await r2Head(env, body.authoriser_key);
  if (!nurseHead || !authHead) return withCORS(env, req, badRequest("Signatures not uploaded"));

  const worked_date_local = londonDate(body.worked_start_iso);
  const week_ending_date  = weekEndingSunday(worked_date_local);
  const break_minutes     = minutesBetween(body.break_start_iso, body.break_end_iso);
  const worked_minutes    = minutesBetween(body.worked_start_iso, body.worked_end_iso);
  const break_expected    = parseInt(env.BREAK_EXPECTED_MINUTES || "60", 10);

  let version = parseInt(body.version || "0", 10);
  if (!version || Number.isNaN(version)) {
    const m = body.nurse_key.match(/\/v(\d+)\//) || body.authoriser_key.match(/\/v(\d+)\//);
    version = m ? parseInt(m[1], 10) : 1;
  }

  const current = await sbGetTimesheetCurrent(env, body.booking_id);
  if (current && current.is_current === true) {
    const maxV = await sbMaxVersion(env, body.booking_id);
    if (maxV >= 1) {
      return withCORS(env, req, conflict("A current timesheet exists for this booking. Revoke before resubmitting."));
    }
  }

  const authorised_at_server = new Date().toISOString();

  const row = {
    booking_id: body.booking_id,
    version,
    is_current: true,

    // ✅ Explicitly classify this as DAILY + ELECTRONIC (so admin UI + routes behave correctly)
    sheet_scope: "DAILY",
    submission_mode: "ELECTRONIC",

    occupant_key_norm: (body.candidate_id || body.occupant_key || "").toLowerCase(),
    hospital_norm: (body.hospital || "").toLowerCase(),
    ward_norm: (body.ward || "").toLowerCase(),
    job_title_norm: (body.job_title || "").toLowerCase(),
    shift_label_norm: (body.shift_label || "").toLowerCase() || null,

    scheduled_start_iso: body.scheduled_start_iso,
    scheduled_end_iso: body.scheduled_end_iso,
    worked_start_iso: body.worked_start_iso,
    worked_end_iso: body.worked_end_iso,
    break_start_iso: body.break_start_iso,
    break_end_iso: body.break_end_iso,
    break_minutes,
    worked_minutes,

    week_ending_date,

    auth_name: body.auth_name,
    auth_job_title: body.auth_job_title,
    authorised_at_server,

    r2_nurse_key: body.nurse_key,
    r2_auth_key: body.authoriser_key,

    // ✅ MUST match timesheet_status_enum (no "SUBMITTED" in your DB enum)
    status: "RECEIVED",

    idempotency_key: body.idempotency_key,
    client_hash: body.client_hash || null,
    client_ua: body.client_user_agent || req.headers.get("user-agent") || "",

    // ✅ Keep NOT NULL safe + avoid default QR “PENDING” making it look like QR
    qr_payload_json: {},
    qr_status: null,
    qr_token: null,
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null
  };

  let ts;
  try {
    ts = await sbUpsertTimesheet(env, row);
  } catch (e) {
    return withCORS(env, req, serverError(`DB upsert failed: ${e.message}`));
  }

  const ts_id = ts?.timesheet_id || null;

  // ─────────────────────────────────────────────────────────────
  // ✅ TIMESHEET TAB AUDIT (minimal + meaningful)
  // Action: TIMESHEET_CREATED (source: daily electronic submit)
  // ─────────────────────────────────────────────────────────────
  try {
    // Actor is not a tms_user here (public submit), so label as mobile submitter.
    const auditActor = {
      id: null,
      display_name: (body.occupant_key || body.candidate_id || "Mobile submit"),
      email: null,
      role: "mobile"
    };

    if (ts_id) {
      await writeAudit(
        env,
        auditActor,
        "TIMESHEET_CREATED",
        {
          source: "DAILY_ELECTRONIC_SUBMIT",
          timesheet_id: ts_id,
          booking_id: body.booking_id,
          sheet_scope: "DAILY",
          submission_mode: "ELECTRONIC",
          version,
          week_ending_date,
          worked_start_iso: body.worked_start_iso,
          worked_end_iso: body.worked_end_iso,
          break_minutes,
          authorised_at_server,
          idempotency_key: body.idempotency_key
        },
        {
          entity: "timesheets",
          subject_id: ts_id,
          correlation_id: body.idempotency_key,
          req
        }
      );
    }
  } catch {
    // best-effort
  }

  return withCORS(env, req, ok({
    ok: true,
    timesheet_id: ts_id,
    status: "RECEIVED",
    break_ok: break_minutes === break_expected,
    version
  }));
}

// ---------------------- Revoke flows ----------------------
async function handleRevoke(env, req) {
  const body = await parseJSONBody(req);
  if (!body) return badRequest("Invalid JSON");
  const { booking_id, reason = null, actor = "candidate" } = body;
  if (!booking_id) return badRequest("booking_id required");

  const current = await sbGetTimesheetCurrent(env, booking_id);
  if (!current) return notFound("No current timesheet to revoke");

  const url = `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=eq.${encodeURIComponent(booking_id)}&is_current=eq.true`;
  const patch = {
    is_current: false,
    status: "REVOKED",
    revoked_at: new Date().toISOString(),
    revoked_reason: reason,
    revoked_by: actor,
  };
  const res = await fetch(url, {
    method: "PATCH",
    headers: { ...sbHeaders(env), "Prefer": "return=representation" },
    body: JSON.stringify(patch),
  });
  if (!res.ok) {
    const t = await res.text().catch(() => "");
    return serverError(`Revoke failed: ${res.status} ${t}`);
  }
  const json = await res.json().catch(() => []);
  const revoked = Array.isArray(json) ? json[0] : json;

  const next_version = (await sbMaxVersion(env, booking_id)) + 1;
  return ok({ ok: true, booking_id, current_revoked: true, timesheet_id: revoked?.timesheet_id || null, next_version });
}

async function handleRevokeAndPresign(env, req) {
  const pre = preflightIfNeeded(env, req); if (pre) return pre;
  const body = await parseJSONBody(req);
  if (!body) return withCORS(env, req, badRequest("Invalid JSON"));
  const { booking_id, reason = null, actor = "candidate" } = body;
  if (!booking_id) return withCORS(env, req, badRequest("booking_id required"));

  const current = await sbGetTimesheetCurrent(env, booking_id);
  if (!current) return withCORS(env, req, notFound("No current timesheet to revoke"));

  const url = `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=eq.${encodeURIComponent(booking_id)}&is_current=eq.true`;
  const patch = { is_current: false, status: "REVOKED", revoked_at: new Date().toISOString(), revoked_reason: reason, revoked_by: actor };
  const res = await fetch(url, { method: "PATCH", headers: { ...sbHeaders(env), "Prefer": "return=representation" }, body: JSON.stringify(patch) });
  if (!res.ok) {
    const t = await res.text().catch(() => "");
    return withCORS(env, req, serverError(`Revoke failed: ${res.status} ${t}`));
  }

  const next_version = (await sbMaxVersion(env, booking_id)) + 1;
  const week_ending_date = current.week_ending_date;
  const weCompact = week_ending_date.replace(/-/g, "");
   const nurseKey = `Signatures/we=${weCompact}/${booking_id}/v${next_version}/nurse.png`;
  const authKey  = `Signatures/we=${weCompact}/${booking_id}/v${next_version}/authoriser.png`;


  const maxBytes = parseInt(env.UPLOAD_MAX_BYTES || "300000", 10);
  const expiresSec = parseInt(env.PRESIGN_EXPIRES_SECONDS || "600", 10);
  const exp = Math.floor(Date.now() / 1000) + expiresSec;
  const secret = env.UPLOAD_TOKEN_SECRET;
  const nurseToken = await createToken(secret, { typ: "upload", booking_id, version: next_version, role: "nurse", key: nurseKey, exp });
  const authToken  = await createToken(secret, { typ: "upload", booking_id, version: next_version, role: "authoriser", key: authKey, exp });

  const base = new URL(req.url); base.pathname = "/upload";
  const mkUrl = (key, token, role) => {
    const u = new URL(base);
    u.searchParams.set("key", key);
    u.searchParams.set("booking_id", booking_id);
    u.searchParams.set("version", String(next_version));
    u.searchParams.set("role", role);
    u.searchParams.set("token", token);
    return u.toString();
  };

  return withCORS(env, req, ok({
    ok: true,
    booking_id,
    version: next_version,
    week_ending_date,
    upload: {
      content_type: "image/png",
      max_bytes: maxBytes,
      expires_at: new Date(exp * 1000).toISOString(),
      nurse: { key: nurseKey, put_url: mkUrl(nurseKey, nurseToken, "nurse"), token: nurseToken },
      authoriser: { key: authKey, put_url: mkUrl(authKey, authToken, "authoriser"), token: authToken },
    },
  }));
}

// ---------------------- Reads ----------------------
async function handleGetOne(env, req, booking_id, url) {
  const version = url.searchParams.get("version");
  const currentOnly = String(url.searchParams.get("current_only") ?? "true").toLowerCase() !== "false";

  let row = null;
  if (version) row = await sbGetTimesheetByVersion(env, booking_id, parseInt(version, 10));
  else if (currentOnly) row = await sbGetTimesheetCurrent(env, booking_id);
  else {
    const u = `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=eq.${encodeURIComponent(booking_id)}&select=*&order=version.desc&limit=10`;
    const { rows } = await sbFetch(env, u);
    row = rows;
  }
  if (!row || (Array.isArray(row) && !row.length)) return withCORS(env, req, notFound("Timesheet not found"));
  return withCORS(env, req, ok(row));
}

// ─────────────────────────────────────────────────────────────────────────────
// Timesheets: list with optional sign keys/urls
// ─────────────────────────────────────────────────────────────────────────────
async function handleList(env, req, url) {
  // Admin-only (exposes keys/URLs when requested)
  const user = await requireUser(env, req, ["admin"]);
  if (!user) return withCORS(env, req, unauthorized());

  const q = Object.fromEntries(url.searchParams.entries());
  const sbUrl = buildTimesheetsQuery(env, q);

  const includeCount = String(q.include_count ?? "false").toLowerCase() === "true";
  const { rows, total } = await sbFetch(env, sbUrl, includeCount);

  const include = new Set(String(q.include || "").split(",").map(s => s.trim()).filter(Boolean));
  const sign_which = String(q.sign_which || "both").toLowerCase();

  // Clamp expiry: 60s–900s, default 180s
  const expReq = parseInt(q.sign_expires_seconds || "180", 10);
  const sign_exp = Math.max(60, Math.min(Number.isFinite(expReq) ? expReq : 180, 900));

  const secret = env.UPLOAD_TOKEN_SECRET;
  if (!secret && include.has("sign_urls")) {
    return withCORS(env, req, serverError("UPLOAD_TOKEN_SECRET not configured"));
  }

  const items = await Promise.all(
    rows.map(async (r) => {
      const have = { nurse: !!r.r2_nurse_key, authoriser: !!r.r2_auth_key };
      const out = { ...r, signatures: { have } };

      if (include.has("sign_keys")) {
        out.signatures.keys = {
          nurse: r.r2_nurse_key || null,
          authoriser: r.r2_auth_key || null
        };
      }

      if (include.has("sign_urls")) {
        const addUrl = async (which, key) => {
          if (!key) return null;
          const exp = Math.floor(Date.now() / 1000) + sign_exp;
          const token = await createToken(secret, {
            typ: "dl",
            booking_id: r.booking_id,
            role: which,
            key,
            exp,
          });
          const u = new URL(req.url);
          u.pathname = "/signatures/get";
          u.search = "";
          u.searchParams.set("key", key);
          u.searchParams.set("booking_id", r.booking_id);
          u.searchParams.set("role", which);
          u.searchParams.set("token", token);
          return u.toString();
        };

        const urls = {};
        if (sign_which === "both" || sign_which === "nurse") {
          urls.nurse = await addUrl("nurse", r.r2_nurse_key);
        }
        if (sign_which === "both" || sign_which === "authoriser") {
          urls.authoriser = await addUrl("authoriser", r.r2_auth_key);
        }
        out.signatures.urls = urls;
      }

      return out;
    })
  );

  const resp = includeCount ? { items, count: total ?? undefined } : { items };
  return withCORS(env, req, ok(resp));
}

async function handleQuery(env, req) {
  const body = await parseJSONBody(req);
  if (!body) return badRequest("Invalid JSON");
  const q = { ...body };
  if (Array.isArray(q.booking_ids) && q.booking_ids.length > 0) q.booking_ids = q.booking_ids.slice(0, 500);
  const sbUrl = buildTimesheetsQuery(env, q);
  const { rows } = await sbFetch(env, sbUrl, !!q.include_count);
  return ok({ items: rows });
}

async function handleAuthorisedStatus(env, req) {
  const body = await parseJSONBody(req);
  if (!body || !Array.isArray(body.booking_ids) || !body.booking_ids.length) return badRequest("booking_ids array required");
  const ids = body.booking_ids.slice(0, 1000);
  const url = `${env.SUPABASE_URL}/rest/v1/timesheets?booking_id=in.(${ids.map(encodeURIComponent).join(",")})&select=booking_id,authorised_at_server`;
  const { rows } = await sbFetch(env, url);
  const map = {};
  for (const r of rows) map[r.booking_id] = !!r.authorised_at_server;
  for (const id of ids) if (!(id in map)) map[id] = false;
  return ok({ statuses: map });
}

// ---------------------- Signatures: presign GET + proxy GET ----------------------
async function handleSignPresignGet(env, req) {
  try {
    const body = await parseJSONBody(req);
    if (!body) return withCORS(env, req, badRequest("Invalid JSON"));

    const {
      booking_id,
      which = "nurse",
      version = null,
      expires_seconds = 180
    } = body;

    if (!booking_id || !["nurse", "authoriser"].includes(which)) {
      return withCORS(env, req, badRequest("booking_id and which required"));
    }

    const row = version
      ? await sbGetTimesheetByVersion(env, booking_id, parseInt(version, 10))
      : await sbGetTimesheetCurrent(env, booking_id);

    if (!row) return withCORS(env, req, notFound("Timesheet not found"));

    const keyRaw = (which === "nurse" ? row.r2_nurse_key : row.r2_auth_key);
    if (!keyRaw) return withCORS(env, req, notFound("Signature not found"));

    // ✅ IMPORTANT: normalise leading slash
    const key = String(keyRaw).trim().replace(/^\/+/, "");
    if (!key) return withCORS(env, req, notFound("Signature not found"));

    const exp = Math.min(parseInt(expires_seconds, 10) || 180, 900);
    const tokenExp = Math.floor(Date.now() / 1000) + exp;

    const secret = env.UPLOAD_TOKEN_SECRET;
    const token = await createToken(secret, {
      typ: "dl",
      booking_id,
      role: which,
      key,
      exp: tokenExp
    });

    const u = new URL(req.url);
    u.pathname = "/signatures/get";
    u.search = "";
    u.searchParams.set("key", key);
    u.searchParams.set("booking_id", booking_id);
    u.searchParams.set("role", which);
    u.searchParams.set("token", token);

    return withCORS(env, req, ok({
      booking_id,
      which,
      get_url: u.toString(),
      expires_at: new Date(tokenExp * 1000).toISOString()
    }));
  } catch (e) {
    // ensure errors still return CORS
    return withCORS(env, req, serverError(e?.message || "Failed to presign signature"));
  }
}
async function handleSignPresignGetBatch(env, req) {
  try {
    const body = await parseJSONBody(req);
    if (!body || !Array.isArray(body.items) || !body.items.length) {
      return withCORS(env, req, badRequest("items array required"));
    }

    const items = body.items.slice(0, 100);
    const exp = Math.min(parseInt(body.expires_seconds || "300", 10) || 300, 900);
    const secret = env.UPLOAD_TOKEN_SECRET;

    const out = [];
    const not_found = [];

    for (const it of items) {
      const booking_id = it?.booking_id;
      const which = it?.which || "nurse";
      const version = it?.version != null ? parseInt(it.version, 10) : null;

      if (!booking_id || !["nurse", "authoriser"].includes(which)) continue;

      const row = (Number.isFinite(version) && version != null)
        ? await sbGetTimesheetByVersion(env, booking_id, version)
        : await sbGetTimesheetCurrent(env, booking_id);

      if (!row) { not_found.push(booking_id); continue; }

      const keyRaw = (which === "nurse" ? row.r2_nurse_key : row.r2_auth_key);
      if (!keyRaw) { not_found.push(booking_id); continue; }

      // ✅ IMPORTANT: normalise leading slash (R2 keys must not start with "/")
      const key = String(keyRaw).trim().replace(/^\/+/, "");
      if (!key) { not_found.push(booking_id); continue; }

      const tokenExp = Math.floor(Date.now() / 1000) + exp;
      const token = await createToken(secret, { typ: "dl", booking_id, role: which, key, exp: tokenExp });

      const u = new URL(req.url);
      u.pathname = "/signatures/get";
      u.search = "";
      u.searchParams.set("key", key);
      u.searchParams.set("booking_id", booking_id);
      u.searchParams.set("role", which);
      u.searchParams.set("token", token);

      out.push({
        booking_id,
        which,
        version: row.version,
        get_url: u.toString(),
        expires_at: new Date(tokenExp * 1000).toISOString()
      });
    }

    return withCORS(env, req, ok({ links: out, not_found }));
  } catch (e) {
    return withCORS(env, req, serverError(e?.message || "Failed to presign signature batch"));
  }
}


// ====================== CLIENTS ======================
/**
 * @openapi
 * /api/clients:
 *   get:
 *     summary: List clients
 *     tags: [Clients]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: include_count
 *         schema: { type: boolean }
 *       - in: query
 *         name: limit
 *         schema: { type: integer, minimum: 1, maximum: 200 }
 *       - in: query
 *         name: offset
 *         schema: { type: integer, minimum: 0 }
 *     responses:
 *       200:
 *         description: List of clients
 *   post:
 *     summary: Create client
 *     tags: [Clients]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *     responses:
 *       200:
 *         description: Created client
 */
async function handleListClients(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const params = new URL(req.url).searchParams;
  const includeCount = params.get('include_count') === 'true';

  // Support page/page_size and legacy limit/offset
  const pageRaw      = parseInt(params.get('page') || '1', 10);
  const pageSizeRaw  = params.get('page_size');
  const legacyLimit  = parseInt(params.get('limit')  || '50', 10);
  const legacyOffset = parseInt(params.get('offset') || '0',  10);

  const page     = Math.max(1, isNaN(pageRaw) ? 1 : pageRaw);
  const pageSize = pageSizeRaw != null ? Math.max(1, Math.min(200, parseInt(pageSizeRaw, 10) || 50)) : null;
  const limit    = pageSize != null ? pageSize : Math.max(1, Math.min(200, isNaN(legacyLimit) ? 50 : legacyLimit));
  const offset   = pageSize != null ? (page - 1) * limit : Math.max(0, isNaN(legacyOffset) ? 0 : legacyOffset);

  const url = new URL(`${env.SUPABASE_URL}/rest/v1/clients`);
  url.searchParams.set('select', '*');      // include all columns (e.g., ts_queries_email)
  url.searchParams.set('order',  'name.asc');
  url.searchParams.set('limit',  String(limit));
  url.searchParams.set('offset', String(offset));

  try {
    const { rows, total } = await sbFetch(env, url.toString(), includeCount);
    const resp = includeCount ? { items: rows, count: total ?? undefined } : { items: rows };
    return withCORS(env, req, ok(resp));
  } catch {
    return withCORS(env, req, serverError('Failed to list clients'));
  }
}

/**
 * @openapi
 * /api/rates/candidate-overrides/overlap-exists:
 *   get:
 *     summary: Check if any candidate override overlaps a client rate window
 *     tags: [Rates]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: client_id
 *         required: true
 *         schema: { type: string, format: uuid }
 *       - in: query
 *         name: role
 *         required: true
 *         schema: { type: string }
 *       - in: query
 *         name: band
 *         required: false
 *         schema:
 *           type: string
 *           nullable: true
 *         description: Use empty string to match NULL band
 *       - in: query
 *         name: from
 *         required: true
 *         schema: { type: string, format: date }
 *         description: Client window date_from (YYYY-MM-DD)
 *       - in: query
 *         name: to
 *         required: false
 *         schema: { type: string, format: date, nullable: true }
 *         description: Client window date_to (YYYY-MM-DD). Omit for open-ended.
 *       - in: query
 *         name: exclude_id
 *         required: false
 *         schema: { type: string, format: uuid }
 *         description: Override id to exclude (useful when editing an existing override)
 *     responses:
 *       200:
 *         description: Overlap summary
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 exists: { type: boolean }
 *                 count:  { type: integer }
 *                 sample_id: { type: string, nullable: true }
 */

 async function handleCandidateOverrideOverlapExists(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj   = new URL(req.url);
  const enc      = (s) => encodeURIComponent(String(s ?? ''));
  const clientId = urlObj.searchParams.get('client_id');
  const role     = urlObj.searchParams.get('role');
  const bandRaw  = urlObj.searchParams.get('band');       // '' (empty) means NULL band
  const from     = urlObj.searchParams.get('from');       // YYYY-MM-DD
  const to       = urlObj.searchParams.get('to');         // YYYY-MM-DD or null
  const exclude  = urlObj.searchParams.get('exclude_id'); // optional

  if (!clientId || !role || !from) {
    return withCORS(env, req, badRequest('client_id, role and from are required'));
  }

  // Open-ended end bound if not supplied (use a far-future date to simplify filters)
  const toEff = to || '9999-12-31';

  // Build PostgREST query over rates_candidate_overrides with overlap logic:
  // Overlap iff (override.date_from <= toEff) AND (override.date_to IS NULL OR override.date_to >= from)
  // Match same (client_id, role, band|NULL). We don’t filter by rate_type — both PAYE/UMBRELLA are relevant.
  let q =
    `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides` +
    `?select=id` +
    `&client_id=eq.${enc(clientId)}` +
    `&role=eq.${enc(role)}` +
    `&date_from=lte.${enc(toEff)}` +
    `&or=(date_to.is.null,date_to.gte.${enc(from)})` +
    `&limit=1`; // fast existence check

  if (bandRaw === '' || String(bandRaw).toLowerCase() === 'null') {
    q += `&band=is.null`;
  } else if (bandRaw != null) {
    q += `&band=eq.${enc(bandRaw)}`;
  } else {
    // no band param -> accept both NULL and non-NULL? For client windows we normally know band; if truly unknown, omit.
  }

  if (exclude) {
    q += `&id=neq.${enc(exclude)}`;
  }

  // Ask sbFetch for total via Content-Range by passing includeCount=true
  const { rows, total } = await sbFetch(env, q, true);
  const exists = (typeof total === 'number' ? total : (rows?.length || 0)) > 0;

  return withCORS(env, req, ok({
    exists,
    count: typeof total === 'number' ? total : (rows?.length || 0),
    sample_id: rows?.[0]?.id || null
  }));
}
async function handleUpdateClient(env, req, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const raw = await parseJSONBody(req);
  if (!raw) return withCORS(env, req, badRequest("Invalid JSON"));

  const { cli_ref, cli_num, ...data } = raw;

  const TIME_KEYS = [
    'day_start','day_end',
    'night_start','night_end',
    'sat_start','sat_end',
    'sun_start','sun_end',
    'bh_start','bh_end'
  ];

  const asBool = (v) => {
    if (v === true) return true;
    if (v === false || v == null) return false;
    const s = String(v).trim().toLowerCase();
    return s === 'true' || s === 'yes' || s === 'y' || s === '1' || s === 'on';
  };

  const normTime = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    if (!s) return null;
    const m = s.match(/^(\d{2}:\d{2})/);
    return m ? m[1] : s;
  };

  const sameTime = (a, b) => {
    const na = normTime(a);
    const nb = normTime(b);
    return String(na ?? '') === String(nb ?? '');
  };

  const normEmail = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    return s ? s : null;
  };

  // ✅ NEW: canonical invoice consolidation mode (never write junk)
  // Allowed: NONE | BY_WEEK | ANY_WEEK (UI may send ALL → ANY_WEEK)
  const normInvoiceConsol = (v) => {
    if (v == null) return null;
    const s = String(v).trim().toUpperCase();
    if (!s) return null;
    if (s === 'ALL') return 'ANY_WEEK';
    if (s === 'ANY') return 'ANY_WEEK';
    if (s === 'NONE' || s === 'BY_WEEK' || s === 'ANY_WEEK') return s;
    return '__INVALID__';
  };

  try {
    const { rows: beforeClientRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/clients` +
      `?id=eq.${encodeURIComponent(clientId)}` +
      `&select=id,name,invoice_address,primary_invoice_email,ap_phone,vat_chargeable,payment_terms_days,mileage_charge_rate,ts_queries_email,updated_at`
    );
    if (!beforeClientRows?.length) return withCORS(env, req, notFound("Client not found"));
    const beforeClient = beforeClientRows[0];

    const { rows: beforeCsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
      `?client_id=eq.${encodeURIComponent(clientId)}` +
      `&select=` +
        [
          'id',
          'hr_validation_required','ts_reference_required','pay_reference_required','invoice_reference_required',
          'default_submission_mode',
          'week_ending_weekday',
          'is_nhsp','self_bill_no_invoices_sent','daily_calc_of_invoices',
          'no_timesheet_required','group_nightsat_sunbh',
          'auto_invoice_default',
          'effective_from','timezone_id',
          'day_start','day_end','night_start','night_end','sat_start','sat_end','sun_start','sun_end','bh_start','bh_end',
          'bh_source','bh_list','bh_feed_url',
          'requires_hr','autoprocess_hr','hr_attach_to_invoice','ts_attach_to_invoice',

          // manual adjustment email routing
          'send_manual_invoices_to_different_email',
          'manual_invoices_alt_email_address',

          // ✅ NEW: invoice settings
          'invoice_consolidation_mode',
          'reference_number_required_to_issue_invoice',

          'created_at','updated_at'
        ].join(',') +
      `&order=effective_from.desc,created_at.desc&limit=1`
    );

    const beforeCs = beforeCsRows?.[0] || null;

    // ✅ FIX: guard against null client_settings (typeof null === 'object')
    const csInput = {
      ...((data.client_settings && typeof data.client_settings === 'object') ? data.client_settings : {})
    };

    delete csInput.weekly_mode;
    delete csInput.hr_weekly_behaviour;
    delete csInput.__from_ui;

    if ('hr_validation_required' in data)        csInput.hr_validation_required        = !!data.hr_validation_required;
    if ('ts_reference_required' in data)         csInput.ts_reference_required         = !!data.ts_reference_required;
    if ('pay_reference_required' in data)        csInput.pay_reference_required        = !!data.pay_reference_required;
    if ('invoice_reference_required' in data)    csInput.invoice_reference_required    = !!data.invoice_reference_required;
    if ('default_submission_mode' in data)       csInput.default_submission_mode       = data.default_submission_mode;

    if ('auto_invoice_default' in data || 'auto_invoice_default' in csInput) {
      csInput.auto_invoice_default = asBool(csInput.auto_invoice_default ?? data.auto_invoice_default);
    }

    if ('requires_hr' in data || 'requires_hr' in csInput) {
      csInput.requires_hr = asBool(csInput.requires_hr ?? data.requires_hr);
    }
    if ('autoprocess_hr' in data || 'autoprocess_hr' in csInput) {
      csInput.autoprocess_hr = asBool(csInput.autoprocess_hr ?? data.autoprocess_hr);
    }
    if ('hr_attach_to_invoice' in data || 'hr_attach_to_invoice' in csInput) {
      csInput.hr_attach_to_invoice = asBool(csInput.hr_attach_to_invoice ?? data.hr_attach_to_invoice);
    }
    if ('ts_attach_to_invoice' in data || 'ts_attach_to_invoice' in csInput) {
      csInput.ts_attach_to_invoice = asBool(csInput.ts_attach_to_invoice ?? data.ts_attach_to_invoice);
    }

    if ('is_nhsp' in data || 'is_nhsp' in csInput) {
      csInput.is_nhsp = asBool(csInput.is_nhsp ?? data.is_nhsp);
    }
    if ('self_bill_no_invoices_sent' in data || 'self_bill_no_invoices_sent' in csInput) {
      csInput.self_bill_no_invoices_sent = asBool(csInput.self_bill_no_invoices_sent ?? data.self_bill_no_invoices_sent);
    }
    if ('daily_calc_of_invoices' in data || 'daily_calc_of_invoices' in csInput) {
      csInput.daily_calc_of_invoices = asBool(csInput.daily_calc_of_invoices ?? data.daily_calc_of_invoices);
    }
    if ('no_timesheet_required' in data || 'no_timesheet_required' in csInput) {
      csInput.no_timesheet_required = asBool(csInput.no_timesheet_required ?? data.no_timesheet_required);
    }
    if ('group_nightsat_sunbh' in data || 'group_nightsat_sunbh' in csInput) {
      csInput.group_nightsat_sunbh = asBool(csInput.group_nightsat_sunbh ?? data.group_nightsat_sunbh);
    }

    if ('send_manual_invoices_to_different_email' in data || 'send_manual_invoices_to_different_email' in csInput) {
      csInput.send_manual_invoices_to_different_email =
        asBool(csInput.send_manual_invoices_to_different_email ?? data.send_manual_invoices_to_different_email);
    }
    if ('manual_invoices_alt_email_address' in data || 'manual_invoices_alt_email_address' in csInput) {
      csInput.manual_invoices_alt_email_address =
        normEmail(csInput.manual_invoices_alt_email_address ?? data.manual_invoices_alt_email_address);
    }

    // ✅ NEW: accept + validate invoice_consolidation_mode (reject invalid; never write junk)
    if ('invoice_consolidation_mode' in data || 'invoice_consolidation_mode' in csInput) {
      const v = normInvoiceConsol(csInput.invoice_consolidation_mode ?? data.invoice_consolidation_mode);
      if (v === '__INVALID__') {
        return withCORS(env, req, badRequest('invoice_consolidation_mode must be one of NONE, BY_WEEK, ANY_WEEK (or ALL).'));
      }
      if (v != null) csInput.invoice_consolidation_mode = v;
    }

    // ✅ NEW: accept reference_number_required_to_issue_invoice boolean
    if ('reference_number_required_to_issue_invoice' in data || 'reference_number_required_to_issue_invoice' in csInput) {
      csInput.reference_number_required_to_issue_invoice =
        asBool(csInput.reference_number_required_to_issue_invoice ?? data.reference_number_required_to_issue_invoice);
    }

    for (const k of TIME_KEYS) {
      if ((k in data) || (k in csInput)) {
        csInput[k] = normTime(csInput[k] ?? data[k]);
      }
    }

    const weIn = (data.week_ending_weekday ?? csInput.week_ending_weekday);
    if (weIn !== undefined) {
      let we = Number(weIn);
      if (!Number.isInteger(we) || we < 0 || we > 6) we = 0;
      csInput.week_ending_weekday = we;
    }

    if ('default_submission_mode' in csInput) {
      let dsm = String(csInput.default_submission_mode || '').toUpperCase();
      if (!['ELECTRONIC','MANUAL'].includes(dsm)) dsm = 'ELECTRONIC';
      csInput.default_submission_mode = dsm;
    }

    const {
      hr_validation_required,
      ts_reference_required,
      pay_reference_required,
      invoice_reference_required,
      default_submission_mode,
      client_settings,
      week_ending_weekday,

      is_nhsp,
      self_bill_no_invoices_sent,
      daily_calc_of_invoices,
      no_timesheet_required,
      group_nightsat_sunbh,
      auto_invoice_default,
      requires_hr,
      autoprocess_hr,
      hr_attach_to_invoice,
      ts_attach_to_invoice,

      // ensure these never fall into clients table patch
      send_manual_invoices_to_different_email,
      manual_invoices_alt_email_address,

      // ✅ NEW: ensure these never fall into clients table patch
      invoice_consolidation_mode,
      reference_number_required_to_issue_invoice,

      ...clientPatchRaw
    } = data;

    const clientPatch = {};
    for (const [k, v] of Object.entries(clientPatchRaw)) {
      if (v === '' || v === undefined) continue;
      clientPatch[k] = v;
    }

    const clientKeysToChange = Object.keys(clientPatch).filter(k => {
      return JSON.stringify(clientPatch[k]) !== JSON.stringify(beforeClient[k]);
    });

    let client = beforeClient;

    if (clientKeysToChange.length) {
      clientPatch.updated_at = new Date().toISOString();

      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${encodeURIComponent(clientId)}`,
        {
          method: "PATCH",
          headers: { ...sbHeaders(env), "Prefer": "return=representation" },
          body: JSON.stringify(clientPatch)
        }
      );
      if (!res.ok) {
        const err = await res.text();
        return withCORS(env, req, badRequest(`Update failed: ${err}`));
      }
      const json = await res.json().catch(() => ({}));
      client = Array.isArray(json) ? json[0] : json;
    }

    let csChanged = false;
    let client_settings_updated = null;

    if (Object.keys(csInput).length) {
      const hasBefore = !!beforeCs?.id;

      // Canonicalise server-side
      const canon = canonicalizeClientSettingsServer(beforeCs, csInput);

      // ✅ Ensure new fields survive canonicaliser; never write junk
      if (Object.prototype.hasOwnProperty.call(csInput, 'invoice_consolidation_mode')) {
        const v = normInvoiceConsol(csInput.invoice_consolidation_mode);
        if (v === '__INVALID__') {
          return withCORS(env, req, badRequest('invoice_consolidation_mode must be one of NONE, BY_WEEK, ANY_WEEK (or ALL).'));
        }
        if (v != null) canon.invoice_consolidation_mode = v;
      }
      if (Object.prototype.hasOwnProperty.call(csInput, 'reference_number_required_to_issue_invoice')) {
        canon.reference_number_required_to_issue_invoice = asBool(csInput.reference_number_required_to_issue_invoice);
      }

      // ✅ VALIDATION: if toggle ON, require email
      if (canon.send_manual_invoices_to_different_email && !canon.manual_invoices_alt_email_address) {
        return withCORS(env, req, badRequest('manual_invoices_alt_email_address is required when send_manual_invoices_to_different_email is true'));
      }

      for (const k of TIME_KEYS) {
        if (Object.prototype.hasOwnProperty.call(canon, k)) {
          canon[k] = normTime(canon[k]);
        }
      }

      // ✅ VALIDATION: shift-time rule = either ALL blank or ALL filled
      {
        const filled = TIME_KEYS.filter(k => canon[k] != null && String(canon[k]).trim() !== '');
        if (filled.length > 0 && filled.length < TIME_KEYS.length) {
          return withCORS(env, req, badRequest('Shift times must be either all blank (inherit global) or all filled.'));
        }
      }

      const patchObj = {};
      if (hasBefore) {
        for (const [k, v] of Object.entries(canon)) {
          if (k === 'id' || k === 'client_id' || k === 'created_at' || k === 'updated_at') continue;

          const beforeV = beforeCs ? beforeCs[k] : undefined;

          if (TIME_KEYS.includes(k)) {
            if (!sameTime(beforeV, v)) patchObj[k] = v;
            continue;
          }

          if (JSON.stringify(beforeV) !== JSON.stringify(v)) patchObj[k] = v;
        }
        patchObj.updated_at = new Date().toISOString();

        const csRes = await fetch(
          `${env.SUPABASE_URL}/rest/v1/client_settings?id=eq.${encodeURIComponent(beforeCs.id)}`,
          {
            method: "PATCH",
            headers: { ...sbHeaders(env), "Prefer": "return=representation" },
            body: JSON.stringify(patchObj)
          }
        );
        if (!csRes.ok) {
          const err = await csRes.text();
          return withCORS(env, req, badRequest(`Client settings update failed: ${err}`));
        }
        const csJson = await csRes.json().catch(() => ({}));
        client_settings_updated = Array.isArray(csJson) ? csJson[0] : csJson;
      } else {
        const insertRow = {
          client_id: clientId,
          ...canon,
          created_at: new Date().toISOString(),
          updated_at: new Date().toISOString()
        };
        delete insertRow.id;

        const csRes = await fetch(`${env.SUPABASE_URL}/rest/v1/client_settings`, {
          method: "POST",
          headers: { ...sbHeaders(env), "Prefer": "return=representation" },
          body: JSON.stringify(insertRow)
        });
        if (!csRes.ok) {
          const err = await csRes.text();
          return withCORS(env, req, badRequest(`Client settings insert failed: ${err}`));
        }
        const csJson = await csRes.json().catch(() => ({}));
        client_settings_updated = Array.isArray(csJson) ? csJson[0] : csJson;
      }

      const beforeHr      = !!(beforeCs?.hr_validation_required        ?? false);
      const beforeRef     = !!(beforeCs?.ts_reference_required         ?? false);
      const beforePayRef  = !!(beforeCs?.pay_reference_required        ?? false);
      const beforeInvRef  = !!(beforeCs?.invoice_reference_required    ?? false);

      const nextHr        = !!(canon.hr_validation_required            ?? false);
      const nextRef       = !!(canon.ts_reference_required             ?? false);
      const nextPayRef    = !!(canon.pay_reference_required            ?? false);
      const nextInvRef    = !!(canon.invoice_reference_required        ?? false);

      const timesChanged = TIME_KEYS.some(k => !sameTime(beforeCs?.[k], canon?.[k]));

      csChanged = (
        beforeHr     !== nextHr     ||
        beforeRef    !== nextRef    ||
        beforePayRef !== nextPayRef ||
        beforeInvRef !== nextInvRef ||
        timesChanged
      );
    }

    const policyChanged =
      (data.vat_chargeable != null && !!data.vat_chargeable !== !!beforeClient.vat_chargeable) ||
      (data.payment_terms_days != null && Number(data.payment_terms_days) !== Number(beforeClient.payment_terms_days));

    const mileageChargeChanged =
      (data.mileage_charge_rate != null && Number(data.mileage_charge_rate) !== Number(beforeClient.mileage_charge_rate));

    if (policyChanged || mileageChargeChanged || csChanged) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?client_id=eq.${encodeURIComponent(clientId)}` +
          `&is_current=eq.true` +
          `&locked_by_invoice_id=is.null`,
        {
          method: "PATCH",
          headers: { ...sbHeaders(env), "Prefer": "return=minimal" },
          body: JSON.stringify({
            is_stale: true,
            stale_reason: 'CLIENT_SETTINGS_CHANGED',
            updated_at: new Date().toISOString()
          })
        }
      );

      const { rows: tsfins } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?select=timesheet_id` +
          `&client_id=eq.${encodeURIComponent(clientId)}` +
          `&is_current=eq.true` +
          `&locked_by_invoice_id=is.null`
      );
      const toEnqueue = (tsfins || []).map(r => ({ timesheet_id: r.timesheet_id, reason: 'POLICY_CHANGED' }));
      if (toEnqueue.length) {
        await fetch(
          `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
          {
            method: "POST",
            headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
            body: JSON.stringify(toEnqueue)
          }
        );
      }
    }

    return withCORS(env, req, ok({
      client,
      client_settings: client_settings_updated || beforeCs || null
    }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to update client"));
  }
}


async function handleCreateClient(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  const TIME_KEYS = [
    'day_start','day_end',
    'night_start','night_end',
    'sat_start','sat_end',
    'sun_start','sun_end',
    'bh_start','bh_end'
  ];

  const normTime = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    if (!s) return null;
    const m = s.match(/^(\d{2}:\d{2})/);
    return m ? m[1] : s;
  };

  // Small helper: accept true / "true" / "yes" / "1" / "on"
  const asBool = (v) => {
    if (v === true) return true;
    if (v === false || v == null) return false;
    const s = String(v).trim().toLowerCase();
    return s === 'true' || s === 'yes' || s === 'y' || s === '1' || s === 'on';
  };

  const normEmail = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    return s ? s : null;
  };

  // ✅ NEW: strict canonical invoice consolidation mode (reject unknown; never write junk)
  // Allowed: NONE | BY_WEEK | ANY_WEEK (UI may send ALL → ANY_WEEK)
  const normInvoiceConsol = (v) => {
    if (v == null) return null;
    const s = String(v).trim().toUpperCase();
    if (!s) return null;
    if (s === 'ALL') return 'ANY_WEEK';
    if (s === 'ANY') return 'ANY_WEEK';
    if (s === 'NONE' || s === 'BY_WEEK' || s === 'ANY_WEEK') return s;
    return '__INVALID__';
  };

  try {
    const {
      cli_ref,
      cli_num,
      client_settings: clientSettingsInput,
      hr_validation_required,
      ts_reference_required,
      pay_reference_required,
      invoice_reference_required,
      default_submission_mode,

      // NEW: auto-invoice default at client_settings level (can be sent at top level)
      auto_invoice_default,

      // ✅ NEW: invoice settings (can be sent at top level OR inside client_settings)
      invoice_consolidation_mode,
      reference_number_required_to_issue_invoice,

      // NEW flags (can be sent at top level)
      is_nhsp,
      self_bill_no_invoices_sent,
      daily_calc_of_invoices,
      no_timesheet_required,
      group_nightsat_sunbh,
      requires_hr,
      autoprocess_hr,
      hr_attach_to_invoice,
      ts_attach_to_invoice,

      // manual adjustment email routing (can be sent at top level)
      send_manual_invoices_to_different_email,
      manual_invoices_alt_email_address,

      ...clientOnly
    } = data || {};

    const clientRes = await fetch(`${env.SUPABASE_URL}/rest/v1/clients`, {
      method: "POST",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify({ ...clientOnly, created_at: new Date().toISOString() })
    });
    if (!clientRes.ok) {
      const err = await clientRes.text();
      return withCORS(env, req, badRequest(`Client creation failed: ${err}`));
    }
    const clientJson = await clientRes.json().catch(() => ({}));
    const client = Array.isArray(clientJson) ? clientJson[0] : clientJson;

    // ✅ FIX: guard against null client_settings (typeof null === 'object')
    const csInput = {
      ...((clientSettingsInput && typeof clientSettingsInput === 'object') ? clientSettingsInput : {}),
    };

    // ✅ Strip UI helper keys that are not DB columns
    delete csInput.weekly_mode;
    delete csInput.hr_weekly_behaviour;
    delete csInput.__from_ui;

    // Existing flags → client_settings
    if ('hr_validation_required' in data)        csInput.hr_validation_required        = !!hr_validation_required;
    if ('ts_reference_required' in data)         csInput.ts_reference_required         = !!ts_reference_required;
    if ('pay_reference_required' in data)        csInput.pay_reference_required        = !!pay_reference_required;
    if ('invoice_reference_required' in data)    csInput.invoice_reference_required    = !!invoice_reference_required;
    if ('default_submission_mode' in data)       csInput.default_submission_mode       = default_submission_mode;

    // NEW: auto-invoice default (accept either top-level or inside client_settings)
    if ('auto_invoice_default' in data || 'auto_invoice_default' in csInput) {
      csInput.auto_invoice_default = asBool(csInput.auto_invoice_default ?? auto_invoice_default);
    }

    // ✅ NEW: invoice settings (strict)
    if ('invoice_consolidation_mode' in data || 'invoice_consolidation_mode' in csInput) {
      const v = normInvoiceConsol(csInput.invoice_consolidation_mode ?? invoice_consolidation_mode);
      if (v === '__INVALID__') {
        return withCORS(env, req, badRequest('invoice_consolidation_mode must be one of NONE, BY_WEEK, ANY_WEEK (or ALL).'));
      }
      if (v != null) csInput.invoice_consolidation_mode = v;
    }

    if ('reference_number_required_to_issue_invoice' in data || 'reference_number_required_to_issue_invoice' in csInput) {
      csInput.reference_number_required_to_issue_invoice =
        asBool(csInput.reference_number_required_to_issue_invoice ?? reference_number_required_to_issue_invoice);
    }

    // NEW flags (default to false/true as per policy)
    if ('is_nhsp' in data || 'is_nhsp' in csInput) {
      csInput.is_nhsp = asBool(csInput.is_nhsp ?? is_nhsp);
    }
    if ('self_bill_no_invoices_sent' in data || 'self_bill_no_invoices_sent' in csInput) {
      csInput.self_bill_no_invoices_sent = asBool(csInput.self_bill_no_invoices_sent ?? self_bill_no_invoices_sent);
    }
    if ('daily_calc_of_invoices' in data || 'daily_calc_of_invoices' in csInput) {
      csInput.daily_calc_of_invoices = asBool(csInput.daily_calc_of_invoices ?? daily_calc_of_invoices);
    }
    if ('no_timesheet_required' in data || 'no_timesheet_required' in csInput) {
      csInput.no_timesheet_required = asBool(csInput.no_timesheet_required ?? no_timesheet_required);
    }
    if ('group_nightsat_sunbh' in data || 'group_nightsat_sunbh' in csInput) {
      csInput.group_nightsat_sunbh = asBool(csInput.group_nightsat_sunbh ?? group_nightsat_sunbh);
    }

    // NEW HR / attach flags
    if ('requires_hr' in data || 'requires_hr' in csInput) {
      csInput.requires_hr = asBool(csInput.requires_hr ?? requires_hr);
    }
    if ('autoprocess_hr' in data || 'autoprocess_hr' in csInput) {
      csInput.autoprocess_hr = asBool(csInput.autoprocess_hr ?? autoprocess_hr);
    }
    if ('hr_attach_to_invoice' in data || 'hr_attach_to_invoice' in csInput) {
      csInput.hr_attach_to_invoice = asBool(csInput.hr_attach_to_invoice ?? hr_attach_to_invoice);
    }
    if ('ts_attach_to_invoice' in data || 'ts_attach_to_invoice' in csInput) {
      csInput.ts_attach_to_invoice = asBool(csInput.ts_attach_to_invoice ?? ts_attach_to_invoice);
    }

    // ✅ manual adjustment email routing
    if ('send_manual_invoices_to_different_email' in data || 'send_manual_invoices_to_different_email' in csInput) {
      csInput.send_manual_invoices_to_different_email =
        asBool(csInput.send_manual_invoices_to_different_email ?? send_manual_invoices_to_different_email);
    }
    if ('manual_invoices_alt_email_address' in data || 'manual_invoices_alt_email_address' in csInput) {
      csInput.manual_invoices_alt_email_address =
        normEmail(csInput.manual_invoices_alt_email_address ?? manual_invoices_alt_email_address);
    }

    // ✅ Normalise any provided time keys ('' => null)
    for (const k of TIME_KEYS) {
      if (Object.prototype.hasOwnProperty.call(csInput, k)) {
        csInput[k] = normTime(csInput[k]);
      }
    }

    // Desired "new client" baseline = Manual (None) + all flags false
    const setDefaultBool = (key, val) => {
      if (!Object.prototype.hasOwnProperty.call(csInput, key)) csInput[key] = val;
    };

    const setDefaultTextIfMissing = (key, val) => {
      if (!Object.prototype.hasOwnProperty.call(csInput, key)) csInput[key] = val;
    };

    setDefaultBool('is_nhsp', false);
    setDefaultBool('self_bill_no_invoices_sent', false);
    setDefaultBool('daily_calc_of_invoices', false);
    setDefaultBool('no_timesheet_required', false);
    setDefaultBool('group_nightsat_sunbh', false);

    setDefaultBool('hr_validation_required', false);
    setDefaultBool('ts_reference_required', false);
    setDefaultBool('pay_reference_required', false);
    setDefaultBool('invoice_reference_required', false);

    setDefaultBool('requires_hr', false);
    setDefaultBool('autoprocess_hr', false);

    if (!Object.prototype.hasOwnProperty.call(csInput, 'hr_attach_to_invoice')) {
      csInput.hr_attach_to_invoice = true;
    }
    if (!Object.prototype.hasOwnProperty.call(csInput, 'ts_attach_to_invoice')) {
      csInput.ts_attach_to_invoice = true;
    }

    if (!Object.prototype.hasOwnProperty.call(csInput, 'auto_invoice_default')) {
      csInput.auto_invoice_default = false;
    }

    // ✅ defaults for new invoice settings
    if (!Object.prototype.hasOwnProperty.call(csInput, 'invoice_consolidation_mode')) {
      csInput.invoice_consolidation_mode = 'NONE';
    } else {
      const v = normInvoiceConsol(csInput.invoice_consolidation_mode);
      if (v === '__INVALID__') {
        return withCORS(env, req, badRequest('invoice_consolidation_mode must be one of NONE, BY_WEEK, ANY_WEEK (or ALL).'));
      }
      csInput.invoice_consolidation_mode = v || 'NONE';
    }

    if (!Object.prototype.hasOwnProperty.call(csInput, 'reference_number_required_to_issue_invoice')) {
      csInput.reference_number_required_to_issue_invoice = false;
    } else {
      csInput.reference_number_required_to_issue_invoice = asBool(csInput.reference_number_required_to_issue_invoice);
    }

    if (asBool(csInput.self_bill_no_invoices_sent)) {
      csInput.auto_invoice_default = false;
    }

    // ✅ if manual-invoice toggle off => clear email
    if (!asBool(csInput.send_manual_invoices_to_different_email)) {
      csInput.send_manual_invoices_to_different_email = false;
      csInput.manual_invoices_alt_email_address = null;
    }

    // ✅ VALIDATION: if toggle ON, require email
    if (asBool(csInput.send_manual_invoices_to_different_email) && !csInput.manual_invoices_alt_email_address) {
      return withCORS(env, req, badRequest('manual_invoices_alt_email_address is required when send_manual_invoices_to_different_email is true'));
    }

    // ✅ DEFAULT TIMES ONLY WHEN KEY IS ABSENT (blank/null explicitly provided must stay null)
    const setDefaultTimeIfMissing = (key, val) => {
      if (!Object.prototype.hasOwnProperty.call(csInput, key)) csInput[key] = val;
    };

    setDefaultTimeIfMissing('day_start',   '06:00');
    setDefaultTimeIfMissing('day_end',     '20:00');
    setDefaultTimeIfMissing('night_start', '20:00');
    setDefaultTimeIfMissing('night_end',   '06:00');

    setDefaultTimeIfMissing('sat_start', '00:00');
    setDefaultTimeIfMissing('sat_end',   '00:00');
    setDefaultTimeIfMissing('sun_start', '00:00');
    setDefaultTimeIfMissing('sun_end',   '00:00');
    setDefaultTimeIfMissing('bh_start',  '00:00');
    setDefaultTimeIfMissing('bh_end',    '00:00');

    // ✅ VALIDATION: shift-time rule = either ALL blank or ALL filled
    {
      // re-normalise in case defaults were applied
      for (const k of TIME_KEYS) {
        if (Object.prototype.hasOwnProperty.call(csInput, k)) {
          csInput[k] = normTime(csInput[k]);
        }
      }

      const filled = TIME_KEYS.filter(k => csInput[k] != null && String(csInput[k]).trim() !== '');
      if (filled.length > 0 && filled.length < TIME_KEYS.length) {
        return withCORS(env, req, badRequest('Shift times must be either all blank (inherit global) or all filled.'));
      }
    }

    // Week ending day (0..6, default 0/Sun)
    const we = Number(csInput.week_ending_weekday);
    csInput.week_ending_weekday = (Number.isInteger(we) && we>=0 && we<=6) ? we : 0;

    // Default + normalise default_submission_mode
    if (!Object.prototype.hasOwnProperty.call(csInput, 'default_submission_mode')) {
      csInput.default_submission_mode = 'ELECTRONIC';
    }
    {
      let dsm = String(csInput.default_submission_mode || '').toUpperCase();
      if (!['ELECTRONIC','MANUAL'].includes(dsm)) dsm = 'ELECTRONIC';
      csInput.default_submission_mode = dsm;
    }

    let client_settings;
    if (Object.keys(csInput).length) {
      const csPayload = {
        client_id: client.id,
        ...csInput,
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      };

      const csRes = await fetch(`${env.SUPABASE_URL}/rest/v1/client_settings`, {
        method: "POST",
        headers: { ...sbHeaders(env), "Prefer": "return=representation" },
        body: JSON.stringify(csPayload)
      });
      if (!csRes.ok) {
        const err = await csRes.text();
        return withCORS(env, req, ok({ client, warning: `Client created but client_settings insert failed: ${err}` }));
      }
      const csJson = await csRes.json().catch(() => ({}));
      client_settings = Array.isArray(csJson) ? csJson[0] : csJson;
    }

    return withCORS(env, req, ok({ client, client_settings }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to create client"));
  }
}


// 1) GET /api/clients/:id  (full client + latest client_settings)
async function handleGetClient(env, req, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    // Client
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${encodeURIComponent(clientId)}`
    );
    if (!rows.length) return withCORS(env, req, notFound("Client not found"));
    const client = rows[0];

    // Latest client_settings
    const { rows: csRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
      `?client_id=eq.${encodeURIComponent(clientId)}` +
      `&select=` +
        [
          'id','client_id',
          'vat_rate_pct','holiday_pay_pct','erni_pct',
          'apply_holiday_to','apply_erni_to','margin_includes',
          'effective_from',
          'timezone_id',
          'day_start','day_end','night_start','night_end','sat_start','sat_end','sun_start','sun_end','bh_start','bh_end',
          'bh_source','bh_list','bh_feed_url',
          'hr_validation_required',
          'ts_reference_required','pay_reference_required','invoice_reference_required',
          'default_submission_mode',
          'week_ending_weekday',
          'is_nhsp','self_bill_no_invoices_sent','daily_calc_of_invoices',
          'no_timesheet_required','group_nightsat_sunbh',
          'auto_invoice_default',
          'requires_hr','autoprocess_hr','hr_attach_to_invoice','ts_attach_to_invoice',

          // ✅ NEW: invoicing settings required by UI
          'invoice_consolidation_mode',
          'reference_number_required_to_issue_invoice',

          // ✅ NEW: manual adjustment email routing
          'send_manual_invoices_to_different_email',
          'manual_invoices_alt_email_address',

          'created_at','updated_at'
        ].join(',') +
      `&order=effective_from.desc,created_at.desc&limit=1`
    );

    const client_settings = csRows?.[0] || null;

    return withCORS(env, req, ok({ client, client_settings }));
  } catch {
    return withCORS(env, req, serverError("Failed to fetch client"));
  }
}


/**
 * @openapi
 * /api/clients/{id}:
 *   get:
 *     summary: Get client
 *     tags: [Clients]
 *     security:
 *       - bearerAuth: []
 *   put:
 *     summary: Update client
 *     tags: [Clients]
 *     security:
 *       - bearerAuth: []
 */




// --------------------------------------------------
// UPDATE CLIENT (mark stale/enqueue on policy change)
// --------------------------------------------------
// --------------------------------------------------
// UPDATE CLIENT (mark stale/enqueue on policy change)
// --------------------------------------------------

// 3) PATCH/PUT /api/clients/:id (update client + upsert/patch latest client_settings)



























 async function handleImportHrRotaParse(env, req) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  // Expect JSON: { file_r2_key, original_name, [client_id], [tz_assumption], [parse_summary_json] }
  const body = await parseJSONBody(req).catch(() => null);
  if (!body) {
    return withCORS(env, req, badRequest('Invalid JSON body'));
  }

  const fileKey   = (body.file_r2_key || body.file_key || '').trim();
  const filename  = (body.original_name || body.filename || fileKey || '').trim();
  const tzAssump  = body.tz_assumption || 'Europe/London';
  const clientId  = body.client_id && String(body.client_id).trim();

  if (!fileKey) {
    return withCORS(
      env,
      req,
      badRequest('file_r2_key (or file_key) is required')
    );
  }

  if (!filename) {
    return withCORS(
      env,
      req,
      badRequest('original_name or file_key is required for HR rota import')
    );
  }

  if (LOG) {
    console.log('[HR_DAILY_IMPORT]', JSON.stringify({
      stage: 'start',
      filename,
      file_key: fileKey,
      client_id: clientId || null,
      tz_assumption: tzAssump
    }));
  }

  const nowIso = new Date().toISOString();

  const insPayload = {
    filename,
    uploaded_by: user.id,
    uploaded_at_utc: nowIso,
    tz_assumption: tzAssump,
    source_system: 'HEALTHROSTER_DAILY',
    file_r2_key: fileKey,
    parse_summary_json: body.parse_summary_json || {}
  };

  if (clientId) {
    insPayload.client_id = clientId;
  }

  let imp;
  try {
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/hr_imports`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify(insPayload)
      }
    );

    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      if (LOG) {
        console.error('[HR_DAILY_IMPORT]', JSON.stringify({
          stage: 'hr_imports_insert_failed',
          filename,
          file_key: fileKey,
          client_id: clientId || null,
          error: txt
        }));
      }
      return withCORS(
        env,
        req,
        serverError(`Failed to insert hr_imports row: ${txt}`)
      );
    }

    const json = await res.json().catch(() => []);
    imp = Array.isArray(json) ? json[0] : json;
  } catch (e) {
    if (LOG) {
      console.error('[HR_DAILY_IMPORT]', JSON.stringify({
        stage: 'hr_imports_insert_exception',
        filename,
        file_key: fileKey,
        client_id: clientId || null,
        error: e?.message || String(e)
      }));
    }
    return withCORS(
      env,
      req,
      serverError(`Failed to insert hr_imports row: ${e?.message || e}`)
    );
  }

  if (!imp || !imp.id) {
    if (LOG) {
      console.error('[HR_DAILY_IMPORT]', JSON.stringify({
        stage: 'no_import_id',
        filename,
        file_key: fileKey,
        client_id: clientId || null
      }));
    }
    return withCORS(
      env,
      req,
      serverError('hr_imports insert did not return an id')
    );
  }

  const importId = imp.id;

  if (LOG) {
    console.log('[HR_DAILY_IMPORT]', JSON.stringify({
      stage: 'before_parse',
      import_id: importId,
      filename,
      file_key: fileKey,
      client_id: imp.client_id || clientId || null,
      tz_assumption: imp.tz_assumption || tzAssump
    }));
  }

  // Parse the workbook into hr_rows with DAILY rota semantics
  let parseResult;
  try {
    parseResult = await parseHealthRosterWorkbookIntoHrRows(env, {
      import_id: importId,
      file_key: fileKey,
      client_id: imp.client_id || clientId || null,
      tz: imp.tz_assumption || tzAssump || 'Europe/London'
    });
  } catch (e) {
    if (LOG) {
      console.error('[HR_DAILY_IMPORT]', JSON.stringify({
        stage: 'parse_failed',
        import_id: importId,
        filename,
        file_key: fileKey,
        error: e?.message || String(e)
      }));
    } else {
      console.error('[HR_ROTA_PARSE] parse failed', {
        import_id: importId,
        err: e?.message || String(e)
      });
    }
    return withCORS(
      env,
      req,
      serverError(`Failed to parse HealthRoster rota workbook: ${e?.message || e}`)
    );
  }

  const mergedSummary = {
    ...(imp.parse_summary_json || {}),
    ...(parseResult || {})
  };

  // Update hr_imports.parse_summary_json
  try {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/hr_imports?id=eq.${encodeURIComponent(importId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({ parse_summary_json: mergedSummary })
      }
    );
  } catch (e) {
    if (LOG) {
      console.warn('[HR_DAILY_IMPORT]', JSON.stringify({
        stage: 'parse_summary_patch_failed',
        import_id: importId,
        error: e?.message || String(e)
      }));
    } else {
      console.warn('[HR_ROTA_PARSE] failed to update parse_summary_json', {
        import_id: importId,
        err: e?.message || String(e)
      });
    }
  }

  if (LOG) {
    console.log('[HR_DAILY_IMPORT]', JSON.stringify({
      stage: 'completed',
      import_id: importId,
      filename,
      file_key: fileKey,
      client_id: imp.client_id || clientId || null,
      parse_summary: mergedSummary
    }));
  }

  return withCORS(env, req, ok({
    import_id: importId,
    parse_summary_json: mergedSummary
  }));
}


// ============================================================
// UPDATED: handleTsfinPatchExpenses / handleTsfinPatchMileage / patchTsfinCommon
// - Supports category expenses (TRAVEL/ACCOMMODATION/OTHER) + totals derived
// - Enforces evidence via public.timesheet_evidence.kind (NOT TSFIN *_evidence_* fields)
// - Mileage evidence enforced via timesheet_evidence.kind = 'MILEAGE'
// - Stores expenses_description as notes/metadata only (string or JSON-stringified)
// ============================================================

async function handleTsfinPatchExpenses(env, req, timesheetId) {
  const body = await parseJSONBody(req).catch(() => ({}));

  // allow either top-level fields or nested { expenses: {...} }
  const src = (body && typeof body.expenses === 'object' && body.expenses) ? body.expenses : body;

  return withCORS(env, req, await patchTsfinCommon(env, req, timesheetId, {
    expected_timesheet_id: body?.expected_timesheet_id ?? src?.expected_timesheet_id,
    reason: body?.reason ?? src?.reason ?? null,
    expenses: {
      travel_pay_ex_vat: src?.travel_pay_ex_vat,
      travel_charge_ex_vat: src?.travel_charge_ex_vat,

      accommodation_pay_ex_vat: src?.accommodation_pay_ex_vat,
      accommodation_charge_ex_vat: src?.accommodation_charge_ex_vat,

      other_pay_ex_vat: src?.other_pay_ex_vat,
      other_charge_ex_vat: src?.other_charge_ex_vat,

      // notes/meta ONLY (string or object); stored into timesheets_financials.expenses_description
      description: (src?.expenses_description ?? src?.description ?? src?.expenses_meta_json)
    }
  }));
}

// 4) PATCH /api/tsfin/:id/mileage  (mileage_units + pay/charge + rates)
async function handleTsfinPatchMileage(env, req, timesheetId) {
  const body = await parseJSONBody(req).catch(() => ({}));

  // allow either top-level fields or nested { mileage: {...} }
  const src = (body && typeof body.mileage === 'object' && body.mileage) ? body.mileage : body;

  return withCORS(env, req, await patchTsfinCommon(env, req, timesheetId, {
    expected_timesheet_id: body?.expected_timesheet_id ?? src?.expected_timesheet_id,
    reason: body?.reason ?? src?.reason ?? null,
    mileage: {
      mileage_units: src?.mileage_units,
      pay_ex_vat: src?.pay_ex_vat,
      charge_ex_vat: src?.charge_ex_vat,
      pay_rate: src?.pay_rate,
      charge_rate: src?.charge_rate
    }
  }));
}

async function patchTsfinCommon(env, req, timesheetId, patch) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const enc = encodeURIComponent;

  const hasAnySegmentInvoiceLock = (tf) => {
    try {
      const ib = tf?.invoice_breakdown_json;
      if (!ib || typeof ib !== 'object') return false;
      const mode = String(ib?.mode || '').toUpperCase();
      if (mode !== 'SEGMENTS') return false;
      const segs = Array.isArray(ib?.segments) ? ib.segments : [];
      return segs.some(s => {
        const v = s?.invoice_locked_invoice_id;
        return v != null && String(v).trim() !== '';
      });
    } catch {
      return false;
    }
  };

  // ─────────────────────────────────────────────────────────────
  // optimistic concurrency guard (expected current id required)
  // ─────────────────────────────────────────────────────────────
  const expected = (patch && patch.expected_timesheet_id) ? String(patch.expected_timesheet_id) : '';
  if (!expected) {
    return badRequest('expected_timesheet_id is required');
  }

  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved || !resolved.current_timesheet_id) {
    return notFound('Timesheet not found');
  }

  const currentTimesheetId = String(resolved.current_timesheet_id);
  if (expected !== currentTimesheetId) {
    const payload = {
      error: 'TIMESHEET_MOVED',
      booking_id: resolved.booking_id || null,
      requested_timesheet_id: resolved.requested_timesheet_id || timesheetId || null,
      current_timesheet_id: resolved.current_timesheet_id || null,
      current_version: resolved.current_version != null ? resolved.current_version : null
    };
    return new Response(JSON.stringify(payload), {
      status: 409,
      headers: { 'Content-Type': 'application/json' }
    });
  }

  // From here on: ALWAYS use currentTimesheetId
  const toNum = (v) => (v === null || v === undefined ? null : Number(v));
  const nonneg = (n) => (n === null || n === undefined ? true : Number(n) >= 0);

  const num0 = (v) => {
    const n = toNum(v);
    return (n == null || Number.isNaN(n)) ? 0 : n;
  };

  const normalizeExpensesDescription = (v) => {
    if (v === undefined) return undefined; // not touched
    if (v === null) return null;
    if (typeof v === 'string') return v;
    try {
      if (typeof v === 'object') return JSON.stringify(v);
    } catch {}
    return String(v);
  };

  // Evidence kind aliases (accept legacy UI values too)
  const KIND_ALIASES = {
    MILEAGE: ['MILEAGE', 'Mileage', 'mileage'],
    TRAVEL: ['TRAVEL', 'Travel', 'travel', 'EXPENSES', 'Expenses', 'expenses'],
    ACCOMMODATION: ['ACCOMMODATION', 'Accommodation', 'accommodation'],
    OTHER: ['OTHER', 'Other', 'other'],
  };

  const hasEvidenceForAnyKind = async (kinds) => {
    const ks = Array.isArray(kinds) ? kinds.filter(Boolean) : [];
    if (!ks.length) return false;

    const inParam = `in.(${ks.join(',')})`;
    const url =
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&kind=${enc(inParam)}` +
      `&select=id` +
      `&limit=1`;

    try {
      const { rows } = await sbFetch(env, url);
      return !!(rows && rows[0] && rows[0].id);
    } catch {
      return false;
    }
  };

  const evidenceError = (missingArr) => {
    return new Response(JSON.stringify({
      error: 'EVIDENCE_REQUIRED',
      missing: missingArr
    }), {
      status: 400,
      headers: { 'Content-Type': 'application/json' }
    });
  };

  // -------- basic numeric validations --------
  if (patch.expenses) {
    const xp = patch.expenses;

    // Category numeric validation (>= 0)
    if (!nonneg(xp.travel_pay_ex_vat) || !nonneg(xp.travel_charge_ex_vat) ||
        !nonneg(xp.accommodation_pay_ex_vat) || !nonneg(xp.accommodation_charge_ex_vat) ||
        !nonneg(xp.other_pay_ex_vat) || !nonneg(xp.other_charge_ex_vat)) {
      return badRequest('Expense values must be >= 0');
    }
  }

  if (patch.mileage) {
    const ml = patch.mileage;

    if (!nonneg(ml.mileage_units) || !nonneg(ml.pay_ex_vat) || !nonneg(ml.charge_ex_vat) || !nonneg(ml.pay_rate) || !nonneg(ml.charge_rate)) {
      return badRequest('Mileage values must be >= 0');
    }
  }

  // -------- load current snapshot --------
  const before = await fetchCurrentTsfin(env, currentTimesheetId);
  if (!before) return notFound('TSFIN current row not found');

  // Segment-aware lock: block expense/mileage/PO changes if ANY segment is invoiced
  if (before.locked_by_invoice_id || hasAnySegmentInvoiceLock(before)) {
    return conflict('Timesheet financials are locked by an invoice');
  }

  // -------- compute "after" values for evidence enforcement + totals coherency --------
  let afterTravelPay = num0(before.travel_pay_ex_vat);
  let afterTravelChg = num0(before.travel_charge_ex_vat);
  let afterAccomPay  = num0(before.accommodation_pay_ex_vat);
  let afterAccomChg  = num0(before.accommodation_charge_ex_vat);
  let afterOtherPay  = num0(before.other_pay_ex_vat);
  let afterOtherChg  = num0(before.other_charge_ex_vat);

  let afterMileageUnits = num0(before.mileage_units);
  let afterMileagePay   = num0(before.mileage_pay_ex_vat);
  let afterMileageChg   = num0(before.mileage_charge_ex_vat);

  if (patch.expenses) {
    const xp = patch.expenses;

    if (xp.travel_pay_ex_vat !== undefined)        afterTravelPay = num0(xp.travel_pay_ex_vat);
    if (xp.travel_charge_ex_vat !== undefined)     afterTravelChg = num0(xp.travel_charge_ex_vat);

    if (xp.accommodation_pay_ex_vat !== undefined)    afterAccomPay = num0(xp.accommodation_pay_ex_vat);
    if (xp.accommodation_charge_ex_vat !== undefined) afterAccomChg = num0(xp.accommodation_charge_ex_vat);

    if (xp.other_pay_ex_vat !== undefined)         afterOtherPay = num0(xp.other_pay_ex_vat);
    if (xp.other_charge_ex_vat !== undefined)      afterOtherChg = num0(xp.other_charge_ex_vat);
  }

  if (patch.mileage) {
    const ml = patch.mileage;
    if (ml.mileage_units !== undefined)   afterMileageUnits = num0(ml.mileage_units);
    if (ml.pay_ex_vat !== undefined)      afterMileagePay   = num0(ml.pay_ex_vat);
    if (ml.charge_ex_vat !== undefined)   afterMileageChg   = num0(ml.charge_ex_vat);
  }

  // -------- evidence requirements (table-driven, deterministic) --------
  const missing = [];

  // Mileage evidence required if any mileage claim > 0
  if (afterMileageUnits > 0 || afterMileagePay > 0 || afterMileageChg > 0) {
    const ok = await hasEvidenceForAnyKind(KIND_ALIASES.MILEAGE);
    if (!ok) missing.push({ category: 'mileage', required_kind: 'MILEAGE' });
  }

  // Travel evidence required if any travel claim > 0
  if (afterTravelPay > 0 || afterTravelChg > 0) {
    const ok = await hasEvidenceForAnyKind(KIND_ALIASES.TRAVEL);
    if (!ok) missing.push({ category: 'travel', required_kind: 'TRAVEL' });
  }

  // Accommodation evidence required if any accommodation claim > 0
  if (afterAccomPay > 0 || afterAccomChg > 0) {
    const ok = await hasEvidenceForAnyKind(KIND_ALIASES.ACCOMMODATION);
    if (!ok) missing.push({ category: 'accommodation', required_kind: 'ACCOMMODATION' });
  }

  // Other evidence required if any other claim > 0
  if (afterOtherPay > 0 || afterOtherChg > 0) {
    const ok = await hasEvidenceForAnyKind(KIND_ALIASES.OTHER);
    if (!ok) missing.push({ category: 'other', required_kind: 'OTHER' });
  }

  if (missing.length) {
    return evidenceError(missing);
  }

  // -------- construct update payload --------
  const upd = {};
  const nowISO = nowIso();

  // Category expenses write + totals coherency
  if (patch.expenses) {
    const xp = patch.expenses;

    // Only write explicit category columns when present in patch
    if (xp.travel_pay_ex_vat !== undefined)        upd.travel_pay_ex_vat = afterTravelPay;
    if (xp.travel_charge_ex_vat !== undefined)     upd.travel_charge_ex_vat = afterTravelChg;

    if (xp.accommodation_pay_ex_vat !== undefined)    upd.accommodation_pay_ex_vat = afterAccomPay;
    if (xp.accommodation_charge_ex_vat !== undefined) upd.accommodation_charge_ex_vat = afterAccomChg;

    if (xp.other_pay_ex_vat !== undefined)         upd.other_pay_ex_vat = afterOtherPay;
    if (xp.other_charge_ex_vat !== undefined)      upd.other_charge_ex_vat = afterOtherChg;

    // Always keep totals coherent when the expenses patch path is used
    const sumPay = num0(afterTravelPay) + num0(afterAccomPay) + num0(afterOtherPay);
    const sumChg = num0(afterTravelChg) + num0(afterAccomChg) + num0(afterOtherChg);

    upd.expenses_pay_ex_vat = sumPay;
    upd.expenses_charge_ex_vat = sumChg;

    const desc = normalizeExpensesDescription(xp.description);
    if (desc !== undefined) upd.expenses_description = desc;
  }

  // Mileage write (NO TSFIN evidence pointer fields; evidence is in timesheet_evidence table)
  if (patch.mileage) {
    const ml = patch.mileage;

    if (ml.mileage_units !== undefined) {
      upd.mileage_units = afterMileageUnits;
    }
    if (ml.pay_ex_vat !== undefined)        upd.mileage_pay_ex_vat = afterMileagePay;
    if (ml.charge_ex_vat !== undefined)     upd.mileage_charge_ex_vat = afterMileageChg;

    if (ml.pay_rate !== undefined)          upd.mileage_pay_rate = (ml.pay_rate === null ? null : toNum(ml.pay_rate));
    if (ml.charge_rate !== undefined)       upd.mileage_charge_rate = (ml.charge_rate === null ? null : toNum(ml.charge_rate));

    // Backfill rates from candidate/client if not provided (preserve existing if present)
    if (ml.pay_rate === undefined || ml.charge_rate === undefined) {
      const needPay = ml.pay_rate === undefined;
      const needChg = ml.charge_rate === undefined;
      if (needPay || needChg) {
        let candRate = null, clientRate = null;
        try {
          if (needPay && before.candidate_id) {
            const { rows: candRows } = await sbFetch(
              env,
              `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${encodeURIComponent(before.candidate_id)}&select=mileage_pay_rate&limit=1`
            );
            candRate = candRows?.[0]?.mileage_pay_rate ?? null;
          }
          if (needChg && before.client_id) {
            const { rows: cliRows } = await sbFetch(
              env,
              `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${encodeURIComponent(before.client_id)}&select=mileage_charge_rate&limit=1`
            );
            clientRate = cliRows?.[0]?.mileage_charge_rate ?? null;
          }
        } catch { /* ignore */ }
        if (needPay) upd.mileage_pay_rate = toNum(before.mileage_pay_rate) ?? (candRate == null ? null : Number(candRate));
        if (needChg) upd.mileage_charge_rate = toNum(before.mileage_charge_rate) ?? (clientRate == null ? null : Number(clientRate));
      }
    }
  }

  if (patch.po && patch.po.number !== undefined) {
    upd.po_number = (patch.po.number ?? null);
  }

  if (!Object.keys(upd).length) {
    return ok({ updated: false, tsfin: before });
  }

  upd.is_stale = true;
  upd.updated_at = nowISO;

  const url =
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?timesheet_id=eq.${encodeURIComponent(currentTimesheetId)}` +
    `&is_current=eq.true` +
    `&locked_by_invoice_id=is.null`;

  const res = await fetch(url, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(upd),
  });

  if (!res.ok) {
    const t = await res.text();
    return serverError(`TSFIN update failed: ${t}`);
  }

  const json = await res.json().catch(() => []);
  const after = Array.isArray(json) ? json[0] : json;

  await enqueueManualTsfinRecalc(env, currentTimesheetId).catch(() => {});

  await insertAuditEvent(env, req, {
    object_type: 'timesheets_financials',
    object_id_text: currentTimesheetId,
    action: 'PATCH',
    reason: patch.reason ?? null,
    before_json: {
      expenses: {
        travel_pay_ex_vat: before.travel_pay_ex_vat ?? 0,
        travel_charge_ex_vat: before.travel_charge_ex_vat ?? 0,
        accommodation_pay_ex_vat: before.accommodation_pay_ex_vat ?? 0,
        accommodation_charge_ex_vat: before.accommodation_charge_ex_vat ?? 0,
        other_pay_ex_vat: before.other_pay_ex_vat ?? 0,
        other_charge_ex_vat: before.other_charge_ex_vat ?? 0,
        expenses_pay_ex_vat: before.expenses_pay_ex_vat ?? 0,
        expenses_charge_ex_vat: before.expenses_charge_ex_vat ?? 0,
        expenses_description: before.expenses_description ?? null
      },
      mileage: {
        mileage_units: before.mileage_units ?? 0,
        pay_ex_vat: before.mileage_pay_ex_vat ?? 0,
        charge_ex_vat: before.mileage_charge_ex_vat ?? 0,
        pay_rate: before.mileage_pay_rate ?? null,
        charge_rate: before.mileage_charge_rate ?? null
      },
      po: { number: before.po_number ?? null }
    },
    after_json: {
      expenses: {
        travel_pay_ex_vat: after?.travel_pay_ex_vat ?? 0,
        travel_charge_ex_vat: after?.travel_charge_ex_vat ?? 0,
        accommodation_pay_ex_vat: after?.accommodation_pay_ex_vat ?? 0,
        accommodation_charge_ex_vat: after?.accommodation_charge_ex_vat ?? 0,
        other_pay_ex_vat: after?.other_pay_ex_vat ?? 0,
        other_charge_ex_vat: after?.other_charge_ex_vat ?? 0,
        expenses_pay_ex_vat: after?.expenses_pay_ex_vat ?? 0,
        expenses_charge_ex_vat: after?.expenses_charge_ex_vat ?? 0,
        expenses_description: after?.expenses_description ?? null
      },
      mileage: {
        mileage_units: after?.mileage_units ?? 0,
        pay_ex_vat: after?.mileage_pay_ex_vat ?? 0,
        charge_ex_vat: after?.mileage_charge_ex_vat ?? 0,
        pay_rate: after?.mileage_pay_rate ?? null,
        charge_rate: after?.mileage_charge_rate ?? null
      },
      po: { number: after?.po_number ?? null }
    }
  }).catch(() => {});

  return ok({
    updated: true,
    tsfin: after,
    booking_id: resolved.booking_id || null,
    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId || null,
    current_timesheet_id: currentTimesheetId,
    current_version: resolved.current_version ?? null,
    was_stale: !!resolved.was_stale
  });
}

// ============================================================
// UPDATED: handleTimesheetEvidenceAdd / handleTimesheetEvidenceUpdateKind
// - Normalizes kind to canonical set where applicable:
//     MILEAGE, TRAVEL, ACCOMMODATION, OTHER, TIMESHEET
// - Maps legacy UI "Expenses" -> TRAVEL
// - Keeps other/system kinds as UPPER(TRIM(...))
// ============================================================

async function handleTimesheetEvidenceAdd(env, req, tsId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!tsId) return withCORS(env, req, badRequest('timesheet_id is required'));

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON payload'));
  }

  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const resolved = await resolveTimesheetToCurrent(env, tsId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTsId = resolved.current_timesheet_id;

  if (String(expected) !== String(currentTsId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTsId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  const rawKind = body && body.kind && String(body.kind).trim();
  const displayNameIn = body && body.display_name != null ? String(body.display_name).trim() : null;

  const normalizeKind = (k) => {
    const s = String(k || '').trim();
    if (!s) return '';
    const u = s.toUpperCase();

    if (u === 'EXPENSES' || u === 'EXPENSE') return 'TRAVEL';
    if (u === 'TRAVEL') return 'TRAVEL';

    if (u === 'MILEAGE' || u === 'MILES' || u === 'MILE') return 'MILEAGE';
    if (u === 'ACCOMMODATION' || u === 'ACCOM') return 'ACCOMMODATION';
    if (u === 'OTHER') return 'OTHER';
    if (u === 'TIMESHEET' || u === 'TS') return 'TIMESHEET';

    return u;
  };

  const prettyKind = (k) => {
    const u = String(k || '').toUpperCase();
    if (u === 'TRAVEL') return 'Travel';
    if (u === 'MILEAGE') return 'Mileage';
    if (u === 'ACCOMMODATION') return 'Accommodation';
    if (u === 'OTHER') return 'Other';
    if (u === 'TIMESHEET') return 'Timesheet';
    return String(k || '');
  };

  const kind = normalizeKind(rawKind);

  const storageKeyRaw = body && body.storage_key && String(body.storage_key).trim();
  const storageKey = storageKeyRaw ? storageKeyRaw.replace(/^\/+/, '') : '';

  if (!kind) return withCORS(env, req, badRequest('kind is required'));
  if (!storageKey) return withCORS(env, req, badRequest('storage_key is required'));

  try {
    // Block evidence add if invoiced/paid
    try {
      const fin = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(currentTsId)}` +
          `&is_current=eq.true` +
          `&select=locked_by_invoice_id,paid_at_utc` +
          `&limit=1`
      );
      if (fin && (fin.locked_by_invoice_id || fin.paid_at_utc)) {
        return withCORS(env, req, badRequest('Timesheet already invoiced or paid; cannot add evidence'));
      }
    } catch (e) {
      return withCORS(env, req, serverError(`Failed to validate timesheet financial lock state: ${e?.message || e}`));
    }

    const { rows: tsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTsId)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,contract_id,week_ending_date,sheet_scope,submission_mode` +
        `&limit=1`
    );
    const ts = tsRows?.[0] || null;
    if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

    // Validate storage_key exists in R2 (best-effort)
    try {
      if (typeof r2Exists === 'function') {
        const exists = await r2Exists(env, storageKey);
        if (!exists) return withCORS(env, req, badRequest('storage_key does not exist in R2'));
      }
    } catch (e) {
      console.warn('[handleTimesheetEvidenceAdd] r2Exists failed (non-fatal)', {
        storage_key: storageKey,
        err: e?.message || String(e)
      });
    }

    const nowIso = new Date().toISOString();

    const payload = [{
      timesheet_id: currentTsId,
      kind,
      display_name: (displayNameIn && displayNameIn.length ? displayNameIn : prettyKind(kind) || kind),
      storage_key: storageKey,
      created_at: nowIso,
      created_by: user.id || null
    }];

    const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheet_evidence`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload)
    });

    const txt = await insRes.text().catch(() => '');
    if (!insRes.ok) {
      return withCORS(env, req, serverError(`Failed to add timesheet evidence: ${txt}`));
    }

    let row = null;
    try {
      const json = txt ? JSON.parse(txt) : [];
      row = Array.isArray(json) ? json[0] : json;
    } catch {
      row = null;
    }

    try {
      await writeAudit(
        env,
        user,
        'TIMESHEET_EVIDENCE_ADDED',
        {
          timesheet_id: currentTsId,
          evidence_id: row?.id || null,
          kind,
          display_name: (displayNameIn && displayNameIn.length ? displayNameIn : prettyKind(kind) || kind),
          storage_key: storageKey,
          contract_id: ts.contract_id || null,
          week_ending_date: ts.week_ending_date || null,
          sheet_scope: ts.sheet_scope || null,
          submission_mode: ts.submission_mode || null
        },
        { entity: 'timesheets', subject_id: currentTsId, req }
      );
    } catch {}

    return withCORS(env, req, ok({
      ok: true,
      requested_timesheet_id: resolved.requested_timesheet_id || tsId,
      current_timesheet_id: currentTsId,
      was_stale: !!resolved.was_stale,
      evidence: row || null
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to add timesheet evidence: ${e?.message || e}`));
  }
}

async function handleTimesheetEvidenceUpdateKind(env, req, tsId, evidenceId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!tsId) return withCORS(env, req, badRequest('timesheet_id is required'));
  if (!evidenceId) return withCORS(env, req, badRequest('evidence_id is required'));

  if (String(evidenceId).startsWith('SYS:')) {
    return withCORS(env, req, badRequest('System evidence cannot be edited'));
  }

  const uuidRe = /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;
  if (!uuidRe.test(String(evidenceId))) {
    return withCORS(env, req, badRequest('Invalid evidence_id'));
  }

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON payload'));
  }

  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const resolved = await resolveTimesheetToCurrent(env, tsId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTsId = resolved.current_timesheet_id;

  if (String(expected) !== String(currentTsId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTsId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  const normalizeKind = (k) => {
    const s = String(k || '').trim();
    if (!s) return '';
    const u = s.toUpperCase();
    if (u === 'EXPENSES' || u === 'EXPENSE') return 'TRAVEL';
    if (u === 'TRAVEL') return 'TRAVEL';
    if (u === 'MILEAGE' || u === 'MILES' || u === 'MILE') return 'MILEAGE';
    if (u === 'ACCOMMODATION' || u === 'ACCOM') return 'ACCOMMODATION';
    if (u === 'OTHER') return 'OTHER';
    if (u === 'TIMESHEET' || u === 'TS') return 'TIMESHEET';
    return u;
  };

  const newKindRaw = body && body.kind != null ? String(body.kind).trim() : '';
  const newKind = normalizeKind(newKindRaw);
  if (!newKind) return withCORS(env, req, badRequest('kind is required'));

  try {
    // Block evidence kind update if invoiced/paid
    try {
      const fin = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(currentTsId)}` +
          `&is_current=eq.true` +
          `&select=locked_by_invoice_id,paid_at_utc` +
          `&limit=1`
      );
      if (fin && (fin.locked_by_invoice_id || fin.paid_at_utc)) {
        return withCORS(env, req, badRequest('Timesheet already invoiced or paid; cannot update evidence kind'));
      }
    } catch (e) {
      return withCORS(env, req, serverError(`Failed to validate timesheet financial lock state: ${e?.message || e}`));
    }

    const { rows: evRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence` +
        `?id=eq.${enc(evidenceId)}` +
        `&timesheet_id=eq.${enc(currentTsId)}` +
        `&select=id,kind,display_name,storage_key,created_at,created_by` +
        `&limit=1`
    );

    const ev = evRows?.[0] || null;
    if (!ev) return withCORS(env, req, notFound('Evidence not found for this timesheet'));

    const oldKind = ev.kind != null ? String(ev.kind) : '';
    if (String(oldKind) === String(newKind)) {
      return withCORS(env, req, ok({
        ok: true,
        requested_timesheet_id: resolved.requested_timesheet_id || tsId,
        current_timesheet_id: currentTsId,
        was_stale: !!resolved.was_stale,
        evidence: ev
      }));
    }

    const patchRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence?id=eq.${enc(evidenceId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify({ kind: newKind })
      }
    );

    const txt = await patchRes.text().catch(() => '');
    if (!patchRes.ok) {
      return withCORS(env, req, serverError(`Failed to update evidence kind: ${txt}`));
    }

    let updated = null;
    try {
      const json = txt ? JSON.parse(txt) : [];
      updated = Array.isArray(json) ? json[0] : json;
    } catch {
      updated = null;
    }

    try {
      await writeAudit(
        env,
        user,
        'TIMESHEET_EVIDENCE_RECLASSIFIED',
        {
          timesheet_id: currentTsId,
          evidence_id: evidenceId,
          old_kind: oldKind || null,
          new_kind: newKind,
          storage_key: ev.storage_key || null,
          display_name: ev.display_name || null
        },
        { entity: 'timesheets', subject_id: currentTsId, req }
      );
    } catch {}

    return withCORS(env, req, ok({
      ok: true,
      requested_timesheet_id: resolved.requested_timesheet_id || tsId,
      current_timesheet_id: currentTsId,
      was_stale: !!resolved.was_stale,
      evidence: updated || { ok: true }
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to update evidence kind: ${e?.message || e}`));
  }
}


async function classifyHrRotaValidationImport(env, importId) {
  const enc   = encodeURIComponent;
  const norm  = (s) => String(s || '').trim().toLowerCase();

  // ─────────────────────────────────────────────────────────────
  // CACHES to avoid per-row subrequests
  // ─────────────────────────────────────────────────────────────
  const candidateByNameTrustCache = new Map(); // `${staffNorm}|${trustNorm}` -> candidate_id|null
  const clientByTrustCache        = new Map(); // trustNorm -> client_id|null
  const timesheetsByCandCache     = new Map(); // candidate_id -> [timesheets...]

  // NEW: TSFIN cache (only 1 lookup per unique timesheet_id)
  const tsfinByTimesheetCache     = new Map(); // timesheet_id -> { paid_at_utc, locked_by_invoice_id } | null

  async function resolveCandidateByNameTrustCached(staffRaw, staffNorm, trustNorm) {
    const nameKey = `${staffNorm || norm(staffRaw)}|${trustNorm || ''}`;
    if (candidateByNameTrustCache.has(nameKey)) {
      return candidateByNameTrustCache.get(nameKey);
    }
    let candidateId = null;
    try {
      candidateId = await findCandidateByImportName(env, staffRaw || staffNorm, { trustNorm });
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] candidate resolve failed (non-fatal)', {
        import_id: importId,
        staff: staffRaw,
        trustNorm,
        err: e?.message || String(e)
      });
    }
    candidateByNameTrustCache.set(nameKey, candidateId || null);
    return candidateId || null;
  }

  async function resolveClientIdCached(hospRaw) {
    const t = String(hospRaw || '').trim();
    const trustNorm = norm(t);
    if (!trustNorm) return null;
    if (clientByTrustCache.has(trustNorm)) return clientByTrustCache.get(trustNorm);

    let clientId = null;
    try {
      clientId = await resolveClientId(env, hospRaw);
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] client resolve failed (non-fatal)', {
        import_id: importId,
        hospital: hospRaw,
        err: e?.message || String(e)
      });
    }
    clientByTrustCache.set(trustNorm, clientId || null);
    return clientId || null;
  }

  async function getDailyTimesheetsForCandidateCached(candidateId) {
    if (!candidateId) return [];
    if (timesheetsByCandCache.has(candidateId)) {
      return timesheetsByCandCache.get(candidateId);
    }
    let tsRows = [];
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?candidate_id=eq.${enc(candidateId)}` +
          `&sheet_scope=eq.DAILY` +
          `&is_current=eq.true` +
          `&select=timesheet_id,worked_start_iso,hospital_norm,contract_id,job_title_norm,band`
      );
      tsRows = rows || [];
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] timesheets lookup failed (non-fatal)', {
        import_id: importId,
        candidate_id: candidateId,
        err: e?.message || String(e)
      });
      tsRows = [];
    }
    timesheetsByCandCache.set(candidateId, tsRows);
    return tsRows;
  }

  // NEW: TSFIN lookup helper (cached)
  async function getTsfinForTimesheetCached(timesheetId) {
    if (!timesheetId) return null;
    const key = String(timesheetId);
    if (tsfinByTimesheetCache.has(key)) return tsfinByTimesheetCache.get(key);

    let out = null;
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(key)}` +
          `&is_current=eq.true` +
          `&select=paid_at_utc,locked_by_invoice_id` +
          `&limit=1`
      );
      const r = rows?.[0] || null;
      if (r) {
        out = {
          paid_at_utc: r.paid_at_utc || null,
          locked_by_invoice_id: r.locked_by_invoice_id || null
        };
      } else {
        out = null;
      }
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] TSFIN lookup failed (non-fatal)', {
        import_id: importId,
        timesheet_id: key,
        err: e?.message || String(e)
      });
      out = null;
    }

    tsfinByTimesheetCache.set(key, out);
    return out;
  }

  // ─────────────────────────────────────────────────────────────
  // 1) Load import and verify source_system
  // ─────────────────────────────────────────────────────────────
  const { rows: impRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_imports` +
      `?id=eq.${enc(importId)}` +
      `&select=id,source_system,client_id,parse_summary_json` +
      `&limit=1`
  );
  const imp = impRows?.[0] || null;
  if (!imp) {
    return {
      import_id: importId,
      source_system: null,
      error: 'import_not_found',
      summary: { total_rows: 0 },
      rows: []
    };
  }

  const src = String(imp.source_system || '').toUpperCase();
  if (src !== 'HEALTHROSTER_DAILY') {
    return {
      import_id: importId,
      source_system: src,
      error: 'source_system_mismatch',
      summary: { total_rows: 0 },
      rows: []
    };
  }

  // ─────────────────────────────────────────────────────────────
  // 2) Load hr_rows for this import (using unit_raw, not hospital_or_trust)
  // ─────────────────────────────────────────────────────────────
  const { rows: hrRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_rows` +
      `?import_id=eq.${enc(importId)}` +
      `&select=id,hr_request_id,date_local,start_time_local,end_time_local,` +
      `staff_raw,staff_norm,unit_raw,assignment_grade_norm,hours_worked,payload_json` +
      `&order=id.asc`
  );

  if (!hrRows?.length) {
    return {
      import_id: importId,
      source_system: 'HEALTHROSTER_DAILY',
      summary: { total_rows: 0 },
      rows: []
    };
  }

  // ─────────────────────────────────────────────────────────────
  // 3) Per-row classification, with batched/cached lookups
  // ─────────────────────────────────────────────────────────────
  const results = [];
  let total = 0;
  let okCount = 0;
  let failedCount = 0;
  let unmatchedCount = 0;
  const byReason = {};

  for (const hr of hrRows) {
    total++;

    const hrRowId       = hr.id;
    const hrRequestId   = hr.hr_request_id || null;
    const dateLocal     = hr.date_local || null;
    const staffRaw      = hr.staff_raw || hr.payload_json?.staff_name || '';
    const staffNorm     = hr.staff_norm || norm(staffRaw);
    const hospRaw       = hr.unit_raw || hr.payload_json?.unit || hr.payload_json?.ward || '';
    const hospNorm      = norm(hospRaw);
    const gradeRaw      = hr.assignment_grade_norm || hr.payload_json?.grade_raw || hr.payload_json?.Request_Grade || null;
    const hoursWorked   = hr.hours_worked ?? hr.payload_json?.actual_hours ?? null;
    const startLocal    = hr.start_time_local || hr.payload_json?.start_local || null;
    const endLocal      = hr.end_time_local || hr.payload_json?.end_local || null;

    // Default classification object
    const baseResult = {
      hr_row_id: hrRowId,
      import_id: importId,
      source_system: 'HEALTHROSTER_DAILY',
      hr_request_id: hrRequestId,
      staff_name: staffRaw || null,
      staff_norm: staffNorm || null,
      hospital_or_trust: hospRaw || null,
      trust_norm: hospNorm || null,
      date_local: dateLocal,
      timesheet_id: null,

      // NEW: remediation hooks (populated when we have a timesheet match)
      tsfin_paid_at_utc: null,
      tsfin_locked_by_invoice_id: null,
      tsfin_is_paid: false,
      tsfin_is_invoiced: false,
      tsfin_invoice_id_detected: null,

      status: 'UNMATCHED',
      reason_code: 'timesheet_not_found_or_ambiguous',
      can_email: false,
      details: {
        start_local: startLocal,
        end_local: endLocal,
        hours_worked: hoursWorked
      }
    };

    // Resolve candidate by staff name + trust (cached)
    let candidateId = null;
    try {
      if (staffNorm) {
        candidateId = await resolveCandidateByNameTrustCached(staffRaw, staffNorm, hospNorm);
      }
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] candidate resolve failed (non-fatal)', {
        import_id: importId,
        hr_row_id: hrRowId,
        err: e?.message || String(e)
      });
    }

    // Resolve client via alias mapping (cached)
    let clientId = null;
    try {
      if (hospRaw) {
        clientId = await resolveClientIdCached(hospRaw);
      }
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] client resolve failed (non-fatal)', {
        import_id: importId,
        hr_row_id: hrRowId,
        err: e?.message || String(e)
      });
    }

    // ── NEW: explicit reason codes for unresolved candidate / client ─────────
    const candidateMissing = !candidateId;
    const clientMissing    = !clientId;
    const dateMissing      = !dateLocal;

    if (candidateMissing || clientMissing || dateMissing) {
      unmatchedCount++;

      let reasonKey;
      if (candidateMissing) {
        reasonKey = 'candidate_unresolved';
      } else if (clientMissing) {
        reasonKey = 'client_unresolved';
      } else {
        // date missing or other non-timesheet-specific issue
        reasonKey = 'timesheet_not_found_or_ambiguous';
      }

      byReason[reasonKey] = (byReason[reasonKey] || 0) + 1;
      results.push({
        ...baseResult,
        status: 'UNMATCHED',
        reason_code: reasonKey
      });
      continue;
    }

    // Find daily timesheet for this candidate + date (+ hospital match where possible)
    let ts = null;
    try {
      const tsRows = await getDailyTimesheetsForCandidateCached(candidateId);
      const candidates = [];
      for (const t of (tsRows || [])) {
        const wsIso = t.worked_start_iso || null;
        if (!wsIso) continue;
        let ymd = null;
        try {
          const parts = toLocalParts(wsIso, null);
          ymd = parts && parts.ymd ? parts.ymd : String(wsIso).slice(0, 10);
        } catch {
          ymd = String(wsIso).slice(0, 10);
        }
        if (ymd !== dateLocal) continue;

        // Optional hospital match: if hr had hosp, prefer same hospital_norm
        if (hospNorm && t.hospital_norm) {
          const tsHospNorm = norm(t.hospital_norm);
          if (tsHospNorm !== hospNorm) {
            continue;
          }
        }
        candidates.push(t);
      }

      if (candidates.length === 1) {
        ts = candidates[0];
      } else if (candidates.length > 1) {
        // More than one candidate timesheet -> ambiguous
        unmatchedCount++;
        byReason['timesheet_not_found_or_ambiguous'] = (byReason['timesheet_not_found_or_ambiguous'] || 0) + 1;
        results.push({
          ...baseResult,
          status: 'UNMATCHED',
          reason_code: 'timesheet_not_found_or_ambiguous'
        });
        continue;
      } else {
        unmatchedCount++;
        byReason['timesheet_not_found_or_ambiguous'] = (byReason['timesheet_not_found_or_ambiguous'] || 0) + 1;
        results.push({
          ...baseResult,
          status: 'UNMATCHED',
          reason_code: 'timesheet_not_found_or_ambiguous'
        });
        continue;
      }
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] timesheet lookup failed (non-fatal)', {
        import_id: importId,
        hr_row_id: hrRowId,
        err: e?.message || String(e)
      });
      unmatchedCount++;
      byReason['timesheet_not_found_or_ambiguous'] = (byReason['timesheet_not_found_or_ambiguous'] || 0) + 1;
      results.push({
        ...baseResult,
        status: 'UNMATCHED',
        reason_code: 'timesheet_not_found_or_ambiguous'
      });
      continue;
    }

    const timesheetId = ts?.timesheet_id || null;
    if (!timesheetId) {
      unmatchedCount++;
      byReason['timesheet_not_found_or_ambiguous'] = (byReason['timesheet_not_found_or_ambiguous'] || 0) + 1;
      results.push({
        ...baseResult,
        status: 'UNMATCHED',
        reason_code: 'timesheet_not_found_or_ambiguous'
      });
      continue;
    }

    // NEW: TSFIN remediation hooks (cached, one call per timesheet_id)
    const tsfin = await getTsfinForTimesheetCached(timesheetId);
    const tsfinPaidAt = tsfin?.paid_at_utc || null;
    const tsfinInvId  = tsfin?.locked_by_invoice_id || null;

    // Map grade → roleForRates
    let roleForRates = null;
    try {
      const gradeUse = gradeRaw || null;
      roleForRates = await mapRequestGradeToRole(env, {
        client_id: clientId,
        candidate_id: candidateId,
        gradeRaw: gradeUse,
        dateYmd: dateLocal
      });
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] mapRequestGradeToRole failed (non-fatal)', {
        import_id: importId,
        hr_row_id: hrRowId,
        err: e?.message || String(e)
      });
    }

    // Wrap hr row for validator
    const hrRowForValidation = {
      id: hrRowId,
      hr_request_id: hrRequestId,
      date_local: dateLocal,
      start_time_local: startLocal,
      end_time_local: endLocal,
      staff_raw: staffRaw,
      staff_norm: staffNorm,
      hospital_or_trust: hospRaw,
      assignment_grade_norm: gradeRaw,
      hours_worked: hoursWorked,
      payload_json: hr.payload_json || {}
    };

    let validationRes = { ok: false, reason_code: 'internal_error', detail: null };
    try {
      validationRes = await validateDailyRotaRowAgainstTimesheet(
        env,
        ts,
        hrRowForValidation,
        { roleForRates }
      );
    } catch (e) {
      console.warn('[HR_ROTA_CLASSIFY] validateDailyRotaRowAgainstTimesheet failed (non-fatal)', {
        import_id: importId,
        hr_row_id: hrRowId,
        timesheet_id: timesheetId,
        err: e?.message || String(e)
      });
    }

    const ok = !!validationRes.ok;
    const reasonCode = validationRes.reason_code || null;
    const canEmail =
      !!timesheetId &&
      !!reasonCode &&
      ['actual_hours_mismatch', 'start_end_mismatch', 'break_minutes_mismatch'].includes(
        String(reasonCode).toLowerCase()
      );

    const resRow = {
      ...baseResult,
      timesheet_id: timesheetId,

      // NEW: TSFIN remediation fields
      tsfin_paid_at_utc: tsfinPaidAt,
      tsfin_locked_by_invoice_id: tsfinInvId,
      tsfin_is_paid: !!tsfinPaidAt,
      tsfin_is_invoiced: !!tsfinInvId,
      tsfin_invoice_id_detected: tsfinInvId,

      status: ok ? 'VALIDATION_OK' : 'FAILED',
      reason_code: reasonCode || (ok ? null : 'validation_failed'),
      can_email: canEmail,
      details: validationRes.detail || baseResult.details
    };

    if (ok) {
      okCount++;
    } else {
      failedCount++;
      const key = resRow.reason_code || 'validation_failed';
      byReason[key] = (byReason[key] || 0) + 1;
    }

    results.push(resRow);
  }

  const summary = {
    total_rows: total,
    ok_count: okCount,
    failed_count: failedCount,
    unmatched_count: unmatchedCount,
    by_reason: byReason
  };

  return {
    import_id: importId,
    source_system: 'HEALTHROSTER_DAILY',
    summary,
    rows: results
  };
}
// Resolve any timesheet_id (current or historical) to the current row for its booking_id.
// Returns null if the requested timesheet_id does not exist.


async function resolveTimesheetToCurrent(env, timesheet_id) {
  const enc = encodeURIComponent;

  if (!timesheet_id) return null;

  // 1) Load the requested row by PK (current OR historical)
  const { rows: reqRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(timesheet_id)}` +
      `&select=timesheet_id,booking_id,version,is_current` +
      `&limit=1`
  );

  const reqRow = (reqRows && reqRows[0]) ? reqRows[0] : null;
  if (!reqRow) return null;

  const booking_id = reqRow.booking_id || null;

  // If booking_id is missing, we cannot resolve the series.
  // Return a structured response so callers can turn this into a 400.
  if (!booking_id) {
    return {
      booking_id: null,
      requested_timesheet_id: reqRow.timesheet_id,
      current_timesheet_id: reqRow.timesheet_id,
      current_version: reqRow.version != null ? Number(reqRow.version) : null,
      was_stale: false
    };
  }

  // 2) Load the current row for this booking_id
  let curRow = null;
  try {
    const { rows: curRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?booking_id=eq.${enc(booking_id)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,booking_id,version,is_current` +
        `&order=version.desc` +
        `&limit=1`
    );
    curRow = (curRows && curRows[0]) ? curRows[0] : null;
  } catch {
    curRow = null;
  }

  // Defensive fallback if data is inconsistent (no is_current row found):
  // pick the highest version row.
  if (!curRow) {
    try {
      const { rows: vRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?booking_id=eq.${enc(booking_id)}` +
          `&select=timesheet_id,booking_id,version,is_current` +
          `&order=version.desc` +
          `&limit=1`
      );
      curRow = (vRows && vRows[0]) ? vRows[0] : null;
    } catch {
      curRow = null;
    }
  }

  // If still missing, treat the requested row as the best-known "current".
  if (!curRow) curRow = reqRow;

  const current_timesheet_id = curRow.timesheet_id;
  const current_version = curRow.version != null ? Number(curRow.version) : null;

  return {
    booking_id,
    requested_timesheet_id: reqRow.timesheet_id,
    current_timesheet_id,
    current_version,
    was_stale: String(reqRow.timesheet_id) !== String(current_timesheet_id)
  };
}


async function handleHrRotaValidationPreview(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) {
    return withCORS(env, req, badRequest('import_id is required'));
  }

  const enc = encodeURIComponent;
  const EMAIL_REASON_CODES = new Set([
    'actual_hours_mismatch',
    'start_end_mismatch',
    'break_minutes_mismatch'
  ]);

  const makeIssueFingerprint = (row) => {
    const reasonCode = String(row.reason_code || '').toLowerCase();
    const tsId       = row.timesheet_id || '';
    const hrRowId    = row.hr_row_id || '';

    const detail = row.details || row.detail || {};
    const hrStart = detail.start_local  || detail.hr_start        || '';
    const hrEnd   = detail.end_local    || detail.hr_end          || '';
    const hrHours = detail.hr_hours     || detail.hr_actual_hours || detail.hours_worked || '';
    const tsHours = detail.ts_hours     || detail.ts_total_hours  || '';

    const dateLocal = row.date_local || row.date || row.shift_date || '';
    const staffNorm = (row.staff_norm || row.staff_name || row.staff_raw || '')
      .toLowerCase()
      .trim();
    const unitNorm  = (row.unit_norm || row.unit || row.hospital_or_trust || row.hospital_norm || '')
      .toLowerCase()
      .trim();

    return [
      'HEALTHROSTER_DAILY',
      reasonCode,
      tsId,
      hrRowId,
      staffNorm,
      unitNorm,
      dateLocal,
      hrStart,
      hrEnd,
      hrHours,
      tsHours
    ].join('|');
  };

  try {
    const result = await classifyHrRotaValidationImport(env, importId);
    if (result.error) {
      if (LOG) {
        console.warn('[HR_DAILY_PREVIEW]', JSON.stringify({
          import_id: importId,
          stage: 'classification_error',
          error: result.error
        }));
      }
      // propagate error in body but still 200 (FE handles it)
      return withCORS(env, req, ok(result));
    }

    const rows = Array.isArray(result.rows) ? result.rows : [];

    // ── Precompute fingerprints for rows that *could* ever have an email ─────
    const fingerprints = [];
    const rowFingerprints = new Array(rows.length).fill(null);

    for (let i = 0; i < rows.length; i++) {
      const row = rows[i];
      const reasonCode = String(row.reason_code || '').toLowerCase();
      const tsId       = row.timesheet_id || null;

      const canEmailBase =
        !!tsId &&
        !!reasonCode &&
        EMAIL_REASON_CODES.has(reasonCode);

      if (!canEmailBase) {
        rowFingerprints[i] = null;
        continue;
      }

      const fp = makeIssueFingerprint(row);
      rowFingerprints[i] = fp;
      if (fp) fingerprints.push(fp);
    }

    // ── Look up which of those fingerprints already have an email row ────────
    let alreadySentSet = new Set();
    if (fingerprints.length) {
      try {
        const uniqueFps = Array.from(new Set(fingerprints));
        const { rows: sentRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/hr_issue_emails` +
            `?issue_fingerprint=in.(${uniqueFps.map(enc).join(',')})` +
            `&select=issue_fingerprint`
        );
        alreadySentSet = new Set((sentRows || []).map(r => r.issue_fingerprint));
      } catch (e) {
        if (LOG) {
          console.warn('[HR_DAILY_PREVIEW]', JSON.stringify({
            stage: 'hr_issue_emails_lookup_failed',
            import_id: importId,
            err: e?.message || String(e)
          }));
        }
      }
    }

    const decoratedRows = rows.map((row, idx) => {
      const reasonCode = String(row.reason_code || '').toLowerCase();
      const tsId       = row.timesheet_id || null;

      const emailEligible =
        !!tsId &&
        !!reasonCode &&
        EMAIL_REASON_CODES.has(reasonCode);

      const fp = rowFingerprints[idx];
      const alreadySent = fp ? alreadySentSet.has(fp) : false;

      return {
        ...row,
        email_eligible: emailEligible,
        email_already_sent: alreadySent
      };
    });

    if (LOG) {
      const summary = result.summary || {};
      const sampleFails = decoratedRows
        .filter(r => String(r.status || '').toUpperCase() !== 'VALIDATION_OK')
        .slice(0, 10)
        .map(r => ({
          hr_row_id: r.hr_row_id,
          timesheet_id: r.timesheet_id,
          status: r.status,
          reason_code: r.reason_code,
          details: (r.details && r.details.reason) || (r.detail && r.detail.reason) || null
        }));

      console.log('[HR_DAILY_PREVIEW]', JSON.stringify({
        import_id: result.import_id,
        source_system: result.source_system,
        summary,
        total_rows: decoratedRows.length,
        sample_failures: sampleFails
      }));
    }

    return withCORS(env, req, ok({
      import_id: result.import_id,
      source_system: result.source_system,
      summary: result.summary,
      rows: decoratedRows
    }));
  } catch (e) {
    console.error('[HR_ROTA_PREVIEW] error', {
      import_id: importId,
      err: e?.message || String(e)
    });
    return withCORS(
      env,
      req,
      serverError(`Failed to classify HR daily rota import: ${e?.message || e}`)
    );
  }
}




async function handleHrRotaValidationApply(env, req, importId) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) {
    return withCORS(env, req, badRequest('import_id is required'));
  }

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    body = null;
  }

  const send_email_row_ids = Array.isArray(body?.send_email_row_ids)
    ? body.send_email_row_ids
    : [];
  const emailRowIdSet = new Set(send_email_row_ids.map(String));

  if (LOG) {
    console.log('[HR_DAILY_APPLY]', JSON.stringify({
      stage: 'start',
      import_id: importId,
      send_email_row_ids_count: send_email_row_ids.length
    }));
  }

  const enc = encodeURIComponent;
  const EMAIL_REASON_CODES = new Set([
    'actual_hours_mismatch',
    'start_end_mismatch',
    'break_minutes_mismatch'
  ]);

  const makeIssueFingerprint = (row) => {
    const reasonCode = String(row.reason_code || '').toLowerCase();
    const tsId       = row.timesheet_id || '';
    const hrRowId    = row.hr_row_id || '';

    const detail = row.details || row.detail || {};
    const hrStart = detail.start_local  || detail.hr_start        || '';
    const hrEnd   = detail.end_local    || detail.hr_end          || '';
    const hrHours = detail.hr_hours     || detail.hr_actual_hours || detail.hours_worked || '';
    const tsHours = detail.ts_hours     || detail.ts_total_hours  || '';

    const dateLocal = row.date_local || row.date || row.shift_date || '';
    const staffNorm = (row.staff_norm || row.staff_name || row.staff_raw || '')
      .toLowerCase()
      .trim();
    const unitNorm  = (row.unit_norm || row.unit || row.hospital_or_trust || row.hospital_norm || '')
      .toLowerCase()
      .trim();

    return [
      'HEALTHROSTER_DAILY',
      reasonCode,
      tsId,
      hrRowId,
      staffNorm,
      unitNorm,
      dateLocal,
      hrStart,
      hrEnd,
      hrHours,
      tsHours
    ].join('|');
  };

  let classification;
  try {
    classification = await classifyHrRotaValidationImport(env, importId);
  } catch (e) {
    console.error('[HR_ROTA_APPLY] classify failed', {
      import_id: importId,
      err: e?.message || String(e)
    });
    return withCORS(
      env,
      req,
      serverError(`Failed to classify HR daily rota import: ${e?.message || e}`)
    );
  }

  if (classification.error) {
    if (LOG) {
      console.warn('[HR_DAILY_APPLY]', JSON.stringify({
        stage: 'classification_error',
        import_id: importId,
        error: classification.error
      }));
    }
    // Return classification error back to FE
    return withCORS(env, req, ok(classification));
  }

  const rows = classification.rows || [];
  let validationsOk = 0;
  let validationsFailed = 0;
  let emailsQueued = 0;
  const reasonCounts = {};

  // ── Precompute fingerprints for rows that the user *wants* to email about ──
  const candidateFingerprints = [];
  const fpByHrRowId = new Map();

  for (const row of rows) {
    const hrRowId     = row.hr_row_id;
    const timesheetId = row.timesheet_id || null;
    const reasonCode  = String(row.reason_code || '').toLowerCase();
    const key         = String(hrRowId || '');

    if (!timesheetId) continue;
    if (!EMAIL_REASON_CODES.has(reasonCode)) continue;
    if (!emailRowIdSet.has(key)) continue;

    const fp = makeIssueFingerprint(row);
    if (!fp) continue;

    candidateFingerprints.push(fp);
    fpByHrRowId.set(key, fp);
  }

  // ── Look up which candidate issues already have an email row ──────────────
  let alreadySentSet = new Set();
  if (candidateFingerprints.length) {
    try {
      const uniqueFps = Array.from(new Set(candidateFingerprints));
      const { rows: sentRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/hr_issue_emails` +
          `?issue_fingerprint=in.(${uniqueFps.map(enc).join(',')})` +
          `&select=issue_fingerprint`
      );
      alreadySentSet = new Set((sentRows || []).map(r => r.issue_fingerprint));
    } catch (e) {
      if (LOG) {
        console.warn('[HR_DAILY_APPLY]', JSON.stringify({
          stage: 'hr_issue_emails_lookup_failed',
          import_id: importId,
          err: e?.message || String(e)
        }));
      }
    }
  }

  // ── Main loop: apply validations + optionally send emails & record issues ──
  for (const row of rows) {
    const hrRowId     = row.hr_row_id;
    const timesheetId = row.timesheet_id || null;
    const status      = String(row.status || '').toUpperCase();
    const reasonCode  = row.reason_code || null;
    const hrRequestId = row.hr_request_id || null;

    const rcKey = reasonCode || (status === 'VALIDATION_OK' ? 'ok' : 'unknown');
    reasonCounts[rcKey] = (reasonCounts[rcKey] || 0) + 1;

    if (!timesheetId) {
      // Nothing to apply for unmatched rows
      continue;
    }

    if (status === 'VALIDATION_OK') {
      // ✅ Fully validated / hours match
      try {
        await upsertValidation(env, user, {
          timesheet_id: timesheetId,
          status: 'VALIDATION_OK',
          reason: 'HEALTHROSTER_DAILY',
          hr_reference: hrRequestId,
          import_id: importId
        });
        validationsOk++;
      } catch (e) {
        console.warn('[HR_ROTA_APPLY] upsertValidation VALIDATION_OK failed', {
          import_id: importId,
          timesheet_id: timesheetId,
          hr_row_id: hrRowId,
          err: e?.message || String(e)
        });
        validationsFailed++;
      }

      // Update reference_number with HR Request ID
      if (hrRequestId) {
        try {
          await fetch(
            `${env.SUPABASE_URL}/rest/v1/timesheets` +
              `?timesheet_id=eq.${encodeURIComponent(timesheetId)}&is_current=eq.true`,
            {
              method: 'PATCH',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
              body: JSON.stringify({
                reference_number: hrRequestId,
                updated_at: new Date().toISOString()
              })
            }
          );
        } catch (e) {
          console.warn('[HR_ROTA_APPLY] reference_number update failed', {
            import_id: importId,
            timesheet_id: timesheetId,
            hr_row_id: hrRowId,
            err: e?.message || String(e)
          });
        }
      }

      // 🧹 Once validated OK, remove any stored email-issue records for this hr_row_id
      if (hrRowId) {
        try {
          await fetch(
            `${env.SUPABASE_URL}/rest/v1/hr_issue_emails` +
              `?hr_row_id=eq.${enc(hrRowId)}`,
            {
              method: 'DELETE',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' }
            }
          );
        } catch (e) {
          console.warn('[HR_ROTA_APPLY] hr_issue_emails cleanup failed', {
            import_id: importId,
            timesheet_id: timesheetId,
            hr_row_id: hrRowId,
            err: e?.message || String(e)
          });
        }
      }

      continue;
    }

    // FAILED rows
    validationsFailed++;

    const rc = String(reasonCode || '').toLowerCase();
    const key = String(hrRowId || '');
    const fp  = fpByHrRowId.get(key) || null;
    const alreadySent = fp ? alreadySentSet.has(fp) : false;

    const emailAllowedByReason = EMAIL_REASON_CODES.has(rc);
    const userWantsEmail       = emailRowIdSet.has(key);
    const shouldSendEmail      =
      emailAllowedByReason &&
      userWantsEmail &&
      !!timesheetId &&
      !!fp; // NOTE: no !alreadySent here – user can resend on purpose

    if (shouldSendEmail) {
      // 🔔 Send / re-send the mismatch email
      try {
        await enqueueHrMismatchEmail(env, {
          timesheet_id: timesheetId,
          importId,
          row
        });
        emailsQueued++;
      } catch (e) {
        console.warn('[HR_ROTA_APPLY] enqueueHrMismatchEmail failed', {
          import_id: importId,
          timesheet_id: timesheetId,
          hr_row_id: hrRowId,
          err: e?.message || String(e)
        });
      }

      // Record this issue snapshot in hr_issue_emails if we haven't already
      if (fp && !alreadySent) {
        try {
          const detail    = row.details || row.detail || {};
          const dateLocal = row.date_local || row.date || row.shift_date || null;
          const staffNorm = (row.staff_norm || row.staff_name || row.staff_raw || '')
            .toLowerCase()
            .trim() || null;
          const unitNorm  = (row.unit_norm || row.unit || row.hospital_or_trust || row.hospital_norm || '')
            .toLowerCase()
            .trim() || null;

          await fetch(
            `${env.SUPABASE_URL}/rest/v1/hr_issue_emails`,
            {
              method: 'POST',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
              body: JSON.stringify([{
                source_system: classification.source_system || 'HEALTHROSTER_DAILY',
                import_id: classification.import_id || importId,
                client_id: row.client_id || null,
                timesheet_id: timesheetId,
                hr_row_id: hrRowId || null,
                staff_norm: staffNorm,
                hospital_norm: unitNorm,
                work_date: dateLocal,
                reason_code: rc,
                issue_fingerprint: fp,
                last_sent_at: new Date().toISOString()
              }])
            }
          ).catch(() => { /* best effort */ });
        } catch (e) {
          console.warn('[HR_ROTA_APPLY] hr_issue_emails insert failed', {
            import_id: importId,
            timesheet_id: timesheetId,
            hr_row_id: hrRowId,
            err: e?.message || String(e)
          });
        }
      }
    }

    // Mark validation state as an error for this line (even if no email)
    try {
      await upsertValidation(env, user, {
        timesheet_id: timesheetId,
        status: 'VALIDATION_ERROR',
        reason: rc || 'actual_hours_mismatch',
        hr_reference: hrRequestId,
        import_id: importId
      });
    } catch (e) {
      console.warn('[HR_ROTA_APPLY] upsertValidation VALIDATION_ERROR failed', {
        import_id: importId,
        timesheet_id: timesheetId,
        hr_row_id: hrRowId,
        err: e?.message || String(e)
      });
    }
  }

  // Audit overall apply
  try {
    await writeAudit(
      env,
      user,
      'HR_DAILY_ROTA_APPLY_COMPLETED',
      {
        import_id: importId,
        validations_ok: validationsOk,
        validations_failed: validationsFailed,
        emails_queued: emailsQueued
      },
      { entity: 'hr_imports', subject_id: importId, req }
    );
  } catch (e) {
    console.warn('[HR_ROTA_APPLY] audit failed', {
      import_id: importId,
      err: e?.message || String(e)
    });
  }

  const reasonsArr = Object.entries(reasonCounts).map(([reason_code, count]) => ({
    reason_code,
    count
  }));

  if (LOG) {
    console.log('[HR_DAILY_APPLY]', JSON.stringify({
      stage: 'completed',
      import_id: importId,
      validations_ok: validationsOk,
      validations_failed: validationsFailed,
      emails_queued: emailsQueued,
      reasons: reasonsArr
    }));
  }

  return withCORS(env, req, ok({
    import_id: importId,
    validations_ok: validationsOk,
    validations_failed: validationsFailed,
    emails_queued: emailsQueued,
    reasons: reasonsArr
  }));
}


async function enqueueHrMismatchEmail(env, { timesheet_id, importId, row }) {
  const enc = encodeURIComponent;

  if (!timesheet_id) return;

  // 1) Ensure there is a PDF for this timesheet
  let pdfKey = null;
  try {
    pdfKey = await ensureTimesheetPdf(env, timesheet_id);
  } catch (e) {
    console.warn('[HR_ROTA_EMAIL] ensureTimesheetPdf failed', {
      timesheet_id,
      err: e?.message || String(e)
    });
  }
  if (!pdfKey) {
    throw new Error('Failed to ensure timesheet PDF for mismatch email');
  }

  // 2) Resolve TSO / Temporary Staffing recipient
  let recipientEmail = null;
  try {
    const tgt = await resolveTsoRecipientForTimesheet(env, {
      timesheet_id,
      booking_id: row?.hr_request_id || null
    });
    recipientEmail = tgt?.recipientEmail || tgt?.to_email || null;
  } catch (e) {
    console.warn('[HR_ROTA_EMAIL] resolveTsoRecipientForTimesheet failed', {
      timesheet_id,
      err: e?.message || String(e)
    });
  }

  if (!recipientEmail) {
    throw new Error('No Temporary Staffing email (ts_queries_email) resolved for this timesheet');
  }

  // 3) Compose subject/body
  const staffName  = row?.staff_name || row?.payload_json?.staff_name || 'Agency worker';
  const dateLocal  = row?.date_local || row?.payload_json?.date_local || 'Unknown date';
  const hrRequestId = row?.hr_request_id || row?.payload_json?.request_id || null;
  const reasonCode  = row?.reason_code || 'actual_hours_mismatch';

  const detail = row?.details || {};
  const hrStart = detail.start_local  || detail.hr_start        || 'N/A';
  const hrEnd   = detail.end_local    || detail.hr_end          || 'N/A';
  const hrHours = detail.hr_hours     || detail.hr_actual_hours || detail.hours_worked || 'N/A';
  const tsHours = detail.ts_hours     || detail.ts_total_hours  || 'N/A';

  const subject = `Timesheet hours mismatch – ${staffName} – ${dateLocal} – ${hrRequestId || 'no HR ref'}`;

  const lines = [
    `Dear Temporary Staffing,`,
    ``,
    `Please can you amend the hours on HealthRoster for the attached agency shift.`,
    ``,
    `Staff: ${staffName}`,
    `Date: ${dateLocal}`,
    `HR Request ID: ${hrRequestId || '(not provided)'}`,
    ``,
    `HealthRoster shows:`,
    `  Start: ${hrStart}`,
    `  End:   ${hrEnd}`,
    `  Actual Hours: ${hrHours}`,
    ``,
    `Signed timesheet attached shows:`,
    `  Actual Hours: ${tsHours}`,
    ``,
    `Once amended, please kindly confirm.`,
    ``,
    `Kind regards,`,
    `CloudTMS`
  ];

  const body_text = lines.join('\n');
  const body_html = `<p>${lines.map(l => (l === '' ? '<br/>' : l)).join('<br/>')}</p>`;

  // 4) Insert into mail_outbox (using existing schema)
  const mailPayload = [{
    // existing columns on mail_outbox
    to: recipientEmail,
    subject,
    body_text,
    body_html,
    // attachments is the existing JSONB field for attachments
    attachments: [{
      r2_key: pdfKey,
      filename: `Timesheet_${timesheet_id}.pdf`
    }],
    // type must be one of the allowed enum values
    type: 'TSO_FAILURE',
    // preserve context in reference / correlation_id for debugging
    reference: hrRequestId || null,
    correlation_id: `HR_DAILY_MISMATCH:${timesheet_id}:${hrRequestId || ''}`
  }];

  try {
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/mail_outbox`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(mailPayload)
      }
    );
    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      console.error('[HR_ROTA_EMAIL] mail_outbox insert failed', {
        timesheet_id,
        import_id: importId,
        error: txt
      });
      throw new Error(`Failed to queue mismatch email: ${txt}`);
    }
  } catch (e) {
    console.error('[HR_ROTA_EMAIL] mail_outbox insert error', {
      timesheet_id,
      import_id: importId,
      err: e?.message || String(e)
    });
    throw e;
  }

  // 5) Audit
  try {
    await writeAudit(
      env,
      null, // system / worker context; no interactive user
      'HR_DAILY_MISMATCH_EMAIL_QUEUED',
      {
        import_id: importId,
        timesheet_id,
        hr_row_id: row?.hr_row_id || null,
        hr_request_id: hrRequestId,
        recipient_email: recipientEmail,
        reason_code: reasonCode,
        pdf_key: pdfKey
      },
      { entity: 'timesheets', subject_id: timesheet_id, req: null }
    );
  } catch (e) {
    console.warn('[HR_ROTA_EMAIL] audit failed', {
      timesheet_id,
      import_id: importId,
      err: e?.message || String(e)
    });
  }
}


async function mapRequestGradeToRole(env, { client_id, candidate_id, gradeRaw, dateYmd, candidate_roles = null }) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L = (...a) => { if (LOG) console.log('[TSFIN][DAILY][mapRequestGradeToRole]', ...a); };

  const enc = encodeURIComponent;
  const norm = (s) => String(s || '').trim().toLowerCase();
  const squash = (s) => norm(s).replace(/[^a-z0-9]+/g, ' ').trim();

  if (!gradeRaw || !client_id || !candidate_id || !dateYmd) {
    L('early return (missing inputs)', { gradeRaw, client_id, candidate_id, dateYmd });
    return null;
  }

  const rawLower = norm(gradeRaw);
  const squashed = squash(gradeRaw);

  let bandFromGrade = null;
  try {
    let m = rawLower.match(/band\s*([0-9]+)/i);
    if (!m) m = rawLower.match(/\bb\s*([0-9]+)\b/i);
    if (!m) m = rawLower.match(/\b([0-9]+)\b/);
    if (m && m[1]) {
      bandFromGrade = `Band ${parseInt(m[1], 10)}`;
    }
  } catch {}

  const mentions = {
    rmn: rawLower.includes('rmn') || rawLower.includes('mental'),
    hca: rawLower.includes('hca') || rawLower.includes('health care'),
    rgn: rawLower.includes('rgn') || rawLower.includes('registered nurse'),
    lead: rawLower.includes('lead')
  };

  const scoreRole = (roleStr) => {
    const rNorm = squash(roleStr || '');
    if (!rNorm) return 0;

    let score = 0;

    if (squashed.includes(rNorm)) score += 5;

    const gradeTokens = squashed.split(/\s+/).filter(Boolean);
    const rTokens = rNorm.split(/\s+/).filter(Boolean);
    score += rTokens.filter(t => gradeTokens.includes(t)).length;

    const joined = `${rNorm}`;
    if (mentions.rmn && joined.includes('rmn')) score += 3;
    if (mentions.hca && joined.includes('hca')) score += 3;
    if (mentions.rgn && joined.includes('rgn')) score += 2;
    if (mentions.lead && joined.includes('lead')) score += 1;

    return score;
  };

  const normRoleOut = (s) =>
    String(s || '')
      .trim()
      .replace(/\s+/g, ' ')
      .toUpperCase();

  let candRoles = Array.isArray(candidate_roles) ? candidate_roles : null;
  if (!candRoles) {
    try {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(candidate_id)}` +
          `&select=roles&limit=1`
      );
      const r0 = rows?.[0] || null;
      let rolesVal = r0?.roles;
      if (typeof rolesVal === 'string') {
        try { rolesVal = JSON.parse(rolesVal); } catch {}
      }
      if (Array.isArray(rolesVal)) {
        candRoles = rolesVal
          .map(r => (r && typeof r === 'object') ? r.code : r)
          .map(normRoleOut)
          .filter(Boolean);
      } else {
        candRoles = [];
      }
    } catch {
      candRoles = [];
    }
  }

  L('ENTRY', { gradeRaw, squashed, bandFromGrade, candRoles, client_id, candidate_id, dateYmd });

  if (candRoles.length) {
    let best = { score: 0, role: null };
    for (const r of candRoles) {
      const s = scoreRole(r);
      if (s > best.score) best = { score: s, role: r };
    }

    L('candidate-role scoring', { best });

    if (best.role && best.score >= 2) {
      const out = { role: best.role, band: bandFromGrade || null };
      L('EXIT via candidate.roles', out);
      return out;
    }

    if (candRoles.length === 1) {
      const out = { role: candRoles[0], band: bandFromGrade || null };
      L('EXIT via single candidate role fallback', out);
      return out;
    }
  }

  // Fallback: client default roles
  try {
    const date = encodeURIComponent(dateYmd);
    const url =
      `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
      `?client_id=eq.${enc(client_id)}` +
      `&and=(date_from.lte.${date},or(date_to.is.null,date_to.gte.${date}))` +
      `&disabled_at_utc=is.null` +
      `&select=role,band`;

    L('fallback query client defaults', { url });

    const { rows: rateRows } = await sbFetch(env, url);

    let best = { score: 0, role: null, band: null };
    const seen = new Set();
    for (const r of rateRows || []) {
      const key = `${r.role || ''}__${r.band || ''}`;
      if (seen.has(key)) continue;
      seen.add(key);

      const s = scoreRole(r.role);
      if (s > best.score) {
        best = { score: s, role: r.role || null, band: r.band || null };
      }
    }

    L('client-default scoring', { best });

    if (best.role && best.score >= 3) {
      const out = { role: best.role, band: best.band || bandFromGrade || null };
      L('EXIT via client defaults', out);
      return out;
    }
  } catch (e) {
    console.warn('[TSFIN][DAILY][mapRequestGradeToRole] rates_client_defaults lookup failed', {
      client_id,
      dateYmd,
      err: e?.message || String(e)
    });
    L('fallback lookup failed', { err: String(e?.message || e) });
  }

  L('EXIT null (no mapping)');
  return null;
}

async function validateDailyRotaRowAgainstTimesheet(env, ts, hrRow, { roleForRates }) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L = (...a) => { if (LOG) console.log('[TSFIN][DAILY][validateDailyRotaRowAgainstTimesheet]', ...a); };

  const enc = encodeURIComponent;

  const normRole = (s) =>
    String(s || '').trim().replace(/\s+/g, ' ').toUpperCase();

  const normBand = (v) => {
    const s = String(v || '').trim();
    if (!s) return null;
    let m = s.match(/^\s*band\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*b\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*([0-9]+)\s*$/);
    if (m && m[1]) return `Band ${parseInt(m[1], 10)}`;
    return s;
  };

  const hrRequestId = hrRow?.hr_request_id || hrRow?.payload_json?.request_id || null;
  const dateLocal   = hrRow?.date_local || null;

  L('START', { timesheet_id: ts?.timesheet_id, hr_request_id: hrRequestId, date_local: dateLocal });

  const pad2 = (n) => String(n).padStart(2, '0');

  const parseHhmm = (v) => {
    if (v == null || v === '') return null;
    if (typeof v === 'number') {
      if (v >= 0 && v < 1) {
        const totalMinutes = Math.round(v * 24 * 60);
        const hh = Math.floor(totalMinutes / 60);
        const mm = totalMinutes % 60;
        return `${pad2(hh)}:${pad2(mm)}`;
      }
    }
    const s = String(v).trim();
    if (!s) return null;
    const m = s.match(/^(\d{1,2}):(\d{2})(?::\d{2})?$/);
    if (!m) {
      const s2 = s.replace(':', '');
      if (/^\d{3,4}$/.test(s2)) {
        const hh = pad2(parseInt(s2.slice(0, -2), 10) || 0);
        const mm = pad2(parseInt(s2.slice(-2), 10) || 0);
        return `${hh}:${mm}`;
      }
      return null;
    }
    return `${pad2(parseInt(m[1], 10) || 0)}:${pad2(parseInt(m[2], 10) || 0)}`;
  };

  const hhmmToMinutes = (hhmm) => {
    if (!hhmm) return null;
    const [h, m] = hhmm.split(':').map(Number);
    if (!Number.isFinite(h) || !Number.isFinite(m)) return null;
    return h * 60 + m;
  };

  const parseActualHours = (v) => {
    if (v == null || v === '') return null;
    if (typeof v === 'number') return Number(v);
    const s = String(v).trim();
    if (!s) return null;
    const m = s.match(/^(\d{1,2}):(\d{2})(?::\d{2})?$/);
    if (m) {
      const h = parseInt(m[1], 10) || 0;
      const mm = parseInt(m[2], 10) || 0;
      return h + mm / 60;
    }
    const num = Number(s);
    return Number.isFinite(num) ? num : null;
  };

  const hrStartLocal = parseHhmm(hrRow?.start_time_local || hrRow?.payload_json?.start_local);
  const hrEndLocal   = parseHhmm(hrRow?.end_time_local   || hrRow?.payload_json?.end_local);

  const hrStartMin = hhmmToMinutes(hrStartLocal);
  const hrEndMin   = hhmmToMinutes(hrEndLocal);

  let shiftMinutes = null;
  if (hrStartMin != null && hrEndMin != null) {
    shiftMinutes = hrEndMin - hrStartMin;
    if (shiftMinutes <= 0) shiftMinutes += 24 * 60;
  }

  const actualHoursRota =
    parseActualHours(hrRow?.hours_worked) ??
    parseActualHours(hrRow?.payload_json?.actual_hours);

  let paidMinutesRota = null;
  if (shiftMinutes != null && actualHoursRota != null) {
    paidMinutesRota = Math.round(actualHoursRota * 60);
  }

  let breakMinutesRota = null;
  if (shiftMinutes != null && paidMinutesRota != null) {
    breakMinutesRota = Math.max(0, shiftMinutes - paidMinutesRota);
  }

  L('rota parsed', {
    hr_start_local: hrStartLocal,
    hr_end_local: hrEndLocal,
    shift_minutes: shiftMinutes,
    actual_hours: actualHoursRota,
    break_minutes: breakMinutesRota
  });

  // Timesheet time derivation
  const tsStartIso = ts.worked_start_iso || null;
  const tsEndIso   = ts.worked_end_iso   || null;
  let tsStartMin = null;
  let tsEndMin   = null;
  let tsShiftMin = null;

  if (tsStartIso && tsEndIso) {
    try {
      const partsStart = toLocalParts(tsStartIso, null);
      const partsEnd   = toLocalParts(tsEndIso, null);
      const sHm = partsStart && partsStart.hm ? partsStart.hm : tsStartIso.slice(11, 16);
      const eHm = partsEnd   && partsEnd.hm   ? partsEnd.hm   : tsEndIso.slice(11, 16);
      tsStartMin = hhmmToMinutes(sHm);
      tsEndMin   = hhmmToMinutes(eHm);
      if (tsStartMin != null && tsEndMin != null) {
        tsShiftMin = tsEndMin - tsStartMin;
        if (tsShiftMin <= 0) tsShiftMin += 24 * 60;
      }
    } catch {}
  }

  // Load TSFIN
  let tsfin = null;
  try {
    const { rows: finRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,total_hours,hours_day,hours_night,hours_sat,hours_sun,hours_bh,` +
        `candidate_id,client_id,break_minutes` +
        `&limit=1`
    );
    tsfin = finRows?.[0] || null;
  } catch (e) {
    console.warn('[HR_DAILY_VALIDATE] TSFIN lookup failed', {
      timesheet_id: ts.timesheet_id,
      err: e?.message || String(e)
    });
  }

  const totalHoursTsfin = tsfin?.total_hours != null ? Number(tsfin.total_hours) : null;

  let breakMinutesTs = null;
  if (typeof ts.break_minutes === 'number') {
    breakMinutesTs = ts.break_minutes;
  } else if (tsfin?.break_minutes != null) {
    breakMinutesTs = tsfin.break_minutes;
  } else if (tsShiftMin != null && totalHoursTsfin != null) {
    const b = tsShiftMin - totalHoursTsfin * 60;
    breakMinutesTs = b > 0 ? b : 0;
  }

  L('timesheet/tsfin derived', {
    ts_start_iso: tsStartIso,
    ts_end_iso: tsEndIso,
    ts_shift_minutes: tsShiftMin,
    ts_break_minutes: breakMinutesTs,
    tsfin_total_hours: totalHoursTsfin,
    tsfin_candidate_id: tsfin?.candidate_id || null,
    tsfin_client_id: tsfin?.client_id || null
  });

  let reason = null;

  // 1) Start/end mismatch
  if (reason == null && hrStartMin != null && tsStartMin != null) {
    const diffStart = Math.abs(hrStartMin - tsStartMin);
    const diffEnd   = (hrEndMin != null && tsEndMin != null) ? Math.abs(hrEndMin - tsEndMin) : 0;
    if (diffStart > 1 || diffEnd > 1) reason = 'start_end_mismatch';
    L('check start/end', { diffStart, diffEnd, reason });
  }

  // 2) Break minutes mismatch
  if (reason == null && breakMinutesRota != null && breakMinutesTs != null) {
    const diffBreak = Math.abs(breakMinutesRota - breakMinutesTs);
    if (diffBreak > 5) reason = 'break_minutes_mismatch';
    L('check breaks', { diffBreak, reason });
  }

  // 3) Actual hours mismatch
  if (reason == null && actualHoursRota != null && totalHoursTsfin != null) {
    const diffHours = Math.abs(actualHoursRota - totalHoursTsfin);
    if (diffHours > 0.05) reason = 'actual_hours_mismatch';
    L('check hours', { diffHours, reason });
  }

  // 4) Grade → rates existence
  if (reason == null) {
    let rf = roleForRates && roleForRates.role
      ? { role: normRole(roleForRates.role), band: normBand(roleForRates.band || null) }
      : null;

    L('roleForRates input', { rf_in: roleForRates || null, rf });

    if (!rf) {
      try {
        const clientId     = tsfin?.client_id || null;
        const candidateId  = tsfin?.candidate_id || null;
        const gradeGuess =
          hrRow?.grade ||
          hrRow?.payload_json?.grade ||
          ts.job_title_norm ||
          null;

        L('derive roleForRates (best-effort)', { clientId, candidateId, dateLocal, gradeGuess });

        if (clientId && candidateId && dateLocal && gradeGuess) {
          const mapped = await mapRequestGradeToRole(env, {
            client_id: clientId,
            candidate_id: candidateId,
            gradeRaw: gradeGuess,
            dateYmd: dateLocal
          });
          L('mapped grade->role', mapped || null);
          if (mapped?.role) rf = { role: normRole(mapped.role), band: normBand(mapped.band || null) };
        }
      } catch (e) {
        L('derive roleForRates failed', { err: String(e?.message || e) });
      }
    }

    if (!rf || !rf.role) {
      reason = 'rate_missing_for_grade';
      L('rate check: missing roleForRates', { reason });
    } else {
      try {
        const usedBuckets = {
          day:   Number(tsfin?.hours_day   || 0),
          night: Number(tsfin?.hours_night || 0),
          sat:   Number(tsfin?.hours_sat   || 0),
          sun:   Number(tsfin?.hours_sun   || 0),
          bh:    Number(tsfin?.hours_bh    || 0)
        };

        const clientId     = tsfin?.client_id || null;
        const candidateId  = tsfin?.candidate_id || null;

        L('rate check: resolveRates', { usedBuckets, clientId, candidateId, rf, dateLocal });

        const rates = await resolveRates(env, {
          candidate_id: candidateId,
          client_id: clientId,
          role: rf.role,
          band: rf.band || null,
          dateYmd: dateLocal || null
        });

        const pay = rates.pay || {};
        const chg = rates.charge || {};

        const anyMissing =
          (usedBuckets.day   > 0 && (pay.day   == null || chg.day   == null)) ||
          (usedBuckets.night > 0 && (pay.night == null || chg.night == null)) ||
          (usedBuckets.sat   > 0 && (pay.sat   == null || chg.sat   == null)) ||
          (usedBuckets.sun   > 0 && (pay.sun   == null || chg.sun   == null)) ||
          (usedBuckets.bh    > 0 && (pay.bh    == null || chg.bh    == null));

        if (anyMissing) reason = 'rate_missing_for_grade';

        L('rate check result', {
          source: rates?.source || null,
          pay,
          charge: chg,
          anyMissing,
          reason
        });
      } catch (e) {
        console.warn('[HR_DAILY_VALIDATE] resolveRates failed for grade role', {
          timesheet_id: ts.timesheet_id,
          err: e?.message || String(e)
        });
        reason = 'rate_missing_for_grade';
        L('rate check exception', { err: String(e?.message || e), reason });
      }
    }
  }

  const detail = {
    hr_request_id: hrRequestId,
    date_local: dateLocal,
    hr_start_local: hrStartLocal,
    hr_end_local: hrEndLocal,
    hr_shift_minutes: shiftMinutes,
    hr_actual_hours: actualHoursRota,
    hr_break_minutes: breakMinutesRota,
    ts_worked_start_iso: tsStartIso,
    ts_worked_end_iso: tsEndIso,
    ts_shift_minutes: tsShiftMin,
    ts_break_minutes: breakMinutesTs,
    ts_total_hours: totalHoursTsfin
  };

  if (!reason) {
    L('EXIT OK', detail);
    return { ok: true, reason_code: null, hr_request_id: hrRequestId, detail };
  }

  L('EXIT FAIL', { reason, detail });
  return { ok: false, reason_code: reason, hr_request_id: hrRequestId, detail };
}





async function handleTimesheetsResolvePreview(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    body = null;
  }

  const ids = Array.isArray(body?.timesheet_ids)
    ? [...new Set(body.timesheet_ids.map(String).filter(Boolean))]
    : [];

  if (!ids.length) {
    return withCORS(
      env,
      req,
      badRequest('timesheet_ids[] required')
    );
  }

  const enc = encodeURIComponent;
  const idsParam = ids.map(enc).join(',');

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
        `?timesheet_id=in.(${idsParam})` +
        `&select=` +
          [
            'timesheet_id',
            'sheet_scope',
            'week_ending_date',
            'candidate_id',
            'client_id',
            'processing_status',
            'occupant_key_norm',
            'hospital_norm',
            // ✅ NEW: needed for hint display + seeded best matches
            'candidate_name',
            'candidate_hint_text'
          ].join(',')
    );

    const filtered = (rows || []).filter((r) => {
      const p = String(r.processing_status || '').toUpperCase();
      return p === 'UNASSIGNED' || p === 'CLIENT_UNRESOLVED';
    });

    return withCORS(env, req, ok(filtered));
  } catch (e) {
    return withCORS(
      env,
      req,
      serverError(`Failed to build resolve preview: ${e?.message || e}`)
    );
  }
}

async function handleTimesheetResolveCandidate(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!timesheetId) {
    return withCORS(env, req, badRequest('timesheet_id is required'));
  }

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }

  // ✅ Guarded write
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const candidateId = body?.candidate_id || body?.candidateId || null;
  if (!candidateId) return withCORS(env, req, badRequest('candidate_id is required'));

  // ✅ stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved?.current_timesheet_id) return withCORS(env, req, notFound('Timesheet not found'));

  const currentTimesheetId   = String(resolved.current_timesheet_id);
  const requestedTimesheetId = String(timesheetId);
  const wasStale = (currentTimesheetId !== requestedTimesheetId);

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  // Pull TSFIN knobs
  let maxInlineItems = 3;
  try {
    const s = await loadSettingsDefaults(env);
    const n = Number(s?.importConfig?.tsfin?.maxInlineItems);
    if (Number.isFinite(n) && n > 0) maxInlineItems = Math.floor(n);
  } catch {}

  try {
    // Load CURRENT timesheet (no candidate_id column on timesheets)
    const ts = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,occupant_key_norm,sheet_scope,submission_mode,authorised_at_server` +
        `&limit=1`
    );
    if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

    // Load candidate
    const cand = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?id=eq.${enc(candidateId)}` +
        `&select=id,nhsp_hr_name_aliases,key_norm` +
        `&limit=1`
    );
    if (!cand) return withCORS(env, req, notFound('Candidate not found'));

    const rawOcc  = ts.occupant_key_norm || '';
    const occNorm = String(rawOcc).trim().toLowerCase();

    const sheetScope = String(ts.sheet_scope || '').toUpperCase();
    const subMode    = String(ts.submission_mode || '').toUpperCase();
    const isDailyElectronic = (sheetScope === 'DAILY' && subMode === 'ELECTRONIC');

    // Helper: enqueue via SQL helper + drain a small, capped set inline
    const bumpTsfinNow = async ({ occKeyNorm }) => {
      // 1) Bulk enqueue (SQL helper)
      //    This queues ALL matching current authorised, unlocked, unpaid timesheets for this occKey.
      let enqueuedCount = 0;
      if (occKeyNorm) {
        try {
          enqueuedCount = await rpcEnqueueTsfinForOccKey(env, {
            occKey: occKeyNorm,
            reason: 'CONTEXT_CHANGED',
            priority: true,
            limit: 500
          });
        } catch (e) {
          console.warn('[TS_RESOLVE_CAND] enqueue_tsfin_for_occ_key failed', e?.message || e);
        }
      } else {
        // Fallback: only enqueue the current timesheet
        try {
          await sbRpc(env, 'enqueue_ts_financials_priority', {
            _timesheet_ids: [currentTimesheetId],
            _reason: 'CONTEXT_CHANGED'
          });
          enqueuedCount = 1;
        } catch {}
      }

      // 2) Determine inline drain ids (bounded)
      //    We always attempt the current timesheet inline.
      const inlineIds = [currentTimesheetId];

      // Optionally include a few related IDs inline (only if we have an occKeyNorm and budget)
      if (occKeyNorm && maxInlineItems > 1) {
        try {
       const { rows } = await sbFetch(
  env,
  `${env.SUPABASE_URL}/rest/v1/timesheets` +
    `?is_current=eq.true` +
    `&occupant_key_norm=eq.${enc(occKeyNorm)}` +
    `&select=timesheet_id` +
    `&limit=${Math.min(500, Math.max(1, maxInlineItems - 1) + 1)}`
);

          for (const r of (rows || [])) {
            const id = r?.timesheet_id ? String(r.timesheet_id) : '';
            if (!id || id === currentTimesheetId) continue;
            inlineIds.push(id);
            if (inlineIds.length >= maxInlineItems) break;
          }
        } catch {}
      }

      // 3) Targeted drain ONLY the inline ids
      let drainRes = null;
      try {
        drainRes = await runTsfinWorkerOnce(env, { limit: inlineIds.length, onlyTimesheetIds: inlineIds });
      } catch (e) {
        console.warn('[TS_RESOLVE_CAND] targeted runTsfinWorkerOnce failed', e?.message || e);
      }

      return { enqueuedCount, inlineIds, drainRes };
    };

    // ==========================================================
    // ✅ DAILY/ELECTRONIC = occupant_key_norm is a GCK (key_norm)
    // ==========================================================
    if (isDailyElectronic) {
      const gck = occNorm;

      if (!gck) {
        return withCORS(env, req, badRequest('Timesheet has no occupant_key_norm (GCK) to assign'));
      }

      // Block if this GCK belongs to a different candidate
      try {
        const other = await sbGetOne(
          env,
          `${env.SUPABASE_URL}/rest/v1/candidates` +
            `?key_norm=eq.${enc(gck)}` +
            `&id=neq.${enc(candidateId)}` +
            `&select=id` +
            `&limit=1`
        );
        if (other?.id) {
          return withCORS(
            env,
            req,
            new Response(
              JSON.stringify({
                error: 'CANDIDATE_KEY_CONFLICT',
                message: 'This GCK is already assigned to another candidate.',
                candidate_id: candidateId,
                conflicting_candidate_id: other.id,
                attempted_key_norm: gck
              }),
              { status: 409, headers: { 'Content-Type': 'application/json' } }
            )
          );
        }
      } catch {}

      // Block overwriting an existing different key_norm on THIS candidate
      const existingKey = String(cand.key_norm || '').trim().toLowerCase();
      if (existingKey && existingKey !== gck) {
        return withCORS(
          env,
          req,
          new Response(
            JSON.stringify({
              error: 'CANDIDATE_KEY_CONFLICT',
              message: 'This candidate already has a different key_norm; cannot assign this GCK.',
              candidate_id: candidateId,
              existing_key_norm: cand.key_norm,
              attempted_key_norm: gck
            }),
            { status: 409, headers: { 'Content-Type': 'application/json' } }
          )
        );
      }

      // Patch candidate key_norm
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candidateId)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({ key_norm: gck })
        }
      );
      if (!res.ok) {
        const txt = await res.text().catch(() => '');
        console.warn('[TS_RESOLVE_CAND] patch candidate key_norm failed', { candidate_id: candidateId, status: res.status, body: txt });
      }

      // ✅ Enqueue all matching occKey timesheets + drain a few inline
      await bumpTsfinNow({ occKeyNorm: gck });

    } else {
      // ==========================================================
      // Legacy behaviour: occupant_key_norm is a name alias list (nhsp_hr_name_aliases)
      // ==========================================================
      const alias = occNorm;

      if (!alias) {
        // Still kick TSFIN for the current timesheet only
        await bumpTsfinNow({ occKeyNorm: null });
      } else {
        const existingAliases = Array.isArray(cand.nhsp_hr_name_aliases) ? cand.nhsp_hr_name_aliases : [];
        const mergedAliases = normaliseAliasList([ ...existingAliases, alias ]);

        // Do NOT touch key_norm here
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candidateId)}`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify({ nhsp_hr_name_aliases: mergedAliases })
          }
        );
        if (!res.ok) {
          const txt = await res.text().catch(() => '');
          console.warn('[TS_RESOLVE_CAND] patch candidate aliases failed', { candidate_id: candidateId, status: res.status, body: txt });
        }

        // Enqueue all timesheets with this occupant_key_norm alias (if that’s how they’re stored)
        await bumpTsfinNow({ occKeyNorm: alias });
      }
    }

    // Return updated summary row (so FE can repaint immediately)
    let summaryRow = null;
    try {
      summaryRow = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&select=timesheet_id,processing_status,candidate_id,client_id,candidate_name,client_name` +
          `&limit=1`
      );
    } catch {}

    return withCORS(env, req, ok({
      ok: true,
      requested_timesheet_id: requestedTimesheetId,
      current_timesheet_id: currentTimesheetId,
      was_stale: wasStale,
      summary: summaryRow || null
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to resolve timesheet candidate: ${e?.message || e}`));
  }
}


async function handleTimesheetResolveClient(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!timesheetId) {
    return withCORS(env, req, badRequest('timesheet_id is required'));
  }

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }

  // ✅ Guarded write
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const clientId = body?.client_id || body?.clientId || null;
  if (!clientId) return withCORS(env, req, badRequest('client_id is required'));

  // ✅ stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved?.current_timesheet_id) return withCORS(env, req, notFound('Timesheet not found'));

  const currentTimesheetId   = String(resolved.current_timesheet_id);
  const requestedTimesheetId = String(timesheetId);
  const wasStale = (currentTimesheetId !== requestedTimesheetId);

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  // Pull TSFIN knobs
  let maxInlineItems = 3;
  try {
    const s = await loadSettingsDefaults(env);
    const n = Number(s?.importConfig?.tsfin?.maxInlineItems);
    if (Number.isFinite(n) && n > 0) maxInlineItems = Math.floor(n);
  } catch {}

  try {
    // Load CURRENT timesheet to get hospital_norm
    const ts = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,hospital_norm,is_current` +
        `&limit=1`
    );
    if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

    const alias = String(ts.hospital_norm || '').trim().toLowerCase();

    const normaliseList = (val) => {
      if (!val) return [];
      if (Array.isArray(val)) return val;
      if (typeof val === 'string') {
        try {
          const parsed = JSON.parse(val);
          return Array.isArray(parsed) ? parsed : [val];
        } catch {
          return [val];
        }
      }
      return [];
    };

    // Helper: enqueue via SQL helper + drain a small, capped set inline
    const bumpTsfinNow = async ({ hospitalNorm }) => {
      // 1) Bulk enqueue (SQL helper)
      let enqueuedCount = 0;
      if (hospitalNorm) {
        try {
          enqueuedCount = await rpcEnqueueTsfinForHospitalNorm(env, {
            hospitalNorm,
            reason: 'CONTEXT_CHANGED',
            priority: true,
            limit: 500
          });
        } catch (e) {
          console.warn('[TS_RESOLVE_CLIENT] enqueue_tsfin_for_hospital_norm failed', e?.message || e);
        }
      } else {
        // Fallback: only enqueue the current timesheet
        try {
          await sbRpc(env, 'enqueue_ts_financials_priority', {
            _timesheet_ids: [currentTimesheetId],
            _reason: 'CONTEXT_CHANGED'
          });
          enqueuedCount = 1;
        } catch {}
      }

      // 2) Inline drain IDs (always include current)
      const inlineIds = [currentTimesheetId];

      if (hospitalNorm && maxInlineItems > 1) {
        try {
    const { rows } = await sbFetch(
  env,
  `${env.SUPABASE_URL}/rest/v1/timesheets` +
    `?is_current=eq.true` +
    `&hospital_norm=eq.${enc(hospitalNorm)}` +
    `&select=timesheet_id` +
    `&limit=${Math.min(500, Math.max(1, maxInlineItems - 1) + 1)}`
);

          for (const r of (rows || [])) {
            const id = r?.timesheet_id ? String(r.timesheet_id) : '';
            if (!id || id === currentTimesheetId) continue;
            inlineIds.push(id);
            if (inlineIds.length >= maxInlineItems) break;
          }
        } catch {}
      }

      // 3) Targeted drain
      try {
        await runTsfinWorkerOnce(env, { limit: inlineIds.length, onlyTimesheetIds: inlineIds });
      } catch (e) {
        console.warn('[TS_RESOLVE_CLIENT] targeted runTsfinWorkerOnce failed', e?.message || e);
      }

      return { enqueuedCount, inlineIds };
    };

    // If there is no alias, we can't enforce mapping; still kick TSFIN for current only.
    if (!alias) {
      await bumpTsfinNow({ hospitalNorm: null });

      let summaryRow = null;
      try {
        summaryRow = await sbGetOne(
          env,
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
            `?timesheet_id=eq.${enc(currentTimesheetId)}` +
            `&select=timesheet_id,processing_status,candidate_id,client_id,candidate_name,client_name` +
            `&limit=1`
        );
      } catch {}

      return withCORS(env, req, ok({
        ok: true,
        requested_timesheet_id: requestedTimesheetId,
        current_timesheet_id: currentTimesheetId,
        was_stale: wasStale,
        summary: summaryRow || null
      }));
    }

    // ✅ Enforce alias uniqueness across clients (existing behaviour preserved)
    try {
      const aliasJson = JSON.stringify([alias]); // ["alias"]
      let rowsWithAlias = [];

      try {
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
            `?hospital_name_norm=cs.${enc(aliasJson)}` +
            `&select=id,client_id,hospital_name_norm` +
            `&order=id.asc`
        );
        rowsWithAlias = Array.isArray(rows) ? rows : [];
      } catch (e) {
        rowsWithAlias = [];
        console.warn('[TS_RESOLVE_CLIENT] client_hospitals cs lookup failed (fallback)', e?.message || e);
      }

      const ownedByChosen = rowsWithAlias.find(r => String(r.client_id) === String(clientId)) || null;
      const ownedByOthers = rowsWithAlias.filter(r => String(r.client_id) !== String(clientId));

      // 1) Remove alias from other clients
      for (const r of ownedByOthers) {
        const cur = normaliseList(r.hospital_name_norm);
        const next = cur.filter(x => String(x || '').trim().toLowerCase() !== alias);

        if (next.length !== cur.length) {
          const res = await fetch(
            `${env.SUPABASE_URL}/rest/v1/client_hospitals?id=eq.${enc(r.id)}`,
            {
              method: 'PATCH',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
              body: JSON.stringify({ hospital_name_norm: next })
            }
          );
          if (!res.ok) {
            const txt = await res.text().catch(() => '');
            console.warn('[TS_RESOLVE_CLIENT] client_hospitals de-alias failed', {
              id: r.id,
              from_client_id: r.client_id,
              alias,
              status: res.status,
              body: txt
            });
          }
        }
      }

      // 2) Ensure chosen client has the alias
      if (!ownedByChosen) {
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/client_hospitals`,
          {
            method: 'POST',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify([{
              client_id: clientId,
              hospital_name_norm: [alias]
            }])
          }
        );
        if (!res.ok) {
          const txt = await res.text().catch(() => '');
          console.warn('[TS_RESOLVE_CLIENT] client_hospitals insert failed', {
            client_id: clientId,
            alias,
            status: res.status,
            body: txt
          });
        }
      }
    } catch (e) {
      console.warn('[TS_RESOLVE_CLIENT] client_hospitals alias enforcement failed (non-fatal)', {
        client_id: clientId,
        alias,
        err: e?.message || String(e)
      });
    }

    // ✅ Enqueue all timesheets matching hospital_norm + drain a few inline
    await bumpTsfinNow({ hospitalNorm: alias });

    // Return updated summary row
    let summaryRow = null;
    try {
      summaryRow = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}` +
          `&select=timesheet_id,processing_status,candidate_id,client_id,candidate_name,client_name` +
          `&limit=1`
      );
    } catch {}

    return withCORS(env, req, ok({
      ok: true,
      requested_timesheet_id: requestedTimesheetId,
      current_timesheet_id: currentTimesheetId,
      was_stale: wasStale,
      summary: summaryRow || null
    }));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to resolve timesheet client: ${e?.message || e}`));
  }
}


async function handleTimesheetDailyQrPrintable(env, req, timesheetId) {
  const enc = encodeURIComponent;
  const cleanKey = (k) => String(k || '').replace(/^\/+/, '').trim();

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = resolved.current_timesheet_id;

  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  const oldQrKey = ts.qr_r2_key ? cleanKey(ts.qr_r2_key) : null;

  const scope = String(ts.sheet_scope || '').toUpperCase();
  let subMode = String(ts.submission_mode || '').toUpperCase();

  if (scope !== 'DAILY') {
    return withCORS(env, req, badRequest('Timesheet is not DAILY; cannot generate daily QR'));
  }

  const tsfin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (tsfin && (tsfin.locked_by_invoice_id || tsfin.paid_at_utc)) {
    return withCORS(env, req, badRequest('Timesheet already invoiced or paid; cannot generate QR'));
  }

  const now = nowIso();

  if (subMode !== 'MANUAL') {
    if (subMode !== 'ELECTRONIC') {
      return withCORS(env, req, badRequest('Unsupported submission_mode for DAILY QR'));
    }

    try {
      const flipRes = await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            submission_mode: 'MANUAL',
            r2_auth_key: null,
            authorised_at_server: null,
            updated_at: now
          })
        }
      );

      if (!flipRes.ok) {
        const t = await flipRes.text().catch(() => '');
        console.warn('[TS_DAILY_QR] failed to flip ELECTRONIC→MANUAL', {
          timesheet_id: currentTimesheetId,
          status: flipRes.status,
          bodyPreview: (t || '').slice(0, 200)
        });
        return withCORS(env, req, serverError('Failed to switch DAILY timesheet to MANUAL for QR'));
      }

      subMode = 'MANUAL';
    } catch (e) {
      console.warn('[TS_DAILY_QR] failed to flip ELECTRONIC→MANUAL (exception)', {
        timesheet_id: currentTimesheetId,
        err: e?.message || String(e)
      });
      return withCORS(env, req, serverError('Failed to switch DAILY timesheet to MANUAL for QR'));
    }
  }

  if (tsfin && String(tsfin.processing_status || '').toUpperCase() !== 'AWAITING_MANUAL_SIGNATURE') {
    try {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(tsfin.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            processing_status: 'AWAITING_MANUAL_SIGNATURE',
            updated_at: now
          })
        }
      );
    } catch (e) {
      console.warn('[TS_DAILY_QR] failed to patch TSFIN to AWAITING_MANUAL_SIGNATURE', {
        timesheet_id: currentTimesheetId,
        err: e?.message || String(e)
      });
    }
  }

  let workedDateYmd = null;
  if (ts.worked_start_iso) {
    try {
      const parts = toLocalParts(ts.worked_start_iso, null);
      workedDateYmd = parts && parts.ymd ? parts.ymd : String(ts.worked_start_iso).slice(0, 10);
    } catch {
      workedDateYmd = String(ts.worked_start_iso).slice(0, 10);
    }
  }

  let qrToken;
  try {
    if (typeof crypto !== 'undefined' && typeof crypto.randomUUID === 'function') {
      qrToken = crypto.randomUUID();
    } else {
      qrToken = `${currentTimesheetId}:${Date.now()}`;
    }
  } catch {
    qrToken = `${currentTimesheetId}:${Date.now()}`;
  }

  let qr_r2_key = null;
  try {
    const res = await generateAndStoreTimesheetQr(env, {
      timesheet_id: currentTimesheetId,
      contract_week_id: null,
      contract_id: ts.contract_id || null,
      candidate_id: ts.candidate_id || null,
      client_id: (tsfin && tsfin.client_id) || ts.client_id || null,
      week_ending_ymd: workedDateYmd || null,
      qr_token: qrToken
    });
    qr_r2_key = res?.qr_r2_key || null;
  } catch (e) {
    console.warn('[TS_DAILY_QR] generateAndStoreTimesheetQr failed', {
      timesheet_id: currentTimesheetId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to generate QR payload'));
  }

  // Patch QR fields
  try {
    const patchRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          qr_token: qrToken,
          qr_status: 'PENDING',
          qr_generated_at: now,
          qr_scanned_at: null,
          qr_scan_info_json: null,
          qr_r2_key: qr_r2_key || null,
          updated_at: now
        })
      }
    );

    if (!patchRes.ok) {
      const t = await patchRes.text().catch(() => '');
      console.warn('[TS_DAILY_QR] failed to patch timesheet QR fields', {
        timesheet_id: currentTimesheetId,
        status: patchRes.status,
        bodyPreview: (t || '').slice(0, 200)
      });
      return withCORS(env, req, serverError('Failed to update timesheet QR fields'));
    }
  } catch (e) {
    console.warn('[TS_DAILY_QR] failed to patch timesheet QR fields (exception)', {
      timesheet_id: currentTimesheetId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to update timesheet QR fields'));
  }

  // ✅ NEW: delete old QR image key now that we replaced it (best-effort)
  try {
    const bucket = env.R2_BUCKET || env.R2;
    const newQrKeyClean = qr_r2_key ? cleanKey(qr_r2_key) : null;
    if (bucket && typeof bucket.delete === 'function' && oldQrKey && newQrKeyClean && oldQrKey !== newQrKeyClean) {
      await bucket.delete(oldQrKey).catch(() => {});
    }
  } catch {
    // non-fatal
  }

  let pdfKey = null;
  try {
    pdfKey = await ensureTimesheetPdf(env, currentTimesheetId);
    if (pdfKey) {
      // ✅ FIX: only set manual_pdf_r2_key if it is currently NULL/empty (do not overwrite scanned evidence)
      const patchUrl =
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true` +
        `&or=(manual_pdf_r2_key.is.null,manual_pdf_r2_key.eq.)`;

      await fetch(
        patchUrl,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            manual_pdf_r2_key: pdfKey,
            updated_at: nowIso()
          })
        }
      ).catch(() => {});
    }
  } catch (e) {
    console.warn('[TS_DAILY_QR] ensureTimesheetPdf failed', {
      timesheet_id: currentTimesheetId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to prepare timesheet PDF'));
  }

  // ─────────────────────────────────────────────────────────────
  // ✅ compute + persist last-sent hash after PDF is ensured
  // ─────────────────────────────────────────────────────────────
  try {
    const stableClone = (v) => {
      if (Array.isArray(v)) return v.map(stableClone);
      if (v && typeof v === 'object') {
        const out = {};
        for (const k of Object.keys(v).sort()) out[k] = stableClone(v[k]);
        return out;
      }
      return v;
    };

    // Daily printable content basis (hours + refs + breaks)
    const hashObj = {
      sheet_scope: scope || 'DAILY',
      worked_start_iso: ts.worked_start_iso || null,
      worked_end_iso: ts.worked_end_iso || null,
      break_start_iso: ts.break_start_iso || null,
      break_end_iso: ts.break_end_iso || null,
      break_minutes: (ts.break_minutes != null ? ts.break_minutes : null),
      reference_number: ts.reference_number || null,
      day_references_json: ts.day_references_json || null
    };

    const current_hash = await sha256Hex(JSON.stringify(stableClone(hashObj)));
    const sentAt = nowIso();

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          qr_last_sent_hash: current_hash,
          qr_last_sent_at_utc: sentAt,
          updated_at: sentAt
        })
      }
    ).catch(() => {});
  } catch (e) {
    console.warn('[TS_DAILY_QR] hash compute/persist failed (non-fatal)', {
      timesheet_id: currentTimesheetId,
      err: e?.message || String(e)
    });
  }

  // Automatically queue email
  try {
    let email = null;
    let candName = null;

    if (ts.candidate_id) {
      const cand = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(ts.candidate_id)}&select=email,display_name&limit=1`
      );
      email = cand?.email ? String(cand.email).trim() : null;
      candName = cand?.display_name || null;
    }

    if (email && pdfKey) {
      const subject = workedDateYmd
        ? `Daily QR timesheet – ${workedDateYmd}`
        : `Daily QR timesheet`;

      const lines = [
        `Please print the attached timesheet, ask the ward manager to sign it,`,
        `and then upload the signed copy via the app.`,
        ``,
        ...(candName ? [`Candidate: ${candName}`] : []),
        ...(workedDateYmd ? [`Date: ${workedDateYmd}`] : []),
        `Timesheet ID: ${currentTimesheetId}`
      ];

      const bodyText = lines.join('\n');
      const bodyHtml = `<p>${lines.map(l => (l === '' ? '<br/>' : l)).join('<br/>')}</p>`;

      await fetch(
        `${env.SUPABASE_URL}/rest/v1/mail_outbox`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            type: 'TIMESHEET_QR',
            to: email,
            cc: null,
            subject,
            body_text: bodyText,
            body_html: bodyHtml,
            attachments: [{
              r2_key: pdfKey,
              filename: workedDateYmd ? `Timesheet_${workedDateYmd}.pdf` : `Timesheet_${currentTimesheetId}.pdf`
            }],
            status: 'QUEUED',
            reference: `timesheet_qr:daily:${currentTimesheetId}:${workedDateYmd || ''}`,
            created_by: user?.id || null
          })
        }
      ).catch(() => {});
    }
  } catch (e) {
    console.warn('[TS_DAILY_QR] mail queue failed (non-fatal)', {
      timesheet_id: currentTimesheetId,
      err: e?.message || String(e)
    });
  }

  // Audit
  try {
    await writeAudit(
      env,
      user,
      'DAILY_QR_PRINTABLE_GENERATED',
      {
        timesheet_id: currentTimesheetId,
        qr_token: qrToken,
        qr_status: 'PENDING',
        qr_r2_key,
        pdf_r2_key: pdfKey || null,
        worked_date: workedDateYmd || null
      },
      { entity: 'timesheets', subject_id: currentTimesheetId, req }
    );
  } catch (e) {
    console.warn('[TS_DAILY_QR] audit failed (non-fatal)', e?.message || e);
  }

  return withCORS(env, req, ok({
    ok: true,
    timesheet_id: currentTimesheetId,
    current_timesheet_id: currentTimesheetId,
    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale,

    sheet_scope: 'DAILY',
    qr_status: 'PENDING',
    qr_token: qrToken,
    qr_r2_key: qr_r2_key || null,
    worked_date: workedDateYmd,
    pdf_key: pdfKey || null
  }));
}



 async function handleHrRotaQueueTsoEmail(env, req) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const timesheetId = body?.timesheet_id || body?.timesheetId || null;
  const hrRequestId = body?.hr_request_id || body?.hrRequestId || null;
  const reasonCode  = body?.reason_code || body?.reasonCode || 'actual_hours_mismatch';
  const mismatch    = body?.mismatch_details || body?.mismatchDetails || null;

  if (!timesheetId) {
    return withCORS(
      env,
      req,
      badRequest('timesheet_id is required')
    );
  }

  // 0) Load agency name from settings_defaults (fallback to CloudTMS)
  let agencyName = 'CloudTMS';
  try {
    const { rows: defRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/settings_defaults` +
        `?id=eq.1&select=agency_name&limit=1`
    );
    if (defRows && defRows[0] && defRows[0].agency_name) {
      agencyName = String(defRows[0].agency_name).trim() || agencyName;
    }
  } catch (e) {
    console.warn('[HR_ROTA_TSO_EMAIL] failed to load agency_name from settings_defaults', {
      err: e?.message || String(e)
    });
  }

  // 1) Ensure PDF
  let pdfKey = null;
  try {
    pdfKey = await ensureTimesheetPdf(env, timesheetId);
  } catch (e) {
    console.error('[HR_ROTA_TSO_EMAIL] ensureTimesheetPdf failed', {
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
    return withCORS(
      env,
      req,
      serverError('Failed to prepare timesheet PDF for email')
    );
  }
  if (!pdfKey) {
    return withCORS(
      env,
      req,
      serverError('No timesheet PDF key returned')
    );
  }

  // 2) Resolve recipient
  let recipientEmail = null;
  try {
    const tgt = await resolveTsoRecipientForTimesheet(env, {
      timesheet_id: timesheetId,
      booking_id: hrRequestId || null
    });
    recipientEmail = tgt?.recipientEmail || tgt?.to_email || null;
  } catch (e) {
    console.error('[HR_ROTA_TSO_EMAIL] resolveTsoRecipientForTimesheet failed', {
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
    return withCORS(
      env,
      req,
      serverError('Failed to resolve Temporary Staffing email')
    );
  }

  if (!recipientEmail) {
    return withCORS(
      env,
      req,
      serverError('No Temporary Staffing email available for this timesheet')
    );
  }

  // 3) Compose subject/body from mismatch_details
  const staffName = mismatch?.staff_name || 'Agency worker';
  const dateLocal = mismatch?.date_local || 'Unknown date';
  const hrStart   = mismatch?.hr_start_local || mismatch?.start_local || 'N/A';
  const hrEnd     = mismatch?.hr_end_local   || mismatch?.end_local   || 'N/A';
  const hrHours   = mismatch?.hr_actual_hours || mismatch?.hours_worked || 'N/A';
  const tsHours   = mismatch?.ts_total_hours  || mismatch?.ts_hours     || 'N/A';

  const subject = `Timesheet hours mismatch – ${staffName} – ${dateLocal} – ${hrRequestId || 'no HR ref'}`;

  const lines = [
    `Dear Temporary Staffing,`,
    ``,
    `Please can you amend the hours on HealthRoster for the attached agency shift.`,
    ``,
    `Staff: ${staffName}`,
    `Date: ${dateLocal}`,
    `HR Request ID: ${hrRequestId || '(not provided)'}`,
    ``,
    `HealthRoster shows:`,
    `  Start: ${hrStart}`,
    `  End:   ${hrEnd}`,
    `  Actual Hours: ${hrHours}`,
    ``,
    `Signed timesheet attached shows:`,
    `  Actual Hours: ${tsHours}`,
    ``,
    `Once amended, please kindly confirm.`,
    ``,
    `Kind regards,`,
    `${agencyName}`
  ];

  const body_text = lines.join('\n');
  const body_html = `<p>${lines.map(l => (l === '' ? '<br/>' : l)).join('<br/>')}</p>`;

  const nowIso = new Date().toISOString();

  // 4) Insert into mail_outbox (using existing schema)
  const mailPayload = [{
    to: recipientEmail,
    subject,
    body_text,
    body_html,
    attachments: [{
      r2_key: pdfKey,
      filename: `Timesheet_${timesheetId}.pdf`
    }],
    type: 'TSO_FAILURE',
    reference: hrRequestId || null,
    correlation_id: `HR_DAILY_MISMATCH:${timesheetId}:${hrRequestId || ''}`
  }];

  try {
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/mail_outbox`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(mailPayload)
      }
    );
    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      console.error('[HR_ROTA_TSO_EMAIL] mail_outbox insert failed', {
        timesheet_id: timesheetId,
        err: txt
      });
      return withCORS(
        env,
        req,
        serverError(`Failed to queue mismatch email: ${txt}`)
      );
    }
  } catch (e) {
    console.error('[HR_ROTA_TSO_EMAIL] mail_outbox insert error', {
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
    return withCORS(
      env,
      req,
      serverError(`Failed to queue mismatch email: ${e?.message || e}`)
    );
  }

  // 5) Audit
  try {
    await writeAudit(
      env,
      user,
      'HR_DAILY_MISMATCH_EMAIL_QUEUED',
      {
        timesheet_id: timesheetId,
        hr_request_id: hrRequestId,
        recipient_email: recipientEmail,
        reason_code: reasonCode,
        pdf_key: pdfKey,
        mismatch_details: mismatch || null
      },
      { entity: 'timesheets', subject_id: timesheetId, req }
    );
  } catch (e) {
    console.warn('[HR_ROTA_TSO_EMAIL] audit failed', {
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
  }

  return withCORS(env, req, ok({ queued: true }));
}






















































// ====================== CLIENT HOSPITALS ======================
/**
 * @openapi
 * /api/clients/{client_id}/hospitals:
 *   get:
 *     summary: List client hospitals
 *     tags: [Client Hospitals]
 *     security:
 *       - bearerAuth: []
 *   post:
 *     summary: Create client hospital
 *     tags: [Client Hospitals]
 *     security:
 *       - bearerAuth: []
 * /api/clients/{client_id}/hospitals/{hospital_id}:
 *   get:
 *     summary: Get client hospital
 *     tags: [Client Hospitals]
 *     security:
 *       - bearerAuth: []
 *   patch:
 *     summary: Update client hospital
 *     tags: [Client Hospitals]
 *     security:
 *       - bearerAuth: []
 *   delete:
 *     summary: Delete client hospital
 *     tags: [Client Hospitals]
 *     security:
 *       - bearerAuth: []
 */
async function handleListHospitals(env, req, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_hospitals?client_id=eq.${encodeURIComponent(clientId)}&select=*`
    );
    return withCORS(env, req, ok({ items: rows }));
  } catch {
    return withCORS(env, req, serverError("Failed to list client hospitals"));
  }
}

async function handleGetHospital(env, req, clientId, hospitalId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_hospitals?id=eq.${encodeURIComponent(hospitalId)}&client_id=eq.${encodeURIComponent(clientId)}&select=*`
    );
    if (!rows.length) return withCORS(env, req, notFound("Hospital not found"));
    return withCORS(env, req, ok({ hospital: rows[0] }));
  } catch {
    return withCORS(env, req, serverError("Failed to fetch client hospital"));
  }
}
async function handleCandidatesGet(env, req, candidateId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!candidateId) return withCORS(env, req, badRequest('candidate_id required'));

  // Base candidate row (unchanged)
  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/candidates` +
      `?id=eq.${enc(candidateId)}` +
      `&select=*` +
      `&limit=1`
  );
  const row = (rows && rows[0]) || null;
  if (!row) return withCORS(env, req, notFound('Candidate not found'));

  // NEW: fetch hr_name_mappings for this candidate so the FE can see aliases
  try {
    const { rows: aliasRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_name_mappings` +
        `?candidate_id=eq.${enc(candidateId)}` +
        `&select=id,hr_name_norm,hospital_or_trust,last_used_at`
    );
    row.hr_aliases = Array.isArray(aliasRows) ? aliasRows : [];
  } catch (e) {
    console.error('handleCandidatesGet: hr_name_mappings lookup failed', {
      candidate_id: candidateId,
      err: e?.message || String(e)
    });
    row.hr_aliases = [];
  }

  return withCORS(env, req, ok(row));
}

// 2) GET /api/clients/:id (picker/base client row + latest client_settings)
async function handleClientsGet(env, req, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!clientId) return withCORS(env, req, badRequest('client_id required'));

  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${enc(clientId)}&select=*&limit=1`
  );
  const client = (rows && rows[0]) || null;
  if (!client) return withCORS(env, req, notFound('Client not found'));

  // Also return the latest client_settings
  const { rows: csRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/client_settings` +
      `?client_id=eq.${enc(client.id)}` +
      `&select=` +
        [
          'id',
          'hr_validation_required',
          'ts_reference_required',
          'pay_reference_required',
          'invoice_reference_required',
          'default_submission_mode',
          'is_nhsp',
          'self_bill_no_invoices_sent',
          'daily_calc_of_invoices',
          'no_timesheet_required',
          'group_nightsat_sunbh',
          'auto_invoice_default',
          'requires_hr',
          'autoprocess_hr',
          'hr_attach_to_invoice',
          'ts_attach_to_invoice',

          // ✅ NEW: manual adjustment email routing
          'send_manual_invoices_to_different_email',
          'manual_invoices_alt_email_address',

          'effective_from',
          'timezone_id',
          'day_start',
          'day_end',
          'night_start',
          'night_end',
          'sat_start',
          'sat_end',
          'sun_start',
          'sun_end',
          'bh_start',
          'bh_end',
          'bh_source',
          'bh_list',
          'bh_feed_url',
          'week_ending_weekday',
          'created_at',
          'updated_at'
        ].join(',') +
      `&order=effective_from.desc,created_at.desc&limit=1`
  );
  const client_settings = (csRows && csRows[0]) || null;

  // Surface week_ending_weekday at top-level for convenience
  const week_ending_weekday = (client_settings && Number.isInteger(Number(client_settings.week_ending_weekday)))
    ? Number(client_settings.week_ending_weekday)
    : (Number.isInteger(Number(client.week_ending_weekday)) ? Number(client.week_ending_weekday) : 0);

  return withCORS(env, req, ok({ ...client, week_ending_weekday, client_settings }));
}



async function handleUpdateHospital(env, req, clientId, hospitalId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  try {
    // Build safe patch: normalise name, tidy empties, block immutable fields
    const patch = { ...data };

    // Work out any hospital_name_norm input (can be string, array, or via name/hospital)
    let hospitalInput =
      typeof patch.hospital_name_norm !== 'undefined'
        ? patch.hospital_name_norm
        : (data.name || data.hospital);

    if (typeof hospitalInput !== 'undefined') {
      let hospitalAliases = [];

      if (Array.isArray(hospitalInput)) {
        hospitalAliases = hospitalInput
          .map((x) => String(x || '').trim().toLowerCase())
          .filter(Boolean);
      } else if (typeof hospitalInput === 'string') {
        const s = hospitalInput.trim();
        hospitalAliases = s ? [s.toLowerCase()] : [];
      } else if (hospitalInput != null) {
        const s = String(hospitalInput).trim();
        hospitalAliases = s ? [s.toLowerCase()] : [];
      }

      patch.hospital_name_norm = hospitalAliases;
    }

    // Treat empty string as null for optional fields
    if ('ward_hint' in patch && (patch.ward_hint === '' || patch.ward_hint == null)) {
      patch.ward_hint = null;
    }

    // Prevent updates to immutable/owner fields
    delete patch.id;
    delete patch.client_id;
    delete patch.created_at;

    patch.updated_at = new Date().toISOString();

    const url =
      `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
      `?id=eq.${encodeURIComponent(hospitalId)}` +
      `&client_id=eq.${encodeURIComponent(clientId)}`;

    const res = await fetch(url, {
      method: "PATCH",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify(patch)
    });

    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Hospital update failed: ${err}`));
    }

    const json = await res.json().catch(() => []);
    const hospital = Array.isArray(json) ? json[0] : json;

    if (!hospital) {
      return withCORS(env, req, notFound("Hospital not found"));
    }

    return withCORS(env, req, ok({ hospital }));
  } catch {
    return withCORS(env, req, serverError("Failed to update client hospital"));
  }
}


async function handleDeleteHospital(env, req, clientId, hospitalId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const url = `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
      `?id=eq.${encodeURIComponent(hospitalId)}` +
      `&client_id=eq.${encodeURIComponent(clientId)}`;

    const res = await fetch(url, {
      method: "DELETE",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" }
    });

    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Hospital delete failed: ${err}`));
    }

    // With Prefer:return=representation PostgREST returns the deleted row(s)
    const json = await res.json().catch(() => []);
    if (!Array.isArray(json) || json.length === 0) {
      return withCORS(env, req, notFound("Hospital not found"));
    }

    return withCORS(env, req, ok({ deleted: true, hospital: json[0] }));
  } catch {
    return withCORS(env, req, serverError("Failed to delete client hospital"));
  }
}

// ====================== UMBRELLAS ======================
/**
 * @openapi
 * /api/umbrellas:
 *   get:
 *     summary: List umbrella companies
 *     tags: [Umbrellas]
 *     security:
 *       - bearerAuth: []
 *   post:
 *     summary: Create umbrella
 *     tags: [Umbrellas]
 *     security:
 *       - bearerAuth: []
 * /api/umbrellas/{umbrella_id}:
 *   get:
 *     summary: Get umbrella
 *     tags: [Umbrellas]
 *     security:
 *       - bearerAuth: []
 *   put:
 *     summary: Update umbrella
 *     tags: [Umbrellas]
 *     security:
 *       - bearerAuth: []
 */

 async function handleListUmbrellas(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const params = new URL(req.url).searchParams;
  const includeCount = params.get('include_count') === 'true';

  // Prefer page/page_size; fall back to limit/offset
  const pageRaw      = parseInt(params.get('page') || '1', 10);
  const pageSizeRaw  = params.get('page_size');
  const legacyLimit  = parseInt(params.get('limit')  || '50', 10);
  const legacyOffset = parseInt(params.get('offset') || '0',  10);

  const page     = Math.max(1, isNaN(pageRaw) ? 1 : pageRaw);
  const pageSize = pageSizeRaw != null ? Math.max(1, Math.min(200, parseInt(pageSizeRaw, 10) || 50)) : null;
  const limit    = pageSize != null ? pageSize : Math.max(1, Math.min(200, isNaN(legacyLimit) ? 50 : legacyLimit));
  const offset   = pageSize != null ? (page - 1) * limit : Math.max(0, isNaN(legacyOffset) ? 0 : legacyOffset);

  const url = new URL(`${env.SUPABASE_URL}/rest/v1/umbrellas`);
  url.searchParams.set('select', '*');
  url.searchParams.set('order',  'name.asc');
  url.searchParams.set('limit',  String(limit));
  url.searchParams.set('offset', String(offset));

  try {
    const { rows, total } = await sbFetch(env, url.toString(), includeCount);
    const resp = includeCount ? { items: rows, count: total ?? undefined } : { items: rows };
    return withCORS(env, req, ok(resp));
  } catch {
    return withCORS(env, req, serverError('Failed to list umbrellas'));
  }
}



async function handleCreateUmbrella(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  try {
    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/umbrellas`, {
      method: "POST",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify({ ...data, created_at: new Date().toISOString() })
    });
    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Umbrella creation failed: ${err}`));
    }
    const json = await res.json().catch(() => ({}));
    const umbrella = Array.isArray(json) ? json[0] : json;
    return withCORS(env, req, ok({ umbrella }));
  } catch {
    return withCORS(env, req, serverError("Failed to create umbrella"));
  }
}
async function handleGetUmbrella(env, req, umbrellaId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/umbrellas?id=eq.${encodeURIComponent(umbrellaId)}&select=*`
    );
    if (!rows.length) return withCORS(env, req, notFound("Umbrella not found"));
    return withCORS(env, req, ok({ umbrella: rows[0] }));
  } catch {
    return withCORS(env, req, serverError("Failed to fetch umbrella"));
  }
}

async function handleUpdateUmbrella(env, req, umbrellaId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  try {
    // 1) Load current umbrella (for change detection)
    const { rows: beforeRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/umbrellas?id=eq.${encodeURIComponent(umbrellaId)}&select=name,bank_name,sort_code,account_number`
    );
    const before = beforeRows?.[0] || {};

    // 2) Update
    const url = `${env.SUPABASE_URL}/rest/v1/umbrellas?id=eq.${encodeURIComponent(umbrellaId)}`;
    const res = await fetch(url, {
      method: "PATCH",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify({ ...data, updated_at: new Date().toISOString() })
    });
    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Umbrella update failed: ${err}`));
    }
    const json = await res.json().catch(() => ({}));
    const umbrella = Array.isArray(json) ? json[0] : json;

    // 3) Detect pay-channel impacting changes
    const watched = ['name','bank_name','sort_code','account_number'];
    const changed = watched.some(k => umbrella?.[k] !== before?.[k]);

    if (changed) {
      // Enqueue recompute for all candidates on this umbrella (current & unlocked TSFIN only)
      const { rows: candidateRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?select=id` +
          `&umbrella_id=eq.${encodeURIComponent(umbrellaId)}` +
          `&pay_method=eq.UMBRELLA`
      );
      const candIds = (candidateRows || []).map(r => r.id);
      if (candIds.length) {
        const idsParam = candIds.map(encodeURIComponent).join(',');
        const { rows: tsfins } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
            `?select=timesheet_id` +
            `&candidate_id=in.(${idsParam})` +
            `&is_current=eq.true` +
            `&locked_by_invoice_id=is.null`
        );
        const toEnqueue = (tsfins || []).map(r => ({ timesheet_id: r.timesheet_id, reason: 'CONTEXT_CHANGED' }));
        if (toEnqueue.length) {
          await fetch(
            `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
            {
              method: "POST",
              headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
              body: JSON.stringify(toEnqueue)
            }
          );
        }
      }
    }

    return withCORS(env, req, ok({ umbrella }));
  } catch {
    return withCORS(env, req, serverError("Failed to update umbrella"));
  }
}

// ====================== CANDIDATES ======================
/**
 * @openapi
 * /api/candidates:
 *   get:
 *     summary: List candidates
 *     tags: [Candidates]
 *     security:
 *       - bearerAuth: []
 *   post:
 *     summary: Create candidate
 *     tags: [Candidates]
 *     security:
 *       - bearerAuth: []
 * /api/candidates/{candidate_id}:
 *   get:
 *     summary: Get candidate
 *     tags: [Candidates]
 *     security:
 *       - bearerAuth: []
 *   put:
 *     summary: Update candidate
 *     tags: [Candidates]
 *     security:
 *       - bearerAuth: []
 */





// ====================== RATES (FIVE-WAY) ======================
/**
 * @openapi
 * /api/rates/client-defaults:
 *   get:
 *     summary: List client default rates
 *     tags: [Rates]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: client_id
 *         required: true
 *         schema: { type: string }
 *   post:
 *     summary: Upsert client default rates (five-way)
 *     tags: [Rates]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               client_id: { type: string }
 *               role: { type: string }
 *               band: { type: string }
 *               date_from: { type: string, format: date }
 *               date_to: { type: string, format: date, nullable: true }
 *               charge_day: { type: number }
 *               charge_night: { type: number }
 *               charge_sat: { type: number }
 *               charge_sun: { type: number }
 *               charge_bh: { type: number }
 *               pay_day: { type: number, nullable: true }
 *               pay_night: { type: number, nullable: true }
 *               pay_sat: { type: number, nullable: true }
 *               pay_sun: { type: number, nullable: true }
 *               pay_bh: { type: number, nullable: true }
 * /api/rates/candidate-overrides:
 *   get:
 *     summary: List candidate override rates
 *     tags: [Rates]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: candidate_id
 *         required: true
 *         schema: { type: string }
 *   post:
 *     summary: Create candidate override (five-way)
 *     tags: [Rates]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               candidate_id: { type: string }
 *               client_id: { type: string, nullable: true }
 *               role: { type: string }
 *               band: { type: string }
 *               date_from: { type: string, format: date }
 *               date_to: { type: string, format: date, nullable: true }
 *               pay_day: { type: number }
 *               pay_night: { type: number }
 *               pay_sat: { type: number }
 *               pay_sun: { type: number }
 *               pay_bh: { type: number }
 * /api/rates/resolve-preview:
 *   post:
 *     summary: Resolve five-way pay/charge for a candidate/client/date/role/band
 *     tags: [Rates]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required: [candidate_id, client_id, date]
 *             properties:
 *               candidate_id: { type: string }
 *               client_id: { type: string }
 *               role: { type: string }
 *               band: { type: string }
 *               date: { type: string, format: date }
 *     responses:
 *       200:
 *         description: Resolved five-way snapshot
 */

// ─────────────────────────────────────────────────────────────────────────────
// Client defaults: list with optional role/band + active_on filters,
// and correct NULL/default semantics. Supports pagination.
// ─────────────────────────────────────────────────────────────────────────────
// ======================================
// BACKEND — handleSearchCandidates (UPDATED)
// Add pass-through support for PostgREST 'id=in.(...)' filter
// ======================================

 async function handleSearchCandidates(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const urlObj = new URL(req.url);
  const q  = (k) => urlObj.searchParams.get(k);
  const qa = (k) => urlObj.searchParams.getAll(k);

  const page     = Math.max(1, parseInt(q('page') || '1', 10));
  const pageSize = Math.max(1, Math.min(200, parseInt(q('page_size') || '50', 10)));
  const format   = (q('format') || 'json').toLowerCase();

  // Sorting
  const orderByParam  = (q('order_by') || '').toLowerCase();
  const orderDirParam = (q('order_dir') || '').toLowerCase();

  const allowedSort = {
    display_name: 'display_name',
    first_name:   'first_name',
    last_name:    'last_name',
    email:        'email',
    phone:        'phone',
    pay_method:   'pay_method',
    active:       'active',
    created_at:   'created_at',
    // you can add 'primary_job_title' or 'job_titles_display' here later if you
    // want direct sort buttons on those
  };

  const defaultOrderCol = 'display_name';
  const orderCol = allowedSort[orderByParam] || defaultOrderCol;
  const orderDir = (orderDirParam === 'desc') ? 'desc' : 'asc';

  // Named filters (top-level)
  const firstName   = q('first_name');
  const lastName    = q('last_name');
  const email       = q('email');
  const phone       = q('phone');
  const payMethod   = q('pay_method') ? q('pay_method').toUpperCase() : null;
  const active      = q('active');
  const createdFrom = q('created_from');
  const createdTo   = q('created_to');

  // New job-title filters
  const jobTitleContainsAll   = q('job_title_contains');            // all job titles
  const primaryJobTitleContains = q('primary_job_title_contains');  // primary only

  // New professional registration filters
  const profRegNumber = q('prof_reg_number');
  const profRegType   = q('prof_reg_type') ? q('prof_reg_type').toUpperCase() : null;

  // DOB exact (YYYY-MM-DD)
  const dobExact = q('dob');

  // New demographic filters
  const gender   = q('gender');
  const townCity = q('town_city');
  const postcode = q('postcode');

  // New updated_at range
  const updatedFrom = q('updated_from');
  const updatedTo   = q('updated_to');

  // New bank / umbrella / ref filters
  const sortCode      = q('sort_code');
  const accountNumber = q('account_number');
  const umbrellaName  = q('umbrella_name');
  const tmsRef        = q('tms_ref');

  // roles_any / roles_all (Care Package Roles)
  let rolesAny = qa('roles_any').filter(Boolean).map(s => s.trim()).filter(Boolean);
  let rolesAll = qa('roles_all').filter(Boolean).map(s => s.trim()).filter(Boolean);

  // explicit-IDs support (either id=in.(...) or ids=uuid1,uuid2,...)
  const idInExpr = q('id');   // raw 'in.(...)'
  const idsRaw   = q('ids');  // friendly csv
  let idFilterExpr = null;
  if (idInExpr && /^in\.\(.+\)$/.test(idInExpr)) {
    idFilterExpr = idInExpr;
  } else if (idsRaw) {
    const list = idsRaw.split(',').map(s => s.trim()).filter(Boolean);
    if (list.length) idFilterExpr = `in.(${list.join(',')})`;
  }

  // Optional simple free-text
  const rawQ = q('q');
  let text = rawQ ? String(rawQ || '').trim() : null;

  rolesAny = Array.from(new Set(rolesAny.map(s => s.toUpperCase())));
  rolesAll = Array.from(new Set(rolesAll.map(s => s.toUpperCase())));

  // Use the summary view and return the FULL row to keep grid prefs + CSV happy
  let url =
    `${env.SUPABASE_URL}/rest/v1/candidates_summary` +
    `?select=*` +
    `&order=${enc(orderCol)}.${orderDir}` +
    `&limit=${pageSize}&offset=${(page - 1) * pageSize}`;

  // Free-text: search name, email, and all job titles
  // (NB: roles_any OR below will overwrite this or-clause if both are used)
  if (text) {
    const esc = enc(text);
    url += `&or=(display_name.ilike.*${esc}*,email.ilike.*${esc}*,job_titles_display.ilike.*${esc}*)`;
  }

  // Basic name / contact / pay filters
  if (firstName)   url += `&first_name=ilike.*${enc(firstName)}*`;
  if (lastName)    url += `&last_name=ilike.*${enc(lastName)}*`;
  if (email)       url += `&email=ilike.*${enc(email)}*`;
  if (phone)       url += `&phone=ilike.*${enc(phone)}*`;

  // Pay method: PAYE, UMBRELLA, or BLANK (null)
  if (payMethod === 'BLANK') {
    url += `&pay_method=is.null`;
  } else if (payMethod) {
    url += `&pay_method=eq.${enc(payMethod)}`;
  }

  if (active === 'true')  url += `&active=eq.true`;
  if (active === 'false') url += `&active=eq.false`;

  if (createdFrom) url += `&created_at=gte.${enc(createdFrom)}`;
  if (createdTo)   url += `&created_at=lte.${enc(createdTo)}`;

  // Primary job title vs all job titles filters
  if (primaryJobTitleContains) {
    url += `&primary_job_title=ilike.*${enc(primaryJobTitleContains)}*`;
  }
  if (jobTitleContainsAll) {
    url += `&job_titles_display=ilike.*${enc(jobTitleContainsAll)}*`;
  }

  // Professional registration filters
  if (profRegNumber) {
    url += `&prof_reg_number=ilike.*${enc(profRegNumber)}*`;
  }
  if (profRegType) {
    url += `&prof_reg_type=eq.${enc(profRegType)}`;
  }

  // DOB exact
  if (dobExact) url += `&date_of_birth=eq.${enc(dobExact)}`;

  // Gender / city / postcode
  if (gender)   url += `&gender=eq.${enc(gender)}`;
  if (townCity) url += `&town_city=ilike.*${enc(townCity)}*`;
  if (postcode) url += `&postcode=ilike.*${enc(postcode)}*`;

  // Updated_at range
  if (updatedFrom) url += `&updated_at=gte.${enc(updatedFrom)}`;
  if (updatedTo)   url += `&updated_at=lte.${enc(updatedTo)}`;

  // Banking / umbrella / ref
  if (sortCode)      url += `&sort_code=ilike.*${enc(sortCode)}*`;
  if (accountNumber) url += `&account_number=ilike.*${enc(accountNumber)}*`;
  if (umbrellaName)  url += `&umbrella_name=ilike.*${enc(umbrellaName)}*`; // requires umbrella_name in view
  if (tmsRef)        url += `&tms_ref=ilike.*${enc(tmsRef)}*`;

  // apply explicit IDs if present
  if (idFilterExpr) url += `&id=${enc(idFilterExpr)}`;

  // Care Package Roles – roles_all (AND)
  if (rolesAll.length) {
    for (const code of rolesAll) {
      const val = JSON.stringify([{ code }]);
      url += `&roles=cs.${enc(val)}`;
    }
  }

  // Care Package Roles – roles_any (OR). Note: this will overwrite any existing `or=` (e.g. free-text)
  if (rolesAny.length) {
    const parts = rolesAny.map(code => {
      const val = enc(JSON.stringify([{ code }]));
      return `roles.cs.${val}`;
    });
    url += `&or=(${parts.join(',')})`;
  }

  let rows = [];
  try {
    ({ rows } = await sbFetch(env, url));
  } catch (err) {
    return withCORS(env, req, ok({
      error: String(err?.message || err),
      rows: [],
      page,
      page_size: pageSize,
      count: 0
    }));
  }

  // CSV : keep rota roles vs job titles separate
  if (format === 'csv') {
    const header = [
      'CandidateId',
      'DisplayName',
      'Email',
      'Phone',
      'PayMethod',
      'Active',
      'CreatedAt',
      'RotaRoles',
      'JobTitles'
    ];
    const out = [csvJoin(header)];
    for (const r of rows || []) {
      const rotaRoles = Array.isArray(r.roles) ? formatRolesSummary(r.roles) : '';
      const jobTitles = (typeof r.job_titles_display === 'string' && r.job_titles_display.trim())
        ? r.job_titles_display.trim()
        : '';
      out.push(csvJoin([
        r.id,
        r.display_name || [r.first_name, r.last_name].filter(Boolean).join(' '),
        r.email || '',
        r.phone || '',
        (r.pay_method || '').toUpperCase(),
        r.active ? 'Y' : 'N',
        r.created_at || '',
        rotaRoles,
        jobTitles
      ]));
    }
    return withCORS(env, req, ok({
      csv: out.join('\n'),
      count: rows?.length || 0,
      page,
      page_size: pageSize
    }));
  }

  // Print HTML 
  if (format === 'print') {
    const rowsHtml = (rows || []).map(r => `
      <tr>
        <td>${r.display_name || [r.first_name, r.last_name].filter(Boolean).join(' ')}</td>
        <td>${r.email || ''}</td>
        <td>${r.phone || ''}</td>
        <td>${(r.pay_method || '').toUpperCase()}</td>
        <td>${r.active ? 'Y' : 'N'}</td>
        <td>${r.created_at || ''}</td>
      </tr>`).join('');
    const html = `
      <div style="font-family:system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif">
        <h3>Candidates — Search Results</h3>
        <table width="100%" cellspacing="0" cellpadding="6" style="border-collapse:collapse">
          <thead><tr style="background:#f5f5f5">
            <th>Candidate</th><th>Email</th><th>Phone</th><th>Pay Method</th><th>Active</th><th>Created At</th>
          </tr></thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      </div>`;
    return withCORS(env, req, ok({
      html,
      count: rows?.length || 0,
      page,
      page_size: pageSize
    }));
  }

  // Normal JSON
  return withCORS(env, req, ok({
    rows,
    page,
    page_size: pageSize,
    count: rows?.length || 0
  }));
}

 async function handleListCandidates(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const params = new URL(req.url).searchParams;
  const includeCount = params.get('include_count') === 'true';

  // Prefer page/page_size; fall back to limit/offset for backward compatibility
  const pageRaw      = parseInt(params.get('page') || '1', 10);
  const pageSizeRaw  = params.get('page_size');
  const legacyLimit  = parseInt(params.get('limit')  || '50', 10);
  const legacyOffset = parseInt(params.get('offset') || '0',  10);

  const page     = Math.max(1, isNaN(pageRaw) ? 1 : pageRaw);
  const pageSize = pageSizeRaw != null ? Math.max(1, Math.min(200, parseInt(pageSizeRaw, 10) || 50)) : null;
  const limit    = pageSize != null ? pageSize : Math.max(1, Math.min(200, isNaN(legacyLimit) ? 50 : legacyLimit));
  const offset   = pageSize != null ? (page - 1) * limit : Math.max(0, isNaN(legacyOffset) ? 0 : legacyOffset);

  const url = new URL(`${env.SUPABASE_URL}/rest/v1/candidates`);
  url.searchParams.set('select', '*');
  url.searchParams.set('order',  'display_name.asc');
  url.searchParams.set('limit',  String(limit));
  url.searchParams.set('offset', String(offset));

  try {
    const { rows, total } = await sbFetch(env, url.toString(), includeCount);
    const resp = includeCount ? { items: rows, count: total ?? undefined } : { items: rows };
    return withCORS(env, req, ok(resp));
  } catch {
    return withCORS(env, req, serverError('Failed to list candidates'));
  }
}


// ======================= NEW: Job titles list ==========================
 async function handleListJobTitles(env, req) {
  const user = await requireUser(env, req);
  if (!user) return unauthorized(); // you could optionally wrap this with withCORS if you want

  const url = new URL(req.url);
  const search = (url.searchParams.get('search') || url.searchParams.get('q') || '').trim();
  const activeOnly = (url.searchParams.get('activeOnly') ?? 'true').toLowerCase() !== 'false';

  let qs = 'select=*';

  if (activeOnly) {
    qs += '&active=eq.true';
  }

  if (search) {
    const safe = search.replace(/\s+/g, ' ').trim();
    const pattern = `*${safe}*`;
    qs += `&label=ilike.${encodeURIComponent(pattern)}`;
  }

  // Optional: sort by depth then label
  qs += '&order=depth.asc&order=label.asc';

  const base = `${env.SUPABASE_URL}/rest/v1/default_job_titles`;
  const urlStr = `${base}?${qs}`;

  try {
    const { rows } = await sbFetch(env, urlStr);
    return withCORS(env, req, ok({ items: rows || [] }));
  } catch (err) {
    console.error('handleListJobTitles failed', err);
    return withCORS(env, req, serverError('job_titles_list_failed'));
  }
}
// ======================= NEW: Job title create ==========================
 async function handleCreateJobTitle(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const body = await parseJSONBody(req).catch(() => null);
  if (!body || typeof body !== 'object') {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const rawLabel = (body.label || '').trim();
  if (!rawLabel) {
    return withCORS(env, req, badRequest('Label is required'));
  }

  const parentId = body.parent_id || null;
  const isRole = !!body.is_role;

  let requiresProfReg = !!body.requires_prof_reg;
  let profRegType = body.prof_reg_type || null;

  const allowedRegTypes = ['NMC', 'GMC', 'HCPC'];

  if (!isRole) {
    // Groups/categories can never require registration
    requiresProfReg = false;
    profRegType = null;
  } else {
    if (requiresProfReg) {
      const t = String(profRegType || '').toUpperCase();
      if (!allowedRegTypes.includes(t)) {
        return withCORS(env, req, badRequest('Invalid professional registration type'));
      }
      profRegType = t;
    } else {
      profRegType = null;
    }
  }

  // Compute depth from parent if provided
  let depth = 0;
  if (parentId) {
    try {
      const parentUrl =
        `${env.SUPABASE_URL}/rest/v1/default_job_titles` +
        `?select=depth&id=eq.${enc(parentId)}&limit=1`;
      const { rows: parents } = await sbFetch(env, parentUrl);
      const parent = (parents && parents[0]) || null;
      if (!parent) {
        return withCORS(env, req, badRequest('Parent job title not found'));
      }
      depth = (Number(parent.depth) || 0) + 1;
    } catch (e) {
      console.error('handleCreateJobTitle parent lookup failed', e);
      return withCORS(env, req, serverError('job_title_parent_lookup_failed'));
    }
  }

  const insertRow = {
    label: rawLabel,
    parent_id: parentId,
    depth,
    is_role: isRole,
    requires_prof_reg: requiresProfReg,
    prof_reg_type: profRegType,
    active: body.active === false ? false : true,
    updated_at: new Date().toISOString()
  };

  const urlStr = `${env.SUPABASE_URL}/rest/v1/default_job_titles`;

  try {
    const { rows } = await sbFetch(env, urlStr, {
      method: 'POST',
      headers: {
        Prefer: 'return=representation'
      },
      body: JSON.stringify(insertRow)
    });

    const created = (rows && rows[0]) || null;
    if (!created) {
      return withCORS(env, req, serverError('job_title_create_failed'));
    }

    return withCORS(env, req, ok({ item: created }, 201));
  } catch (err) {
    console.error('handleCreateJobTitle failed', err);
    return withCORS(env, req, serverError('job_title_create_failed'));
  }
}


// ======================= NEW: Job title update ==========================
 async function handleUpdateJobTitle(env, req, jobTitleId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  if (!jobTitleId) {
    return withCORS(env, req, badRequest('Missing job title id'));
  }

  const body = await parseJSONBody(req).catch(() => null);
  if (!body || typeof body !== 'object') {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  // Load existing row so we can reason about is_role / reg settings / depth
  let existing;
  try {
    const existingUrl =
      `${env.SUPABASE_URL}/rest/v1/default_job_titles` +
      `?select=id,label,parent_id,depth,is_role,requires_prof_reg,prof_reg_type,active` +
      `&id=eq.${enc(jobTitleId)}&limit=1`;
    const { rows } = await sbFetch(env, existingUrl);
    existing = (rows && rows[0]) || null;
    if (!existing) {
      return withCORS(env, req, notFound());
    }
  } catch (e) {
    console.error('handleUpdateJobTitle existing lookup failed', e);
    return withCORS(env, req, serverError('job_title_existing_lookup_failed'));
  }

  const patch = {};
  let newParentId = undefined;

  if (body.label != null) {
    const rawLabel = String(body.label || '').trim();
    if (!rawLabel) {
      return withCORS(env, req, badRequest('Label cannot be empty'));
    }
    patch.label = rawLabel;
  }

  if (Object.prototype.hasOwnProperty.call(body, 'parent_id')) {
    newParentId = body.parent_id || null;
    if (newParentId === jobTitleId) {
      return withCORS(env, req, badRequest('parent_id cannot be the same as id'));
    }
    patch.parent_id = newParentId;
  }

  if (Object.prototype.hasOwnProperty.call(body, 'is_role')) {
    patch.is_role = !!body.is_role;
  }

  if (Object.prototype.hasOwnProperty.call(body, 'requires_prof_reg')) {
    patch.requires_prof_reg = !!body.requires_prof_reg;
  }

  if (Object.prototype.hasOwnProperty.call(body, 'prof_reg_type')) {
    if (body.prof_reg_type == null || body.prof_reg_type === '') {
      patch.prof_reg_type = null;
    } else {
      const allowed = ['NMC', 'GMC', 'HCPC'];
      const t = String(body.prof_reg_type).toUpperCase();
      if (!allowed.includes(t)) {
        return withCORS(env, req, badRequest('Invalid professional registration type'));
      }
      patch.prof_reg_type = t;
    }
  }

  if (Object.prototype.hasOwnProperty.call(body, 'active')) {
    patch.active = !!body.active;
  }

  // If parent changed, recompute depth
  if (newParentId !== undefined) {
    let depth = 0;
    if (newParentId) {
      try {
        const parentUrl =
          `${env.SUPABASE_URL}/rest/v1/default_job_titles` +
          `?select=depth&id=eq.${enc(newParentId)}&limit=1`;
        const { rows: parents } = await sbFetch(env, parentUrl);
        const parent = (parents && parents[0]) || null;
        if (!parent) {
          return withCORS(env, req, badRequest('Parent job title not found'));
        }
        depth = (Number(parent.depth) || 0) + 1;
      } catch (e) {
        console.error('handleUpdateJobTitle parent lookup failed', e);
        return withCORS(env, req, serverError('job_title_parent_lookup_failed'));
      }
    }
    patch.depth = depth;
  }

  // Enforce group vs role rules for registration
  const finalIsRole =
    Object.prototype.hasOwnProperty.call(patch, 'is_role') ? !!patch.is_role : !!existing.is_role;

  const finalRequiresProf =
    Object.prototype.hasOwnProperty.call(patch, 'requires_prof_reg')
      ? !!patch.requires_prof_reg
      : !!existing.requires_prof_reg;

  const finalProfType =
    Object.prototype.hasOwnProperty.call(patch, 'prof_reg_type') && patch.prof_reg_type !== undefined
      ? patch.prof_reg_type
      : existing.prof_reg_type;

  if (!finalIsRole) {
    // Groups/categories cannot have registration requirements
    patch.requires_prof_reg = false;
    patch.prof_reg_type = null;
  } else if (finalRequiresProf && !finalProfType) {
    return withCORS(env, req, badRequest('Professional registration type required when registration is required'));
  }

  // Block Role → Group change when in use
  const isRoleToGroup = !!existing.is_role && !finalIsRole;
  if (isRoleToGroup) {
    try {
      const usageUrl =
        `${env.SUPABASE_URL}/rest/v1/candidate_job_titles` +
        `?select=candidate_id&job_title_id=eq.${enc(jobTitleId)}&limit=200`;
      const { rows: used } = await sbFetch(env, usageUrl);
      const candidateIds = Array.from(new Set((used || []).map(r => r.candidate_id).filter(Boolean)));
      if (candidateIds.length) {
        return withCORS(env, req, ok({
          error: 'JOB_TITLE_IN_USE',
          message: `This role is assigned to ${candidateIds.length} candidates.`,
          candidate_ids: candidateIds
        }));
      }
    } catch (e) {
      console.error('handleUpdateJobTitle usage check failed', e);
      // fall through – if the check fails, we still try to apply patch, but log it
    }
  }

  patch.updated_at = new Date().toISOString();

  const urlStr =
    `${env.SUPABASE_URL}/rest/v1/default_job_titles` +
    `?id=eq.${enc(jobTitleId)}&select=*`;

  try {
    const { rows } = await sbFetch(env, urlStr, {
      method: 'PATCH',
      headers: {
        Prefer: 'return=representation'
      },
      body: JSON.stringify(patch)
    });

    const updated = (rows && rows[0]) || null;
    if (!updated) {
      return withCORS(env, req, notFound());
    }

    return withCORS(env, req, ok({ item: updated }));
  } catch (err) {
    console.error('handleUpdateJobTitle failed', err);
    return withCORS(env, req, serverError('job_title_update_failed'));
  }
}

// ======================= NEW: Job title delete ==========================
 async function handleDeleteJobTitle(env, req, jobTitleId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  if (!jobTitleId) {
    return withCORS(env, req, badRequest('Missing job title id'));
  }

  try {
    // 1) Check for children
    const childUrl =
      `${env.SUPABASE_URL}/rest/v1/default_job_titles` +
      `?select=id&parent_id=eq.${enc(jobTitleId)}&limit=1`;
    const { rows: children } = await sbFetch(env, childUrl);
    if (children && children.length > 0) {
      return withCORS(
        env,
        req,
        badRequest('Cannot delete: this job title has child nodes. Re-parent or delete children first.')
      );
    }

    // 2) Check for candidate references via candidate_job_titles
    const usageUrl =
      `${env.SUPABASE_URL}/rest/v1/candidate_job_titles` +
      `?select=candidate_id&job_title_id=eq.${enc(jobTitleId)}&limit=200`;
    const { rows: used } = await sbFetch(env, usageUrl);
    const candidateIds = Array.from(new Set((used || []).map(r => r.candidate_id).filter(Boolean)));
    if (candidateIds.length) {
      // Do not delete; surface a structured "in use" error envelope
      return withCORS(env, req, ok({
        error: 'JOB_TITLE_IN_USE',
        message: `This role is assigned to ${candidateIds.length} candidates.`,
        candidate_ids: candidateIds
      }));
    }

    // 3) Hard delete (no usage)
    const delUrl =
      `${env.SUPABASE_URL}/rest/v1/default_job_titles` +
      `?id=eq.${enc(jobTitleId)}`;
    const { raw } = await sbFetch(env, delUrl, {
      method: 'DELETE',
      headers: { Prefer: 'return=minimal' }
    });

    if (!raw.ok && raw.status !== 204) {
      console.error('job_title hard delete non-OK', raw.status);
      return withCORS(env, req, serverError('job_title_delete_failed'));
    }

    return withCORS(env, req, ok({ deleted: true }));
  } catch (err) {
    console.error('handleDeleteJobTitle failed', err);
    return withCORS(env, req, serverError('job_title_delete_failed'));
  }
}


// ======================= NEW: Postcode lookup (EasyPostcodes) ==========================
 async function handlePostcodeLookup(env, req) {
  const user = await requireUser(env, req);
  if (!user) return unauthorized();

  const url = new URL(req.url);
  const rawPostcode = (url.searchParams.get('postcode') || '').trim();
  const rawHouse = (url.searchParams.get('house') || '').trim();

  if (!rawPostcode) {
    return withCORS(env, req, badRequest('postcode is required'));
  }

  const apiKey = env.EASYPOSTCODES_API_KEY;
  if (!apiKey) {
    console.error('EASYPOSTCODES_API_KEY missing in env');
    return withCORS(env, req, serverError('postcode_lookup_not_configured'));
  }

  // Normalise postcode by stripping extra spaces
  const cleanedPostcode = rawPostcode.replace(/\s+/g, '');
  const epUrl = `https://api.easypostcodes.com/addresses/${encodeURIComponent(
    cleanedPostcode
  )}?includeGeo=false`;

  let resp;
  try {
    resp = await fetch(epUrl, {
      method: 'GET',
      headers: {
        Key: apiKey
      }
    });
  } catch (err) {
    console.error('EasyPostcodes network error', err);
    return withCORS(env, req, serverError('postcode_lookup_failed'));
  }

  if (!resp.ok) {
    console.error('EasyPostcodes non-OK', resp.status);
    return withCORS(env, req, serverError('postcode_lookup_failed'));
  }

  let raw;
  try {
    raw = await resp.json();
  } catch (err) {
    console.error('EasyPostcodes JSON parse error', err);
    return withCORS(env, req, serverError('postcode_lookup_failed'));
  }

  if (!Array.isArray(raw)) {
    return withCORS(env, req, ok({ addresses: [] }));
  }

  // Optional filter by house number / name
  let candidates = raw;
  const house = rawHouse.trim();
  if (house) {
    const needle = house.replace(/\s+/g, '').toLowerCase();

    const filtered = raw.filter((a) => {
      const bn = String(a.buildingNumber || '')
        .replace(/\s+/g, '')
        .toLowerCase();
      const sub = String(a.subBuildingName || '').toLowerCase();
      const addr1 = String(a.envelopeAddress?.addressLine1 || '').toLowerCase();

      if (bn && bn === needle) return true;
      if (addr1 && addr1.includes(needle)) return true;
      if (sub && sub.includes(needle)) return true;
      return false;
    });

    if (filtered.length > 0) {
      candidates = filtered;
    }
  }

  const mapped = candidates.map((a, idx) => {
    const envAddr = a.envelopeAddress || {};

    const line1 =
      envAddr.addressLine1 ||
      [a.subBuildingName, a.buildingNumber, a.thoroughfareAndDescriptor]
        .filter(Boolean)
        .join(' ')
        .trim();

    const line2 =
      envAddr.addressLine2 ||
      a.dependentLocality ||
      a.doubleDependentLocality ||
      '';

    const city = envAddr.town || a.postTown || '';
    const postcode = envAddr.postCode || a.postCode || rawPostcode;

    return {
      id: envAddr.summaryLine || `${idx}:${postcode}`,
      line1,
      line2,
      line3: '',
      city,
      postcode
    };
  });

  return withCORS(env, req, ok({ addresses: mapped }));
}





















// ================== BROKER: handleCreateCandidate (UPDATED to strip CCR fields) ==================
async function handleCreateCandidate(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const dataRaw = await parseJSONBody(req);
  if (!dataRaw) return withCORS(env, req, badRequest("Invalid JSON"));

  // Strip any accidental CCR fields (immutable/minted by DB)
  const { tms_ref, ccr_num, job_titles, ...data } = dataRaw;

  const enc = encodeURIComponent;

  // Normalise NHSP/HR name aliases (JSONB) if provided
  if (Object.prototype.hasOwnProperty.call(data, 'nhsp_hr_name_aliases')) {
    const rawAliases = data.nhsp_hr_name_aliases;
    let aliases = [];

    if (Array.isArray(rawAliases)) {
      aliases = rawAliases
        .map((x) => String(x || '').trim().toLowerCase())
        .filter(Boolean);
    } else if (typeof rawAliases === 'string') {
      const s = rawAliases.trim();
      if (s) {
        if (s.startsWith('[')) {
          try {
            const arr = JSON.parse(s);
            if (Array.isArray(arr)) {
              aliases = arr
                .map((x) => String(x || '').trim().toLowerCase())
                .filter(Boolean);
            }
          } catch {
            aliases = s
              .split(',')
              .map((x) => x.trim().toLowerCase())
              .filter(Boolean);
          }
        } else {
          aliases = s
            .split(',')
            .map((x) => x.trim().toLowerCase())
            .filter(Boolean);
        }
      }
    } else if (rawAliases != null) {
      const s = String(rawAliases).trim();
      if (s) aliases = [s.toLowerCase()];
    }

    data.nhsp_hr_name_aliases = Array.from(new Set(aliases));
  }

  // ✅ Normalise key_norm (GCK) and allow empty -> null
  if (Object.prototype.hasOwnProperty.call(data, 'key_norm')) {
    const v = String(data.key_norm ?? '').trim();
    data.key_norm = v ? v.toLowerCase() : null;
  }

  // ✅ Enforce key_norm uniqueness if provided
  if (data.key_norm) {
    const other = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?key_norm=eq.${enc(data.key_norm)}` +
        `&select=id` +
        `&limit=1`
    ).catch(() => null);

    if (other?.id) {
      return withCORS(env, req, badRequest('Global Candidate Key (key_norm) is already assigned to another candidate.'));
    }
  }

  // Normalise pay_method: only PAYE/UMBRELLA; Unknown/other -> "use DB default" (do not send)
  if (Object.prototype.hasOwnProperty.call(data, 'pay_method')) {
    let pm = (data.pay_method == null ? '' : String(data.pay_method)).trim().toUpperCase();
    if (pm === 'UNKNOWN' || pm === '') {
      delete data.pay_method;
    } else if (pm === 'PAYE' || pm === 'UMBRELLA') {
      data.pay_method = pm;
    } else {
      delete data.pay_method;
    }
  }

  // Normalise job_titles array -> list of UUID strings
  const jtArray = Array.isArray(job_titles)
    ? job_titles.map((x) => String(x)).filter(Boolean)
    : [];

  const primaryJobTitleId = jtArray[0] || null;

  const enqueueTsfinOutbox = async (items) => {
    if (!Array.isArray(items) || !items.length) return { enqueued: 0 };
    try {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
        {
          method: "POST",
          headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
          body: JSON.stringify(items)
        }
      );
      return { enqueued: items.length };
    } catch (e) {
      console.warn('[TSFIN] enqueue outbox failed', e?.message || e);
      return { enqueued: 0 };
    }
  };

  const runTsfinImmediate = async (limitHint) => {
    try {
      if (typeof runTsfinWorkerOnce !== 'function') {
        return { ran: false, picked: 0, ok: 0, fail: 0 };
      }
      const limit = Math.min(Math.max(parseInt(limitHint || '50', 10) || 50, 1), 200);
      const res = await runTsfinWorkerOnce(env, { limit });
      return { ran: true, ...(res || {}) };
    } catch (e) {
      console.warn('[TSFIN] immediate run failed', e?.message || e);
      return { ran: false, picked: 0, ok: 0, fail: 0 };
    }
  };

 const assignTimesheetsByOccKey = async (occKeyLower, candId) => {
  // candId is kept as a guard so callers don’t accidentally call with null,
  // but we do NOT write candidate_id into timesheets (column does not exist).
  if (!occKeyLower || !candId) return [];
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?is_current=eq.true` +
        `&occupant_key_norm=eq.${enc(occKeyLower)}` +
        `&select=timesheet_id` +
        `&limit=500`
    );

    const ids = (rows || []).map(r => r?.timesheet_id).filter(Boolean);

    // ✅ Do NOT PATCH timesheets here (timesheets.candidate_id does not exist).
    // TSFIN rebuild will populate candidate_id/client_id in timesheets_financials / v_timesheets_summary.
    return ids;
  } catch (e) {
    console.warn('[CAND] assignTimesheetsByOccKey failed', e?.message || e);
    return [];
  }
};

  try {
    // Insert candidate; set job_title_id to primary (or null)
    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/candidates`, {
      method: "POST",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify({
        ...data,
        job_title_id: primaryJobTitleId,
        created_at: new Date().toISOString()
      })
    });
    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Candidate creation failed: ${err}`));
    }

    const json = await res.json().catch(() => ({}));
    const candidate = Array.isArray(json) ? json[0] : json;
    const candidateId = candidate?.id;

    // Insert candidate_job_titles join rows if provided
    if (candidateId && jtArray.length) {
      const nowIso = new Date().toISOString();
      const rows = jtArray.map((jobTitleId, idx) => ({
        candidate_id: candidateId,
        job_title_id: jobTitleId,
        is_primary: idx === 0,
        created_at: nowIso,
        updated_at: nowIso
      }));

      const jtRes = await fetch(`${env.SUPABASE_URL}/rest/v1/candidate_job_titles`, {
        method: "POST",
        headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
        body: JSON.stringify(rows)
      });

      if (!jtRes.ok) {
        const err = await jtRes.text().catch(() => 'insert candidate_job_titles failed');
        console.error('candidate_job_titles insert failed', err);
      }
    }

    // ✅ NEW: on candidate create, try to resolve any unassigned timesheets by key_norm
    let autoAssignedTimesheets = [];
    if (candidateId && candidate?.key_norm) {
      const k = String(candidate.key_norm || '').trim().toLowerCase();
      if (k) {
        autoAssignedTimesheets = await assignTimesheetsByOccKey(k, candidateId);
      }
    }

// ✅ Priority enqueue + targeted drain for any auto-assigned timesheets
const tsfinRun = await tsfinTargetedDrainNow(env, {
  timesheetIds: autoAssignedTimesheets,
  reason: 'CONTEXT_CHANGED',
  chunkSize: 50
});

return withCORS(env, req, ok({
  candidate,
  tsfin: {
    enqueued: tsfinRun.enqueued || 0,
    ran_now: tsfinRun.ran || 0,
    picked: tsfinRun.picked || 0,
    ok: tsfinRun.ok || 0,
    fail: tsfinRun.fail || 0,
    auto_assigned_timesheets: autoAssignedTimesheets.length
  }
}));

  } catch (e) {
    console.error('handleCreateCandidate failed', e);
    return withCORS(env, req, serverError("Failed to create candidate"));
  }
}


async function handleUpdateCandidate(env, req, candidateId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const raw = await parseJSONBody(req);
  if (!raw) return withCORS(env, req, badRequest("Invalid JSON"));

  // Strip any accidental CCR fields (immutable/minted by DB)
  const { tms_ref, ccr_num, job_titles, ...data } = raw;

  // Normalise NHSP/HR name aliases (JSONB) if provided
  let aliasesChanged = false;
  if (Object.prototype.hasOwnProperty.call(data, 'nhsp_hr_name_aliases')) {
    const rawAliases = data.nhsp_hr_name_aliases;
    let aliases = [];

    if (Array.isArray(rawAliases)) {
      aliases = rawAliases
        .map((x) => String(x || '').trim().toLowerCase())
        .filter(Boolean);
    } else if (typeof rawAliases === 'string') {
      const s = rawAliases.trim();
      if (s) {
        if (s.startsWith('[')) {
          try {
            const arr = JSON.parse(s);
            if (Array.isArray(arr)) {
              aliases = arr
                .map((x) => String(x || '').trim().toLowerCase())
                .filter(Boolean);
            }
          } catch {
            aliases = s
              .split(',')
              .map((x) => x.trim().toLowerCase())
              .filter(Boolean);
          }
        } else {
          aliases = s
            .split(',')
            .map((x) => x.trim().toLowerCase())
            .filter(Boolean);
        }
      }
    } else if (rawAliases != null) {
      const s = String(rawAliases).trim();
      if (s) aliases = [s.toLowerCase()];
    }

    // de-dupe
    aliases = Array.from(new Set(aliases));
    data.nhsp_hr_name_aliases = aliases;
    aliasesChanged = true; // we’ll compute exact diff after loading "before"
  }

  // ✅ Normalise key_norm (GCK): allow clear -> null
  let keyNormTouched = false;
  if (Object.prototype.hasOwnProperty.call(data, 'key_norm')) {
    keyNormTouched = true;
    const v = String(data.key_norm ?? '').trim();
    data.key_norm = v ? v.toLowerCase() : null;
  }

  // Normalise pay_method:
  // - only PAYE/UMBRELLA are allowed
  // - Unknown/empty/other => "no change" (do NOT PATCH null because DB is NOT NULL)
  let payMethodAttemptedUnknown = false;
  if (Object.prototype.hasOwnProperty.call(data, 'pay_method')) {
    let pm = (data.pay_method == null ? '' : String(data.pay_method)).trim().toUpperCase();
    if (pm === 'UNKNOWN' || pm === '') {
      payMethodAttemptedUnknown = true;
      delete data.pay_method;
    } else if (pm === 'PAYE' || pm === 'UMBRELLA') {
      data.pay_method = pm;
    } else {
      payMethodAttemptedUnknown = true;
      delete data.pay_method;
    }
  }

  // Normalise job_titles array if present; undefined => "no change"
  let jtArray = null;
  if (Array.isArray(job_titles)) {
    jtArray = job_titles.map((x) => String(x)).filter(Boolean);
    data.job_title_id = jtArray[0] || null; // primary is first
  }

  // helpers
  const enc = encodeURIComponent;

  const arraysEqual = (a, b) => {
    const aa = Array.isArray(a) ? a.slice() : [];
    const bb = Array.isArray(b) ? b.slice() : [];
    if (aa.length !== bb.length) return false;
    for (let i = 0; i < aa.length; i++) if (String(aa[i]) !== String(bb[i])) return false;
    return true;
  };

  const normaliseAliasArr = (v) => {
    try {
      let out = [];
      if (Array.isArray(v)) out = v;
      else if (typeof v === 'string') {
        const s = v.trim();
        if (s.startsWith('[')) {
          try {
            const arr = JSON.parse(s);
            out = Array.isArray(arr) ? arr : [];
          } catch {
            out = s.split(',');
          }
        } else {
          out = s.split(',');
        }
      } else if (v != null) out = [v];
      return Array.from(
        new Set(
          out
            .map(x => String(x || '').trim().toLowerCase())
            .filter(Boolean)
        )
      ).sort();
    } catch {
      return [];
    }
  };

  const enqueueTsfinOutbox = async (items) => {
    if (!Array.isArray(items) || !items.length) return { enqueued: 0 };
    try {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
        {
          method: "POST",
          headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
          body: JSON.stringify(items)
        }
      );
      return { enqueued: items.length };
    } catch (e) {
      console.warn('[TSFIN] enqueue outbox failed', e?.message || e);
      return { enqueued: 0 };
    }
  };

  const runTsfinImmediate = async (limitHint) => {
    try {
      if (typeof runTsfinWorkerOnce !== 'function') {
        return { ran: false, picked: 0, ok: 0, fail: 0 };
      }
      const limit = Math.min(Math.max(parseInt(limitHint || '50', 10) || 50, 1), 200);
      const res = await runTsfinWorkerOnce(env, { limit });
      return { ran: true, ...(res || {}) };
    } catch (e) {
      console.warn('[TSFIN] immediate run failed', e?.message || e);
      return { ran: false, picked: 0, ok: 0, fail: 0 };
    }
  };

 const assignTimesheetsByOccKey = async (occKeyLower, candId) => {
  // candId is kept as a guard so callers don’t accidentally call with null,
  // but we do NOT write candidate_id into timesheets (column does not exist).
  if (!occKeyLower || !candId) return [];
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?is_current=eq.true` +
        `&occupant_key_norm=eq.${enc(occKeyLower)}` +
        `&select=timesheet_id` +
        `&limit=500`
    );

    const ids = (rows || []).map(r => r?.timesheet_id).filter(Boolean);

    // ✅ Do NOT PATCH timesheets here (timesheets.candidate_id does not exist).
    // TSFIN rebuild will populate candidate_id/client_id in timesheets_financials / v_timesheets_summary.
    return ids;
  } catch (e) {
    console.warn('[CAND] assignTimesheetsByOccKey failed', e?.message || e);
    return [];
  }
};


  try {
    // 1) Load current candidate (include key_norm + aliases for diff + uniqueness)
    const sel = [
      'pay_method',
      'mileage_pay_rate',
      'umbrella_id',
      'account_holder',
      'bank_name',
      'sort_code',
      'account_number',
      'key_norm',
      'nhsp_hr_name_aliases'
    ].join(',');

    const { rows: beforeRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?id=eq.${enc(candidateId)}` +
        `&select=${sel}` +
        `&limit=1`
    );
    const before = beforeRows?.[0] || {};

    const originalPayMethod = (before.pay_method == null)
      ? null
      : String(before.pay_method).toUpperCase();

    // If user attempted to set Unknown, enforce your rule (only allowed if NO contracts)
    if (payMethodAttemptedUnknown && (originalPayMethod === 'PAYE' || originalPayMethod === 'UMBRELLA')) {
      const { rows: conRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?candidate_id=eq.${enc(candidateId)}` +
          `&select=id&limit=1`
      );
      const hasAnyContract = Array.isArray(conRows) && conRows.length > 0;
      if (hasAnyContract) {
        return withCORS(
          env,
          req,
          badRequest(
            'Cannot change pay method to Unknown while this candidate has contracts. ' +
            'Set pay method to PAYE or UMBRELLA instead.'
          )
        );
      }
      // If no contracts, "Unknown" just means "no change" (we already deleted pay_method)
    }

    // ✅ Enforce key_norm uniqueness if it’s being set (non-null)
    const beforeKey = (before.key_norm == null) ? null : String(before.key_norm).trim().toLowerCase();
    const nextKey   = keyNormTouched ? (data.key_norm == null ? null : String(data.key_norm)) : beforeKey;

    const keyNormChanged = keyNormTouched && (String(beforeKey || '') !== String(nextKey || ''));

    if (keyNormTouched && nextKey) {
      const other = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?key_norm=eq.${enc(nextKey)}` +
          `&id=neq.${enc(candidateId)}` +
          `&select=id` +
          `&limit=1`
      ).catch(() => null);

      if (other?.id) {
        return withCORS(env, req, badRequest('Global Candidate Key (key_norm) is already assigned to another candidate.'));
      }
    }

    // Compute alias exact diff only if field was touched
    let aliasesActuallyChanged = false;
    if (aliasesChanged) {
      const beforeAliases = normaliseAliasArr(before.nhsp_hr_name_aliases).sort();
      const afterAliases  = normaliseAliasArr(data.nhsp_hr_name_aliases).sort();
      aliasesActuallyChanged = !arraysEqual(beforeAliases, afterAliases);
    }

    // 2) Update candidate
    const url =
      `${env.SUPABASE_URL}/rest/v1/candidates` +
      `?id=eq.${enc(candidateId)}`;

    const res = await fetch(url, {
      method: "PATCH",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify({ ...data, updated_at: new Date().toISOString() })
    });
    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Candidate update failed: ${err}`));
    }
    const json = await res.json().catch(() => ({}));
    const candidate = Array.isArray(json) ? json[0] : json;

    // 2b) Upsert candidate_job_titles if job_titles were explicitly provided
    if (jtArray !== null) {
      try {
        const { rows: existingRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/candidate_job_titles` +
            `?candidate_id=eq.${enc(candidateId)}` +
            `&select=job_title_id`
        );
        const existingIds = new Set((existingRows || []).map((r) => String(r.job_title_id)));
        const newIds = new Set(jtArray.map(String));

        const toDelete = [];
        for (const r of existingRows || []) {
          const id = String(r.job_title_id);
          if (!newIds.has(id)) toDelete.push(id);
        }
        const toInsert = [];
        for (const id of jtArray.map(String)) {
          if (!existingIds.has(id)) toInsert.push(id);
        }

        for (const jobTitleId of toDelete) {
          const delUrl =
            `${env.SUPABASE_URL}/rest/v1/candidate_job_titles` +
            `?candidate_id=eq.${enc(candidateId)}` +
            `&job_title_id=eq.${enc(jobTitleId)}`;
          await fetch(delUrl, { method: 'DELETE', headers: sbHeaders(env) }).catch(() => {});
        }

        if (toInsert.length) {
          const nowIso = new Date().toISOString();
          const rows = toInsert.map((jobTitleId) => ({
            candidate_id: candidateId,
            job_title_id: jobTitleId,
            is_primary: false,
            created_at: nowIso,
            updated_at: nowIso
          }));
          await fetch(`${env.SUPABASE_URL}/rest/v1/candidate_job_titles`, {
            method: 'POST',
            headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
            body: JSON.stringify(rows)
          }).catch(() => {});
        }

        const clearPrimaryUrl =
          `${env.SUPABASE_URL}/rest/v1/candidate_job_titles` +
          `?candidate_id=eq.${enc(candidateId)}`;
        await fetch(clearPrimaryUrl, {
          method: 'PATCH',
          headers: { ...sbHeaders(env), "Prefer": "return=minimal" },
          body: JSON.stringify({ is_primary: false, updated_at: new Date().toISOString() })
        }).catch(() => {});

        const primaryId = jtArray[0] || null;
        if (primaryId) {
          const setPrimaryUrl =
            `${env.SUPABASE_URL}/rest/v1/candidate_job_titles` +
            `?candidate_id=eq.${enc(candidateId)}` +
            `&job_title_id=eq.${enc(primaryId)}`;
          await fetch(setPrimaryUrl, {
            method: 'PATCH',
            headers: { ...sbHeaders(env), "Prefer": "return=minimal" },
            body: JSON.stringify({ is_primary: true, updated_at: new Date().toISOString() })
          }).catch(() => {});
        }
      } catch (jtErr) {
        console.error('handleUpdateCandidate: candidate_job_titles upsert failed', jtErr);
      }
    }

    // 3) Change detection (existing + NEW key_norm/aliases)
    const payMethodChanged  = (data.pay_method != null) && data.pay_method !== before.pay_method;
    const umbrellaChanged   = (data.umbrella_id !== undefined) && data.umbrella_id !== before.umbrella_id;
    const mileagePayChanged = (data.mileage_pay_rate != null) && Number(data.mileage_pay_rate) !== Number(before.mileage_pay_rate);

    const bankKeys = ['account_holder','bank_name','sort_code','account_number'];
    const bankChanged = bankKeys.some(k => Object.prototype.hasOwnProperty.call(data, k) && data[k] !== before[k]);

    // 4A) If key_norm changed, try to auto-assign matching unassigned timesheets now
    let autoAssignedTimesheets = [];
    if (keyNormChanged && nextKey) {
      autoAssignedTimesheets = await assignTimesheetsByOccKey(nextKey, candidateId);
    }

    // 4B) Build TSFIN outbox items
    const outboxItems = [];

    // Existing behaviour: recompute for current TSFIN rows for this candidate
    if (payMethodChanged || umbrellaChanged || bankChanged || mileagePayChanged || keyNormChanged || aliasesActuallyChanged) {
      const { rows: tsfins } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?select=timesheet_id` +
          `&candidate_id=eq.${enc(candidateId)}` +
          `&is_current=eq.true` +
          `&locked_by_invoice_id=is.null`
      );

      for (const r of (tsfins || [])) {
        if (payMethodChanged || umbrellaChanged || bankChanged || keyNormChanged || aliasesActuallyChanged) {
          outboxItems.push({ timesheet_id: r.timesheet_id, reason: 'CONTEXT_CHANGED' });
        }
        if (mileagePayChanged) {
          outboxItems.push({ timesheet_id: r.timesheet_id, reason: 'RATE_CHANGED' });
        }
      }
    }

    // Also enqueue for any newly auto-assigned timesheets (so they become “resolved” immediately)
    for (const tsid of autoAssignedTimesheets) {
      outboxItems.push({ timesheet_id: tsid, reason: 'GCK_ASSIGNED' });
    }

 // 4C) Priority enqueue + targeted drain
const ids = Array.from(
  new Set(outboxItems.map(x => x?.timesheet_id).filter(Boolean).map(String))
);

const tsfinRun = await tsfinTargetedDrainNow(env, {
  timesheetIds: ids,
  reason: 'CONTEXT_CHANGED',
  chunkSize: 50
});

return withCORS(env, req, ok({
  candidate,
  tsfin: {
    enqueued: tsfinRun.enqueued || 0,
    ran_now: tsfinRun.ran || 0,
    picked: tsfinRun.picked || 0,
    ok: tsfinRun.ok || 0,
    fail: tsfinRun.fail || 0,
    auto_assigned_timesheets: autoAssignedTimesheets.length
  }
}));

  } catch (e) {
    console.error('handleUpdateCandidate failed', e);
    return withCORS(env, req, serverError("Failed to update candidate"));
  }
}



async function handleGetCandidate(env, req, candidateId) {
  const enc  = encodeURIComponent;
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    // Fetch candidate
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?id=eq.${enc(candidateId)}` +
        `&select=*`
    );
    if (!rows.length) {
      return withCORS(env, req, notFound("Candidate not found"));
    }
    const candidate = rows[0];

    // Fetch joined job titles for this candidate
    let job_titles = [];
    try {
      const { rows: jtRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidate_job_titles` +
          `?candidate_id=eq.${enc(candidateId)}` +
          `&select=job_title_id,is_primary`
      );
      job_titles = Array.isArray(jtRows) ? jtRows : [];
    } catch (e) {
      console.error('handleGetCandidate: candidate_job_titles lookup failed', e);
      job_titles = [];
    }

    // If umbrella, fetch umbrella minimal fields
    let umbrella = undefined;
    if (candidate.pay_method === 'UMBRELLA' && candidate.umbrella_id) {
      const { rows: umbRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/umbrellas` +
          `?id=eq.${enc(candidate.umbrella_id)}` +
          `&select=id,name,bank_name,sort_code,account_number`
      );
      umbrella = umbRows?.[0];
    }

    const effective_pay_channel = resolveEffectivePayChannel({
      pay_method: candidate.pay_method,
      candidate,
      umbrella
    });

    // NEW: fetch hr_name_mappings aliases for this candidate
    let hr_aliases = [];
    try {
      const { rows: aliasRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/hr_name_mappings` +
          `?candidate_id=eq.${enc(candidateId)}` +
          `&select=id,hr_name_norm,hospital_or_trust,last_used_at`
      );
      hr_aliases = Array.isArray(aliasRows) ? aliasRows : [];
    } catch (e) {
      console.error('handleGetCandidate: hr_name_mappings lookup failed', {
        candidate_id: candidateId,
        err: e?.message || String(e)
      });
      hr_aliases = [];
    }

    return withCORS(
      env,
      req,
      ok({
        candidate,
        effective_pay_channel,
        job_titles,
        hr_aliases
      })
    );
  } catch (e) {
    console.error('handleGetCandidate failed', e);
    return withCORS(env, req, serverError("Failed to fetch candidate"));
  }
}


async function handleCandidateAliasesDelete(env, req, candidateId) {
  const enc  = encodeURIComponent;
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!candidateId) {
    return withCORS(env, req, badRequest('candidate_id required'));
  }

  let body;
  try {
    body = await parseJSONBody(req);
  } catch (e) {
    return withCORS(env, req, badRequest('Invalid JSON body'));
  }

  const mappingIds = Array.isArray(body?.mapping_ids)
    ? body.mapping_ids.map(String).filter(Boolean)
    : [];

  if (!mappingIds.length) {
    return withCORS(env, req, badRequest('mapping_ids (array) is required'));
  }

  try {
    // Delete only mappings that belong to this candidate
    const filter =
      `id=in.(${mappingIds.map((id) => enc(id)).join(',')})` +
      `&candidate_id=eq.${enc(candidateId)}`;

    const url =
      `${env.SUPABASE_URL}/rest/v1/hr_name_mappings?${filter}`;

    const res = await fetch(url, {
      method: 'DELETE',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' }
    });

    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      return withCORS(env, req, serverError(
        txt || 'Failed to delete candidate alias mappings'
      ));
    }

    return withCORS(env, req, ok({
      candidate_id: candidateId,
      deleted: mappingIds.length
    }));
  } catch (e) {
    console.error('handleCandidateAliasesDelete failed', {
      candidate_id: candidateId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to delete candidate aliases'));
  }
}

async function handleClientAliasesDelete(env, req, clientId) {
  const enc  = encodeURIComponent;
  const norm = (s) => String(s || '').trim().toLowerCase();

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!clientId) {
    return withCORS(env, req, badRequest('client_id required'));
  }

  let body;
  try {
    body = await parseJSONBody(req);
  } catch (e) {
    return withCORS(env, req, badRequest('Invalid JSON body'));
  }

  // Allow either a single alias or an array of aliases
  let aliasesToDelete = [];
  if (Array.isArray(body?.aliases)) {
    aliasesToDelete = body.aliases.map(norm).filter(Boolean);
  } else if (body?.alias) {
    aliasesToDelete = [norm(body.alias)];
  }

  if (!aliasesToDelete.length) {
    return withCORS(env, req, badRequest('alias or aliases (array) is required'));
  }

  const deleteSet = new Set(aliasesToDelete);

  // Helper copied from applyWeeklyMappingsOnly
  const normAliasList = (val) => {
    if (!val) return [];
    if (Array.isArray(val)) return val;
    if (typeof val === 'string') {
      try {
        const parsed = JSON.parse(val);
        return Array.isArray(parsed) ? parsed : [val];
      } catch {
        return [val];
      }
    }
    return [];
  };

  try {
    // There is typically a single client_hospitals row per client
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
        `?client_id=eq.${enc(clientId)}` +
        `&select=id,display_name,hospital_name_norm`
    );

    if (!Array.isArray(rows) || !rows.length) {
      return withCORS(env, req, ok({
        client_id: clientId,
        deleted: 0
      }));
    }

    let totalRemoved = 0;

    for (const r of rows) {
      const existing = normAliasList(r.hospital_name_norm);
      if (!existing.length) continue;

      const kept = [];
      let removedHere = 0;

      for (const alias of existing) {
        const canonical = norm(alias);
        if (deleteSet.has(canonical)) {
          removedHere++;
        } else {
          kept.push(alias);
        }
      }

      if (!removedHere) continue;
      totalRemoved += removedHere;

      // Patch this row with the pruned alias list
      const patchUrl =
        `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
        `?id=eq.${enc(r.id)}`;

      const res = await fetch(patchUrl, {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
        body: JSON.stringify({ hospital_name_norm: kept })
      });

      if (!res.ok) {
        const txt = await res.text().catch(() => '');
        console.warn('handleClientAliasesDelete: PATCH failed', {
          id: r.id,
          client_id: clientId,
          err: txt
        });
      }
    }

    return withCORS(env, req, ok({
      client_id: clientId,
      deleted: totalRemoved
    }));
  } catch (e) {
    console.error('handleClientAliasesDelete failed', {
      client_id: clientId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to delete client aliases'));
  }
}

// ─────────────────────────────────────────────────────────────────────────────
// Files: secure download via short-lived token
// GET /api/files/download?key=...&token=...[&filename=...]
// ─────────────────────────────────────────────────────────────────────────────



// ====================== HEALTHROSTER ======================
/**
 * @openapi
 * /api/healthroster/import:
 *   post:
 *     summary: Register an HR import (file already in R2)
 *     tags: [HealthRoster]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required: [file_key]
 *             properties:
 *               file_key: { type: string, description: "R2 key of uploaded file" }
 *     responses:
 *       200:
 *         description: import_id returned
 * /api/healthroster/{import_id}/rows:
 *   get:
 *     summary: List parsed rows for an import
 *     tags: [HealthRoster]
 *     security:
 *       - bearerAuth: []
 * /api/healthroster/{import_id}/mapping:
 *   get:
 *     summary: List active HR name mappings (global)
 *     tags: [HealthRoster]
 *     security:
 *       - bearerAuth: []
 *   post:
 *     summary: Upsert HR name mappings (global)
 *     tags: [HealthRoster]
 *     security:
 *       - bearerAuth: []
 * /api/healthroster/{import_id}/validate:
 *   post:
 *     summary: Trigger validation run (delegates to Flow if configured)
 *     tags: [HealthRoster]
 *     security:
 *       - bearerAuth: []
 */
async function handleHRRows(env, req, importId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!importId) {
    return withCORS(env, req, badRequest("import_id is required"));
  }

  try {
    const { searchParams } = new URL(req.url);
    const limit  = Math.min(Math.max(parseInt(searchParams.get('limit')  || '500', 10) || 500, 1), 5000);
    const offset = Math.max(parseInt(searchParams.get('offset') || '0',   10) || 0, 0);
    const order  = searchParams.get('order') || 'id.asc';

    const url =
      `${env.SUPABASE_URL}/rest/v1/hr_rows` +
      `?import_id=eq.${encodeURIComponent(importId)}` +
      `&select=*` +
      `&order=${encodeURIComponent(order)}` +
      `&limit=${limit}` +
      `&offset=${offset}`;

    const { rows } = await sbFetch(env, url, false);
    return withCORS(env, req, ok({ rows }));
  } catch {
    return withCORS(env, req, serverError("Failed to fetch HR rows"));
  }
}

async function handleFilesDownload(env, req) {
  const LOG = true; // set false if you want to reduce console noise

  try {
    const url = new URL(req.url);
    const keyParam = url.searchParams.get('key');
    const token = url.searchParams.get('token');
    const overrideName = url.searchParams.get('filename') || null;

    if (!keyParam || !token) {
      if (LOG) console.warn('[FILES][DL] deny: missing_params', {
        hasKey: !!keyParam,
        hasToken: !!token
      });
      return withCORS(env, req, badRequest("key and token are required"));
    }

    // Normalize incoming key to a bare R2 key (no leading slash)
    const key = String(keyParam || '').replace(/^\/+/, '').trim();

    if (key.includes('..')) {
      if (LOG) console.warn('[FILES][DL] deny: dotdot', { key });
      return withCORS(env, req, unauthorized());
    }

    // Allow uploaded evidence + other doc prefixes
    const ALLOWED_PREFIXES = [
      'files/',                     // evidence uploads
      'invoices/', 'remittances/', 'paper_ts/', 'signatures/', 'docs/',
      'docs-pdf/',
      'Assets/', 'assets/'
    ];
    if (!ALLOWED_PREFIXES.some(p => key.startsWith(p))) {
      if (LOG) console.warn('[FILES][DL] deny: prefix', { key });
      return withCORS(env, req, unauthorized());
    }

    const secret = env.UPLOAD_TOKEN_SECRET;
    if (!secret) {
      if (LOG) console.warn('[FILES][DL] deny: missing_secret');
      return withCORS(env, req, serverError("Server not configured"));
    }

    // ✅ FIX: verifyToken returns { ok, payload } (NOT the payload itself)
    let ver;
    try {
      ver = await verifyToken(secret, token);
    } catch (e) {
      if (LOG) console.warn('[FILES][DL] deny: verify_throw', {
        key,
        err: e?.message || String(e)
      });
      await writeAudit(env, null, 'FILE_DOWNLOAD_DENIED', { key, reason: 'invalid_token_throw' }, { entity: 'r2', subject_id: key, req });
      return withCORS(env, req, unauthorized());
    }

    if (!ver || !ver.ok) {
      if (LOG) console.warn('[FILES][DL] deny: invalid_token', { key });
      await writeAudit(env, null, 'FILE_DOWNLOAD_DENIED', { key, reason: 'invalid_token' }, { entity: 'r2', subject_id: key, req });
      return withCORS(env, req, unauthorized());
    }

    const p = ver.payload || {};
    const payloadKey = (typeof p.key === 'string') ? p.key.replace(/^\/+/, '').trim() : '';
    const typ = (p.typ != null) ? String(p.typ) : null;
    const exp = (typeof p.exp === 'number') ? p.exp : null;

    // Accept both token types (backwards compatible)
    const typOk = (typ === 'dl' || typ === 'file_dl');

    if (!typOk || !payloadKey || payloadKey !== key) {
      if (LOG) console.warn('[FILES][DL] deny: claims_mismatch', {
        key,
        payloadKey: payloadKey || null,
        typ
      });
      await writeAudit(
        env,
        null,
        'FILE_DOWNLOAD_DENIED',
        { key, reason: 'claims_mismatch', payload_key: payloadKey || null, typ },
        { entity: 'r2', subject_id: key, req }
      );
      return withCORS(env, req, unauthorized());
    }

    // Expiry check (unix seconds)
    const now = Math.floor(Date.now() / 1000);
    if (!exp || now >= exp) {
      if (LOG) console.warn('[FILES][DL] deny: expired', { key, exp, now });
      await writeAudit(env, null, 'FILE_DOWNLOAD_DENIED', { key, reason: 'expired', exp }, { entity: 'r2', subject_id: key, req });
      return withCORS(env, req, new Response("Link expired", { status: 410 }));
    }

    const bucket = env.R2_BUCKET || env.R2;
    if (!bucket || !bucket.get) {
      if (LOG) console.warn('[FILES][DL] deny: no_bucket');
      return withCORS(env, req, serverError("Storage not configured"));
    }

    const obj = await bucket.get(key);
    if (!obj) {
      if (LOG) console.warn('[FILES][DL] not_found', { key });
      await writeAudit(env, null, 'FILE_DOWNLOAD_NOT_FOUND', { key }, { entity: 'r2', subject_id: key, req });
      return withCORS(env, req, notFound("File not found"));
    }

    const headers = new Headers();
    const ct = obj.httpMetadata?.contentType || 'application/octet-stream';
    headers.set('Content-Type', ct);
    if (typeof obj.size === 'number') headers.set('Content-Length', String(obj.size));
    headers.set('X-Content-Type-Options', 'nosniff');
    headers.set('Cache-Control', 'no-store');

    const metaName = obj.customMetadata?.originalName || null;
    const baseName = key.split('/').pop() || 'download.bin';
    const chosen = (overrideName || metaName || baseName)
      .replace(/[/\\]/g, '_')
      .replace(/[\r\n"]/g, '');

    // ✅ inline so iframe preview works
    headers.set('Content-Disposition', `inline; filename="${chosen}"`);

    await writeAudit(env, null, 'FILE_DOWNLOAD_OK', { key, size: obj.size || null }, { entity: 'r2', subject_id: key, req });
    return withCORS(env, req, new Response(obj.body, { status: 200, headers }));
  } catch (e) {
    try {
      console.warn('[FILES][DL] fatal', { err: e?.message || String(e) });
    } catch {}
    return withCORS(env, req, serverError("Failed to download file"));
  }
}


// ====================== TIMESHEETS FINANCE PREVIEW ======================
/**
 * @openapi
 * /api/timesheets/finance-preview:
 *   post:
 *     summary: Finance preview for selected authorised timesheets (read-only)
 *     tags: [Timesheets]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required: [timesheet_ids]
 *             properties:
 *               timesheet_ids:
 *                 type: array
 *                 items: { type: string }
 *     responses:
 *       200:
 *         description: Aggregate totals & margin (ex VAT)
 */
// ─────────────────────────────────────────────────────────────────────────────
// Timesheets: finance preview (aggregate five-way totals)
// ─────────────────────────────────────────────────────────────────────────────

// ---------------------- Email Outbox, Broadcast, and Files (unified /api/*) ----------------------
/**
 * @openapi
 * /api/email/outbox:
 *   get:
 *     summary: List email outbox items (most recent first)
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: status
 *         schema:
 *           type: string
 *           enum: [QUEUED, SENT, FAILED]
 *       - in: query
 *         name: limit
 *         schema:
 *           type: integer
 *           default: 100
 *           minimum: 1
 *           maximum: 500
 *
 * /api/email/outbox/mark-sent:
*   post:
*     summary: Mark a queued outbox item as sent (callback from mail provider/Flow)
*     security:
*       - bearerAuth: []
*     requestBody:
*       required: true
*       content:
*         application/json:
*           schema:
*             type: object
*             required: [id]
*             properties:
*               id:
*                 type: string
*               sent_at:
*                 type: string
*                 format: date-time
*               provider_message_id:
*                 type: string
 *
 * /api/email/outbox/mark-failed:
*   post:
*     summary: Mark a queued outbox item as failed (callback from mail provider/Flow)
*     security:
*       - bearerAuth: []
*     requestBody:
*       required: true
*       content:
*         application/json:
*           schema:
*             type: object
*             required: [id, error]
*             properties:
*               id:
*                 type: string
*               error:
*                 type: string
*               failed_at:
*                 type: string
*                 format: date-time
 *
 * /api/email/broadcast:
 *   post:
 *     summary: Send broadcast email (enqueues via webhook and records a summary outbox row)
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               group:
 *                 type: string
 *                 description: One of "candidates" or "clients". Ignored if "emails" is provided.
 *                 enum: [candidates, clients]
 *               emails:
 *                 type: array
 *                 items:
 *                   type: string
 *                 description: Explicit recipient list. If present, overrides "group".
 *               subject:
 *                 type: string
 *               body_text:
 *                 type: string
 *
 * /api/files/presign-download:
 *   post:
 *     summary: Create a short-lived, tokenized download URL for a stored file
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required: [key]
 *             properties:
 *               key:
 *                 type: string
 *                 description: Object key/path in storage (e.g. "invoices/abc.pdf")
 *               expires_seconds:
 *                 type: integer
 *                 default: 180
 *                 minimum: 60
 *                 maximum: 900
 *     responses:
 *       200:
 *         description: URL created
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 url:
 *                   type: string
 *
 * /api/files/download:
 *   get:
 *     summary: Token-verified file download (serves with correct Content-Type and Content-Disposition)
 *     parameters:
 *       - in: query
 *         name: key
 *         required: true
 *         schema:
 *           type: string
 *       - in: query
 *         name: token
 *         required: true
 *         schema:
 *           type: string
 *       - in: query
 *         name: inline
 *         required: false
 *         schema:
 *           type: boolean
 *           default: false
 *         description: If true, attempt inline display (e.g. PDFs in browser). Otherwise download attachment.
 */

async function handleOutboxList(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    const { searchParams } = new URL(req.url);
    const status = searchParams.get('status');
    const limit = Math.min(Math.max(parseInt(searchParams.get('limit') || '100', 10) || 100, 1), 500);
    const where = status ? `&status=eq.${encodeURIComponent(status)}` : '';

    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/mail_outbox?select=*&order=created_at_utc.desc&limit=${limit}${where}`
    );

    return withCORS(env, req, ok({ items: rows }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to fetch mail_outbox"));
  }
}

// ─────────────────────────────────────────────────────────────────────────────
// Broadcast email: send via webhook, write summary row to mail_outbox
// ─────────────────────────────────────────────────────────────────────────────
async function handleBroadcastEmail(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  let emails = [];
  if (Array.isArray(data.emails) && data.emails.length) {
    emails = data.emails;
  } else if (data.group === "candidates") {
    const { rows: candRows } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/candidates?select=email`);
    emails = candRows.map(c => c.email).filter(Boolean);
  } else if (data.group === "clients") {
    // Use primary_invoice_email only (clients table has no generic 'email' column)
    const { rows: clientRows } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/clients?select=primary_invoice_email`);
    emails = clientRows.map(c => c.primary_invoice_email).filter(Boolean);
  }

  // Normalise + de-duplicate
  emails = [...new Set(emails.map(e => String(e || '').trim()).filter(Boolean))];
  if (!emails.length) return withCORS(env, req, badRequest("No recipients found"));

  const subject = data.subject || "(No Subject)";
  const bodyText = data.body_text || "";

  try {
    const map = JSON.parse(env.TSO_WEBHOOK_MAP || "{}");
    const url = map["broadcast_email"];
    if (!url) return withCORS(env, req, serverError("Broadcast email webhook not configured"));

    const payload = { to_emails: emails, subject, body_text: bodyText };

    const flowRes = await fetch(url, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload)
    });

    if (!flowRes.ok) {
      const err = await flowRes.text();
      return withCORS(env, req, serverError(`Broadcast failed: ${err}`));
    }

    // Record a single summary row in mail_outbox
    const nowIso = new Date().toISOString();
    const insRes = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
      method: "POST",
      headers: sbHeaders(env),
      body: JSON.stringify({
        type: "BROADCAST",
        reference: data.group ? String(data.group).toUpperCase() : "CUSTOM",
        to: `${emails.length} recipients`,
        subject,
        body_text: bodyText.slice(0, 2000),
        status: "SENT",
        created_at_utc: nowIso,
        sent_at: nowIso
      })
    });

    if (!insRes.ok) {
      const err = await insRes.text();
      return withCORS(env, req, serverError(`Outbox insert failed: ${err}`));
    }

    await writeAudit(env, user, 'EMAIL_BROADCAST', { subject, count: emails.length });

    return withCORS(env, req, ok({ ok: true, recipients: emails.length }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to send broadcast email"));
  }
}

/**
 * Persist a single audit event. Never throws; logs a warning on failure.
 *
 * @param {Object} env                    - Worker env (must include SUPABASE_URL + sbHeaders())
 * @param {Object|null} user              - From requireUser(); may be null
 * @param {string} action                 - e.g. 'EMAIL_BROADCAST', 'OUTBOX_MARK_SENT'
 * @param {Object|null} details           - JSON-serialisable details (kept small)
 * @param {Object} [opts]
 * @param {string|null} [opts.entity]     - Domain entity (e.g. 'mail_outbox','invoice','timesheet')
 * @param {string|number|null} [opts.subject_id] - Primary key of affected record (if any)
 * @param {Request|null} [opts.req]       - Incoming Request to capture headers (optional)
 */
async function writeAudit(env, user, action, details = null, opts = {}) {
  try {
    const req = opts.req || null;

    // Request meta (all optional)
    const ip  = req?.headers?.get('cf-connecting-ip')
             || (req?.headers?.get('x-forwarded-for') || '').split(',')[0].trim()
             || null;
    const ua  = req?.headers?.get('user-agent') || null;

    // Prefer an explicit correlation_id (e.g., mail_outbox.id), then fallbacks
    const correlationId =
      opts.correlation_id ??
      (details && (details.mail_id || details.mailId)) ??
      req?.headers?.get('x-correlation-id') ??
      req?.headers?.get('x-request-id') ??
      req?.headers?.get('idempotency-key') ??
      req?.headers?.get('x-idempotency-key') ??
      null;

    // Actor normalization
    const actor_user_id      = user?.id ?? user?.sub ?? null;
    const actor_role_at_time = user?.role ?? 'system';

    // Prefer display_name from DB (tms_users) so audit renders nicely
    let actor_display = user?.display_name ?? user?.email ?? null;
    if (actor_user_id && !user?.display_name) {
      try {
        const enc = encodeURIComponent;
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/tms_users` +
            `?id=eq.${enc(String(actor_user_id))}` +
            `&select=display_name,email` +
            `&limit=1`
        );
        const u = rows?.[0] || null;
        actor_display = (u?.display_name || '').trim()
          || (u?.email || '').trim()
          || actor_display;
      } catch {
        // non-fatal
      }
    }
    if (!actor_display) actor_display = 'CloudTMS server';

    // Object targeting
    const object_type = opts.entity || opts.object_type || 'generic';
    const object_id_text =
      opts.subject_id != null
        ? String(opts.subject_id)
        : (opts.object_id_text != null ? String(opts.object_id_text) : null);

    // Build payload aligned to audit_events schema
    const payload = {
      object_type,
      object_id_text,
      action: String(action),

      before_json: opts.before ?? null,
      after_json: details ?? null,

      reason: opts.reason ?? null,

      actor_user_id,
      actor_display,
      actor_role_at_time,

      ip,
      user_agent: ua,
      correlation_id: correlationId
      // ts_utc is implicit (DEFAULT now()) – no need to send
    };

    // Best-effort POST; do not throw on failure
    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/audit_events`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify(payload)
    });

    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      console.warn('writeAudit failed', res.status, txt);
    }
  } catch (err) {
    console.warn('writeAudit error', err);
  }
}

// ---------------------- HealthRoster Endpoints (expanded) ----------------------
/**
 * Canonical HR pipeline:
 * 1) /healthroster/import      -> create import record (file key + metadata)
 * 2) /healthroster/{id}/rows   -> list parsed rows (assumes a separate parser populated hr_rows)
 * 3) /healthroster/{id}/mapping (GET/POST) -> view/save sticky name mappings (candidate resolution)
 * 4) /healthroster/{id}/validate -> run validation, write hr_results + timesheet_validations
 *
 * Validation rules (per brief):
 * - Staff name -> candidate via sticky mappings; else fuzzy; allow surname<->firstname inversion
 * - Request Grade must map to RMN or HCA (ignore band)
 * - Treat Date/Start/End as UK local; convert to UTC and compare to authorised timesheets
 * - Overnights if End < Start => add 1 day
 * - Ignore breaks (not present in HR)
 * - PASS: write VALIDATION_OK with hr_reference; never mutate timesheets/signatures
 * - FAIL: write reason codes (STAFF_NOT_FOUND, TIME_MISMATCH, ROLE_MISMATCH, TIMESHEET_NOT_FOUND, MULTIPLE_MATCHES, REQUEST_GRADE_UNKNOWN)
 */

/** Utility: basic normalisation */
function normName(s){
  return String(s||'')
    .toUpperCase()
    .replace(/\([^)]*\)/g,'') // remove parentheticals like (RMN)
    .replace(/[^A-Z\s]/g,' ')  // strip punctuation/accents (assumes upstream already de-accented if needed)
    .replace(/\s+/g,' ')
    .trim();
}
function nameVariants(raw){
  const n = normName(raw);
  const parts = n.split(' ');
  if (parts.length < 2) return [n];
  const first = parts[0], last = parts[parts.length-1];
  const full = `${last} ${first}`; // surname first
  return [n, full];
}

/** Utility: derive RMN/HCA from Request Grade */
function roleFromRequestGrade(grade){
  const g = String(grade||'').toUpperCase();
  if (/HCA|HEALTH\s*CARE/i.test(g)) return 'HCA';
  if (/RMN|MENTAL|NURSE/i.test(g)) return 'RMN';
  return null;
}

/** Utility: UK DST (BST) check; last Sunday of Mar to last Sunday of Oct */
function ukLocalToUtcISO(ymd, hhmm = "00:00") {
  // ymd: "YYYY-MM-DD" (UK local date), hhmm: "HH:MM" (UK local clock time)
  const [Y, Mo, D] = String(ymd || "").split("-").map(Number);
  const [H, Mi]    = String(hhmm || "00:00").split(":").map(Number);
  if (!Y || !Mo || !D || Number.isNaN(H) || Number.isNaN(Mi)) return null;

  const offsetHours = isBSTLocalDate(Y, Mo, D) ? 1 : 0; // UK summer = UTC+1
  const dt = new Date(Date.UTC(Y, Mo - 1, D, H - offsetHours, Mi, 0));
  return dt.toISOString();
}

function isBSTLocalDate(Y, Mo, D) {
  // Decide DST for that calendar date using a noon sentinel to avoid boundary weirdness.
  const noonUtcGuess = Date.UTC(Y, Mo - 1, D, 12, 0, 0);
  const start = bstStartUtc(Y); // last Sunday in March, 01:00 UTC
  const end   = bstEndUtc(Y);   // last Sunday in October, 01:00 UTC
  return noonUtcGuess >= start && noonUtcGuess < end;
}

function bstStartUtc(year) {
  // Last Sunday in March at 01:00 UTC
  const day = lastSundayUtc(year, 2); // March = 2 (0-indexed)
  return Date.UTC(year, 2, day, 1, 0, 0);
}

function bstEndUtc(year) {
  // Last Sunday in October at 01:00 UTC
  const day = lastSundayUtc(year, 9); // October = 9 (0-indexed)
  return Date.UTC(year, 9, day, 1, 0, 0);
}

function lastSundayUtc(year, monthIndex /* 0-11 */) {
  // Date-of-month for the last Sunday of the given month (UTC).
  const d = new Date(Date.UTC(year, monthIndex + 1, 0)); // last day of month
  const dow = d.getUTCDay(); // 0 = Sun
  return d.getUTCDate() - dow; // backtrack to Sunday
}

async function getStickyMappings(env, importId) {
  // Global active mappings only; use existing columns
  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/hr_name_mappings` +
      `?active=eq.true` +
      `&select=hr_name_norm,hospital_or_trust,candidate_id` +
      `&order=last_used_at.desc,created_at.desc`
  );

  // Prefer most recently used; key by hr_name_norm (hospital dimension optional/not supplied here)
  const map = new Map();
  for (const r of rows) {
    if (r.hr_name_norm && r.candidate_id && !map.has(r.hr_name_norm)) {
      map.set(r.hr_name_norm, r.candidate_id);
    }
  }
  return map;
}

async function resolveCandidateId(env, staffRaw, stickyMap) {
  const variants = nameVariants(staffRaw); // includes "FIRST LAST" and "LAST FIRST" normalized
  for (const v of variants) {
    const cid = stickyMap.get(v);
    if (cid) return cid;
  }

  // Fallback fuzzy using available candidate fields
  const { rows: cands } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/candidates?select=id,first_name,last_name,display_name,key_norm`
  );

  const normCandidates = cands.map((c) => {
    const key1 = normName(`${c.last_name || ''} ${c.first_name || ''}`);
    const key2 = normName(`${c.first_name || ''} ${c.last_name || ''}`);
    const key3 = normName(c.display_name || '');
    const key4 = (c.key_norm || '').toUpperCase().trim(); // already-normalized key if present
    return { id: c.id, keys: new Set([key1, key2, key3, key4].filter(Boolean)) };
  });

  for (const v of variants) {
    const hit = normCandidates.find((c) => c.keys.has(v));
    if (hit) return hit.id;
  }

  // Also try direct normalized raw (covers single-name display cases)
  const rawNorm = normName(staffRaw);
  const hitRaw = normCandidates.find((c) => c.keys.has(rawNorm));
  return hitRaw ? hitRaw.id : null;
}
async function findAuthorisedTimesheet(env, { candidate_id, ymd, start_hhmm, end_hhmm, unit }) {
  // Convert UK local to UTC boundaries
  const startUtcIso = ukLocalToUtcISO(ymd, start_hhmm);

  // Handle overnights: if end < start => add 1 day before converting
  let endYmd = ymd;
  const [sh, sm] = start_hhmm.split(':').map(Number);
  const [eh, em] = end_hhmm.split(':').map(Number);
  const isOvernight = (eh * 60 + em) <= (sh * 60 + sm);
  if (isOvernight) {
    const dt = new Date(Date.UTC(...ymd.split('-').map((n, i) => (i === 1 ? Number(n) - 1 : Number(n)))));
    dt.setUTCDate(dt.getUTCDate() + 1);
    endYmd = `${dt.getUTCFullYear()}-${String(dt.getUTCMonth() + 1).padStart(2, '0')}-${String(dt.getUTCDate()).padStart(2, '0')}`;
  }
  const endUtcIso = ukLocalToUtcISO(endYmd, end_hhmm);

  // ✅ Query the HR view (not base timesheets) and use "unit" (not hospital/ward)
  // View columns: id, candidate_id, start_utc, end_utc, unit, role_code, authorised, date_ymd
  let q =
    `${env.SUPABASE_URL}/rest/v1/timesheets_hr_view` +
    `?select=id,candidate_id,start_utc,end_utc,unit,role_code,authorised,date_ymd` +
    `&authorised=eq.true` +
    `&candidate_id=eq.${encodeURIComponent(candidate_id)}` +
    `&start_utc=eq.${encodeURIComponent(startUtcIso)}` +
    `&end_utc=eq.${encodeURIComponent(endUtcIso)}`;

  if (unit) {
    q += `&unit=eq.${encodeURIComponent(unit)}`;
  }

  const { rows } = await sbFetch(env, q);

  if (rows.length === 1) return rows[0];
  if (rows.length > 1) return { MULTIPLE: rows };
  // If exact match not found, try loose match on date + role later in validator
  return null;
}

async function upsertValidation(env, user, { timesheet_id, status, reason, hr_reference, import_id }) {
  const enc    = encodeURIComponent;
  const nowIso = new Date().toISOString();

  // Only stamp validated_at_utc for "OK / PASS / VALID" statuses
  const shouldStamp =
    typeof status === 'string' && /ok|pass|valid/i.test(status);

  // HR request triple (id + set_at + source) must be all-null or all-non-null
  let hr_request_id          = hr_reference || null;
  let hr_request_set_at_utc  = null;
  let hr_request_source      = null;

  if (hr_request_id) {
    hr_request_set_at_utc = nowIso;

    // Try to infer source from hr_imports if import_id is present
    if (import_id) {
      try {
        const { rows: impRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/hr_imports` +
            `?id=eq.${enc(import_id)}` +
            `&select=source_system` +
            `&limit=1`
        );
        const imp = impRows?.[0] || null;
        if (imp && imp.source_system) {
          // e.g. 'HEALTHROSTER_DAILY', 'HEALTHROSTER', 'NHSP'
          hr_request_source = String(imp.source_system);
        } else {
          hr_request_source = 'HR_IMPORT';
        }
      } catch (e) {
        console.warn('[upsertValidation] failed to resolve hr_request_source from hr_imports', {
          import_id,
          err: e?.message || String(e)
        });
        hr_request_source = 'HR_IMPORT';
      }
    } else {
      // No import_id → manual/other source
      hr_request_source = 'MANUAL';
    }
  }

  const payload = {
    timesheet_id,
    status,
    reason_code:    reason || null,
    hr_request_id,
    hr_request_set_at_utc,
    hr_request_source,
    validated_at_utc: shouldStamp ? nowIso : null,
    last_source: import_id || null
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheet_validations?on_conflict=timesheet_id`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), 'Prefer': 'resolution=merge-duplicates,return=minimal' },
      body: JSON.stringify(payload)
    }
  );
  if (!res.ok) {
    const err = await res.text().catch(() => '');
    throw new Error(`timesheet_validations upsert failed: ${err}`);
  }
}

async function handleHrRotaResolveMappings(env, req, importId) {
  const enc   = encodeURIComponent;
  const norm  = (s) => String(s || '').trim().toLowerCase();
  const nowIso = new Date().toISOString();

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!importId) {
    return withCORS(env, req, badRequest('import_id is required'));
  }

  let body;
  try {
    body = await parseJSONBody(req);
  } catch (e) {
    console.warn('[HR_ROTA_RESOLVE] failed to parse body', {
      import_id: importId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, badRequest('Invalid JSON body'));
  }

  const candidateMappings = Array.isArray(body?.candidate_mappings)
    ? body.candidate_mappings.filter(Boolean)
    : [];
  const clientAliases = Array.isArray(body?.client_aliases)
    ? body.client_aliases.filter(Boolean)
    : [];

  // ─────────────────────────────────────────────────────────────
  // 1) Upsert hr_name_mappings for candidate mappings
  //    (still driven by staff_norm + hospital_or_trust from FE)
  // ─────────────────────────────────────────────────────────────
  const hrNameRows = [];

  for (const m of candidateMappings) {
    if (!m) continue;
    const rawStaff  = m.staff_norm || m.staff_raw || '';
    const staffNorm = norm(rawStaff);
    const hospRaw   = m.hospital_or_trust || '';
    const hospNorm  = hospRaw ? norm(hospRaw) : null;
    const candidateId = m.candidate_id || null;

    if (!staffNorm || !candidateId) continue;

    hrNameRows.push({
      hr_name_norm:      staffNorm,
      hospital_or_trust: hospNorm,
      candidate_id:      candidateId,
      active:            true,
      last_used_at:      nowIso
    });
  }

  if (hrNameRows.length) {
    try {
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/hr_name_mappings?on_conflict=hr_name_norm,hospital_or_trust`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'resolution=merge-duplicates,return=minimal' },
          body: JSON.stringify(hrNameRows)
        }
      );
      if (!res.ok) {
        const err = await res.text().catch(() => '');
        console.warn('[HR_ROTA_RESOLVE] hr_name_mappings upsert failed', {
          import_id: importId,
          err
        });
      }
    } catch (e) {
      console.warn('[HR_ROTA_RESOLVE] hr_name_mappings upsert exception', {
        import_id: importId,
        err: e?.message || String(e)
      });
    }
  }

  // ─────────────────────────────────────────────────────────────
  // 2) Upsert client_hospitals aliases for rota:
  //    derive aliases from hr_rows using hr_row_ids when present.
  //    Fallback: use explicit hospital_norm strings if provided.
  // ─────────────────────────────────────────────────────────────

  // (a) Collect hr_row_ids and legacy hints per client
  const hrRowIdsByClient = new Map();    // client_id -> Set<hr_row_id>
  const extraAliasByClient = new Map();  // client_id -> Set<alias from hospital_norm>

  for (const a of clientAliases) {
    if (!a) continue;
    const clientId = a.client_id || null;
    if (!clientId) continue;

    // Preferred: hr_row_ids from rota preview rows
    if (Array.isArray(a.hr_row_ids) && a.hr_row_ids.length) {
      let set = hrRowIdsByClient.get(clientId);
      if (!set) {
        set = new Set();
        hrRowIdsByClient.set(clientId, set);
      }
      a.hr_row_ids
        .map(String)
        .map((id) => id.trim())
        .filter(Boolean)
        .forEach((id) => set.add(id));
    }

    // Fallback: explicit hospital_norm string
    const hospNormRaw = a.hospital_norm || '';
    const aliasFromHint = norm(hospNormRaw);
    if (aliasFromHint) {
      let set = extraAliasByClient.get(clientId);
      if (!set) {
        set = new Set();
        extraAliasByClient.set(clientId, set);
      }
      set.add(aliasFromHint);
    }
  }

  // (b) Build alias sets per client
  const aliasSetsByClient = new Map(); // client_id -> Set<alias>

  // Seed from any explicit hints
  for (const [clientId, set] of extraAliasByClient.entries()) {
    const tgt = aliasSetsByClient.get(clientId) || new Set();
    set.forEach((a) => tgt.add(a));
    aliasSetsByClient.set(clientId, tgt);
  }

  // Add aliases derived from hr_rows (rota rows)
  const allHrRowIds = new Set();
  for (const set of hrRowIdsByClient.values()) {
    for (const id of set) allHrRowIds.add(id);
  }

  if (allHrRowIds.size) {
    try {
      const idParam = Array.from(allHrRowIds).map(enc).join(',');
      const { rows: hrRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/hr_rows` +
          `?import_id=eq.${enc(importId)}` +
          `&id=in.(${idParam})` +
          `&select=id,unit_raw,payload_json`
      );
      const hrMap = new Map(
        (hrRows || []).map((r) => [String(r.id), r])
      );

      for (const [clientId, idSet] of hrRowIdsByClient.entries()) {
        let aliasSet = aliasSetsByClient.get(clientId);
        if (!aliasSet) {
          aliasSet = new Set();
          aliasSetsByClient.set(clientId, aliasSet);
        }

        for (const id of idSet) {
          const row = hrMap.get(String(id));
          if (!row) continue;
          const payload = row.payload_json || {};
          // Rota classification uses: unit_raw || payload.unit || payload.ward
          const hospRaw =
            (row.unit_raw ||
             payload.unit ||
             payload.ward ||
             '').toString().trim();

          const alias = norm(hospRaw);
          if (alias) aliasSet.add(alias);
        }
      }
    } catch (e) {
      console.warn('[HR_ROTA_RESOLVE] hr_rows lookup for aliases failed', {
        import_id: importId,
        err: e?.message || String(e)
      });
    }
  }

  // (c) Upsert client_hospitals per client
  const normAliasList = (val) => {
    if (!val) return [];
    if (Array.isArray(val)) return val;
    if (typeof val === 'string') {
      try {
        const parsed = JSON.parse(val);
        return Array.isArray(parsed) ? parsed : [val];
      } catch {
        return [val];
      }
    }
    return [];
  };

  for (const [clientId, aliasSet] of aliasSetsByClient.entries()) {
    const aliases = Array.from(aliasSet).filter(Boolean);
    if (!clientId || !aliases.length) continue;

    try {
      const { rows: chRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
          `?client_id=eq.${enc(clientId)}` +
          `&select=id,hospital_name_norm` +
          `&limit=1`
      );
      const existing = chRows?.[0] || null;

      if (!existing) {
        // Insert a new row for this client with these aliases
        try {
          const res = await fetch(
            `${env.SUPABASE_URL}/rest/v1/client_hospitals`,
            {
              method: 'POST',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
              body: JSON.stringify([{
                client_id:          clientId,
                hospital_name_norm: aliases,
                updated_at:         nowIso
              }])
            }
          );
          if (!res.ok) {
            const err = await res.text().catch(() => '');
            console.warn('[HR_ROTA_RESOLVE] client_hospitals insert failed', {
              import_id: importId,
              client_id: clientId,
              aliases,
              err
            });
          }
        } catch (e) {
          console.warn('[HR_ROTA_RESOLVE] client_hospitals insert exception', {
            import_id: importId,
            client_id: clientId,
            aliases,
            err: e?.message || String(e)
          });
        }
      } else {
        // Merge existing aliases + new ones
        const current = normAliasList(existing.hospital_name_norm).map(norm);
        const merged  = new Set(current);
        aliases.forEach((a) => merged.add(a));
        const updated = Array.from(merged);

        try {
          const res = await fetch(
            `${env.SUPABASE_URL}/rest/v1/client_hospitals` +
              `?id=eq.${enc(existing.id)}`,
            {
              method: 'PATCH',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
              body: JSON.stringify({
                hospital_name_norm: updated,
                updated_at: nowIso
              })
            }
          );
          if (!res.ok) {
            const err = await res.text().catch(() => '');
            console.warn('[HR_ROTA_RESOLVE] client_hospitals update failed', {
              import_id: importId,
              client_id: clientId,
              aliases: updated,
              err
            });
          }
        } catch (e) {
          console.warn('[HR_ROTA_RESOLVE] client_hospitals update exception', {
            import_id: importId,
            client_id: clientId,
            aliases: updated,
            err: e?.message || String(e)
          });
        }
      }
    } catch (e) {
      console.warn('[HR_ROTA_RESOLVE] client_hospitals fetch failed', {
        import_id: importId,
        client_id: clientId,
        err: e?.message || String(e)
      });
    }
  }

  return withCORS(env, req, ok({
    import_id: importId,
    candidate_mappings_applied: hrNameRows.length,
    client_aliases_applied: clientAliases.length
  }));
}


// --- FIXED: hr_results insert uses correct columns only ---
async function writeHRResult(env, importId, rowId, payload) {
  const nowIso = new Date().toISOString();

  const rec = {
    row_id: rowId,
    status: payload?.status,                 // 'SUCCESS' | 'FAIL'
    reason_code: payload?.reason_code ?? null,
    details_json: payload?.details_json ?? null,
    created_at_utc: nowIso
  };

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/hr_results`, {
    method: 'POST',
    headers: sbHeaders(env),
    body: JSON.stringify(rec),
  });

  if (!res.ok) {
    const err = await res.text();
    throw new Error(`hr_results insert failed: ${err}`);
  }
}


/**
 * @openapi
 * /healthroster/import:
 *   post:
 *     summary: Import HealthRoster data file
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             properties:
 *               file_key: { type: string, description: R2 key of uploaded file }
 *               original_name: { type: string }
 *               tz_assumption: { type: string, description: Optional IANA tz, defaults to Europe/London }
 *     responses:
 *       200:
 *         description: Import record created
 */
async function handleHRImport(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await parseJSONBody(req);
  const filename = (body?.original_name || body?.file_key || '').trim();
  if (!filename) {
    return withCORS(env, req, badRequest("original_name or file_key is required"));
  }

  try {
    const nowIso = new Date().toISOString();

    // hr_imports columns:
    //   filename, uploaded_by, uploaded_at_utc, tz_assumption,
    //   parse_summary_json, source_system, file_r2_key
    const payload = {
      filename,
      uploaded_by: user.id,
      uploaded_at_utc: nowIso,
      tz_assumption: body?.tz_assumption || 'Europe/London',

      // Explicitly mark this as a HealthRoster import (NHSP will use its own handler)
      source_system: 'HEALTHROSTER',

      // If the FE passes the R2 key, keep it
      ...(body?.file_key ? { file_r2_key: body.file_key } : {}),

      // Preserve any parse summary hints provided by caller
      ...(body?.parse_summary_json ? { parse_summary_json: body.parse_summary_json } : {}),
    };

    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/hr_imports`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload),
    });

    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Import record create failed: ${err}`));
    }

    const json = await res.json().catch(() => ([]));
    const rec = Array.isArray(json) ? json[0] : json;

    if (!rec || !rec.id) {
      return withCORS(env, req, serverError("Import record create returned no id"));
    }

    // Best-effort audit
    await writeAudit(
      env,
      user,
      'HR_IMPORT_CREATED',
      { import_id: rec.id, filename },
      { entity: 'hr_imports', subject_id: rec.id, req }
    );

    return withCORS(env, req, ok({ import_id: rec.id }));
  } catch {
    return withCORS(env, req, serverError("Failed to create HR import"));
  }
}

/**
 * @openapi
 * /healthroster/{import_id}/mapping:
 *   get:
 *     summary: Get mapping suggestions
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: q
 *         schema: { type: string }
 *         description: Filter by hr_name_norm (ILIKE)
 *   post:
 *     summary: Save mapping adjustments (array or object)
 *     security:
 *       - bearerAuth: []
 */

async function handleHRMapping(env, req, importId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!importId) {
    // Path keeps importId for routing; table has no import_id (global mappings).
  }

  if (req.method === 'GET') {
    try {
      const { searchParams } = new URL(req.url);
      const limit = Math.min(Math.max(parseInt(searchParams.get('limit') || '500', 10) || 500, 1), 5000);
      const offset = Math.max(parseInt(searchParams.get('offset') || '0', 10) || 0, 0);
      const order = searchParams.get('order') || 'created_at.desc';
      const q = (searchParams.get('q') || '').trim();

      let url =
        `${env.SUPABASE_URL}/rest/v1/hr_name_mappings?select=*` +
        `&active=eq.true` +
        `&order=${encodeURIComponent(order)}` +
        `&limit=${limit}` +
        `&offset=${offset}`;

      if (q) url += `&hr_name_norm=ilike.${encodeURIComponent(`%${q}%`)}`;

      const { rows } = await sbFetch(env, url, false);
      return withCORS(env, req, ok({ mappings: rows }));
    } catch {
      return withCORS(env, req, serverError('Failed to fetch mappings'));
    }
  }

  if (req.method === 'POST') {
    try {
      const data = await parseJSONBody(req);
      if (!data) return withCORS(env, req, badRequest('Invalid JSON'));

      // hr_name_mappings requires: hr_name_norm (text), candidate_id (uuid), optional hospital_or_trust
      const nowUser = user.id;
      const input = Array.isArray(data) ? data : [data];

      const payload = input
        .map((m) => ({
          hr_name_norm: (m?.hr_name_norm || m?.staff_norm || '').trim(),
          hospital_or_trust: m?.hospital_or_trust ?? null,
          candidate_id: m?.candidate_id || null,
          active: m?.active === false ? false : true,
          created_by: nowUser,
          notes: m?.notes ?? null,
        }))
        .filter((m) => m.hr_name_norm && m.candidate_id);

      if (!payload.length) {
        return withCORS(env, req, badRequest('No valid mappings to upsert'));
      }

      // Upsert against global active uniqueness (hr_name_norm, hospital_or_trust) with active=true rows
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/hr_name_mappings?on_conflict=hr_name_norm,hospital_or_trust`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), Prefer: 'resolution=merge-duplicates,return=representation' },
          body: JSON.stringify(payload),
        }
      );

      if (!res.ok) {
        const err = await res.text();
        return withCORS(env, req, badRequest(`Mapping upsert failed: ${err}`));
      }

      const json = await res.json().catch(() => []);

      await writeAudit(
        env,
        user,
        'HR_MAPPINGS_UPSERT',
        { import_id: importId, count: payload.length },
        { entity: 'hr_name_mappings', subject_id: importId, req }
      );

      return withCORS(env, req, ok({ mappings: json }));
    } catch {
      return withCORS(env, req, serverError('Failed to upsert mappings'));
    }
  }

  return withCORS(env, req, badRequest('Unsupported method'));
}

/**
 * @openapi
 * /healthroster/{import_id}/validate:
 *   post:
 *     summary: Validate imported data -> writes hr_results + timesheet_validations
 *     security:
 *       - bearerAuth: []
 */
async function handleHRValidate(env, req, importId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    // Mark the import as "validation requested" inside hr_imports.parse_summary_json
    // (since there is no status/requested_at_utc column on hr_imports)
    const nowIso = new Date().toISOString();

    // Load current parse_summary_json
    const selUrl = `${env.SUPABASE_URL}/rest/v1/hr_imports?id=eq.${encodeURIComponent(importId)}&select=parse_summary_json&limit=1`;
    const { rows: curRows } = await sbFetch(env, selUrl, false);
    const cur = (curRows?.[0]?.parse_summary_json && typeof curRows[0].parse_summary_json === 'object')
      ? curRows[0].parse_summary_json
      : {};

    const patchBody = {
      parse_summary_json: {
        ...cur,
        validation_requested_at_utc: nowIso,
      },
    };

    const patchRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/hr_imports?id=eq.${encodeURIComponent(importId)}`,
      {
        method: "PATCH",
        headers: sbHeaders(env),
        body: JSON.stringify(patchBody),
      }
    );

    if (!patchRes.ok) {
      const err = await patchRes.text().catch(() => "");
      return withCORS(env, req, serverError(`Failed to update import: ${err}`));
    }

    // Optionally trigger downstream validation flow (Power Automate, etc.)
    const map = JSON.parse(env.TSO_WEBHOOK_MAP || "{}");
    const hook = map["hr_validate"];
    if (hook) {
      const resp = await fetch(hook, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ import_id: importId }),
      });
      if (!resp.ok) {
        const err = await resp.text().catch(() => "");
        return withCORS(env, req, serverError(`Validation trigger failed: ${err}`));
      }
    }

    // Audit (best-effort)
    await writeAudit(
      env,
      user,
      "HR_VALIDATE_REQUESTED",
      { import_id: importId },
      { entity: "hr_imports", subject_id: importId, req }
    );

    return withCORS(env, req, ok({ ok: true }));
  } catch {
    return withCORS(env, req, serverError("Validation trigger failed"));
  }
}

// ---------------------- Router wiring hint (additions) ----------------------
// if (req.method === 'GET'  && p === '/emails/outbox')            return withCORS(env, req, await handleOutboxList(env, req));
// if (req.method === 'POST' && p === '/emails/outbox/mark-sent')  return withCORS(env, req, await handleOutboxMarkSent(env, req));
// if (req.method === 'POST' && p === '/emails/outbox/mark-failed')return withCORS(env, req, await handleOutboxMarkFailed(env, req));
// if (req.method === 'POST' && p === '/broadcast/email')          return withCORS(env, req, await handleBroadcastEmail(env, req));
// if (req.method === 'POST' && p === '/healthroster/import')      return withCORS(env, req, await handleHRImport(env, req));
// if (req.method === 'GET'  && p.startsWith('/healthroster/') && p.endsWith('/rows')){
//   const importId = p.split('/')[2];
//   return withCORS(env, req, await handleHRRows(env, req, importId));
// }
// if (p.startsWith('/healthroster/') && p.endsWith('/mapping')){
//   const importId = p.split('/')[2];
//   return withCORS(env, req, await handleHRMapping(env, req, importId));
// }
// if (req.method === 'POST' && p.startsWith('/healthroster/') && p.endsWith('/validate')){
//   const importId = p.split('/')[2];
//   return withCORS(env, req, await handleHRValidate(env, req, importId));
// }

// ---------------------- Notes ----------------------
// - mail_outbox table expected columns: id, type, reference, to, subject, body_text, status, sent_at, failed_at, last_error, provider_message_id, created_at
// - hr_* tables expected columns:
//   hr_imports: id, file_key, original_name, status, created_at, created_by, validated_at, pass_count, fail_count
//   hr_rows: id, import_id, date_ymd (YYYY-MM-DD), start_hhmm, end_hhmm, unit, request_grade, request_id, staff
//   hr_name_mappings: import_id (nullable), staff_norm, candidate_id, locked, confidence, updated_at, updated_by
//   hr_results: id, import_id, row_id, status (OK/FAIL), reason, request_id, timesheet_id, candidate_id, created_at
// - timesheet_validations: timesheet_id, status (VALIDATION_OK/ERROR_* or OVERRIDDEN), reason, hr_reference, updated_at, updated_by
// - timesheets: id, candidate_id, start_utc, end_utc, hospital, ward, authorised, role_code (HCA/RMN)
// - All timestamps stored in UTC; UK local used only for classification/HR comparison.

// ====================== INVOICES ======================
/**
 * @openapi
 * /api/invoices:
 *   get:
 *     summary: List invoices
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: query
 *         name: status
 *         schema: { type: string, enum: [paid, unpaid] }
 *       - in: query
 *         name: include_count
 *         schema: { type: boolean }
 *       - in: query
 *         name: limit
 *         schema: { type: integer, minimum: 1, maximum: 200 }
 *       - in: query
 *         name: offset
 *         schema: { type: integer, minimum: 0 }
 *   post:
 *     summary: Create invoice from eligible timesheets
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required: [client_id, timesheet_ids]
 *             properties:
 *               client_id: { type: string }
 *               issue_date: { type: string, format: date, nullable: true }
 *               timesheet_ids:
 *                 type: array
 *                 items: { type: string }
 * /api/invoices/{invoice_id}:
 *   get:
 *     summary: Get invoice with lines
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 * /api/invoices/{invoice_id}/render:
 *   post:
 *     summary: Render invoice PDF (stores to R2 and records key)
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 * /api/invoices/{invoice_id}/email:
 *   post:
 *     summary: Queue invoice email in mail_outbox
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 * /api/invoices/{invoice_id}/credit-note:
 *   post:
 *     summary: Create a credit note referencing original invoice
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 * /api/invoices/{invoice_id}/mark-paid:
 *   post:
 *     summary: Mark invoice as paid (sets paid_at_utc)
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 * /api/invoices/{invoice_id}/unpay:
 *   post:
 *     summary: Revert invoice to unpaid
 *     tags: [Invoices]
 *     security:
 *       - bearerAuth: []
 */
// ------------------------
// LIST INVOICES (light UI)
// ------------------------
// ------------------------
// LIST INVOICES (light UI)
// ------------------------
 
async function handleInvoiceBatchGenerateCandidates(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const u = new URL(req.url);
  const allowEarly = (() => {
    const v = String(u.searchParams.get('allow_early') || '').trim().toLowerCase();
    return (v === '1' || v === 'true' || v === 'yes' || v === 'y' || v === 'on');
  })();

  const limit = (() => {
    const n = Number(u.searchParams.get('limit'));
    const v = Number.isFinite(n) ? Math.trunc(n) : 5000;
    return Math.max(1, Math.min(v, 20000));
  })();

  try {
    const res = await sbRpc(env, 'invoice_batch_generate_candidates', {
      p_allow_early: allowEarly,
      p_limit: limit
    });

    // RPC returns JSONB; sbRpc may return object or array depending on wrapper
    const groups = Array.isArray(res) ? res : (res?.data ?? res ?? []);

    // ✅ 3.1: pass through new fields returned by RPC (consolidation mode, expected invoice count, etc.)
    return withCORS(env, req, ok({ allow_early: allowEarly, limit, groups }));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}

async function handleInvoiceBatchGenerateConfirm(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body = null;
  try { body = await parseJSONBody(req); } catch {}
  if (!body || typeof body !== 'object') return withCORS(env, req, badRequest('Invalid JSON'));

  const allowEarly = (() => {
    const v = body.allow_early;
    if (v === true) return true;
    if (v === false) return false;
    const s = String(v || '').trim().toLowerCase();
    return (s === '1' || s === 'true' || s === 'yes' || s === 'y' || s === 'on');
  })();

  const rows = body.rows;
  if (!Array.isArray(rows) || rows.length === 0) {
    return withCORS(env, req, badRequest('rows[] is required'));
  }

  const enc = encodeURIComponent;

  const chunk = (arr, n) => {
    const out = [];
    for (let i = 0; i < (arr || []).length; i += n) out.push(arr.slice(i, i + n));
    return out;
  };

  const parseYmd = (s) => {
    const t = String(s || '').trim();
    return (/^\d{4}-\d{2}-\d{2}$/.test(t)) ? t : null;
  };

  const addDaysYmd = (ymd, days) => {
    const d0 = parseYmd(ymd);
    if (!d0) return null;
    const d = new Date(`${d0}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return null;
    d.setUTCDate(d.getUTCDate() + Number(days || 0));
    const yyyy = d.getUTCFullYear();
    const mm = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const getInvoiceWeekStartFromHeader = (header) => {
    if (!header || typeof header !== 'object') return null;
    const meta = (header.meta && typeof header.meta === 'object') ? header.meta : null;
    const v =
      (meta && (meta.invoice_week_start || meta.invoiceWeekStart || meta.week_start || meta.weekStart)) ||
      header.invoice_week_start ||
      header.invoiceWeekStart ||
      null;
    return parseYmd(v);
  };

  // Optional meta to store on the outbox payload
  const meta = {
    source: 'BATCH_UI',
    requested_by_user_id: user?.id || null,
    requested_at_utc: nowIso(),
  };

  try {
    // 1) Enqueue selected BY_WEEK jobs (1 RPC)
    const enq = await sbRpc(env, 'invoice_outbox_enqueue_by_week_selected', {
      p_rows: rows,
      p_actor_user_id: user?.id || null,
      p_allow_early: allowEarly,
      p_meta: meta
    });

    const enqRows = Array.isArray(enq) ? enq : (enq?.data || []);
    const outboxIds = Array.from(new Set(enqRows.map(r => r?.outbox_id).filter(Boolean)));

    if (!outboxIds.length) {
      return withCORS(env, req, ok({
        allow_early: allowEarly,
        enqueued: 0,
        generated: 0,
        invoice_ids: [],
        warnings: [],
        jobs: [],
        generated_rows: [],
        results_invoices: []
      }));
    }

    // 2) Generate invoices for those jobs (single RPC for the batch)
    const gen = await sbRpc(env, 'invoice_generate_from_outbox_batch', {
      p_outbox_ids: outboxIds,
      p_actor_user_id: user?.id || null
    });

    const genRows = Array.isArray(gen) ? gen : (gen?.data || []);
    const genByOutbox = new Map(genRows.map(r => [String(r?.outbox_id || ''), r]));

    // Build job summary grouped by client/week from enqueue result
    const jobs = enqRows.map(j => {
      const oid = j?.outbox_id ? String(j.outbox_id) : '';
      const g = genByOutbox.get(oid) || null;
      const invoiceIds = Array.isArray(g?.invoice_ids) ? g.invoice_ids : [];
      return {
        client_id: j?.client_id || null,
        invoice_week_start: j?.invoice_week_start || null,
        outbox_id: j?.outbox_id || null,
        enqueue_action: j?.action || null,
        ok: !!g?.ok,
        invoice_ids: invoiceIds,
        warnings: g?.warnings ?? null
      };
    });

    // ✅ 3.2: flatten invoice_ids and warnings arrays for UI navigation & debug
    const allInvoices = [];
    const allWarnings = [];
    for (const r of jobs) {
      for (const id of (r.invoice_ids || [])) allInvoices.push(id);
      if (Array.isArray(r.warnings)) {
        for (const w of r.warnings) allWarnings.push(w);
      } else if (r.warnings) {
        allWarnings.push(r.warnings);
      }
    }

    const uniqueInvoices = Array.from(new Set(allInvoices.map(String))).filter(Boolean);

    // ✅ 3.3: Enrich with display-ready invoice fields (one bulk fetch + optional 2 more bulk fetches)
    const invoiceDisplayById = new Map();
    const candidateNamesByInvoiceId = new Map();

    if (uniqueInvoices.length) {
      // 3.3a) Bulk fetch invoices + client name
      for (const idChunk of chunk(uniqueInvoices, 200)) {
        const { rows: invRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/invoices` +
            `?id=in.(${idChunk.map(enc).join(',')})` +
            `&select=id,invoice_no,client_id,do_not_send,header_snapshot_json,client:clients(name)`,
          false
        );

        for (const r of (invRows || [])) {
          if (!r?.id) continue;
          const header = (r.header_snapshot_json && typeof r.header_snapshot_json === 'object') ? r.header_snapshot_json : {};
          const weekStart = getInvoiceWeekStartFromHeader(header);
          const weekEnd = weekStart ? addDaysYmd(weekStart, 6) : null;

          invoiceDisplayById.set(String(r.id), {
            invoice_id: String(r.id),
            invoice_no: r.invoice_no || null,
            client_id: r.client_id || null,
            client_name: r.client?.name || null,
            do_not_send: (r.do_not_send === true),
            invoice_week_start: weekStart,
            week_ending_date: weekEnd,
            header_snapshot_json: header
          });
        }
      }

      // 3.3b) Bulk fetch invoice_lines (invoice_id + timesheet_id) for candidate derivation
      const tsIds = new Set();
      const tsIdsByInvoice = new Map(); // invoice_id -> Set(timesheet_id)
      for (const idChunk of chunk(uniqueInvoices, 200)) {
        const { rows: lineRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/invoice_lines` +
            `?invoice_id=in.(${idChunk.map(enc).join(',')})` +
            `&select=invoice_id,timesheet_id`,
          false
        );

        for (const lr of (lineRows || [])) {
          const iid = lr?.invoice_id ? String(lr.invoice_id) : '';
          const tid = lr?.timesheet_id ? String(lr.timesheet_id) : '';
          if (!iid || !tid) continue;
          tsIds.add(tid);
          let set = tsIdsByInvoice.get(iid);
          if (!set) { set = new Set(); tsIdsByInvoice.set(iid, set); }
          set.add(tid);
        }
      }

      // 3.3c) Bulk fetch candidate_name from v_timesheets_summary_base for those timesheet_ids
      const candByTs = new Map(); // timesheet_id -> candidate_name
      const tsIdsArr = Array.from(tsIds);
      for (const idChunk of chunk(tsIdsArr, 200)) {
        const { rows: sRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary_base` +
            `?timesheet_id=in.(${idChunk.map(enc).join(',')})` +
            `&select=timesheet_id,candidate_name`,
          false
        );
        for (const sr of (sRows || [])) {
          if (!sr?.timesheet_id) continue;
          candByTs.set(String(sr.timesheet_id), sr.candidate_name || null);
        }
      }

      // Per-invoice candidate_name (single vs Multiple)
      for (const [iid, set] of tsIdsByInvoice.entries()) {
        const names = [];
        for (const tid of set) {
          const nm = candByTs.get(String(tid));
          if (nm) names.push(String(nm));
        }
        const uniq = Array.from(new Set(names.map(s => s.trim()).filter(Boolean)));
        const candidate_name = (uniq.length === 0) ? null : (uniq.length === 1 ? uniq[0] : 'Multiple');
        candidateNamesByInvoiceId.set(iid, { candidate_name, candidate_names: uniq });
      }
    }

    // Map invoice_id -> combined job diagnostics
    const diagByInvoiceId = new Map();
    for (const j of (jobs || [])) {
      const invIds = Array.isArray(j?.invoice_ids) ? j.invoice_ids : [];
      for (const invIdRaw of invIds) {
        const iid = invIdRaw != null ? String(invIdRaw) : '';
        if (!iid) continue;
        const prev = diagByInvoiceId.get(iid) || { ok: true, warnings: [], outbox_ids: [], enqueue_actions: [], client_id: null, invoice_week_start: null };
        // ok should be false if ANY job for this invoice reports ok=false
        prev.ok = prev.ok && !!j.ok;
        // warnings
        if (Array.isArray(j.warnings)) prev.warnings.push(...j.warnings);
        else if (j.warnings) prev.warnings.push(j.warnings);
        // ids/actions
        if (j.outbox_id) prev.outbox_ids.push(j.outbox_id);
        if (j.enqueue_action) prev.enqueue_actions.push(j.enqueue_action);
        if (!prev.client_id && j.client_id) prev.client_id = j.client_id;
        if (!prev.invoice_week_start && j.invoice_week_start) prev.invoice_week_start = j.invoice_week_start;
        diagByInvoiceId.set(iid, prev);
      }
    }
    for (const [iid, d] of diagByInvoiceId.entries()) {
      d.outbox_ids = Array.from(new Set((d.outbox_ids || []).map(String).filter(Boolean)));
      d.enqueue_actions = Array.from(new Set((d.enqueue_actions || []).map(String).filter(Boolean)));
      // keep warnings as-is (can include duplicates; UI may want full list)
    }

    const results_invoices = uniqueInvoices.map((iid) => {
      const disp = invoiceDisplayById.get(String(iid)) || null;
      const cand = candidateNamesByInvoiceId.get(String(iid)) || { candidate_name: null, candidate_names: [] };
      const diag = diagByInvoiceId.get(String(iid)) || { ok: null, warnings: [], outbox_ids: [], enqueue_actions: [], client_id: null, invoice_week_start: null };

      return {
        invoice_id: String(iid),
        invoice_no: disp?.invoice_no || null,
        client_id: disp?.client_id || diag.client_id || null,
        client_name: disp?.client_name || null,
        do_not_send: (disp?.do_not_send === true),
        invoice_week_start: disp?.invoice_week_start || (diag.invoice_week_start ? String(diag.invoice_week_start).slice(0, 10) : null),
        week_ending_date: disp?.week_ending_date || null,

        candidate_name: cand.candidate_name,
        candidate_names: cand.candidate_names,

        ok: (diag.ok === true),
        warnings: diag.warnings || [],
        outbox_ids: diag.outbox_ids || [],
        enqueue_actions: diag.enqueue_actions || []
      };
    });

    return withCORS(env, req, ok({
      allow_early: allowEarly,
      enqueued: outboxIds.length,
      generated: uniqueInvoices.length,
      invoice_ids: uniqueInvoices,
      warnings: allWarnings,
      jobs,
      generated_rows: genRows,

      // ✅ Display-ready rows for the frontend batch results modal
      results_invoices
    }));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}

async function _renderInvoiceBundleAndStore(env, req, invoiceId, userForAudit, opts) {
  const enc = encodeURIComponent;

  const options = (opts && typeof opts === 'object') ? opts : {};
  const forceRegen = !!(options.force_regen === true || options.forceRegen === true);

  function toMarginsObj(m) {
    const dflt = { top: 32, right: 12, bottom: 20, left: 12 };
    if (Array.isArray(m) && m.length === 4) {
      return {
        top: Number(m[0] ?? dflt.top),
        right: Number(m[1] ?? dflt.right),
        bottom: Number(m[2] ?? dflt.bottom),
        left: Number(m[3] ?? dflt.left),
      };
    }
    if (m && typeof m === "object") {
      return {
        top: Number(m.top ?? dflt.top),
        right: Number(m.right ?? dflt.right),
        bottom: Number(m.bottom ?? dflt.bottom),
        left: Number(m.left ?? dflt.left),
      };
    }
    return dflt;
  }

  // Date parsing used for HR/NHSP sorting.
  // - Supports YYYY-MM-DD, ISO strings, and DD/MM/YYYY.
  // - Invalid/missing => Infinity (sorted last).
  function _parseSortDateToMs(v) {
    if (v == null) return Number.POSITIVE_INFINITY;
    const s0 = String(v).trim();
    if (!s0) return Number.POSITIVE_INFINITY;

    // DD/MM/YYYY
    const m = s0.match(/^(\d{2})\/(\d{2})\/(\d{4})$/);
    if (m) {
      const dd = Number(m[1]), mm = Number(m[2]), yyyy = Number(m[3]);
      if (dd >= 1 && dd <= 31 && mm >= 1 && mm <= 12 && yyyy >= 1900 && yyyy <= 2100) {
        const ms = Date.parse(`${yyyy}-${String(mm).padStart(2, '0')}-${String(dd).padStart(2, '0')}T00:00:00Z`);
        return Number.isFinite(ms) ? ms : Number.POSITIVE_INFINITY;
      }
    }

    // YYYY-MM-DD (or ISO)
    const ms = Date.parse(s0);
    return Number.isFinite(ms) ? ms : Number.POSITIVE_INFINITY;
  }

  function _safeGetDateFromAnyRow(raw) {
    if (!raw || typeof raw !== 'object') return '';
    // common candidates
    return (
      raw.work_date ??
      raw.WorkDate ??
      raw.workDate ??
      raw.date ??
      raw.Date ??
      raw.shift_date ??
      raw.shiftDate ??
      raw['Work Date'] ??
      raw['WORK DATE'] ??
      ''
    );
  }
function buildHrReportHTML(inv, header, hrRows) {
  const safe = (v) => (v == null ? '' : String(v));
  const h = header || {};
  const clientName = safe(h.client_name || h.client || '');
  const invNo = safe(inv.invoice_no || '');
  const issued = safe(inv.issued_at_utc || '');

  // ✅ Sort rows oldest→newest by work_date/date; invalid dates last; stable by original idx.
  const sortedRows = (Array.isArray(hrRows) ? hrRows : [])
    .map((r, idx) => ({ r, idx }))
    .sort((a, b) => {
      const ra = a.r?.raw_row || a.r || {};
      const rb = b.r?.raw_row || b.r || {};
      const da = _parseSortDateToMs(a.r?.date || ra.work_date || ra.date || _safeGetDateFromAnyRow(ra));
      const db = _parseSortDateToMs(b.r?.date || rb.work_date || rb.date || _safeGetDateFromAnyRow(rb));
      if (da !== db) return da - db;
      return a.idx - b.idx;
    })
    .map(x => x.r);

  const rowsHtml = sortedRows.map((r, idx) => {
    const raw = r.raw_row || {};
    const date      = safe(r.date || raw.work_date || raw.date || '');
    const staff     = safe(raw.staff_name || raw.worker || '');
    const ward      = safe(raw.ward || '');
    const start     = safe(raw.start_utc || '');
    const end       = safe(raw.end_utc || '');
    const breakMins = safe(raw.break_mins != null ? raw.break_mins : '');
    const ref       = safe(r.reference || raw.reference || raw.ref_num || '');
    return `
        <tr>
          <td>${idx + 1}</td>
          <td>${date}</td>
          <td>${staff}</td>
          <td>${ward}</td>
          <td>${start}</td>
          <td>${end}</td>
          <td>${breakMins}</td>
          <td>${ref}</td>
        </tr>
      `;
  }).join('');

  const hasRows = sortedRows.length > 0;

  return `
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>HealthRoster Report</title>
  <style>
    body { font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif; font-size: 11px; margin: 24px; }
    h1 { font-size: 18px; margin-bottom: 4px; }
    h2 { font-size: 13px; margin-top: 4px; margin-bottom: 12px; }
    table { width: 100%; border-collapse: collapse; font-size: 9px; }
    th, td { border: 1px solid #ccc; padding: 3px 4px; text-align: left; }
    th { background: #f2f2f2; }
    .meta { margin-bottom: 12px; font-size: 10px; }
    .meta span { display: inline-block; margin-right: 16px; }
    .no-data { margin-top: 12px; font-style: italic; }
  </style>
</head>
<body>
  <h1>HealthRoster report</h1>
  <h2>Invoice ${invNo}</h2>
  <div class="meta">
    <span><strong>Client:</strong> ${clientName}</span>
    <span><strong>Issued:</strong> ${issued}</span>
  </div>
  ${hasRows ? `
    <table>
      <thead>
        <tr>
          <th>#</th>
          <th>Date</th>
          <th>Staff</th>
          <th>Ward</th>
          <th>Start</th>
          <th>End</th>
          <th>Break (mins)</th>
          <th>Reference</th>
        </tr>
      </thead>
      <tbody>
        ${rowsHtml}
      </tbody>
    </table>
  ` : `
    <div class="no-data">No HealthRoster rows captured for this invoice.</div>
  `}
</body>
</html>
    `;
}

function buildNhspReportHTML(inv, header, nhspData) {
  const safe = (v) => (v == null ? '' : String(v));
  const h = header || {};
  const clientName = safe(h.client_name || h.client || '');
  const invNo = safe(inv.invoice_no || '');
  const issued = safe(inv.issued_at_utc || '');

  // Normalize payload into one or more tables.
  // If we have header_columns, we MUST preserve that exact column order.
  const tables = [];

  const unwrapRow = (r) => {
    if (!r) return null;
    if (r.raw_row && typeof r.raw_row === 'object') return r.raw_row;
    if (r.raw && typeof r.raw === 'object') return r.raw;
    return r;
  };

  if (Array.isArray(nhspData)) {
    const rows = nhspData.map(unwrapRow).filter(r => r && typeof r === 'object');
    if (rows.length) tables.push({ header_columns: [], rows });
  } else if (nhspData && typeof nhspData === 'object') {
    const tList = Array.isArray(nhspData.tables) ? nhspData.tables : [nhspData];
    for (const t of tList) {
      const headerCols = Array.isArray(t?.header_columns) ? t.header_columns.map(safe) : [];
      const rowsRaw = Array.isArray(t?.rows_json)
        ? t.rows_json
        : (Array.isArray(t?.rows) ? t.rows : []);
      const rows = rowsRaw.map(unwrapRow).filter(r => r && typeof r === 'object');
      if (rows.length) tables.push({ header_columns: headerCols, rows });
    }
  }

  // Best-effort date extraction for object rows
  const safeGetDateFromAnyRow = (row) => {
    if (!row || typeof row !== 'object') return '';
    const candidates = [
      row.work_date, row.workDate,
      row.date, row.Date,
      row.shift_date, row.shiftDate,
      row.start_date, row.startDate
    ];
    for (const c of candidates) {
      const s = (c == null ? '' : String(c)).trim();
      if (s) return s;
    }
    return '';
  };

  // Parse any date-ish string into ms for sorting.
  // Invalid or empty => Infinity so these rows are pushed to the end.
  const parseSortDateToMs = (v) => {
    const s = (v == null ? '' : String(v)).trim();
    if (!s) return Number.POSITIVE_INFINITY;

    // YYYY-MM-DD
    const mYmd = s.match(/^(\d{4})-(\d{2})-(\d{2})$/);
    if (mYmd) {
      const y = Number(mYmd[1]), mo = Number(mYmd[2]) - 1, d = Number(mYmd[3]);
      const t = Date.UTC(y, mo, d);
      return Number.isFinite(t) ? t : Number.POSITIVE_INFINITY;
    }

    // DD/MM/YYYY or DD/MM/YY
    const mDmy = s.match(/^(\d{1,2})\/(\d{1,2})\/(\d{2}|\d{4})$/);
    if (mDmy) {
      const dd = Number(mDmy[1]), mo = Number(mDmy[2]) - 1;
      let y = Number(mDmy[3]);
      if (mDmy[3].length === 2) y = (y >= 70 ? 1900 + y : 2000 + y);
      const t = Date.UTC(y, mo, dd);
      return Number.isFinite(t) ? t : Number.POSITIVE_INFINITY;
    }

    // Fallback: Date parse
    const dt = new Date(s);
    const t = dt.getTime();
    return Number.isFinite(t) ? t : Number.POSITIVE_INFINITY;
  };

  // If table rows are raw_columns, attempt to locate a date-like header so we can sort.
  const findDateColIndex = (cols) => {
    if (!Array.isArray(cols) || !cols.length) return -1;
    const lc = cols.map(c => String(c || '').toLowerCase());
    // prefer "work date" then "date"
    let idx = lc.findIndex(s => s.includes('work') && s.includes('date'));
    if (idx >= 0) return idx;
    idx = lc.findIndex(s => s === 'date' || s.includes(' date'));
    if (idx >= 0) return idx;
    idx = lc.findIndex(s => s.includes('date'));
    return idx;
  };

  const sortRowsByDate = (headerCols, rows) => {
    const cols = Array.isArray(headerCols) ? headerCols : [];
    const dateIdx = findDateColIndex(cols);

    return rows.map((r, idx) => ({ r, idx })).sort((a, b) => {
      const ra = a.r;
      const rb = b.r;

      let da = '';
      let db = '';

      if (Array.isArray(ra?.raw_columns) && dateIdx >= 0) da = ra.raw_columns[dateIdx] ?? '';
      else da = safeGetDateFromAnyRow(ra);

      if (Array.isArray(rb?.raw_columns) && dateIdx >= 0) db = rb.raw_columns[dateIdx] ?? '';
      else db = safeGetDateFromAnyRow(rb);

      const ta = parseSortDateToMs(da);
      const tb = parseSortDateToMs(db);
      if (ta !== tb) return ta - tb;
      return a.idx - b.idx; // stable
    }).map(x => x.r);
  };

  for (const t of tables) {
    t.rows = sortRowsByDate(t.header_columns, t.rows);
  }

  const hasTables = tables.length > 0;

  const renderTable = (t, idx) => {
    const headerCols = Array.isArray(t.header_columns) ? t.header_columns : [];

    // Prefer rendering using raw_columns (which maps 1:1 to header_columns).
    const firstWithRawCols = t.rows.find(r => Array.isArray(r.raw_columns));
    const rawLen = firstWithRawCols ? firstWithRawCols.raw_columns.length : 0;

    // Column labels:
    //  - If header_columns exist, use them exactly as imported.
    //  - Else, if raw_columns exist, use generic Column 1..N (still preserves column ORDER).
    //  - Else, fall back to object keys (best-effort).
    const columns = (headerCols && headerCols.length)
      ? headerCols
      : (rawLen > 0
          ? Array.from({ length: rawLen }, (_, i) => `Column ${i + 1}`)
          : Object.keys(t.rows[0] || {}));

    const headerHtml = `<tr>${columns.map(col => `<th>${escapeHtml(safe(col))}</th>`).join('')}</tr>`;

    const rowsHtml = t.rows.map(r => {
      let cells = [];

      if (Array.isArray(r.raw_columns)) {
        const arr = r.raw_columns;
        for (let i = 0; i < columns.length; i++) {
          const v = (i < arr.length) ? arr[i] : '';
          cells.push(`<td>${escapeHtml(safe(v))}</td>`);
        }
      } else {
        for (const col of columns) {
          cells.push(`<td>${escapeHtml(safe(r?.[col]))}</td>`);
        }
      }

      return `<tr>${cells.join('')}</tr>`;
    }).join('');

    const sep = (idx > 0) ? `<div class="page-break"></div>` : '';

    return `${sep}
        <table class="nhsp">
          <thead>${headerHtml}</thead>
          <tbody>${rowsHtml}</tbody>
        </table>
      `;
  };

  return `
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>NHSP Attachment</title>
  <style>
    @page { size: A4 landscape; margin: 0; }
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      font-size: 10px;
      margin: 0;
    }
    h1 { font-size: 18px; margin-bottom: 4px; }
    h2 { font-size: 13px; margin-top: 4px; margin-bottom: 12px; }
    .meta { margin-bottom: 12px; font-size: 10px; }
    .meta span { display: inline-block; margin-right: 16px; }

    .page-break { break-before: page; page-break-before: always; }

    table.nhsp {
      width: 100%;
      border-collapse: collapse;
      font-size: 8.5px;
      table-layout: fixed;
    }

    table.nhsp thead { display: table-header-group; }

    table.nhsp th,
    table.nhsp td {
      border: 1px solid #ccc;
      padding: 2px 3px;
      text-align: left;
      vertical-align: top;
      word-break: break-word;
      overflow-wrap: anywhere;
    }

    table.nhsp th { background: #f2f2f2; }

    .no-data { margin-top: 12px; font-style: italic; }
  </style>
</head>
<body>
  <h1>NHSP attachment</h1>
  <h2>Invoice ${escapeHtml(invNo)}</h2>
  <div class="meta">
    <span><strong>Client:</strong> ${escapeHtml(clientName)}</span>
    <span><strong>Issued:</strong> ${escapeHtml(issued)}</span>
  </div>

  ${hasTables ? tables.map(renderTable).join('') : `
    <div class="no-data">No NHSP rows captured for this invoice.</div>
  `}
</body>
</html>
    `;
}

// ==========================================================
// UPDATED: buildHTML (render FREEFORM reference rows as single-column list/table)
// ==========================================================
function buildHTML(payload) {
  const {
    header = {},
    meta: payloadMeta = {},
    invoice_no = "",
    issued_at_utc,
    due_at_utc,
    totals = { subtotal_ex_vat: 0, vat_amount: 0, total_inc_vat: 0 },
    items = [],
    reference_rows = []
  } = payload || {};

  // Snapshot fields (populated by your issuing worker)
  const clientName = pick(header, "client_name", "");
  const clientAddress = (pick(header, "client_invoice_address", "") || "")
    .split("\n")
    .map((l) => l.trim())
    .filter(Boolean);

  const vatChargeable = !!pick(header, "vat_chargeable", true);
  const appliedVatPct = Number(pick(header, "applied_vat_rate_pct", 0)); // NOTE: never displayed
  const termsDays = pick(header, "payment_terms_days", null);
  const bank = pick(header, "bank", {}) || {};

   // Agency branding (passed via header snapshot)
  const agencyName =
    pick(header, "agency_name", "") ||
    pick(header, "agency_display_name", "") ||
    pick(header, "company_name", "") ||
    "";

  const agencyLogoUrl =
    pick(header, "agency_logo_url", "") ||
    pick(header, "logo_url", "") ||
    "";

  // Registered details (passed via header snapshot)
  const registeredAddressLines = (pick(header, "registered_address", "") || "")
    .split("\n")
    .map((l) => l.trim())
    .filter(Boolean);

  const companyRegNumber =
    pick(header, "company_reg_number", "") ||
    pick(header, "company_registration_number", "") ||
    "";

  // VAT reg: use settings value if present; otherwise fallback to hard-wired number
  const DEFAULT_VAT_REG = "363 6805 80";
  const vatReg = pick(header, "vat_registration_number", "") || DEFAULT_VAT_REG;

  // Stationery (letterhead) — expects PNG/JPG URL (signed) + safe-area margins (mm)
  const stationeryUrl = pick(header, "stationery_url", ""); // PNG/JPG URL or data: URI

  const defaultMargins = stationeryUrl
    ? { top: 32, right: 12, bottom: 20, left: 12 } // safe defaults with artwork
    : { top: 18, right: 12, bottom: 34, left: 12 }; // plain layout defaults
  const mgIn = pick(header, "stationery_margins_mm", {}) || {};
  const mg = {
    top: Number(pick(mgIn, "top", defaultMargins.top)),
    right: Number(pick(mgIn, "right", defaultMargins.right)),
    bottom: Number(pick(mgIn, "bottom", defaultMargins.bottom)),
    left: Number(pick(mgIn, "left", defaultMargins.left))
  };

  // Hide transactional footer if your artwork already includes it
  const hideBankFooter = !!pick(header, "hide_bank_footer", false);

  // Header-level PO only if a single unique PO exists across header + all items
  const headerPo = pick(header, "po_number", null);
  const itemPos = items.map((i) => i?.meta?.po_number).filter(Boolean);
  const uniquePos = Array.from(new Set([...(headerPo ? [headerPo] : []), ...itemPos]));
  const poNo = uniquePos.length === 1 ? uniquePos[0] : "";

  const showVatCols = vatChargeable && (appliedVatPct > 0 || Number(totals.vat_amount) > 0);

  // ─────────────────────────────────────────────────────────────
  // Helpers for breakdown rendering (keeps styling consistent)
  // ─────────────────────────────────────────────────────────────
  const num = (v) => {
    const n = Number(v);
    return Number.isFinite(n) ? n : 0;
  };
  const round2 = (v) => Math.round(num(v) * 100) / 100;
  const fmtQty = (v, decimals = 2) => {
    const n = num(v);
    if (Math.abs(n - Math.round(n)) < 1e-9) return String(Math.round(n));
    return n.toFixed(decimals);
  };
  const eqRate = (a, b) => {
    // Compare to 2dp to avoid tiny float drift; rates are normally stored as numeric
    return round2(a) === round2(b);
  };

  const getLineTypeNorm = (it) => {
    const m = it?.meta || {};
    const s = String(m.line_type_norm || m.line_type || "").toUpperCase();
    return s;
  };

  const getTimesheetId = (it) => {
    return (it && it.timesheet_id != null) ? String(it.timesheet_id)
      : (it?.meta?.timesheet_id != null ? String(it.meta.timesheet_id) : null);
  };

  const isAdjustmentItem = (it) => {
    const t = getLineTypeNorm(it);
    const tsId = getTimesheetId(it);
    return (!tsId || t === "ADJUSTMENT");
  };

  // Labels (use per-line labels if provided; fallback to defaults)
  const DEFAULT_LABELS = { day: "Day", night: "Night", sat: "Sat", sun: "Sun", bh: "BH" };
  const bucketLabelOf = (labels, key) => String((labels && labels[key]) || DEFAULT_LABELS[key] || key);

  // ─────────────────────────────────────────────────────────────
  // Group items by timesheet_id, keep adjustments separate
  // ─────────────────────────────────────────────────────────────
  const groupMap = new Map(); // tsId -> { items: [], metaHint: {} }
  const adjustments = [];

  for (const it of (items || [])) {
    if (isAdjustmentItem(it)) {
      adjustments.push(it);
      continue;
    }
    const tsId = getTimesheetId(it);
    if (!tsId) {
      adjustments.push(it);
      continue;
    }
    if (!groupMap.has(tsId)) groupMap.set(tsId, { tsId, items: [] });
    groupMap.get(tsId).items.push(it);
  }

  // Sort groups deterministically by week ending then candidate
  const groups = Array.from(groupMap.values()).sort((a, b) => {
    const aMeta = (a.items.find(x => getLineTypeNorm(x) === "HOURS")?.meta) || a.items[0]?.meta || {};
    const bMeta = (b.items.find(x => getLineTypeNorm(x) === "HOURS")?.meta) || b.items[0]?.meta || {};
    const awe = String(aMeta.week_ending_date || aMeta.week_ending || aMeta.weekEnding || "");
    const bwe = String(bMeta.week_ending_date || bMeta.week_ending || bMeta.weekEnding || "");
    if (awe !== bwe) return awe < bwe ? 1 : -1; // desc
    const ac = String(aMeta.candidate_display || aMeta.candidate || "");
    const bc = String(bMeta.candidate_display || bMeta.candidate || "");
    if (ac !== bc) return ac.localeCompare(bc);
    return String(a.tsId).localeCompare(String(b.tsId));
  });

  // ─────────────────────────────────────────────────────────────
  // Build breakdown rows for a single timesheet group
  // Unit Description | Quantity | Unit Charge (ex VAT) | Charge (ex VAT)
  // ─────────────────────────────────────────────────────────────
  const groupBreakdownTableHtml = (grp) => {
    const its = grp.items || [];
    const hoursItem = its.find((x) => getLineTypeNorm(x) === "HOURS") || null;

    // meta for display/header
    const metaBase = (hoursItem?.meta || its[0]?.meta || {}) || {};
    const labels = (metaBase.bucket_labels && typeof metaBase.bucket_labels === "object") ? metaBase.bucket_labels : DEFAULT_LABELS;

    // Pull bucket hours/rates from meta (these are merged by _renderInvoiceBundleAndStore)
    const hDay = num(metaBase.hours_day);
    const hNgt = num(metaBase.hours_night);
    const hSat = num(metaBase.hours_sat);
    const hSun = num(metaBase.hours_sun);
    const hBh  = num(metaBase.hours_bh);

    const rDay = num(metaBase.charge_day);
    const rNgt = num(metaBase.charge_night);
    const rSat = num(metaBase.charge_sat);
    const rSun = num(metaBase.charge_sun);
    const rBh  = num(metaBase.charge_bh);

    const groupFlag = !!pick(payloadMeta, "group_nightsat_sunbh", false);
    const canMerge = groupFlag && eqRate(rNgt, rSat) && eqRate(rSun, rBh);

    const rows = [];

    const pushRow = (desc, qty, unit, charge) => {
      const q = num(qty);
      const u = num(unit);
      const c = round2(charge);
      // Requirement: hide zero-subtotal rows, but show positive and negative rows.
      if (c === 0) return;
      rows.push({ desc: String(desc || ""), qty: q, unit: u, charge: c });
    };

    // HOURS breakdown
    if (hoursItem) {
      if (canMerge) {
        const nightSatQty = hNgt + hSat;
        const sunBhQty = hSun + hBh;
        pushRow(bucketLabelOf(labels, "day"), hDay, rDay, hDay * rDay);
        pushRow(`${bucketLabelOf(labels, "night")}/${bucketLabelOf(labels, "sat")}`, nightSatQty, rNgt, nightSatQty * rNgt);
        pushRow(`${bucketLabelOf(labels, "sun")}/${bucketLabelOf(labels, "bh")}`, sunBhQty, rSun, sunBhQty * rSun);
      } else {
        pushRow(bucketLabelOf(labels, "day"), hDay, rDay, hDay * rDay);
        pushRow(bucketLabelOf(labels, "night"), hNgt, rNgt, hNgt * rNgt);
        pushRow(bucketLabelOf(labels, "sat"), hSat, rSat, hSat * rSat);
        pushRow(bucketLabelOf(labels, "sun"), hSun, rSun, hSun * rSun);
        pushRow(bucketLabelOf(labels, "bh"), hBh, rBh, hBh * rBh);
      }
    }

    // Additional rates / mileage / expenses (non-hours)
    for (const it of its) {
      const t = getLineTypeNorm(it);
      if (t === "HOURS") continue;
      if (t === "ADJUSTMENT") continue;

      const m = it.meta || {};
      const totalEx = num(it.total_ex_vat);

      // Default label (keep the human-friendly SQL-generated description where available)
      const unitLabel = String(m.unit_label || it.description || t || "").trim() || t;

      let qty = null;
      let unitCharge = null;

      // Mileage (miles + rate)
      if (t === "MILEAGE") {
        if (m?.mileage && m.mileage.mileage_units != null) qty = num(m.mileage.mileage_units);
        else if (m.mileage_units != null) qty = num(m.mileage_units);
        else if (m.qty != null) qty = num(m.qty);

        if (m?.mileage && m.mileage.charge_rate != null) unitCharge = num(m.mileage.charge_rate);
        else if (m.unit_charge_ex_vat != null) unitCharge = num(m.unit_charge_ex_vat);
      }

      // Additional units/rates
      else if (t.startsWith("ADDITIONAL_RATE")) {
        if (m?.units && m.units.unit_count != null) qty = num(m.units.unit_count);
        else if (m.unit_count != null) qty = num(m.unit_count);
        else if (m.qty != null) qty = num(m.qty);

        if (m?.units && m.units.charge_rate != null) unitCharge = num(m.units.charge_rate);
        else if (m.unit_charge_ex_vat != null) unitCharge = num(m.unit_charge_ex_vat);
      }

      // Expenses (travel / accommodation / other etc.)
      else if (t.startsWith("EXPENSE")) {
        qty = (m.qty != null) ? num(m.qty) : 1;
        unitCharge = (m.unit_charge_ex_vat != null)
          ? num(m.unit_charge_ex_vat)
          : (qty !== 0 ? totalEx / qty : totalEx);
      }

      // Generic fallback
      else {
        qty = (m.qty != null) ? num(m.qty) : 1;
        unitCharge = (m.unit_charge_ex_vat != null)
          ? num(m.unit_charge_ex_vat)
          : (qty !== 0 ? totalEx / qty : totalEx);
      }

      if (qty == null) qty = 1;

      // Requirement: skip zero-qty rows (but DO show negative qty/charges)
      if (round2(qty) === 0) continue;

      if (unitCharge == null) {
        unitCharge = (qty !== 0) ? (totalEx / qty) : totalEx;
      }

      pushRow(unitLabel, qty, unitCharge, totalEx);
    }

    if (!rows.length) return "";

    const head = `
      <table class="breakdown">
        <thead>
          <tr>
            <th class="b-desc">Unit Description</th>
            <th class="b-qty">Quantity</th>
            <th class="b-unit">Unit Charge (ex VAT)</th>
            <th class="b-charge">Charge (ex VAT)</th>
          </tr>
        </thead>
        <tbody>
    `;

    const body = rows.map(r => `
      <tr>
        <td class="b-desc">${escapeHtml(r.desc)}</td>
        <td class="b-qty mono">${fmtQty(r.qty, 2)}</td>
        <td class="b-unit mono">${fmtGBP(r.unit)}</td>
        <td class="b-charge mono">${fmtGBP(r.charge)}</td>
      </tr>
    `).join("");

    const tail = `
        </tbody>
      </table>
    `;

    return head + body + tail;
  };

  // ─────────────────────────────────────────────────────────────
  // Booking reference rows (manifest.reference_rows)
  // Rendered under each timesheet group (never show timesheet_id)
  // - Structured rows (SEGMENT/DAY/TIMESHEET) => Day/Start/End/Reference table
  // - Freeform rows (no day/start/end)        => single-column Reference table
  // ─────────────────────────────────────────────────────────────
  const refsByTsId = new Map();
  for (const r of (reference_rows || [])) {
    const tsId = (r && r.timesheet_id != null) ? String(r.timesheet_id) : null;
    if (!tsId) continue;
    if (!refsByTsId.has(tsId)) refsByTsId.set(tsId, []);
    refsByTsId.get(tsId).push(r);
  }

  const refsTableHtmlForTs = (tsId) => {
    const refs = refsByTsId.get(String(tsId || "")) || [];
    if (!refs.length) return "";

    const isStructured = (r) => {
      const d = (r?.day_ymd != null) ? String(r.day_ymd).trim() : '';
      const st = (r?.start_utc != null) ? String(r.start_utc).trim() : '';
      const en = (r?.end_utc != null) ? String(r.end_utc).trim() : '';
      return !!(d || st || en);
    };

    const structured = [];
    const freeform = [];
    refs.forEach((r) => {
      (isStructured(r) ? structured : freeform).push(r);
    });

    const hasRefTxt = (r) => (r?.current_reference != null) && String(r.current_reference).trim();
    const refText = (r) => hasRefTxt(r) ? String(r.current_reference).trim() : (r?.is_required ? "MISSING" : "—");
    const refCls = (r) => (!hasRefTxt(r) && r?.is_required) ? "ref-missing" : "";

    // Stable render (do not re-sort; reference_rows are already filtered and ordered server-side)
    const structuredTable = structured.length ? (() => {
      const rowsHtml = structured.map((r) => {
        const day = r?.day_ymd ? fmtDateGB(r.day_ymd) : "";
        const st = r?.start_utc ? fmtUKTime(r.start_utc) : "";
        const en = r?.end_utc ? fmtUKTime(r.end_utc) : "";
        return `
        <tr>
          <td class="r-day mono">${escapeHtml(day)}</td>
          <td class="r-time mono">${escapeHtml(st)}</td>
          <td class="r-time mono">${escapeHtml(en)}</td>
          <td class="r-ref mono ${refCls(r)}">${escapeHtml(refText(r))}</td>
        </tr>
      `;
      }).join("");

      return `
        <table class="refs">
          <thead>
            <tr>
              <th class="r-day">Day</th>
              <th class="r-time">Start</th>
              <th class="r-time">End</th>
              <th class="r-ref">Reference</th>
            </tr>
          </thead>
          <tbody>
            ${rowsHtml}
          </tbody>
        </table>
      `;
    })() : "";

    const freeformTable = freeform.length ? (() => {
      const rowsHtml = freeform.map((r) => `
        <tr>
          <td class="r-ref mono ${refCls(r)}">${escapeHtml(refText(r))}</td>
        </tr>
      `).join("");

      return `
        <table class="refs refs-freeform">
          <thead>
            <tr>
              <th class="r-ref">Reference</th>
            </tr>
          </thead>
          <tbody>
            ${rowsHtml}
          </tbody>
        </table>
      `;
    })() : "";

    return `
      <div class="refs-wrap">
        <div class="refs-title">Booking references</div>
        ${structuredTable || ""}
        ${freeformTable ? `<div style="height:6px;"></div>${freeformTable}` : ""}
      </div>
    `;
  };

  // ─────────────────────────────────────────────────────────────
  // Build main table rows:
  // - One row per timesheet group (with nested breakdown table)
  // - Optional adjustments section at the end
  // ─────────────────────────────────────────────────────────────
  const groupRowsHtml = groups.map((grp, idx) => {
    const its = grp.items || [];
    const metaFirst = (its.find(x => getLineTypeNorm(x) === "HOURS")?.meta) || its[0]?.meta || {};
    const we = metaFirst.week_ending_date || metaFirst.week_ending || metaFirst.weekEnding || null;

    const sublineParts = [
      metaFirst.candidate_display || metaFirst.candidate || null,
      metaFirst.role || metaFirst.job_title || null,
      metaFirst.hospital || metaFirst.hospital_norm || null,
      metaFirst.ward || metaFirst.ward_norm || null,
      we ? `W/E ${fmtDateGB(we)}` : null,
      metaFirst.po_number ? `PO ${metaFirst.po_number}` : null
    ].filter(Boolean).join(" • ");

    const grpEx = round2(its.reduce((a, it) => a + num(it.total_ex_vat), 0));
    const grpVat = round2(its.reduce((a, it) => a + num(it.vat_amount), 0));
    const grpInc = round2(its.reduce((a, it) => a + num(it.total_inc_vat), 0));

    const title = escapeHtml(metaFirst.candidate_display || metaFirst.candidate || `Timesheet ${idx + 1}`);
    const breakdown = groupBreakdownTableHtml(grp);
    const refsHtml = refsTableHtmlForTs(grp.tsId);

    return `
      <tr class="line">
        <td class="desc">
          <div class="desc-title">${title}</div>
          <div class="desc-meta">
            ${escapeHtml(sublineParts)}
            ${breakdown ? `<div class="breakdown-wrap">${breakdown}</div>` : ""}
            ${refsHtml || ""}
          </div>
        </td>
        <td class="money exvat">${fmtGBP(grpEx)}</td>
        ${showVatCols ? `<td class="money vat">${fmtGBP(grpVat)}</td>` : ""}
        <td class="money totalinc">${fmtGBP(grpInc)}</td>
      </tr>
    `;
  }).join("");

  const adjustmentsRowsHtml = (adjustments && adjustments.length)
    ? (() => {
        const head = `
          <tr class="section-row">
            <td class="desc" colspan="${showVatCols ? 4 : 3}">
              <div class="section-title">Adjustments</div>
            </td>
          </tr>
        `;

        const rows = adjustments.map((it, idx) => {
          const meta = it.meta || {};
          const desc = escapeHtml(it.description || meta.unit_label || `Adjustment ${idx + 1}`);
          const sub = [
            meta.po_number ? `PO ${meta.po_number}` : null
          ].filter(Boolean).join(" • ");

          return `
            <tr class="line">
              <td class="desc">
                <div class="desc-title">${desc}</div>
                ${sub ? `<div class="desc-meta">${escapeHtml(sub)}</div>` : ""}
              </td>
              <td class="money exvat">${fmtGBP(it.total_ex_vat)}</td>
              ${showVatCols ? `<td class="money vat">${fmtGBP(it.vat_amount)}</td>` : ""}
              <td class="money totalinc">${fmtGBP(it.total_inc_vat)}</td>
            </tr>
          `;
        }).join("");

        return head + rows;
      })()
    : "";

  const lineRows = (groupRowsHtml || adjustmentsRowsHtml)
    ? (groupRowsHtml + adjustmentsRowsHtml)
    : "";

  // Build full HTML (stationery background + reserved margins + fixed footer)
  return `<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Invoice ${escapeHtml(invoice_no || "")}</title>
  <style>
    /* Reserve safe areas so content never overlaps header/footer artwork */
    @page { size: A4; margin: ${mg.top}mm ${mg.right}mm ${mg.bottom}mm ${mg.left}mm; }

    html, body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif;
      color: #111;
      font-size: 11px; /* fixed size per spec */
      line-height: 1.35;
      -webkit-print-color-adjust: exact;
    }

    /* Stationery (full page) */
    .stationery {
      position: fixed;
      inset: 0;
      z-index: 0;
      background-repeat: no-repeat;
      background-position: center;
      background-size: cover; /* A4 PNG should fill edge-to-edge */
      opacity: 1;
      pointer-events: none;
    }

    .wrap { position: relative; z-index: 1; width: 100%; }

    .header {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 16px;
      margin-bottom: 16px;
    }
      .title { font-size: 20px; font-weight: 700; letter-spacing: .5px; }
    .muted { color: #666; }
    .mono { font-variant-numeric: tabular-nums; }

    /* Agency brand header */
    .brand {
      display: flex;
      align-items: center;
      gap: 10px;
      margin-bottom: 6px;
    }
    .brand-logo {
      height: 34px;
      max-width: 180px;
      object-fit: contain;
    }
    .brand-name {
      font-weight: 700;
      font-size: 13px;
      line-height: 1.1;
    }

    .panel { border: 1px solid #e5e7eb; border-radius: 8px; padding: 10px; }
    .billto-title { font-weight: 600; margin-bottom: 4px; }
    .billto { white-space: pre-wrap; }

    .meta-table { width: 100%; border-collapse: collapse; }
    .meta-table th { text-align: left; font-weight: 600; padding: 0 0 2px 0; }
    .meta-table td { padding: 2px 0; }

    .lines {
      width: 100%;
      border-collapse: collapse;
      border: 1px solid #e5e7eb;
      border-radius: 10px;
      overflow: hidden;
    }
    .lines thead th {
      background: #f9fafb;
      padding: 8px 10px;
      text-align: left;
      font-weight: 600;
    }
    .lines th, .lines td {
      border: 1px solid #e5e7eb;  /* full grid */
      padding: 8px 10px;
      vertical-align: top;
    }
    .lines thead th.money, .lines td.money { text-align: right; }
    .desc-title { font-weight: 600; margin-bottom: 2px; }
    .desc-meta { color: #555; }
    .money { font-variant-numeric: tabular-nums; }

    .lines tfoot td { background: #fcfcfd; font-weight: 600; }
    .lines tfoot .label { text-align: right; color: #333; font-weight: 600; }

    /* New: neat nested breakdown table (keeps existing styling palette) */
    .breakdown-wrap { margin-top: 6px; }
    table.breakdown {
      width: 100%;
      border-collapse: collapse;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      overflow: hidden;
      font-size: 10px;
      background: #fff;
    }
    table.breakdown th, table.breakdown td {
      border: 1px solid #e5e7eb;
      padding: 6px 8px;
      vertical-align: top;
    }
    table.breakdown thead th {
      background: #f9fafb;
      font-weight: 600;
      text-align: left;
    }
    table.breakdown .b-qty,
    table.breakdown .b-unit,
    table.breakdown .b-charge { text-align: right; white-space: nowrap; }
    table.breakdown .b-desc { text-align: left; }

    /* Booking references table */
    .refs-wrap { margin-top: 6px; }
    .refs-title { font-weight: 600; margin: 2px 0 4px; color: #333; }
    table.refs {
      width: 100%;
      border-collapse: collapse;
      border: 1px solid #e5e7eb;
      border-radius: 8px;
      overflow: hidden;
      font-size: 10px;
      background: #fff;
    }
    table.refs th, table.refs td {
      border: 1px solid #e5e7eb;
      padding: 6px 8px;
      vertical-align: top;
    }
    table.refs thead th {
      background: #f9fafb;
      font-weight: 600;
      text-align: left;
    }
    table.refs .r-day { width: 90px; white-space: nowrap; }
    table.refs .r-time { width: 60px; white-space: nowrap; text-align: right; }
    table.refs .r-ref { text-align: left; }
    table.refs td.r-time { text-align: right; }
    table.refs.refs-freeform .r-ref { width: auto; }
    .ref-missing { color: #b91c1c; font-weight: 700; }

    /* New: adjustments section header */
    .section-row td {
      background: #f9fafb;
      border-left: 1px solid #e5e7eb;
      border-right: 1px solid #e5e7eb;
    }
    .section-title { font-weight: 700; color: #333; }

    /* Transactional footer pinned above bottom margin */
    .footer {
      position: fixed;
      left: ${mg.left}mm; right: ${mg.right}mm; bottom: ${mg.bottom}mm;
      font-size: 10px; color: #333;
      display: ${hideBankFooter ? "none" : "grid"};
      grid-template-columns: 2fr 1fr; gap: 12px;
    }
    .right { text-align: right; }
  </style>
</head>
<body>
  ${stationeryUrl ? `<div class="stationery" style="background-image:url('${escapeUrl(stationeryUrl)}');"></div>` : ""}

  <div class="wrap">
    <div class="header">
      <div>
           <div class="brand">
          ${agencyLogoUrl ? `<img class="brand-logo" src="${escapeUrl(agencyLogoUrl)}" alt="Agency logo" />` : ""}
          ${agencyName ? `<div class="brand-name">${escapeHtml(agencyName)}</div>` : ""}
        </div>

        <div class="title">INVOICE ${invoice_no ? `<span class="muted mono">#${escapeHtml(invoice_no)}</span>` : ""}</div>

        <div class="panel" style="margin-top:8px;">
          <div class="billto-title">Bill To</div>
          <div class="billto"><b>${escapeHtml(clientName)}</b>${clientAddress.length ? `<br>${clientAddress.map(escapeHtml).join("<br>")}` : ""}</div>
        </div>
      </div>
      <div class="panel">
        <table class="meta-table">
          <tr><th>Issue date</th><td class="mono">${fmtDateGB(issued_at_utc)}</td></tr>
          <tr><th>Due date</th><td class="mono">${fmtDateGB(due_at_utc)}</td></tr>
          ${termsDays != null ? `<tr><th>Payment terms</th><td class="mono">${termsDays} days</td></tr>` : ""}
          ${poNo ? `<tr><th>PO Number</th><td class="mono">${escapeHtml(poNo)}</td></tr>` : ""}
          <!-- VAT % intentionally NOT displayed -->
        </table>
      </div>
    </div>

    <table class="lines">
      <thead>
        <tr>
          <th>Description</th>
          <th class="money">Ex VAT</th>
          ${showVatCols ? `<th class="money">VAT</th>` : ""}
          <th class="money">Total</th>
        </tr>
      </thead>
      <tbody>
        ${lineRows || `<tr><td colspan="${showVatCols ? 4 : 3}">No lines.</td></tr>`}
      </tbody>
      <tfoot>
        <tr>
          <td class="label">Subtotal (ex VAT)</td>
          <td class="money mono">${fmtGBP(totals.subtotal_ex_vat)}</td>
          ${showVatCols ? `<td></td>` : ""}
          <td></td>
        </tr>
        ${showVatCols ? `
        <tr>
          <td class="label">VAT</td>
          <td></td>
          <td class="money mono">${fmtGBP(totals.vat_amount)}</td>
          <td></td>
        </tr>` : ""}
        <tr>
          <td class="label"><b>Total due</b></td>
          <td></td>
          ${showVatCols ? `<td></td>` : ""}
          <td class="money mono"><b>${fmtGBP(totals.total_inc_vat)}</b></td>
        </tr>
      </tfoot>
    </table>
  </div>

  <div class="footer">
    <div>
      <div><b>BACS Payment Details</b></div>
      <div>Banker: <span class="mono">${escapeHtml(pick(bank, "name", ""))}</span></div>
      <div>Sort Code: <span class="mono">${escapeHtml(pick(bank, "sort_code", ""))}</span> &nbsp;&nbsp; Account No.: <span class="mono">${escapeHtml(pick(bank, "account_number", ""))}</span></div>
    </div>
     <div class="right">
      ${vatReg ? `<div>VAT Reg: <b class="mono">${escapeHtml(vatReg)}</b></div>` : ""}
      ${companyRegNumber ? `<div>Company Reg: <b class="mono">${escapeHtml(companyRegNumber)}</b></div>` : ""}
      ${registeredAddressLines.length ? `<div style="margin-top:4px;">Registered address:<br>${registeredAddressLines.map(escapeHtml).join("<br>")}</div>` : ""}
    </div>

  </div>
</body>
</html>`;
}



  // Helpers local to this function
  const isTimesheetKind = (k) => String(k || '').toUpperCase() === 'TIMESHEET';
  const isDefaultDocsPdfKeyFor = (tsId, key) => {
    if (!tsId || !key) return false;
    const norm = normalizeKey(String(key));
    return norm === normalizeKey(`docs-pdf/timesheets/ts_${String(tsId)}.pdf`);
  };

  try {
    // 1) Manifest (single RPC)
    const man = await sbRpc(env, 'invoice_render_manifest', { p_invoice_id: invoiceId });
    const manRows = Array.isArray(man) ? man : (man?.data || []);
    const manifest = (manRows && manRows.length) ? manRows[0] : man;

    if (!manifest || typeof manifest !== 'object') {
      return { ok: false, error: 'Failed to load invoice render manifest' };
    }

    const inv = manifest.invoice || manifest.invoice_row || null;
    if (!inv || !inv.id) return { ok: false, error: 'Invoice not found' };

    // ✅ Cache short-circuit INSIDE render (covers email path too)
    try {
      if (!forceRegen) {
        const key = (inv && typeof inv.invoice_pdf_r2_key === 'string') ? inv.invoice_pdf_r2_key.trim() : '';
        const genAt = inv ? inv.invoice_pdf_generated_at_utc : null;
        const updAt = inv ? inv.updated_at : null;

        if (key && genAt && updAt) {
          const tUpd = new Date(updAt).getTime();
          const tGen = new Date(genAt).getTime();

          if (Number.isFinite(tUpd) && Number.isFinite(tGen) && tUpd <= tGen) {
            return {
              ok: true,
              pdf_key: key.replace(/^\/+/, ''),
              cached: true,
              attached_timesheets: 0,
              attached_hr: false,
              attached_nhsp: false,
              attached_evidence: 0,
              attached_timesheet_evidence: 0,
              attached_manual_timesheets: 0
            };
          }
        }
      }
    } catch {
      // non-fatal; proceed to render
    }

    const header = (manifest.header_snapshot_json && typeof manifest.header_snapshot_json === 'object')
      ? manifest.header_snapshot_json
      : (inv.header_snapshot_json && typeof inv.header_snapshot_json === 'object' ? inv.header_snapshot_json : {});

    const attachPolicy = (manifest.attach_policy && typeof manifest.attach_policy === 'object')
      ? manifest.attach_policy
      : (header.attach_policy && typeof header.attach_policy === 'object' ? header.attach_policy : null);

    const requiresHr = !!(attachPolicy && attachPolicy.requires_hr === true);
    const hrAttach = !!(attachPolicy && Object.prototype.hasOwnProperty.call(attachPolicy, 'hr_attach_to_invoice') && attachPolicy.hr_attach_to_invoice !== false);

    const tsAttach = (attachPolicy && Object.prototype.hasOwnProperty.call(attachPolicy, 'ts_attach_to_invoice'))
      ? (attachPolicy.ts_attach_to_invoice !== false)
      : true;

    // Stationery resolution + presign
    let stationeryKey =
      (typeof header.stationery_key === "string" && header.stationery_key.trim()) ||
      env.INVOICE_STATIONERY_KEY ||
      "Assets/Stationery/Letterhead/A4/Letterhead_v1@300dpi.png";
    if (/\.pdf$/i.test(stationeryKey)) stationeryKey = stationeryKey.replace(/\.pdf$/i, "@300dpi.png");
    stationeryKey = normalizeKey(stationeryKey);

    const stationeryUrl = await presignR2Url(
      env,
      req,
      stationeryKey,
      Number(env.PRESIGN_EXPIRES_SECONDS || 600)
    );

    const marginsObj = toMarginsObj(header.stationery_margins_mm);
    const hideBankFooter = header.hide_bank_footer === true;

    const lineRows = Array.isArray(manifest.lines) ? manifest.lines : [];

    const evidenceAll = Array.isArray(manifest.evidence) ? manifest.evidence : [];
    const timesheetEvidenceRows = Array.isArray(manifest.timesheet_evidence)
      ? manifest.timesheet_evidence
      : evidenceAll.filter(ev => isTimesheetKind(ev?.kind));
    const otherEvidenceRows = Array.isArray(manifest.evidence_other)
      ? manifest.evidence_other
      : evidenceAll.filter(ev => !isTimesheetKind(ev?.kind));

    const tsfinRows = Array.isArray(manifest.tsfin_external_source_rows) ? manifest.tsfin_external_source_rows : [];
    const hrCacheRows = Array.isArray(manifest.hr_source_rows_cache) ? manifest.hr_source_rows_cache : [];

    // Determine group_nightsat_sunbh for template:
    // IMPORTANT: this should be snapped into header_snapshot_json at issue time.
    let groupNightsat = false;
    if (typeof header.group_nightsat_sunbh === 'boolean') groupNightsat = header.group_nightsat_sunbh;
    else if (typeof header?.meta?.group_nightsat_sunbh === 'boolean') groupNightsat = header.meta.group_nightsat_sunbh;

    // Build invoiceData for buildHTML
    const invoiceData = {
      header: {
        ...header,
        stationery_url: stationeryUrl,
        stationery_margins_mm: marginsObj,
        hide_bank_footer: hideBankFooter,
      },
      meta: {
        kind: 'invoice',
        generated_at_utc: new Date().toISOString(),
        group_nightsat_sunbh: groupNightsat,
      },
      invoice_no: inv.invoice_no || null,
      issued_at_utc: inv.issued_at_utc,
      due_at_utc: inv.due_at_utc,
      totals: {
        subtotal_ex_vat: Number(inv.subtotal_ex_vat || 0),
        vat_amount: Number(inv.vat_amount || 0),
        total_inc_vat: Number(inv.total_inc_vat || 0),
      },
      items: (lineRows || []).map((l) => {
        const meta0 = (l.meta_json && typeof l.meta_json === 'object') ? { ...l.meta_json } : {};
        if (!meta0.week_ending_date && meta0.week_ending_date_local) meta0.week_ending_date = meta0.week_ending_date_local;

        if (!meta0.line_type_norm && l.line_type_norm) meta0.line_type_norm = String(l.line_type_norm);
        if (!meta0.line_type_norm) meta0.line_type_norm = String(meta0.line_type || '').toUpperCase();
        if (meta0.timesheet_id == null && l.timesheet_id) meta0.timesheet_id = String(l.timesheet_id);

        const hourKeys = ['hours_day','hours_night','hours_sat','hours_sun','hours_bh'];
        for (const k of hourKeys) {
          if (meta0[k] == null && l[k] != null) meta0[k] = Number(l[k] || 0);
        }
        const rateKeys = ['charge_day','charge_night','charge_sat','charge_sun','charge_bh'];
        for (const k of rateKeys) {
          if (meta0[k] == null && l[k] != null) meta0[k] = Number(l[k] || 0);
        }

        return {
          description: l.description,
          timesheet_id: l.timesheet_id || null,
          meta: meta0,
          total_ex_vat: Number(l.total_charge_ex_vat || 0),
          vat_rate_pct: Number(l.vat_rate_pct || 0),
          vat_amount: Number(l.vat_amount || 0),
          total_inc_vat: Number(l.total_inc_vat || 0),
        };
      }),
      reference_rows: Array.isArray(manifest.reference_rows) ? manifest.reference_rows : [],
    };

    // Render base invoice pdf
    const html = buildHTML(invoiceData);
    const invoicePdfU8 = await withBrowser(env, async (browser) => {
      const page = await browser.newPage();
      await page.setContent(html, { waitUntil: "networkidle0" });
      await page.emulateMediaType("screen");
      const pdfArrayBuffer = await page.pdf({
        format: "a4",
        printBackground: true,
        margin: { top: 0, right: 0, bottom: 0, left: 0 },
      });
      return new Uint8Array(pdfArrayBuffer);
    });

    // Timesheet IDs from invoice lines
    const tsIds = [...new Set(lineRows.map(r => r?.timesheet_id).filter(Boolean).map(String))];

    // Canonical docs-pdf keys (only used when tsAttach=true)
    const docsKeys = tsIds.map(tsId => normalizeKey(`docs-pdf/timesheets/ts_${tsId}.pdf`));

    // Manual / override canonical keys (ALWAYS included)
    const manualKeyByTsId = new Map();
    for (const l of lineRows) {
      const tsId = l?.timesheet_id ? String(l.timesheet_id) : null;
      if (!tsId) continue;
      const k = (l.paper_ts_r2_key || l.effective_paper_ts_r2_key || null);
      if (!k) continue;
      const nk = normalizeKey(String(k));
      if (isDefaultDocsPdfKeyFor(tsId, nk)) continue;
      if (!manualKeyByTsId.has(tsId)) manualKeyByTsId.set(tsId, nk);
    }
    const manualKeys = tsIds.map(tsId => manualKeyByTsId.get(tsId) || null).filter(Boolean);

    // Determine expense-only timesheets (no HOURS/ADDITIONAL lines on this invoice, but has EXPENSE/MILEAGE lines),
    // so missing TS PDF is non-fatal (matches precheck behaviour) — computed from manifest lines (no extra RPCs).
    const expenseOnlySet = new Set();
    if ((tsAttach || manualKeys.length) && tsIds.length) {
      const byTs = new Map();
      for (const l of (lineRows || [])) {
        const tsId = l?.timesheet_id ? String(l.timesheet_id) : null;
        if (!tsId) continue;
        if (!byTs.has(tsId)) byTs.set(tsId, []);
        byTs.get(tsId).push(l);
      }

      const typeOf = (l) => {
        const m = (l?.meta_json && typeof l.meta_json === 'object') ? l.meta_json : {};
        const t = String(l?.line_type_norm || m?.line_type_norm || m?.line_type || '').toUpperCase();
        return t;
      };

      for (const tsId of tsIds) {
        const lines = byTs.get(String(tsId)) || [];
        if (!lines.length) continue;

        const types = lines.map(typeOf);

        const hasHours = types.includes('HOURS');
        const hasAdditional = types.some(t => t.startsWith('ADDITIONAL_RATE'));
        const hasExpenseOrMileage = types.some(t => t === 'MILEAGE' || t.startsWith('EXPENSE'));

        if (!hasHours && !hasAdditional && hasExpenseOrMileage) {
          expenseOnlySet.add(String(tsId));
        }
      }
    }

    const missing = [];
    const dedupeKeys = new Set();
    const tsEvidenceFetchedSet = new Set();

    const timesheetEvidenceBytesList = [];
    for (const ev of timesheetEvidenceRows) {
      const key = ev?.storage_key;
      if (!key) continue;
      const norm = normalizeKey(String(key));
      if (dedupeKeys.has(norm)) continue;

      const bytes = await r2GetBytes(env, norm);
      if (!bytes || !bytes.length) {
        missing.push({ kind: 'TIMESHEET_EVIDENCE_PDF', timesheet_id: ev?.timesheet_id || null, storage_key: norm });
        continue;
      }
      dedupeKeys.add(norm);
      timesheetEvidenceBytesList.push(bytes);
      if (ev?.timesheet_id) tsEvidenceFetchedSet.add(String(ev.timesheet_id));
    }

    const tsBytesList = [];
    if (tsAttach) {
      for (let i = 0; i < tsIds.length; i++) {
        const tsId = tsIds[i];
        const key = docsKeys[i];
        const norm = normalizeKey(String(key));
        if (dedupeKeys.has(norm)) continue;

        const bytes = await r2GetBytes(env, norm);
        if (!bytes || !bytes.length) {
          if (expenseOnlySet.has(String(tsId)) || tsEvidenceFetchedSet.has(String(tsId))) continue;
          missing.push({ kind: 'TIMESHEET_PDF', timesheet_id: tsId, storage_key: norm });
          continue;
        }
        dedupeKeys.add(norm);
        tsBytesList.push(bytes);
      }
    }

    const manualTsBytesList = [];
    for (let i = 0; i < tsIds.length; i++) {
      const tsId = tsIds[i];
      const key = manualKeyByTsId.get(String(tsId));
      if (!key) continue;

      const norm = normalizeKey(String(key));
      if (dedupeKeys.has(norm)) continue;

      const bytes = await r2GetBytes(env, norm);
      if (!bytes || !bytes.length) {
        if (expenseOnlySet.has(String(tsId)) || tsEvidenceFetchedSet.has(String(tsId))) continue;
        missing.push({ kind: 'MANUAL_TIMESHEET_PDF', timesheet_id: tsId, storage_key: norm });
        continue;
      }
      dedupeKeys.add(norm);
      manualTsBytesList.push(bytes);
    }

    const evidenceBytesList = [];
    for (const ev of otherEvidenceRows) {
      const key = ev?.storage_key;
      if (!key) continue;
      const norm = normalizeKey(String(key));
      if (dedupeKeys.has(norm)) continue;

      const bytes = await r2GetBytes(env, norm);
      if (!bytes || !bytes.length) {
        missing.push({ kind: 'EVIDENCE_PDF', timesheet_id: ev?.timesheet_id || null, storage_key: norm });
        continue;
      }
      dedupeKeys.add(norm);
      evidenceBytesList.push(bytes);
    }

    if (missing.length) {
      try {
        if (userForAudit) {
          await writeAudit(
            env,
            userForAudit,
            'INVOICE_RENDER_FAILED_MISSING_ARTEFACTS',
            { invoice_id: invoiceId, missing },
            { entity: 'invoice', subject_id: invoiceId, req }
          );
        }
      } catch {}
      return { ok: false, error: `Invoice render failed: missing required artefacts (${missing.length}).` };
    }

    // Optional HR report
    let hrBytes = null;
    if (requiresHr && hrAttach) {
      const hrRows = [];
      if (hrCacheRows.length) {
        for (const r of hrCacheRows) {
          if (String(r.source_system || '').toUpperCase() !== 'HEALTHROSTER') continue;
          const rows = Array.isArray(r.rows_json) ? r.rows_json : [];
          for (const raw of rows) hrRows.push({ raw_row: raw });
        }
      } else {
        for (const tf of tsfinRows) {
          const ext = (tf.external_source_rows_json && typeof tf.external_source_rows_json === 'object') ? tf.external_source_rows_json : {};
          const hrWeekly = Array.isArray(ext.HR_WEEKLY) ? ext.HR_WEEKLY : [];
          for (const row of hrWeekly) hrRows.push(row);
        }
      }

      if (hrRows.length) {
        const hrHtml = buildHrReportHTML(inv, header, hrRows);
        hrBytes = await withBrowser(env, async (browser) => {
          const page = await browser.newPage();
          await page.setContent(hrHtml, { waitUntil: 'networkidle0' });
          await page.emulateMediaType('screen');
          const pdfArrayBuffer = await page.pdf({
            format: 'a4',
            printBackground: true,
            margin: { top: 24, right: 24, bottom: 24, left: 24 }
          });
          return new Uint8Array(pdfArrayBuffer);
        });
      }
    }

    // Optional NHSP breakdown report
    let nhspBytes = null;
    {
      const nhspTables = [];

      // Preferred: invoice-level cache rows (already filtered for this invoice)
      if (hrCacheRows.length) {
        for (const r of hrCacheRows) {
          if (String(r.source_system || '').toUpperCase() !== 'NHSP') continue;
          const rows = Array.isArray(r.rows_json) ? r.rows_json : [];
          if (!rows.length) continue;
          const headerCols = Array.isArray(r.header_columns) ? r.header_columns : [];
          nhspTables.push({
            import_id: r.import_id || null,
            header_columns: headerCols,
            rows_json: rows
          });
        }
      }

      // Fallback: per-timesheet snapshot external rows
      if (!nhspTables.length) {
        const fallbackRows = [];
        for (const tf of tsfinRows) {
          const ext = (tf.external_source_rows_json && typeof tf.external_source_rows_json === 'object')
            ? tf.external_source_rows_json
            : {};
          const nhspWeekly = Array.isArray(ext.NHSP_WEEKLY) ? ext.NHSP_WEEKLY : [];
          for (const row of nhspWeekly) fallbackRows.push(row);
        }
        if (fallbackRows.length) {
          nhspTables.push({
            import_id: null,
            header_columns: [],
            rows_json: fallbackRows
          });
        }
      }

      if (nhspTables.length) {
        const nhspHtml = buildNhspReportHTML(inv, header, { tables: nhspTables });
        nhspBytes = await withBrowser(env, async (browser) => {
          const page = await browser.newPage();
          await page.setContent(nhspHtml, { waitUntil: 'networkidle0' });
          await page.emulateMediaType('screen');
          const pdfArrayBuffer = await page.pdf({
            format: 'a4',
            landscape: true,
            printBackground: true,
            margin: { top: 24, right: 24, bottom: 24, left: 24 }
          });
          return new Uint8Array(pdfArrayBuffer);
        });
      }
    }

    // ==========================================================
    // Merge PDFs (UPDATED ORDER):
    // 1) Invoice
    // 2) Timesheet PDFs (canonical, if tsAttach)
    // 3) Manual/override Timesheet PDFs (always when present)
    // 4) HR report (if present)
    // 5) NHSP report (if present)
    // 6) Evidence PDFs (timesheet evidence + other evidence)
    // ==========================================================
    const merged = await PDFDocument.create();

    // 1) Invoice
    const invDoc = await PDFDocument.load(invoicePdfU8);
    (await merged.copyPages(invDoc, invDoc.getPageIndices())).forEach(p => merged.addPage(p));

    // 2) Timesheet PDFs (canonical)
    let attachedTsCount = 0;
    if (tsAttach) {
      for (const b of tsBytesList) {
        const doc = await PDFDocument.load(b);
        (await merged.copyPages(doc, doc.getPageIndices())).forEach(p => merged.addPage(p));
        attachedTsCount++;
      }
    }

    // 3) Manual/override Timesheet PDFs (always included when present)
    let attachedManualTsCount = 0;
    for (const b of manualTsBytesList) {
      const doc = await PDFDocument.load(b);
      (await merged.copyPages(doc, doc.getPageIndices())).forEach(p => merged.addPage(p));
      attachedManualTsCount++;
    }

    // 4) HR report
    if (hrBytes?.length) {
      const doc = await PDFDocument.load(hrBytes);
      (await merged.copyPages(doc, doc.getPageIndices())).forEach(p => merged.addPage(p));
    }

    // 5) NHSP report
    if (nhspBytes?.length) {
      const doc = await PDFDocument.load(nhspBytes);
      (await merged.copyPages(doc, doc.getPageIndices())).forEach(p => merged.addPage(p));
    }

    // 6) Evidence PDFs (timesheet evidence + other evidence)
    let attachedTimesheetEvidenceCount = 0;
    for (const b of timesheetEvidenceBytesList) {
      const doc = await PDFDocument.load(b);
      (await merged.copyPages(doc, doc.getPageIndices())).forEach(p => merged.addPage(p));
      attachedTimesheetEvidenceCount++;
    }

    let attachedEvidenceCount = 0;
    for (const b of evidenceBytesList) {
      const doc = await PDFDocument.load(b);
      (await merged.copyPages(doc, doc.getPageIndices())).forEach(p => merged.addPage(p));
      attachedEvidenceCount++;
    }

    const combinedU8 = await merged.save();

    // Store combined PDF in R2 and patch invoice row
    const pdfKey = normalizeKey(`docs-pdf/invoices/invoice_${invoiceId}.pdf`);
    await r2Put(env, pdfKey, combinedU8, { httpMetadata: { contentType: "application/pdf" } });

    const nowIso = new Date().toISOString();

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoiceId)}`,
      {
        method: "PATCH",
        headers: sbHeaders(env),
        body: JSON.stringify({
          invoice_pdf_r2_key: pdfKey,
          invoice_pdf_generated_at_utc: nowIso,
          paper_ts_r2_manifest: docsKeys,
          updated_at: nowIso,
        }),
      }
    );

    return {
      ok: true,
      pdf_key: pdfKey,
      cached: false,
      attached_timesheets: attachedTsCount,
      attached_hr: !!(hrBytes && hrBytes.length),
      attached_nhsp: !!(nhspBytes && nhspBytes.length),
      attached_evidence: attachedEvidenceCount,
      attached_timesheet_evidence: attachedTimesheetEvidenceCount,
      attached_manual_timesheets: attachedManualTsCount
    };
  } catch {
    return { ok: false, error: "Failed to render invoice bundle" };
  }
}


async function handleInvoiceRender(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const enc = encodeURIComponent;

  // Parse optional { force_regen: true }
  let forceRegen = false;
  try {
    const body = await req.clone().json();
    forceRegen = !!(body && (body.force_regen === true || body.forceRegen === true));
  } catch {
    forceRegen = false;
  }

  try {
    // ✅ Fast-path caching (skip render entirely if still valid and not force_regen)
    if (!forceRegen) {
      try {
        const { rows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/invoices` +
            `?id=eq.${enc(invoiceId)}` +
            `&select=invoice_pdf_r2_key,invoice_pdf_generated_at_utc,updated_at` +
            `&limit=1`,
          false
        );

        const inv = rows && rows.length ? rows[0] : null;
        const key = (inv && typeof inv.invoice_pdf_r2_key === 'string') ? inv.invoice_pdf_r2_key.trim() : '';
        const genAt = inv ? inv.invoice_pdf_generated_at_utc : null;
        const updAt = inv ? inv.updated_at : null;

        if (key && genAt && updAt) {
          const tUpd = new Date(updAt).getTime();
          const tGen = new Date(genAt).getTime();

          if (Number.isFinite(tUpd) && Number.isFinite(tGen) && tUpd <= tGen) {
            return withCORS(env, req, ok({
              pdf_key: key.replace(/^\/+/, ''),
              attached_timesheets: 0,
              attached_hr: false,
              attached_nhsp: false,
              attached_evidence: 0,
              attached_timesheet_evidence: 0,
              attached_manual_timesheets: 0,
              cached: true
            }));
          }
        }
      } catch {
        // non-fatal: fall through to render
      }
    }

    const core = await _renderInvoiceBundleAndStore(env, req, invoiceId, user, { force_regen: forceRegen });
    if (!core?.ok) {
      return withCORS(env, req, serverError(core?.error || "Failed to render invoice bundle"));
    }

    return withCORS(env, req, ok({
      pdf_key: core.pdf_key,
      attached_timesheets: core.attached_timesheets || 0,
      attached_hr: !!core.attached_hr,
      attached_nhsp: !!core.attached_nhsp,
      attached_evidence: core.attached_evidence || 0,

      attached_timesheet_evidence: core.attached_timesheet_evidence || 0,
      attached_manual_timesheets: core.attached_manual_timesheets || 0,

      cached: !!core.cached
    }));
  } catch {
    return withCORS(env, req, serverError("Failed to render invoice bundle"));
  }
}

async function handleInvoiceEmail(env, req, invoiceId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    // Load invoice basics + header meta (for self-bill guard) + client id + primary invoice email + status + do_not_send
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices` +
        `?id=eq.${enc(invoiceId)}` +
        `&select=id,client_id,invoice_no,status,issued_at_utc,paid_at_utc,do_not_send,header_snapshot_json,client:clients(primary_invoice_email,name)` +
        `&limit=1`,
      false
    );
    if (!rows?.length) return withCORS(env, req, notFound('Invoice not found'));

    const inv = rows[0];
    const status = String(inv?.status || '').toUpperCase();

    // ✅ Hard-block do_not_send invoices from being emailed
    if (inv?.do_not_send === true) {
      return withCORS(env, req, badRequest('This invoice is marked do_not_send and must not be emailed.'));
    }

    // ✅ Require invoice already issued (do NOT issue automatically)
    if (status !== 'ISSUED' || !inv.issued_at_utc) {
      return withCORS(env, req, badRequest('Issue invoice first.'));
    }

    const header = (inv?.header_snapshot_json && typeof inv.header_snapshot_json === 'object')
      ? inv.header_snapshot_json
      : {};
    const meta = (header?.meta && typeof header.meta === 'object') ? header.meta : {};

    // Hard-block self-bill invoices from being emailed
    const isSelfBill = (meta?.self_bill === true) || (String(meta?.source || '').toUpperCase() === 'TSFIN_SEGMENTS');
    if (isSelfBill) {
      return withCORS(env, req, badRequest('Self-bill invoices must not be emailed.'));
    }

    const clientId = inv?.client_id || null;
    if (!clientId) return withCORS(env, req, badRequest('Invoice client_id missing'));

    // Load latest client_settings (fallback behaviour when no contract override applies)
    let cs = null;
    try {
      const { rows: csRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_settings` +
          `?client_id=eq.${enc(clientId)}` +
          `&select=send_manual_invoices_to_different_email,manual_invoices_alt_email_address,effective_from,created_at` +
          `&order=effective_from.desc,created_at.desc&limit=1`
      );
      cs = csRows?.[0] || null;
    } catch {
      cs = null;
    }

    const altEnabled = (cs && cs.send_manual_invoices_to_different_email === true);
    const altEmail = (cs && typeof cs.manual_invoices_alt_email_address === 'string')
      ? cs.manual_invoices_alt_email_address.trim()
      : null;

    // Determine whether THIS invoice relates to a manual/QR adjustment timesheet,
    // and resolve any contract-level manual invoice email override(s).
    let hasManualOrQrAdjustment = false;
    const contractAltEmails = new Map(); // email -> Set(contract_id)

    try {
      const { rows: lineRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/invoice_lines` +
          `?invoice_id=eq.${enc(invoiceId)}` +
          `&select=timesheet_id`
      );

      const tsIds = Array.from(
        new Set((lineRows || []).map(r => r?.timesheet_id).filter(Boolean).map(String))
      );

      if (tsIds.length) {
        const chunkSize = 200;

        const tsById = new Map();
        for (let i = 0; i < tsIds.length; i += chunkSize) {
          const chunk = tsIds.slice(i, i + chunkSize);
          const { rows: tsRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/timesheets` +
              `?timesheet_id=in.(${chunk.map(enc).join(',')})` +
              `&is_current=eq.true` +
              `&select=timesheet_id,submission_mode,sheet_scope,qr_status,qr_token,is_adjustment,contract_id`
          );
          for (const t of (tsRows || [])) {
            if (t && t.timesheet_id) tsById.set(String(t.timesheet_id), t);
          }
        }

        const cwAdjSet = new Set();
        const cwContractByTsId = new Map();
        for (let i = 0; i < tsIds.length; i += chunkSize) {
          const chunk = tsIds.slice(i, i + chunkSize);
          const { rows: cwRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
              `?timesheet_id=in.(${chunk.map(enc).join(',')})` +
              `&select=timesheet_id,is_adjustment,contract_id`
          );
          for (const w of (cwRows || [])) {
            if (!w || !w.timesheet_id) continue;
            const tid = String(w.timesheet_id);
            if (w.is_adjustment === true) cwAdjSet.add(tid);
            if (w.contract_id) cwContractByTsId.set(tid, String(w.contract_id));
          }
        }

        // Load relevant contracts (for contract-level email override)
        const contractIds = Array.from(new Set(tsIds.map((tsId) => {
          const t = tsById.get(String(tsId)) || null;
          const cid = t?.contract_id || cwContractByTsId.get(String(tsId)) || null;
          return cid ? String(cid) : null;
        }).filter(Boolean)));

        const contractById = new Map();
        if (contractIds.length) {
          for (let i = 0; i < contractIds.length; i += chunkSize) {
            const chunk = contractIds.slice(i, i + chunkSize);
            const { rows: cRows } = await sbFetch(
              env,
              `${env.SUPABASE_URL}/rest/v1/contracts` +
                `?id=in.(${chunk.map(enc).join(',')})` +
                `&select=id,overrideclientsettings,send_manual_invoices_to_different_email,manual_invoices_alt_email_address`
            );
            for (const c of (cRows || [])) {
              if (c && c.id) contractById.set(String(c.id), c);
            }
          }
        }

        for (const tsId of tsIds) {
          const t = tsById.get(String(tsId)) || null;

          const sub = String(t?.submission_mode || '').toUpperCase();
          const isManual = (sub === 'MANUAL');

          const qrStatus = (t?.qr_status != null) ? String(t.qr_status).trim() : '';
          const qrToken  = (t?.qr_token  != null) ? String(t.qr_token).trim()  : '';
          const isQrish  = !!(qrStatus || qrToken);

          const isDailyAdj = (t && t.is_adjustment === true);
          const isWeeklyAdj = cwAdjSet.has(String(tsId));

          const isAdj = (isDailyAdj || isWeeklyAdj);
          const isManualOrQr = (isManual || isQrish);

          if (!(isAdj && isManualOrQr)) continue;

          hasManualOrQrAdjustment = true;

          const contractId = (t?.contract_id != null && String(t.contract_id))
            ? String(t.contract_id)
            : (cwContractByTsId.get(String(tsId)) || null);

          if (!contractId) continue;

          const cRow = contractById.get(String(contractId)) || null;

          // Contract-level override applies only when overrideclientsettings=true AND the manual-email flag is enabled.
          const contractOverrideEnabled =
            !!(cRow && cRow.overrideclientsettings === true && cRow.send_manual_invoices_to_different_email === true);

          if (!contractOverrideEnabled) continue;

          const email = (cRow && typeof cRow.manual_invoices_alt_email_address === 'string')
            ? cRow.manual_invoices_alt_email_address.trim()
            : '';

          if (!email) {
            return withCORS(
              env,
              req,
              badRequest(`Contract manual invoice email is enabled but no alternate email address is configured (contract_id=${contractId}).`)
            );
          }

          if (!contractAltEmails.has(email)) contractAltEmails.set(email, new Set());
          contractAltEmails.get(email).add(String(contractId));
        }
      }
    } catch {
      hasManualOrQrAdjustment = false;
      contractAltEmails.clear();
    }

    // Decide recipient
    let to = inv.client?.primary_invoice_email || null;

    // Prefer contract-level routing when present
    if (contractAltEmails.size > 0) {
      const emails = Array.from(contractAltEmails.keys());
      if (emails.length > 1) {
        const details = emails.map((em) => {
          const ids = Array.from(contractAltEmails.get(em) || []);
          return `${em} (contracts: ${ids.join(', ')})`;
        }).join(' ; ');
        return withCORS(
          env,
          req,
          badRequest(`Multiple contract manual invoice email overrides apply to this invoice and they disagree: ${details}`)
        );
      }
      to = emails[0];
    } else if (hasManualOrQrAdjustment && altEnabled) {
      // Fallback: client_settings manual-adjustment routing (legacy behaviour)
      if (!altEmail) {
        return withCORS(env, req, badRequest('Client manual adjustment email is enabled but no alternate email address is configured.'));
      }
      to = altEmail;
    }

    if (!to) return withCORS(env, req, badRequest('Client invoice email not configured'));

    // ✅ Ensure the bundled invoice PDF exists (includes TIMESHEET evidence + manual TS PDFs).
    // This uses caching internally if invoice_pdf_generated_at_utc is up-to-date.
    const core = await _renderInvoiceBundleAndStore(env, req, invoiceId, user, { force_regen: false });
    if (!core?.ok || !core?.pdf_key) {
      return withCORS(env, req, serverError(core?.error || 'Failed to render invoice PDF for emailing'));
    }

    // Queue mail_outbox with invoice_id attachment placeholder; mail worker will attach invoice_pdf_r2_key.
    const invNo = inv.invoice_no || invoiceId;
    const subject = `Invoice ${invNo}`;

    const out = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({
        type: 'INVOICE',
        to,
        cc: null,
        subject,
        body_text: `Please find Invoice ${invNo} attached.`,
        attachments: [{ invoice_id: String(invoiceId), filename: `Invoice_${invNo}.pdf` }],
        status: 'QUEUED',
        reference: `invoice:${invoiceId}`,
        created_at_utc: nowIso(),
        created_by: user?.id || null,
      })
    });

    if (!out.ok) {
      const err = await out.text();
      return withCORS(env, req, serverError(`Failed to queue email: ${err}`));
    }

    const outJson = await out.json().catch(() => ({}));
    const mailRow = Array.isArray(outJson) ? outJson[0] : outJson;
    const mailId = mailRow?.id || null;

    await writeAudit(
      env,
      user,
      'EMAIL_QUEUED',
      {
        to,
        subject,
        mail_id: mailId,
        reference: `invoice:${invoiceId}`,
        routing: {
          used_contract_alt_manual_email: contractAltEmails.size > 0,
          used_alt_manual_email: !!(contractAltEmails.size === 0 && hasManualOrQrAdjustment && altEnabled),
          has_manual_or_qr_adjustment: !!hasManualOrQrAdjustment
        },
        render: {
          pdf_key: core.pdf_key,
          cached: !!core.cached,
          attached_timesheets: core.attached_timesheets || 0,
          attached_timesheet_evidence: core.attached_timesheet_evidence || 0,
          attached_manual_timesheets: core.attached_manual_timesheets || 0,
          attached_evidence: core.attached_evidence || 0
        }
      },
      { entity: 'invoice', subject_id: invoiceId, correlation_id: mailId, req }
    );

    return withCORS(env, req, ok({ queued: true, mail_id: mailId, to }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to queue invoice email'));
  }
}


async function handleInvoiceDeleteOne(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  try {
    // 1) Load invoice guards
    const { rows: invRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices` +
        `?id=eq.${enc(invoiceId)}` +
        `&select=id,type,status,issued_at_utc,paid_at_utc` +
        `&limit=1`,
      false
    );

    const inv = invRows?.[0] || null;
    if (!inv?.id) return withCORS(env, req, notFound('Invoice not found'));

    const invType = String(inv.type || '').toUpperCase();
    if (invType === 'CREDIT_NOTE') {
      return withCORS(env, req, badRequest('Cannot delete a CREDIT_NOTE via this route.'));
    }

    // ✅ 3.6: strict delete eligibility
    const invStatus = String(inv.status || '').toUpperCase();
    if (invStatus !== 'DRAFT') {
      return withCORS(env, req, badRequest('Invoice must be DRAFT (unissued). Unissue first if needed.'));
    }
    if (inv.issued_at_utc) {
      return withCORS(env, req, badRequest('Invoice is issued and cannot be deleted. Unissue first.'));
    }
    if (inv.paid_at_utc) {
      return withCORS(env, req, badRequest('Invoice is PAID and cannot be deleted.'));
    }

    // 2) Ensure invoice has no remaining lines
    const { rows: lineCheck } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoice_lines?invoice_id=eq.${enc(invoiceId)}&select=id&limit=1`,
      false
    );
    if (lineCheck?.length) {
      return withCORS(env, req, badRequest('Invoice still has lines. Remove all timesheets/lines before deleting.'));
    }

    // 3) Best-effort cleanup: invoice HR cache rows (if table exists)
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/invoice_hr_source_rows?invoice_id=eq.${enc(invoiceId)}`,
      { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return=minimal' } }
    ).catch(() => {});

    // 4) Best-effort cleanup: queued mail_outbox rows referencing this invoice
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/mail_outbox` +
        `?reference=eq.${enc(`invoice:${invoiceId}`)}` +
        `&status=eq.QUEUED`,
      { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return=minimal' } }
    ).catch(() => {});

    // 5) Delete invoice
    const del = await fetch(
      `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoiceId)}`,
      { method: 'DELETE', headers: { ...sbHeaders(env), Prefer: 'return=minimal' } }
    );
    if (!del.ok) {
      const t = await del.text();
      return withCORS(env, req, serverError(`Failed to delete invoice: ${t}`));
    }
    try { await del.arrayBuffer(); } catch {}

    // 6) Audit
    try {
      await writeAudit(
        env,
        user,
        'INVOICE_DELETED',
        { invoice_id: invoiceId },
        { entity: 'invoice', subject_id: invoiceId, req }
      );
    } catch {}

    return withCORS(env, req, ok({ ok: true, deleted: true, invoice_id: invoiceId }));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}

async function handleListInvoices(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const sp = new URL(req.url).searchParams;
  const enc = encodeURIComponent;

  // Paging (support both styles: page/page_size OR limit/offset)
  const pageRaw = sp.get('page');
  const pageSizeRaw = sp.get('page_size');

  const page = pageRaw ? Math.max(1, parseInt(pageRaw || '1', 10)) : null;
  const pageSize = pageSizeRaw ? Math.max(1, Math.min(200, parseInt(pageSizeRaw || '50', 10))) : null;

  const legacyLimit  = Math.min(parseInt(sp.get('limit')  || '50', 10), 200);
  const legacyOffset = Math.max(0, parseInt(sp.get('offset') || '0', 10));

  const limit = pageSize ?? legacyLimit;
  const offset = (page && pageSize) ? ((page - 1) * pageSize) : legacyOffset;

  const includeCount = sp.get('include_count') === 'true';
  const includeTotals = sp.get('include_totals') === 'true';

  // Filters
  const clientId    = sp.get('client_id') || null;

  const statusParams = sp.getAll('status').map(s => (s || '').trim()).filter(Boolean);
  const q = (sp.get('q') || '').trim(); // partial invoice_no

  // Date filters
  const issuedFrom   = sp.get('issued_from')  || null;
  const issuedTo     = sp.get('issued_to')    || null;
  const dueFrom      = sp.get('due_from')     || null;
  const dueTo        = sp.get('due_to')       || null;
  const createdFrom  = sp.get('created_from') || null;
  const createdTo    = sp.get('created_to')   || null;

  // Week ending filter (derived from linked timesheets)
  const weFrom = sp.get('week_ending_from') || null;
  const weTo   = sp.get('week_ending_to') || null;

  // Sort
  const orderByRaw  = (sp.get('order_by') || 'issued_at_utc').toLowerCase();
  const orderDirRaw = (sp.get('order_dir') || 'desc').toLowerCase();
  const orderDir = (orderDirRaw === 'asc') ? 'asc' : 'desc';

  const allowedSort = new Set([
    'issued_at_utc',
    'due_at_utc',
    'created_at',
    'status_date_utc',
    'invoice_no',
    'subtotal_ex_vat',
    'vat_amount',
    'total_inc_vat',
    'status'
  ]);

  const orderBy = allowedSort.has(orderByRaw) ? orderByRaw : 'issued_at_utc';

  const select = [
    'id',
    'invoice_no',
    'client_id',
    'type',
    'status',
    'status_date_utc',
    'issued_at_utc',
    'due_at_utc',
    'created_at',
    'subtotal_ex_vat',
    'vat_amount',
    'total_inc_vat',
    'paid_at_utc',
    'on_hold_reason',
    'invoice_pdf_r2_key',
    'header_snapshot_json',
    'client:clients(name,primary_invoice_email)'
  ].join(',');

  // Status logic
  const normStatuses = (() => {
    if (!statusParams.length) return null;

    // if someone passes a single "paid"/"unpaid" legacy value, honour it
    if (statusParams.length === 1) {
      const s0 = statusParams[0].toLowerCase();
      if (s0 === 'paid' || s0 === 'unpaid') return [s0];
    }

    // Flatten comma lists
    const out = [];
    for (const s of statusParams) {
      for (const part of String(s).split(',')) {
        const v = part.trim();
        if (v) out.push(v.toUpperCase());
      }
    }
    return out.length ? out : null;
  })();

  // Build base invoices URL (without paging modifiers yet)
  let urlBase =
    `${env.SUPABASE_URL}/rest/v1/invoices` +
    `?select=${enc(select)}` +
    `&order=${enc(orderBy)}.${orderDir},invoice_no.asc`;

  // Status filters
  if (normStatuses && normStatuses.length === 1 && (normStatuses[0] === 'PAID' || normStatuses[0] === 'UNPAID' || normStatuses[0] === 'paid' || normStatuses[0] === 'unpaid')) {
    const s0 = normStatuses[0].toLowerCase();
    if (s0 === 'paid') urlBase += `&paid_at_utc=not.is.null`;
    if (s0 === 'unpaid') urlBase += `&paid_at_utc=is.null`;
  } else if (normStatuses && normStatuses.length) {
    const safe = normStatuses
      .map(s => s.replace(/[(),]/g, ''))
      .filter(s => s === 'DRAFT' || s === 'ISSUED' || s === 'ON_HOLD' || s === 'PAID');

    if (safe.length === 1) urlBase += `&status=eq.${enc(safe[0])}`;
    if (safe.length > 1) urlBase += `&status=in.(${safe.map(enc).join(',')})`;
  }

  if (clientId) urlBase += `&client_id=eq.${enc(clientId)}`;
  if (q) urlBase += `&invoice_no=ilike.*${enc(q)}*`;

  if (issuedFrom) urlBase += `&issued_at_utc=gte.${enc(issuedFrom)}`;
  if (issuedTo)   urlBase += `&issued_at_utc=lte.${enc(issuedTo)}`;

  if (dueFrom) urlBase += `&due_at_utc=gte.${enc(dueFrom)}`;
  if (dueTo)   urlBase += `&due_at_utc=lte.${enc(dueTo)}`;

  if (createdFrom) urlBase += `&created_at=gte.${enc(createdFrom)}`;
  if (createdTo)   urlBase += `&created_at=lte.${enc(createdTo)}`;

  // ✅ Derive invoice_ids by week ending range (if provided)
  let invoiceIdFilter = null;
  if (weFrom || weTo) {
    try {
      // 1) find timesheets in week range
      let tsUrl =
        `${env.SUPABASE_URL}/rest/v1/timesheets?select=timesheet_id` +
        `&limit=20000&offset=0`;
      if (weFrom) tsUrl += `&week_ending_date=gte.${enc(weFrom)}`;
      if (weTo)   tsUrl += `&week_ending_date=lte.${enc(weTo)}`;

      const { rows: tsRows } = await sbFetch(env, tsUrl, false);
      const tsIds = Array.from(new Set((tsRows || []).map(r => r?.timesheet_id).filter(Boolean).map(String)));

      if (!tsIds.length) {
        // No timesheets in range => empty result set
        const empty = { items: [], page: page ?? undefined, page_size: pageSize ?? undefined, limit, offset };
        if (includeCount) empty.count = 0;
        if (includeTotals) empty.totals = { count_all: 0, subtotal_ex_vat_sum: 0, total_inc_vat_sum: 0, margin_ex_vat_sum: 0 };
        return withCORS(env, req, ok(empty));
      }

      // 2) find invoice_ids via invoice_lines for those timesheets
      const chunkSize = 200;
      const invIdSet = new Set();
      for (let i = 0; i < tsIds.length; i += chunkSize) {
        const chunk = tsIds.slice(i, i + chunkSize);
        const ilUrl =
          `${env.SUPABASE_URL}/rest/v1/invoice_lines?select=invoice_id` +
          `&timesheet_id=in.(${chunk.map(enc).join(',')})`;
        const { rows: ilRows } = await sbFetch(env, ilUrl, false);
        (ilRows || []).forEach(r => { if (r?.invoice_id) invIdSet.add(String(r.invoice_id)); });
      }

      const invIds = Array.from(invIdSet);
      if (!invIds.length) {
        const empty = { items: [], page: page ?? undefined, page_size: pageSize ?? undefined, limit, offset };
        if (includeCount) empty.count = 0;
        if (includeTotals) empty.totals = { count_all: 0, subtotal_ex_vat_sum: 0, total_inc_vat_sum: 0, margin_ex_vat_sum: 0 };
        return withCORS(env, req, ok(empty));
      }

      // Apply invoice_id filter (cap for URL safety; typical week range stays small)
      invoiceIdFilter = invIds;
    } catch (e) {
      return withCORS(env, req, serverError(`Failed week-ending invoice filter: ${e?.message || e}`));
    }
  }

  // Build final URL with paging + optional id filter
  let url = urlBase + `&limit=${limit}&offset=${offset}`;
  if (invoiceIdFilter && invoiceIdFilter.length) {
    // For safety, cap in-list length; if ever exceeds, you should move this to a dedicated SQL RPC.
    if (invoiceIdFilter.length > 600) {
      return withCORS(env, req, serverError(`Week-ending filter matched too many invoices (${invoiceIdFilter.length}). Narrow the range.`));
    }
    url += `&id=in.(${invoiceIdFilter.map(enc).join(',')})`;
  }

  // Totals helper
  const buildInvoiceTotalsFilters = () => {
    const f = {};
    if (clientId) f.client_id = clientId;
    if (statusParams && statusParams.length) f.status = statusParams;
    if (q) f.q = q;
    if (issuedFrom) f.issued_from = issuedFrom;
    if (issuedTo) f.issued_to = issuedTo;
    if (dueFrom) f.due_from = dueFrom;
    if (dueTo) f.due_to = dueTo;
    if (createdFrom) f.created_from = createdFrom;
    if (createdTo) f.created_to = createdTo;
    // week ending handled externally via id filter (not in totals RPC)
    return f;
  };

  try {
    const { rows, total } = await sbFetch(env, url, includeCount);

    const resp = includeCount
      ? { items: rows || [], count: total ?? undefined, page: page ?? undefined, page_size: pageSize ?? undefined, limit, offset }
      : { items: rows || [], page: page ?? undefined, page_size: pageSize ?? undefined, limit, offset };

    // ✅ 3.7 totals
    if (includeTotals) {
      if (!invoiceIdFilter) {
        // no week filter => can use SQL totals RPC directly
        const totRes = await sbRpc(env, 'invoice_list_totals', { p_filters: buildInvoiceTotalsFilters() });
        const totRows = Array.isArray(totRes) ? totRes : (totRes?.data || []);
        resp.totals = (totRows && totRows.length) ? totRows[0] : { count_all: 0, subtotal_ex_vat_sum: 0, total_inc_vat_sum: 0, margin_ex_vat_sum: 0 };
      } else {
        // week filter => compute totals from the filtered invoice ids to remain accurate
        const allInvIds = invoiceIdFilter;
        if (!allInvIds.length) {
          resp.totals = { count_all: 0, subtotal_ex_vat_sum: 0, total_inc_vat_sum: 0, margin_ex_vat_sum: 0 };
        } else {
          // Fetch invoices for those IDs with the same non-week filters (no paging)
          let invFetchUrl =
            `${env.SUPABASE_URL}/rest/v1/invoices?select=id,subtotal_ex_vat,total_inc_vat` +
            `&id=in.(${allInvIds.map(enc).join(',')})` +
            `&limit=20000&offset=0`;

          // Re-apply same filters that were applied to list (except paging and q which is invoice_no filter on invoices)
          if (clientId) invFetchUrl += `&client_id=eq.${enc(clientId)}`;
          if (q) invFetchUrl += `&invoice_no=ilike.*${enc(q)}*`;
          if (issuedFrom) invFetchUrl += `&issued_at_utc=gte.${enc(issuedFrom)}`;
          if (issuedTo)   invFetchUrl += `&issued_at_utc=lte.${enc(issuedTo)}`;
          if (dueFrom) invFetchUrl += `&due_at_utc=gte.${enc(dueFrom)}`;
          if (dueTo)   invFetchUrl += `&due_at_utc=lte.${enc(dueTo)}`;
          if (createdFrom) invFetchUrl += `&created_at=gte.${enc(createdFrom)}`;
          if (createdTo)   invFetchUrl += `&created_at=lte.${enc(createdTo)}`;

          // status re-apply
          if (normStatuses && normStatuses.length === 1 && (normStatuses[0].toLowerCase() === 'paid' || normStatuses[0].toLowerCase() === 'unpaid')) {
            const s0 = normStatuses[0].toLowerCase();
            if (s0 === 'paid') invFetchUrl += `&paid_at_utc=not.is.null`;
            if (s0 === 'unpaid') invFetchUrl += `&paid_at_utc=is.null`;
          } else if (normStatuses && normStatuses.length) {
            const safe = normStatuses
              .map(s => String(s).replace(/[(),]/g, ''))
              .filter(s => s === 'DRAFT' || s === 'ISSUED' || s === 'ON_HOLD' || s === 'PAID');
            if (safe.length === 1) invFetchUrl += `&status=eq.${enc(safe[0])}`;
            if (safe.length > 1) invFetchUrl += `&status=in.(${safe.map(enc).join(',')})`;
          }

          const { rows: allRows } = await sbFetch(env, invFetchUrl, false);
          const invIds2 = Array.from(new Set((allRows || []).map(r => r?.id).filter(Boolean).map(String)));

          let subtotalSum = 0;
          let totalIncSum = 0;
          for (const r of (allRows || [])) {
            subtotalSum += Number(r?.subtotal_ex_vat || 0);
            totalIncSum += Number(r?.total_inc_vat || 0);
          }

          // Margin from invoice_lines
          let marginSum = 0;
          if (invIds2.length) {
            const chunkSize = 200;
            for (let i = 0; i < invIds2.length; i += chunkSize) {
              const chunk = invIds2.slice(i, i + chunkSize);
              const lUrl =
                `${env.SUPABASE_URL}/rest/v1/invoice_lines?select=margin_ex_vat` +
                `&invoice_id=in.(${chunk.map(enc).join(',')})` +
                `&limit=20000&offset=0`;
              const { rows: lRows } = await sbFetch(env, lUrl, false);
              for (const lr of (lRows || [])) marginSum += Number(lr?.margin_ex_vat || 0);
            }
          }

          resp.totals = {
            count_all: invIds2.length,
            subtotal_ex_vat_sum: subtotalSum,
            total_inc_vat_sum: totalIncSum,
            margin_ex_vat_sum: marginSum
          };
        }
      }
    }

    return withCORS(env, req, ok(resp));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to list invoices: ${e?.message || e}`));
  }
}


// New: one-email-per-candidate remittance composer + queue + audit

/**
 * @openapi
 * /api/remittances/email-for-candidate:
 *   post:
 *     summary: Queue a remittance email for a candidate (HTML; one email per pay-run)
 *     description: >
 *       Queues a single HTML remittance email to a candidate, either for an explicit list
 *       of timesheets or for a date range. The email is queued in `mail_outbox` and an audit
 *       trail is written to `audit_events` for the candidate and each included timesheet.
 *     tags: [Remittances]
 *     security:
 *       - bearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             oneOf:
 *               - type: object
 *                 required: [timesheet_ids]
 *                 properties:
 *                   timesheet_ids:
 *                     type: array
 *                     items: { type: string, format: uuid }
 *                     description: Explicit list of timesheet IDs to include.
 *               - type: object
 *                 required: [candidate_id, period_start, period_end]
 *                 properties:
 *                   candidate_id: { type: string, format: uuid }
 *                   period_start: { type: string, format: date }
 *                   period_end:   { type: string, format: date }
 *     responses:
 *       "200":
 *         description: Email queued successfully
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 queued: { type: boolean }
 *                 mail_id: { type: string, format: uuid, nullable: true }
 *                 items: { type: integer, description: "Number of timesheets included" }
 *       "400":
 *         description: Bad request (missing selector or invalid input)
 *       "401":
 *         description: Unauthorized
 *       "404":
 *         description: No matching timesheets for the selection
 */

// -------------------
// GET INVOICE (+meta)
// -------------------
// -------------------
// GET INVOICE (+meta)
// -------------------

async function handleGetInvoice(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    // ✅ Single RPC call for full invoice context (manifest includes reference_rows + tsfin map + reference sources)
    const man = await sbRpc(env, 'invoice_render_manifest', { p_invoice_id: invoiceId });
    const manRows = Array.isArray(man) ? man : (man?.data || []);
    const manifest = (manRows && manRows.length) ? manRows[0] : man;

    if (!manifest || typeof manifest !== 'object') {
      return withCORS(env, req, serverError('Failed to fetch invoice manifest'));
    }

    const invoice = manifest.invoice || manifest.invoice_row || null;
    if (!invoice || !invoice.id) return withCORS(env, req, notFound('Invoice not found'));

    const header_snapshot_json =
      (manifest.header_snapshot_json && typeof manifest.header_snapshot_json === 'object')
        ? manifest.header_snapshot_json
        : (invoice.header_snapshot_json && typeof invoice.header_snapshot_json === 'object' ? invoice.header_snapshot_json : {});

    const lineRows = Array.isArray(manifest.lines) ? manifest.lines : [];

    const items = lineRows.map(l => ({
      invoice_line_id: l.id ?? null,
      source_key: l.source_key ?? null,
      booking_id: l.booking_id ?? null,
      timesheet_id: l.timesheet_id ?? null,

      is_adjustment: (l.is_adjustment != null)
        ? !!l.is_adjustment
        : (!l.timesheet_id || String(l?.meta_json?.line_type || '').toUpperCase() === 'ADJUSTMENT'),
      line_type_norm: (typeof l.line_type_norm === 'string' && l.line_type_norm)
        ? l.line_type_norm
        : String(l?.meta_json?.line_type || '').toUpperCase(),

      qty: {
        day: l.hours_day, night: l.hours_night, sat: l.hours_sat, sun: l.hours_sun, bh: l.hours_bh
      },
      pay_rate: {
        day: l.pay_day, night: l.pay_night, sat: l.pay_sat, sun: l.pay_sun, bh: l.pay_bh
      },
      charge_rate: {
        day: l.charge_day, night: l.charge_night, sat: l.charge_sat, sun: l.charge_sun, bh: l.charge_bh
      },

      total_pay_ex_vat: l.total_pay_ex_vat ?? null,
      total_charge_ex_vat: l.total_charge_ex_vat ?? null,
      margin_ex_vat: l.margin_ex_vat ?? null,

      vat_rate_pct: l.vat_rate_pct ?? null,
      vat_amount: l.vat_amount ?? null,
      total_inc_vat: l.total_inc_vat ?? null,

      description: l.description ?? null,
      paper_ts_r2_key: l.paper_ts_r2_key ?? l.effective_paper_ts_r2_key ?? null,

      meta_json: (l.meta_json && typeof l.meta_json === 'object') ? l.meta_json : {},

      // ✅ filled in below (precheck diagnostics)
      precheck_status: null,
      has_timesheet_evidence_pdf: null,
    }));

    // ✅ Precheck diagnostics for all timesheets on this invoice (batched)
    try {
      const tsIds = Array.from(
        new Set(items.map(it => it?.timesheet_id).filter(Boolean).map(String))
      );

      if (tsIds.length) {
        const chunkSize = 200;
        const pcMap = new Map();

        for (let i = 0; i < tsIds.length; i += chunkSize) {
          const chunk = tsIds.slice(i, i + chunkSize);
          const { rows: pcRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/v_ts_invoice_precheck` +
              `?select=timesheet_id,precheck_status,has_timesheet_evidence_pdf` +
              `&timesheet_id=in.(${chunk.map(encodeURIComponent).join(',')})`
          );
          for (const r of (pcRows || [])) {
            if (!r?.timesheet_id) continue;
            pcMap.set(String(r.timesheet_id), {
              precheck_status: r.precheck_status ?? null,
              has_timesheet_evidence_pdf: (r.has_timesheet_evidence_pdf === true),
            });
          }
        }

        for (const it of items) {
          const tsId = it?.timesheet_id ? String(it.timesheet_id) : null;
          if (!tsId) continue;
          const pc = pcMap.get(tsId);
          if (!pc) continue;
          it.precheck_status = pc.precheck_status;
          it.has_timesheet_evidence_pdf = pc.has_timesheet_evidence_pdf;
        }
      }
    } catch {
      // omit diagnostics on failure
    }

    // ✅ Pass-through: segment structures + history from manifest (single-source-of-truth support)
    const segments_on_invoice_by_timesheet =
      (manifest.segments_on_invoice_by_timesheet && typeof manifest.segments_on_invoice_by_timesheet === 'object')
        ? manifest.segments_on_invoice_by_timesheet
        : ((manifest.segments_by_timesheet && typeof manifest.segments_by_timesheet === 'object')
            ? manifest.segments_by_timesheet
            : null);

    const history = Array.isArray(manifest.history) ? manifest.history : [];

    // ✅ Additional pass-throughs for frontend convenience (already present in manifest, but exposed top-level)
    const tsfin_id_by_timesheet_id =
      (manifest.tsfin_id_by_timesheet_id && typeof manifest.tsfin_id_by_timesheet_id === 'object')
        ? manifest.tsfin_id_by_timesheet_id
        : {};

    const reference_rows = Array.isArray(manifest.reference_rows) ? manifest.reference_rows : [];

    // ✅ UPDATED: take reference sources directly from the manifest (RPC now embeds this)
    // Also: ensure any timesheet_ids mentioned by items/reference_rows have a key in the map.
    const timesheet_reference_sources_by_id = (() => {
      const out = Object.create(null);

      try {
        const src =
          (manifest.timesheet_reference_sources_by_id && typeof manifest.timesheet_reference_sources_by_id === 'object')
            ? manifest.timesheet_reference_sources_by_id
            : null;

        if (src) {
          for (const [k, v] of Object.entries(src)) {
            const tid = String(k || '').trim();
            if (!tid) continue;

            const obj = (v && typeof v === 'object') ? v : {};
            out[tid] = {
              reference_number: (obj.reference_number != null) ? obj.reference_number : null,
              day_references_json: (obj.day_references_json != null) ? obj.day_references_json : null,
              actual_schedule_json: (obj.actual_schedule_json != null) ? obj.actual_schedule_json : null
            };
          }
        }

        const idSet = new Set();

        for (const it of (items || [])) {
          const tid = it?.timesheet_id != null ? String(it.timesheet_id).trim() : '';
          if (tid) idSet.add(tid);
        }

        for (const rr of (reference_rows || [])) {
          if (!rr || typeof rr !== 'object') continue;
          const tid = rr.timesheet_id != null ? String(rr.timesheet_id).trim() : '';
          if (tid) idSet.add(tid);
        }

        for (const tid of idSet) {
          if (!out[tid]) {
            out[tid] = {
              reference_number: null,
              day_references_json: null,
              actual_schedule_json: null
            };
          }
        }
      } catch {}

      return out;
    })();

    // Optional correspondence (legacy query param)
    const includeCorr = new URL(req.url).searchParams.get('include_correspondence');
    if (includeCorr) {
      let correspondence = [];
      try {
        const { rows: corrRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/audit_events` +
          `?object_type=eq.invoice` +
          `&object_id_text=eq.${encodeURIComponent(invoiceId)}` +
          `&or=(action.eq.EMAIL_QUEUED,action.eq.EMAIL_SENT)` +
          `&select=ts_utc,action,after_json,correlation_id` +
          `&order=ts_utc.desc`
        );

        const mailIds = [...new Set((corrRows || []).map(r => r.correlation_id).filter(Boolean))];
        let mailMap = {};
        if (mailIds.length) {
          const { rows: mailRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/mail_outbox` +
            `?id=in.(${mailIds.map(encodeURIComponent).join(',')})` +
            `&select=id,to,cc,subject,status,created_at_utc,sent_at,failed_at,reference,provider_message_id`
          );
          mailMap = Object.fromEntries((mailRows || []).map(m => [m.id, m]));
        }

        correspondence = (corrRows || []).map(ev => ({
          ts_utc: ev.ts_utc,
          action: ev.action,
          correlation_id: ev.correlation_id || null,
          after_json: ev.after_json ?? null,
          email: ev.correlation_id && mailMap[ev.correlation_id] ? mailMap[ev.correlation_id] : null
        }));
      } catch {
        correspondence = [];
      }

      return withCORS(env, req, ok({
        manifest,

        invoice,
        items,
        header_snapshot_json,
        email_summary: manifest.email_summary ?? null,

        attach_policy: manifest.attach_policy ?? null,

        evidence: Array.isArray(manifest.evidence) ? manifest.evidence : [],
        timesheet_evidence: Array.isArray(manifest.timesheet_evidence) ? manifest.timesheet_evidence : [],
        evidence_other: Array.isArray(manifest.evidence_other) ? manifest.evidence_other : [],

        hr_source_rows_cache: Array.isArray(manifest.hr_source_rows_cache) ? manifest.hr_source_rows_cache : [],
        tsfin_external_source_rows: Array.isArray(manifest.tsfin_external_source_rows) ? manifest.tsfin_external_source_rows : [],

        segments_on_invoice_by_timesheet,
        segments_by_timesheet: segments_on_invoice_by_timesheet,
        history,
        tsfin_id_by_timesheet_id,
        reference_rows,

        // ✅ reference sources now come from the RPC (no extra DB reads here)
        timesheet_reference_sources_by_id,

        correspondence
      }));
    }

    return withCORS(env, req, ok({
      manifest,

      invoice,
      items,
      header_snapshot_json,
      email_summary: manifest.email_summary ?? null,

      attach_policy: manifest.attach_policy ?? null,

      evidence: Array.isArray(manifest.evidence) ? manifest.evidence : [],
      timesheet_evidence: Array.isArray(manifest.timesheet_evidence) ? manifest.timesheet_evidence : [],
      evidence_other: Array.isArray(manifest.evidence_other) ? manifest.evidence_other : [],

      hr_source_rows_cache: Array.isArray(manifest.hr_source_rows_cache) ? manifest.hr_source_rows_cache : [],
      tsfin_external_source_rows: Array.isArray(manifest.tsfin_external_source_rows) ? manifest.tsfin_external_source_rows : [],

      segments_on_invoice_by_timesheet,
      segments_by_timesheet: segments_on_invoice_by_timesheet,
      history,
      tsfin_id_by_timesheet_id,
      reference_rows,

      // ✅ reference sources now come from the RPC (no extra DB reads here)
      timesheet_reference_sources_by_id
    }));
  } catch {
    return withCORS(env, req, serverError('Failed to fetch invoice'));
  }
}

// ============================================================================
// NEW: ensureInvoicePdf(env, invoiceId, opts)
// - Internal helper (NO auth check, NO HTTP self-call)
// - If invoices.invoice_pdf_r2_key exists -> returns it
// - Otherwise renders + stores using the same core code as handleInvoiceRender
// - Re-reads invoice row afterwards and returns the updated key
//
// opts:
//   - req: optional Request (used for presignR2Url + download URL base)
//   - user: optional user object for audit attribution (can be null for system tasks)
// ============================================================================
async function ensureInvoicePdf(env, invoiceId, opts = {}) {
  const enc = encodeURIComponent;

  const req =
    (opts && opts.req) ||
    new Request((env.PUBLIC_DOWNLOAD_BASE_URL || 'https://localhost') + '/internal/ensure-invoice-pdf');

  // 1) Fast path: key already exists
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoiceId)}&select=id,invoice_pdf_r2_key&limit=1`
    );
    const inv0 = rows?.[0] || null;
    const existingKey = inv0?.invoice_pdf_r2_key ? String(inv0.invoice_pdf_r2_key).trim() : null;
    if (existingKey) {
      return { ok: true, invoice_id: invoiceId, invoice_pdf_r2_key: existingKey, rendered: false };
    }
  } catch {
    // fall through to render attempt
  }

  // 2) Render + store (shared core)
  const core = await _renderInvoiceBundleAndStore(env, req, invoiceId, opts.user || null);
  if (!core?.ok) {
    return { ok: false, invoice_id: invoiceId, rendered: false, error: core?.error || 'RENDER_FAILED' };
  }

  // 3) Re-read invoice row (explicit requirement)
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoiceId)}&select=id,invoice_pdf_r2_key&limit=1`
    );
    const inv1 = rows?.[0] || null;
    const key1 = inv1?.invoice_pdf_r2_key ? String(inv1.invoice_pdf_r2_key).trim() : null;

    if (!key1) {
      return { ok: false, invoice_id: invoiceId, rendered: true, error: 'RENDERED_BUT_KEY_NOT_SAVED' };
    }

    return {
      ok: true,
      invoice_id: invoiceId,
      invoice_pdf_r2_key: key1,
      rendered: true,
      attached_timesheets: core.attached_timesheets || 0,
      attached_hr: !!core.attached_hr,
      attached_nhsp: !!core.attached_nhsp,
      attached_evidence: core.attached_evidence || 0
    };
  } catch {
    // If re-read fails, still return key from core
    return {
      ok: true,
      invoice_id: invoiceId,
      invoice_pdf_r2_key: core.pdf_key,
      rendered: true,
      attached_timesheets: core.attached_timesheets || 0,
      attached_hr: !!core.attached_hr,
      attached_nhsp: !!core.attached_nhsp,
      attached_evidence: core.attached_evidence || 0,
      warning: 'RE_READ_FAILED'
    };
  }
}


// ============================================================================
// INTERNAL CORE: _renderInvoiceBundleAndStore(env, req, invoiceId, userForAudit)
// - Shared core logic for rendering + storing invoice bundle PDF
// - Returns { ok, pdf_key, attached_* counts }
// - Does NOT build a downloadUrl (that remains in handleInvoiceRender)
// ============================================================================

async function handleInvoiceBatchIssueCandidates(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const u = new URL(req.url);
  const allowEarly = (() => {
    const v = String(u.searchParams.get('allow_early') || '').trim().toLowerCase();
    return (v === '1' || v === 'true' || v === 'yes' || v === 'y' || v === 'on');
  })();

  const limit = (() => {
    const n = Number(u.searchParams.get('limit'));
    const v = Number.isFinite(n) ? Math.trunc(n) : 2000;
    return Math.max(1, Math.min(v, 20000));
  })();

  try {
    const res = await sbRpc(env, 'invoice_batch_issue_candidates', {
      p_allow_early: allowEarly,
      p_limit: limit
    });

    const groups = Array.isArray(res) ? res : (res?.data ?? res ?? []);
    return withCORS(env, req, ok({ allow_early: allowEarly, limit, groups }));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}
async function handleInvoiceBatchIssueConfirm(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body = null;
  try { body = await parseJSONBody(req); } catch {}
  if (!body || typeof body !== 'object') return withCORS(env, req, badRequest('Invalid JSON'));

  const invoiceIds = body.invoice_ids;
  if (!Array.isArray(invoiceIds) || invoiceIds.length === 0) {
    return withCORS(env, req, badRequest('invoice_ids[] is required'));
  }

  const allowEarly = (() => {
    const v = body.allow_early;
    if (v === true) return true;
    if (v === false) return false;
    const s = String(v || '').trim().toLowerCase();
    return (s === '1' || s === 'true' || s === 'yes' || s === 'y' || s === 'on');
  })();

  const enc = encodeURIComponent;

  const chunk = (arr, n) => {
    const out = [];
    for (let i = 0; i < (arr || []).length; i += n) out.push(arr.slice(i, i + n));
    return out;
  };

  const parseYmd = (s) => {
    const t = String(s || '').trim();
    return (/^\d{4}-\d{2}-\d{2}$/.test(t)) ? t : null;
  };

  const addDaysYmd = (ymd, days) => {
    const d0 = parseYmd(ymd);
    if (!d0) return null;
    const d = new Date(`${d0}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return null;
    d.setUTCDate(d.getUTCDate() + Number(days || 0));
    const yyyy = d.getUTCFullYear();
    const mm = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const getInvoiceWeekStartFromHeader = (header) => {
    if (!header || typeof header !== 'object') return null;
    const meta = (header.meta && typeof header.meta === 'object') ? header.meta : null;
    const v =
      (meta && (meta.invoice_week_start || meta.invoiceWeekStart || meta.week_start || meta.weekStart)) ||
      header.invoice_week_start ||
      header.invoiceWeekStart ||
      null;
    return parseYmd(v);
  };

  // Normalize/unique ids (strings are fine; PostgREST will cast to uuid)
  const ids = Array.from(new Set(invoiceIds.map(String).filter(Boolean)));

  try {
    const res = await sbRpc(env, 'invoice_issue_and_queue_emails_batch', {
      p_invoice_ids: ids,
      p_actor_user_id: user?.id || null,
      p_allow_early: allowEarly
    });

    const out = Array.isArray(res) ? (res[0] ?? res) : (res?.data ?? res);

    // Enrich per-invoice results with display fields (one bulk fetch + optional 2 more bulk fetches)
    const invoiceDisplayById = new Map();
    const candidateNamesByInvoiceId = new Map();

    if (ids.length) {
      // Bulk fetch invoices + client name
      for (const idChunk of chunk(ids, 200)) {
        const { rows: invRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/invoices` +
            `?id=in.(${idChunk.map(enc).join(',')})` +
            `&select=id,invoice_no,client_id,do_not_send,header_snapshot_json,client:clients(name)`,
          false
        );

        for (const r of (invRows || [])) {
          if (!r?.id) continue;
          const header = (r.header_snapshot_json && typeof r.header_snapshot_json === 'object') ? r.header_snapshot_json : {};
          const weekStart = getInvoiceWeekStartFromHeader(header);
          const weekEnd = weekStart ? addDaysYmd(weekStart, 6) : null;

          invoiceDisplayById.set(String(r.id), {
            invoice_id: String(r.id),
            invoice_no: r.invoice_no || null,
            client_id: r.client_id || null,
            client_name: r.client?.name || null,
            do_not_send: (r.do_not_send === true),
            invoice_week_start: weekStart,
            week_ending_date: weekEnd,
            header_snapshot_json: header
          });
        }
      }

      // Bulk fetch invoice_lines (invoice_id + timesheet_id) for candidate derivation
      const tsIds = new Set();
      const tsIdsByInvoice = new Map(); // invoice_id -> Set(timesheet_id)
      for (const idChunk of chunk(ids, 200)) {
        const { rows: lineRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/invoice_lines` +
            `?invoice_id=in.(${idChunk.map(enc).join(',')})` +
            `&select=invoice_id,timesheet_id`,
          false
        );

        for (const lr of (lineRows || [])) {
          const iid = lr?.invoice_id ? String(lr.invoice_id) : '';
          const tid = lr?.timesheet_id ? String(lr.timesheet_id) : '';
          if (!iid || !tid) continue;
          tsIds.add(tid);
          let set = tsIdsByInvoice.get(iid);
          if (!set) { set = new Set(); tsIdsByInvoice.set(iid, set); }
          set.add(tid);
        }
      }

      // Bulk fetch candidate_name from v_timesheets_summary_base
      const candByTs = new Map(); // timesheet_id -> candidate_name
      const tsIdsArr = Array.from(tsIds);
      for (const idChunk of chunk(tsIdsArr, 200)) {
        const { rows: sRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary_base` +
            `?timesheet_id=in.(${idChunk.map(enc).join(',')})` +
            `&select=timesheet_id,candidate_name`,
          false
        );
        for (const sr of (sRows || [])) {
          if (!sr?.timesheet_id) continue;
          candByTs.set(String(sr.timesheet_id), sr.candidate_name || null);
        }
      }

      for (const [iid, set] of tsIdsByInvoice.entries()) {
        const names = [];
        for (const tid of set) {
          const nm = candByTs.get(String(tid));
          if (nm) names.push(String(nm));
        }
        const uniq = Array.from(new Set(names.map(s => s.trim()).filter(Boolean)));
        const candidate_name = (uniq.length === 0) ? null : (uniq.length === 1 ? uniq[0] : 'Multiple');
        candidateNamesByInvoiceId.set(iid, { candidate_name, candidate_names: uniq });
      }
    }

    const invoice_results = Array.isArray(out?.invoice_results) ? out.invoice_results : [];
    const invoice_results_enriched = invoice_results.map((r) => {
      const iid = r?.invoice_id ? String(r.invoice_id) : '';
      const disp = iid ? (invoiceDisplayById.get(iid) || null) : null;
      const cand = iid ? (candidateNamesByInvoiceId.get(iid) || { candidate_name: null, candidate_names: [] }) : { candidate_name: null, candidate_names: [] };

      return {
        ...r,
        invoice_no: disp?.invoice_no || null,
        client_id: disp?.client_id || null,
        client_name: disp?.client_name || null,
        do_not_send: (disp?.do_not_send === true),
        invoice_week_start: disp?.invoice_week_start || null,
        week_ending_date: disp?.week_ending_date || null,
        candidate_name: cand.candidate_name,
        candidate_names: cand.candidate_names
      };
    });

    // Keep backwards compatibility: preserve original out, but add enriched results + convenience invoice map
    const invoice_map = {};
    for (const [iid, disp] of invoiceDisplayById.entries()) {
      const cand = candidateNamesByInvoiceId.get(iid) || { candidate_name: null, candidate_names: [] };
      invoice_map[iid] = {
        invoice_id: iid,
        invoice_no: disp?.invoice_no || null,
        client_id: disp?.client_id || null,
        client_name: disp?.client_name || null,
        do_not_send: (disp?.do_not_send === true),
        invoice_week_start: disp?.invoice_week_start || null,
        week_ending_date: disp?.week_ending_date || null,
        candidate_name: cand.candidate_name,
        candidate_names: cand.candidate_names
      };
    }

    return withCORS(env, req, ok({
      ...out,
      invoice_results_enriched,
      invoice_map
    }));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}
// ============================================================================
// UPDATED: handleInvoiceRender(env, req, invoiceId)
// - External admin handler remains
// - Uses shared core (no logic duplication)
// ============================================================================


async function handleInvoiceHold(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await parseJSONBody(req).catch(() => ({}));
  const reason = (body && typeof body.reason === 'string' && body.reason.trim()) ? body.reason.trim() : null;

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_hold_one', {
      p_invoice_id: invoiceId,
      p_actor_user_id: actorUserId,
      p_reason: reason
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x) return withCORS(env, req, serverError('Hold RPC returned no result'));

    return withCORS(env, req, ok({
      ok: true,
      status: x.status || 'ON_HOLD',
      on_hold_reason: x.on_hold_reason || reason || null
    }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to hold invoice'));
  }
}

async function handleInvoiceUnhold(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_unhold_one', {
      p_invoice_id: invoiceId,
      p_actor_user_id: actorUserId
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x) return withCORS(env, req, serverError('Unhold RPC returned no result'));

    return withCORS(env, req, ok({ ok: true, status: x.status || 'DRAFT' }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to unhold invoice'));
  }
}

async function handleInvoiceUnissue(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await parseJSONBody(req).catch(() => ({}));
  const clearPdf = !!body?.clear_pdf;

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_unissue_one', {
      p_invoice_id: invoiceId,
      p_actor_user_id: actorUserId,
      p_clear_pdf: clearPdf
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x) return withCORS(env, req, serverError('Unissue RPC returned no result'));

    return withCORS(env, req, ok({
      status: x.status || 'DRAFT',
      cleared_pdf: x.cleared_pdf === true
    }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to unissue invoice'));
  }
}




async function handleInvoiceCredit(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${encodeURIComponent(invoiceId)}&select=invoice_no,client_id`
    );
    if (!rows.length) return withCORS(env, req, notFound("Invoice not found"));
    const orig = rows[0];

    const { rows: latest } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices?select=invoice_no&order=invoice_no.desc&limit=1`
    );
    const nextNo = latest.length ? ((latest[0].invoice_no | 0) + 1) : 1001;

    const now = new Date().toISOString();
    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/invoices`, {
      method: "POST",
      headers: { ...sbHeaders(env), "Prefer": "return=representation" },
      body: JSON.stringify({
        client_id: orig.client_id,
        invoice_no: nextNo,
        type: "CREDIT_NOTE",
        status: "ISSUED",
        original_invoice_id: invoiceId,
        issued_at_utc: now
      })
    });
    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, serverError(`Credit note creation failed: ${err}`));
    }
    const json = await res.json().catch(() => ({}));
    const creditInv = Array.isArray(json) ? json[0] : json;

    // Mirror original lines with negative monetary amounts (hours unchanged)
    const { rows: origLines } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoice_lines?invoice_id=eq.${encodeURIComponent(invoiceId)}&select=id,invoice_id,timesheet_id,booking_id,description,hours_day,hours_night,hours_sat,hours_sun,hours_bh,pay_day,pay_night,pay_sat,pay_sun,pay_bh,charge_day,charge_night,charge_sat,charge_sun,charge_bh,total_pay_ex_vat,total_charge_ex_vat,margin_ex_vat,vat_rate_pct,vat_amount,total_inc_vat,paper_ts_r2_key`
    );

    const creditLines = origLines.map((l) => ({
      invoice_id: creditInv.id,
      timesheet_id: l.timesheet_id || null,
      booking_id: l.booking_id || null,
      description: l.description || null,
      hours_day: Number(l.hours_day || 0),
      hours_night: Number(l.hours_night || 0),
      hours_sat: Number(l.hours_sat || 0),
      hours_sun: Number(l.hours_sun || 0),
      hours_bh: Number(l.hours_bh || 0),
      pay_day: l.pay_day == null ? null : -Math.abs(Number(l.pay_day)),
      pay_night: l.pay_night == null ? null : -Math.abs(Number(l.pay_night)),
      pay_sat: l.pay_sat == null ? null : -Math.abs(Number(l.pay_sat)),
      pay_sun: l.pay_sun == null ? null : -Math.abs(Number(l.pay_sun)),
      pay_bh: l.pay_bh == null ? null : -Math.abs(Number(l.pay_bh)),
      charge_day: l.charge_day == null ? null : -Math.abs(Number(l.charge_day)),
      charge_night: l.charge_night == null ? null : -Math.abs(Number(l.charge_night)),
      charge_sat: l.charge_sat == null ? null : -Math.abs(Number(l.charge_sat)),
      charge_sun: l.charge_sun == null ? null : -Math.abs(Number(l.charge_sun)),
      charge_bh: l.charge_bh == null ? null : -Math.abs(Number(l.charge_bh)),
      total_pay_ex_vat: -Math.abs(Number(l.total_pay_ex_vat || 0)),
      total_charge_ex_vat: -Math.abs(Number(l.total_charge_ex_vat || 0)),
      margin_ex_vat: -Math.abs(Number(l.margin_ex_vat || 0)),
      vat_rate_pct: l.vat_rate_pct == null ? 20.0 : Number(l.vat_rate_pct),
      vat_amount: -Math.abs(Number(l.vat_amount || 0)),
      total_inc_vat: -Math.abs(Number(l.total_inc_vat || 0)),
      paper_ts_r2_key: l.paper_ts_r2_key || null
    }));

    if (creditLines.length) {
      const liRes = await fetch(`${env.SUPABASE_URL}/rest/v1/invoice_lines`, {
        method: "POST",
        headers: sbHeaders(env),
        body: JSON.stringify(creditLines)
      });
      if (!liRes.ok) {
        const err = await liRes.text();
        return withCORS(env, req, serverError(`Failed to insert credit lines: ${err}`));
      }
    }

    return withCORS(env, req, ok({ credit_invoice_id: creditInv.id, invoice_no: creditInv.invoice_no }));
  } catch {
    return withCORS(env, req, serverError("Failed to create credit note"));
  }
}


async function handleInvoiceMarkPaid(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const data = await parseJSONBody(req).catch(() => null);
  let paidAtIso = null;
  if (data && data.paid_date) {
    const pd = new Date(data.paid_date);
    if (!Number.isNaN(pd.getTime())) paidAtIso = pd.toISOString();
  }

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_mark_paid_one', {
      p_invoice_id: invoiceId,
      p_actor_user_id: actorUserId,
      p_paid_at: paidAtIso
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x) return serverError('Mark paid RPC returned no result');

    return withCORS(env, req, ok({ ok: true }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to mark invoice paid'));
  }
}

async function handleInvoiceMarkUnpaid(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_mark_unpaid_one', {
      p_invoice_id: invoiceId,
      p_actor_user_id: actorUserId
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x) return serverError('Mark unpaid RPC returned no result');

    return withCORS(env, req, ok({ ok: true }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to mark invoice unpaid'));
  }
}


// ====================== RELATED: COUNTS (generic) ======================
/**
 * @openapi
 * /api/related/{entity}/{id}/counts:
 *   get:
 *     summary: Get counts of related records for an entity (candidate, timesheet, invoice, remittance)
 *     tags: [Related]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: path
 *         name: entity
 *         required: true
 *         schema:
 *           type: string
 *           enum: [candidate, timesheet, invoice, remittance]
 *       - in: path
 *         name: id
 *         required: true
 *         schema:
 *           type: string
 *           description: The entity identifier (UUID for candidate/timesheet/invoice; mail_outbox.id for remittance)
 *     responses:
 *       200:
 *         description: Counts keyed by related type for the given entity.
 *         content:
 *           application/json:
 *             schema:
 *               oneOf:
 *                 - type: object
 *                   properties:
 *                     timesheets: { type: integer }
 *                     invoices:   { type: integer }
 *                     remittances:{ type: integer }
 *                 - type: object
 *                   properties:
 *                     candidate:  { type: integer }
 *                     invoice:    { type: integer }
 *                     remittances:{ type: integer }
 *                 - type: object
 *                   properties:
 *                     timesheets:     { type: integer }
 *                     candidates:     { type: integer }
 *                     correspondence: { type: integer }
 *                 - type: object
 *                   properties:
 *                     timesheets: { type: integer }
 *                     candidate:  { type: integer }
 */


// ─────────────────────────────────────────────────────────────────────────────
// Rates: LIST CLIENT DEFAULTS (UNIFIED WINDOW)
// GET /api/rates/client-defaults
// Supports: client_id, role, band, active_on, limit, offset, only_enabled
// - only_enabled=true → adds disabled_at_utc=is.null to the query
// ─────────────────────────────────────────────────────────────────────────────

async function handleListClientRates(env, req, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const sp         = new URL(req.url).searchParams;
  const cid        = clientId || sp.get("client_id");
  const role       = sp.get("role");
  const bandRaw    = sp.get("band");
  const on         = sp.get("active_on");
  const onlyEnabled= sp.get("only_enabled") === 'true';

  const limit   = Math.min(Math.max(parseInt(sp.get('limit')  || '100', 10) || 100, 1), 500);
  const offset  = Math.max(parseInt(sp.get('offset') || '0',   10) || 0, 0);

  try {
    // Base query
    let q = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?select=*`;

    if (cid)  q += `&client_id=eq.${encodeURIComponent(cid)}`;
    if (role) q += `&role=eq.${encodeURIComponent(role)}`;

    // Band filter: explicit '' or 'null' → IS NULL; otherwise exact match.
    if (bandRaw !== null) {
      if (bandRaw === '' || String(bandRaw).toLowerCase() === 'null') q += `&band=is.null`;
      else q += `&band=eq.${encodeURIComponent(bandRaw)}`;
    }

    // Active-on-date filter
    if (on) {
      q += `&date_from=lte.${encodeURIComponent(on)}`;
      q += `&or=(date_to.gte.${encodeURIComponent(on)},date_to.is.null)`;
    }

    // Enabled-only filter
    if (onlyEnabled) q += `&disabled_at_utc=is.null`;

    // Order & pagination
    q += `&order=date_from.desc,role.asc,band.nullsfirst&limit=${limit}&offset=${offset}`;

    const { rows } = await sbFetch(env, q);

    // Enrich with disabled_by_name (email local-part), and strip disabled_by
    const ids = Array.from(
      new Set(
        (rows || [])
          .filter(r => r && r.disabled_by)
          .map(r => String(r.disabled_by))
      )
    );

    const idToName = new Map();

    if (ids.length) {
      // Build IN list WITHOUT URL-encoding the parentheses; PostgREST expects raw "(id1,id2,...)"
      const inList = `(${ids.join(',')})`;

      const ures = await fetch(
        `${env.SUPABASE_URL}/rest/v1/tms_users?select=id,email&id=in.${inList}`,
        { method:'GET', headers: { ...sbHeaders(env) } }
      );

      if (ures.ok) {
        const urows = await ures.json().catch(()=>[]);
        for (const u of (urows || [])) {
          const em = (u && typeof u.email === 'string') ? u.email : '';
          const short = em && em.includes('@') ? em.split('@')[0] : null;
          if (u?.id) idToName.set(String(u.id), short);
        }
      } else {
        // If lookup fails, leave map empty; FE will render blank (no "unknown")
      }
    }

    const enriched = (rows || []).map(r => {
      const out = { ...r };
      if (out.disabled_by) {
        out.disabled_by_name = idToName.get(String(out.disabled_by)) ?? null;
        delete out.disabled_by; // do not leak UUID
      }
      return out;
    });

    return withCORS(env, req, ok({ items: enriched }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to fetch client default rates"));
  }
}


// ─────────────────────────────────────────────────────────────────────────────
// Rates: upsert client default (now requires rate_type; uniqueness includes it)
// ─────────────────────────────────────────────────────────────────────────────

// ─────────────────────────────────────────────────────────────────────────────
// Rates: upsert client default (require rate_type; enqueue RATE_CHANGED by rate_type)
// ─────────────────────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────────────────────
// Rates: CLIENT DEFAULTS (UNIFIED WINDOW)
// POST /api/rates/client-defaults
// - Unified payload: one row holds 5×charge + 5×PAYE + 5×Umbrella
// - No rate_type in API
// - On insert with start N: truncate incumbent window (same category) to N−1
// - If a later window exists and new.date_to is null or overlaps, clamp new.date_to to (nextStart−1)
// - Unique key: (client_id, role, band|null, date_from)
// - Enqueue TSFIN recompute for current, unlocked rows for this client (all pay methods)
// ─────────────────────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────────────────────
// Rates: CLIENT DEFAULTS (UNIFIED WINDOW) UPSERT
// POST /api/rates/client-defaults
// - Unified payload: one row holds 5×charge + 5×PAYE + 5×Umbrella
// - No rate_type in API
// - Insert with start N: truncate incumbent (enabled-only) to N−1
// - If a later (enabled) window exists and new.date_to is null/overlaps, clamp new.date_to to (nextStart−1)
// - Unique key: (client_id, role, band|null, date_from) — DB enforces only for enabled rows
// - Enqueue TSFIN recompute **only if today is within [date_from, date_to] inclusive**
// ─────────────────────────────────────────────────────────────────────────────
async function handleUpsertClientRate(env, req, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const body = await parseJSONBody(req);
  if (!body) return withCORS(env, req, badRequest("Invalid JSON"));

  // Expect unified fields in the body
  const rec = {
    client_id: body.client_id || clientId,
    role:      body.role ?? null,
    band:      (body.band === '' ? null : body.band ?? null),
    date_from: body.date_from ?? null,
    date_to:   (body.date_to === '' ? null : body.date_to ?? null),

    // charge (5)
    charge_day:   body.charge_day   ?? null,
    charge_night: body.charge_night ?? null,
    charge_sat:   body.charge_sat   ?? null,
    charge_sun:   body.charge_sun   ?? null,
    charge_bh:    body.charge_bh    ?? null,

    // PAYE (5)
    paye_day:   body.paye_day   ?? null,
    paye_night: body.paye_night ?? null,
    paye_sat:   body.paye_sat   ?? null,
    paye_sun:   body.paye_sun   ?? null,
    paye_bh:    body.paye_bh    ?? null,

    // Umbrella (5)
    umb_day:    body.umb_day    ?? null,
    umb_night:  body.umb_night  ?? null,
    umb_sat:    body.umb_sat    ?? null,
    umb_sun:    body.umb_sun    ?? null,
    umb_bh:     body.umb_bh     ?? null
  };

  if (!rec.client_id) return withCORS(env, req, badRequest("client_id required"));
  if (!rec.role)       return withCORS(env, req, badRequest("role required"));
  if (!rec.date_from)  return withCORS(env, req, badRequest("date_from required"));

  const client_id = rec.client_id;
  const role      = rec.role;
  const band      = rec.band;
  const dateFrom  = rec.date_from;

  // Helper: encode "(band is null)" vs "band = value"
  const bandFilter = (b) => (b == null ? 'band=is.null' : `band=eq.${encodeURIComponent(b)}`);

  // Helper: YMD day before
  function dayBeforeYmd(ymd) {
    if (!ymd) return null;
    const d = new Date(`${ymd}T00:00:00Z`);
    d.setUTCDate(d.getUTCDate() - 1);
    const y = d.getUTCFullYear();
    const m = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${y}-${m}-${dd}`;
  }

  // Helper: is today within [from, to] inclusive (to may be null = open)
  function todayWithinWindow(fromYmd, toYmd) {
    if (!fromYmd) return false;
    const today = new Date().toISOString().slice(0, 10);
    if (today < String(fromYmd)) return false;
    if (toYmd && today > String(toYmd)) return false;
    return true;
  }

  try {
    // 0) UPDATE path? (exact unique key exists among ENABLED rows)
    {
      let q = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
              `?client_id=eq.${encodeURIComponent(client_id)}` +
              `&role=eq.${encodeURIComponent(role)}` +
              `&${bandFilter(band)}` +
              `&date_from=eq.${encodeURIComponent(dateFrom)}` +
              `&disabled_at_utc=is.null` +                 // ← ignore disabled rows
              `&select=id`;
      const { rows: exactRows } = await sbFetch(env, q);
      if (Array.isArray(exactRows) && exactRows.length === 1) {
        const id = exactRows[0].id;
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?id=eq.${encodeURIComponent(id)}`,
          { method: "PATCH", headers: { ...sbHeaders(env), "Prefer": "return=representation" }, body: JSON.stringify({ ...rec, updated_at: nowIso() }) }
        );
        if (!res.ok) {
          const err = await res.text();
          return withCORS(env, req, badRequest(`Rate update failed: ${err}`));
        }
        const json = await res.json().catch(() => ({}));
        const result = Array.isArray(json) ? json[0] : json;

        // Enqueue recompute ONLY if window is currently effective (inclusive)
        if (todayWithinWindow(rec.date_from, rec.date_to)) {
          await enqueueTsfinRecomputeForClient(env, client_id);
        }

        return withCORS(env, req, ok({ rate: result }));
      }
    }

    // 1) INSERT path — rollover behavior & no overlaps (consider ENABLED rows only)
    // 1a) Find incumbent window (same category) active at new start N = dateFrom
    {
      let qInc = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
                 `?client_id=eq.${encodeURIComponent(client_id)}` +
                 `&role=eq.${encodeURIComponent(role)}` +
                 `&${bandFilter(band)}` +
                 `&date_from=lte.${encodeURIComponent(dateFrom)}` +
                 `&or=(date_to.gte.${encodeURIComponent(dateFrom)},date_to.is.null)` +
                 `&disabled_at_utc=is.null` +               // ← ignore disabled rows
                 `&select=id,date_from,date_to` +
                 `&order=date_from.desc&limit=2`;
      const { rows: incumbents } = await sbFetch(env, qInc);

      if (incumbents.length > 1) {
        return withCORS(env, req, badRequest("Multiple incumbent windows found at the proposed start date. Please tidy overlaps first."));
      }
      if (incumbents.length === 1) {
        const inc = incumbents[0];
        if (String(inc.date_from) === String(dateFrom)) {
          return withCORS(env, req, badRequest("A window for this role/band already starts on the same date. Edit that window instead or choose a different start."));
        }
        const cut = dayBeforeYmd(dateFrom);
        if (inc.date_from && cut < inc.date_from) {
          return withCORS(env, req, badRequest("Proposed start would back-cut before the incumbent's start. Adjust dates."));
        }
        // Truncate incumbent to N−1
        const p = await fetch(
          `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?id=eq.${encodeURIComponent(inc.id)}`,
          { method: "PATCH", headers: { ...sbHeaders(env), "Prefer": "return=representation" }, body: JSON.stringify({ date_to: cut, updated_at: nowIso() }) }
        );
        if (!p.ok) {
          const err = await p.text();
          return withCORS(env, req, badRequest(`Failed to truncate incumbent: ${err}`));
        }
      }
    }

    // 1b) If a later ENABLED window exists, clamp new.date_to to the day before the next start
    {
      let qNext = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
                  `?client_id=eq.${encodeURIComponent(client_id)}` +
                  `&role=eq.${encodeURIComponent(role)}` +
                  `&${bandFilter(band)}` +
                  `&date_from=gt.${encodeURIComponent(dateFrom)}` +
                  `&disabled_at_utc=is.null` +             // ← ignore disabled rows
                  `&select=date_from` +
                  `&order=date_from.asc&limit=1`;
      const { rows: nexts } = await sbFetch(env, qNext);
      if (Array.isArray(nexts) && nexts.length === 1) {
        const nextStart = nexts[0].date_from;
        const clampTo = dayBeforeYmd(nextStart);
        if (!rec.date_to || rec.date_to > clampTo) {
          rec.date_to = clampTo;
        }
      }
    }

    // 2) Insert the new unified window
    {
      const res = await fetch(`${env.SUPABASE_URL}/rest/v1/rates_client_defaults`, {
        method: "POST",
        headers: { ...sbHeaders(env), "Prefer": "return=representation" },
        body: JSON.stringify({ ...rec, created_at: nowIso() })
      });
      if (!res.ok) {
        const err = await res.text();
        return withCORS(env, req, badRequest(`Rate insert failed: ${err}`));
      }
      const json = await res.json().catch(() => ({}));
      const result = Array.isArray(json) ? json[0] : json;

      // Enqueue recompute ONLY if window is currently effective (inclusive)
      if (todayWithinWindow(rec.date_from, rec.date_to)) {
        await enqueueTsfinRecomputeForClient(env, client_id);
      }

      return withCORS(env, req, ok({ rate: result }));
    }
  } catch (e) {
    return withCORS(env, req, serverError("Failed to upsert client default window"));
  }
}

// Toggle enable/disable for a client default rate window
// PATCH /api/rates/client-defaults/:id
// Body: { "disabled": true|false }

async function handlePatchClientDefault(env, req, rateId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const body = await parseJSONBody(req);
  if (!body || typeof body.disabled !== 'boolean') {
    return withCORS(env, req, badRequest('Field "disabled" (boolean) is required.'));
  }

  const now = nowIso();
  const patch = body.disabled
    ? { disabled_at_utc: now, disabled_by: user.id, updated_at: now }
    : { disabled_at_utc: null, disabled_by: null,     updated_at: now };

  // Apply patch and return the updated row
  const url = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?id=eq.${encodeURIComponent(rateId)}`;
  const res = await fetch(url, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(patch),
  });

  if (!res.ok) {
    const msg = await res.text().catch(() => '');
    return withCORS(env, req, badRequest(msg || `Failed to toggle rate window (status ${res.status})`));
  }

  const rows = await res.json().catch(() => []);
  const updated = Array.isArray(rows) ? rows[0] : rows;
  if (!updated) return withCORS(env, req, serverError('Toggle succeeded but no row returned.'));

  // Compute short name from tms_users.email (left-of-@), fallback to auth user email if needed.
  let disabled_by_name = null;
  if (updated.disabled_by) {
    try {
      const ures = await fetch(
        `${env.SUPABASE_URL}/rest/v1/tms_users?select=id,email&id=eq.${encodeURIComponent(updated.disabled_by)}`,
        { method: 'GET', headers: { ...sbHeaders(env) } }
      );
      if (ures.ok) {
        const arr = await ures.json().catch(()=>[]);
        if (Array.isArray(arr) && arr[0]) {
          const em = (arr[0].email || '');
          disabled_by_name = (typeof em === 'string' && em.includes('@')) ? em.split('@')[0] : null;
        }
      }
    } catch (_) {
      // fall through to auth user fallback
    }
  }
  if (!disabled_by_name) {
    const em = (user && typeof user.email === 'string') ? user.email : '';
    disabled_by_name = (em && em.includes('@')) ? em.split('@')[0] : null;
  }

  // enqueue TSFIN recompute only if window is currently effective
  const today = new Date().toISOString().slice(0,10);
  const fromYmd = String(updated.date_from || '');
  const toYmd   = updated.date_to ? String(updated.date_to) : null;
  const inWindow = fromYmd && (fromYmd <= today) && (!toYmd || today <= toYmd);
  if (updated?.client_id && inWindow) {
    try { await enqueueTsfinRecomputeForClient(env, updated.client_id); } catch (_) {}
  }

  const { disabled_by, ...rest } = updated;
  return withCORS(env, req, ok({ rate: { ...rest, disabled_by_name: disabled_by_name || null } }));
}



























 async function handleContractChangeRatesPreview(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!contractId) return withCORS(env, req, badRequest('contract_id required'));

  const url = new URL(req.url);

  // Normalise YYYY-MM-DD or ISO into YMD safely
  const cutoffRaw = url.searchParams.get('cutoff_week_ending_date') || null;
  let cutoffYmd = null;
  if (cutoffRaw) {
    try {
      cutoffYmd = toYmd(cutoffRaw);
    } catch {
      cutoffYmd = null;
    }
  }

  // Load the contract shell for context
  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts` +
    `?id=eq.${enc(contractId)}&select=id,start_date,end_date,pay_method_snapshot`
  );
  if (!contract) {
    return withCORS(env, req, notFound('Contract not found'));
  }

  // Use the shared helper to find outstanding weeks for this contract
  const weeksRaw = await findOutstandingWeeksForContract(env, contractId, cutoffYmd);
  const weeks = Array.isArray(weeksRaw) ? weeksRaw : [];

  return withCORS(env, req, ok({
    contract_id: contract.id,
    start_date: contract.start_date,
    end_date: contract.end_date,
    pay_method_snapshot: contract.pay_method_snapshot,
    cutoff_week_ending_date: cutoffYmd || null,
    weeks: weeks.map(w => ({
      week_id: w.id,
      week_ending_date: w.week_ending_date,
      status: w.status,
      timesheet_id: w.timesheet_id,
      is_invoiced: w.is_invoiced,
      is_paid: w.is_paid
    }))
  }));
}

async function handleContractChangeRatesOutstanding(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!contractId) return withCORS(env, req, badRequest('contract_id required'));

  const method = (req.method || 'GET').toUpperCase();
  const url = new URL(req.url);

  // Small helper: normalise YYYY-MM-DD or ISO into YMD
  const toYmdSafe = (val) => {
    if (!val) return null;
    try {
      return toYmd(val); // existing helper already in this file
    } catch {
      return null;
    }
  };

  // Shared helper: load outstanding weeks for this contract
  const findOutstandingWeeks = async (cutoffYmd /* may be null */) => {
    const filters = [
      `contract_id=eq.${enc(contractId)}`,
      'additional_seq=eq.0' // only primary weeks; additional handled manually if needed
    ];
    if (cutoffYmd) {
      filters.push(`week_ending_date=gte.${enc(cutoffYmd)}`);
    }

    const cwUrl =
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?select=id,week_ending_date,additional_seq,status,timesheet_id` +
      `&${filters.join('&')}` +
      `&order=week_ending_date.asc,additional_seq.asc`;

    const { rows: weeks } = await sbFetch(env, cwUrl);
    const list = Array.isArray(weeks) ? weeks : [];

    const tsIds = Array.from(
      new Set(list.map(w => w.timesheet_id).filter(Boolean).map(String))
    );

    const finByTsId = new Map();

    if (tsIds.length) {
      const finUrl =
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?is_current=eq.true` +
        `&timesheet_id=in.(${tsIds.map(enc).join(',')})` +
        `&select=timesheet_id,locked_by_invoice_id,paid_at_utc`;
      const { rows: fins } = await sbFetch(env, finUrl);
      for (const r of (fins || [])) {
        if (r && r.timesheet_id) {
          finByTsId.set(String(r.timesheet_id), r);
        }
      }
    }

    return list.map(w => {
      const tsId = w.timesheet_id ? String(w.timesheet_id) : null;
      const fin = tsId ? finByTsId.get(tsId) || null : null;
      const isInvoiced = !!(fin && fin.locked_by_invoice_id);
      const isPaid = !!(fin && fin.paid_at_utc);
      const isOutstanding = !tsId || (!isInvoiced && !isPaid);
      return {
        id: w.id,
        week_ending_date: w.week_ending_date,
        additional_seq: w.additional_seq,
        status: w.status,
        timesheet_id: w.timesheet_id || null,
        is_invoiced: isInvoiced,
        is_paid: isPaid,
        outstanding: isOutstanding
      };
    }).filter(w => w.outstanding);
  };

  if (method === 'GET') {
    // Preview mode: list all outstanding weeks for this contract (optionally from cutoff)
    const cutoffRaw = url.searchParams.get('cutoff_week_ending_date') || null;
    const cutoffYmd = toYmdSafe(cutoffRaw);

    const contract = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?id=eq.${enc(contractId)}&select=id,start_date,end_date,pay_method_snapshot`
    );
    if (!contract) {
      return withCORS(env, req, notFound('Contract not found'));
    }

    const weeks = await findOutstandingWeeks(cutoffYmd);
    return withCORS(env, req, ok({
      contract_id: contract.id,
      start_date: contract.start_date,
      end_date: contract.end_date,
      pay_method_snapshot: contract.pay_method_snapshot,
      cutoff_week_ending_date: cutoffYmd || null,
      weeks: weeks.map(w => ({
        week_id: w.id,
        week_ending_date: w.week_ending_date,
        status: w.status,
        timesheet_id: w.timesheet_id,
        is_invoiced: w.is_invoiced,
        is_paid: w.is_paid
      }))
    }));
  }

  if (method !== 'POST') {
    return withCORS(env, req, badRequest('Only GET and POST are supported'));
  }

  // Mutation: create successor contract, move outstanding weeks, rebuild TSFIN for weekly
  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const cutoffYmd = toYmdSafe(body?.cutoff_week_ending_date);
  if (!cutoffYmd) {
    return withCORS(env, req, badRequest('cutoff_week_ending_date (YYYY-MM-DD) is required'));
  }

  const newRates = body?.rates_json && typeof body.rates_json === 'object'
    ? body.rates_json
    : null;

  if (!newRates) {
    return withCORS(env, req, badRequest('rates_json (object) is required'));
  }

  const newStdSchedule = (body && body.std_schedule_json && typeof body.std_schedule_json === 'object')
    ? body.std_schedule_json
    : null;

  // Load original contract (includes additional_rates_json)
  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts` +
    `?id=eq.${enc(contractId)}&select=*`
  );
  if (!contract) {
    return withCORS(env, req, notFound('Contract not found'));
  }

  // Find all outstanding weeks at/after cutoff
  const outstandingWeeks = await findOutstandingWeeks(cutoffYmd);
  if (!outstandingWeeks.length) {
    return withCORS(env, req, badRequest('No outstanding weeks at or after the cutoff date'));
  }

  // Earliest week-ending among those outstanding
  const earliestWe = outstandingWeeks
    .map(w => w.week_ending_date)
    .filter(Boolean)
    .sort()[0];

  const earliestStart = addDays(earliestWe, -6); // start-of-week = week-ending minus 6 days

  // Derive std_hours_json from schedule if provided, else reuse existing
  let successorStdSchedule = newStdSchedule != null ? newStdSchedule : (contract.std_schedule_json || null);
  let successorStdHours = null;
  if (successorStdSchedule) {
    try {
      successorStdHours = deriveStdHoursFromSchedule(successorStdSchedule);
    } catch (e) {
      return withCORS(env, req, badRequest(e?.message || 'Invalid std_schedule_json'));
    }
  } else {
    successorStdHours = contract.std_hours_json || null;
  }

  // Create successor contract C2
  const now = nowIso();
  const successorPayload = {
    candidate_id: contract.candidate_id,
    client_id: contract.client_id,
    role: contract.role,
    band: contract.band,
    display_site: contract.display_site,
    ward_hint: contract.ward_hint,
    start_date: earliestStart,
    end_date: contract.end_date,
    pay_method_snapshot: contract.pay_method_snapshot,
    rates_json: newRates,
    std_schedule_json: successorStdSchedule,
    std_hours_json: successorStdHours,
    bucket_labels_json: contract.bucket_labels_json,
    // carry over any configured additional per-unit buckets
    additional_rates_json: contract.additional_rates_json || null,
    default_submission_mode: contract.default_submission_mode,
    week_ending_weekday_snapshot: contract.week_ending_weekday_snapshot,
    auto_invoice: contract.auto_invoice,
    require_reference_to_pay: contract.require_reference_to_pay,
    require_reference_to_invoice: contract.require_reference_to_invoice,
    mileage_pay_rate: contract.mileage_pay_rate,
    mileage_charge_rate: contract.mileage_charge_rate,
    created_at: now,
    updated_at: now
  };

  const ins = await fetch(
    `${env.SUPABASE_URL}/rest/v1/contracts`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(successorPayload)
    }
  );
  if (!ins.ok) {
    const txt = await ins.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to create successor contract: ${txt || ins.status}`));
  }
  const insJson = await ins.json().catch(() => []);
  const successor = Array.isArray(insJson) ? insJson[0] : insJson;
  if (!successor || !successor.id) {
    return withCORS(env, req, serverError('Failed to create successor contract (no row returned)'));
  }

  // Truncate original contract end_date to the day before the new start
  let truncatedEnd = addDays(earliestStart, -1);
  if (truncatedEnd < contract.start_date) truncatedEnd = contract.start_date;

  try {
    if (truncatedEnd !== contract.end_date) {
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
          body: JSON.stringify({ end_date: truncatedEnd, updated_at: nowIso() })
        }
      );
    }
  } catch (e) {
    // Non-fatal, but log
    try { console.warn('[CONTRACTS][CHANGE-RATES] truncate original failed', e); } catch {}
  }

  // Move outstanding weeks + timesheets to successor
  const weekIds = outstandingWeeks.map(w => w.id).filter(Boolean);
  const tsIds = Array.from(
    new Set(outstandingWeeks.map(w => w.timesheet_id).filter(Boolean).map(String))
  );

  if (weekIds.length) {
    const cwPatchUrl =
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?id=in.(${weekIds.map(enc).join(',')})`;
    await fetch(cwPatchUrl, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({ contract_id: successor.id, updated_at: nowIso() })
    });
  }

  if (tsIds.length) {
    const tsPatchUrl =
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=in.(${tsIds.map(enc).join(',')})`;
    await fetch(tsPatchUrl, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({ contract_id: successor.id, updated_at: nowIso() })
    });
  }

  // Clean up any future weeks on the old contract without timesheets (beyond truncated end)
  try {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(contractId)}` +
      `&week_ending_date=gt.${enc(truncatedEnd)}` +
      `&timesheet_id=is.null`,
      {
        method: 'DELETE',
        headers: { ...sbHeaders(env), Prefer: 'return=minimal' }
      }
    );
  } catch (e) {
    try { console.warn('[CONTRACTS][CHANGE-RATES] prune future empty weeks failed', e); } catch {}
  }

  // Generate full future weeks for successor (non-fatal if this fails)
  try {
    if (typeof handleContractsGenerateWeeks === 'function') {
      await handleContractsGenerateWeeks(env, req, successor.id);
    }
  } catch (e) {
    try { console.warn('[CONTRACTS][CHANGE-RATES] generate-weeks for successor failed', e); } catch {}
  }

  // ✅ NEW: SQL-first targeted TSFIN recompute (bulk enqueue + deterministic targeted drain)
  // This avoids per-timesheet REST policy loads and prevents subrequest blowups.
  try {
    if (tsIds.length) {
      await tsfinTargetedDrainNow(env, {
        timesheetIds: tsIds,
        reason: 'RATE_CHANGED',
        chunkSize: 50
      });
    }
  } catch (e) {
    // Non-fatal: items are at least enqueued; inline drain may not complete.
    try { console.warn('[CONTRACTS][CHANGE-RATES] tsfinTargetedDrainNow failed', e); } catch {}
  }

  return withCORS(env, req, ok({
    old_contract_id: contract.id,
    new_contract_id: successor.id,
    cutoff_week_ending_date: cutoffYmd,
    weeks_migrated: weekIds.length,
    timesheets_migrated: tsIds.length
  }));
}

async function cloneContractForRatesChange(env, contract, overrides = {}) {
  if (!contract || !contract.id) {
    throw new Error('cloneContractForRatesChange: source contract missing or invalid');
  }

  const ov = overrides || {};

  const start_date = ov.start_date || contract.start_date;
  const end_date   = ov.end_date   || contract.end_date;

  // std_schedule_json / std_hours_json composition:
  // 1) prefer explicit override std_schedule_json if supplied
  // 2) else use contract.std_schedule_json
  // 3) derive std_hours_json from schedule if present
  // 4) else fall back to override.std_hours_json or contract.std_hours_json
  let successorStdSchedule =
    (Object.prototype.hasOwnProperty.call(ov, 'std_schedule_json'))
      ? (ov.std_schedule_json || null)
      : (contract.std_schedule_json || null);

  // Handle stringified JSON defensively
  if (successorStdSchedule && typeof successorStdSchedule === 'string') {
    try { successorStdSchedule = JSON.parse(successorStdSchedule); } catch { /* leave as-is; deriveStdHoursFromSchedule will throw */ }
  }

  let successorStdHours = null;
  if (successorStdSchedule && typeof successorStdSchedule === 'object') {
    // Derive hours from schedule
    successorStdHours = deriveStdHoursFromSchedule(successorStdSchedule);
  } else {
    successorStdHours =
      (Object.prototype.hasOwnProperty.call(ov, 'std_hours_json'))
        ? (ov.std_hours_json || null)
        : (contract.std_hours_json || null);
  }

  // Helper: allow explicit null in overrides to clear nullable contract override fields
  const boolOrNull = (v, fallback) => {
    if (v === null) return null;
    if (v === undefined) return fallback;
    return (v === true || v === 'true' || v === 1 || v === '1' || v === 'on');
  };

  // NEW: copy contract route/calc/group flags into successor (allow override if present)
  const successor_is_nhsp =
    (Object.prototype.hasOwnProperty.call(ov, 'is_nhsp'))
      ? boolOrNull(ov.is_nhsp, contract.is_nhsp ?? null)
      : (contract.is_nhsp ?? null);

  const successor_autoprocess_hr =
    (Object.prototype.hasOwnProperty.call(ov, 'autoprocess_hr'))
      ? boolOrNull(ov.autoprocess_hr, contract.autoprocess_hr ?? null)
      : (contract.autoprocess_hr ?? null);

  const successor_requires_hr =
    (Object.prototype.hasOwnProperty.call(ov, 'requires_hr'))
      ? boolOrNull(ov.requires_hr, contract.requires_hr ?? null)
      : (contract.requires_hr ?? null);

  const successor_no_timesheet_required =
    (Object.prototype.hasOwnProperty.call(ov, 'no_timesheet_required'))
      ? boolOrNull(ov.no_timesheet_required, contract.no_timesheet_required ?? null)
      : (contract.no_timesheet_required ?? null);

  const successor_daily_calc_of_invoices =
    (Object.prototype.hasOwnProperty.call(ov, 'daily_calc_of_invoices'))
      ? boolOrNull(ov.daily_calc_of_invoices, contract.daily_calc_of_invoices ?? null)
      : (contract.daily_calc_of_invoices ?? null);

  const successor_group_nightsat_sunbh =
    (Object.prototype.hasOwnProperty.call(ov, 'group_nightsat_sunbh'))
      ? boolOrNull(ov.group_nightsat_sunbh, contract.group_nightsat_sunbh ?? null)
      : (contract.group_nightsat_sunbh ?? null);

  const successor_self_bill =
    (Object.prototype.hasOwnProperty.call(ov, 'self_bill'))
      ? boolOrNull(ov.self_bill, contract.self_bill ?? null)
      : (contract.self_bill ?? null);

  // Friendly validation mirroring DB constraints (validate successor state)
  if (successor_is_nhsp === true && successor_autoprocess_hr === true) {
    throw new Error('cloneContractForRatesChange: invalid successor route (is_nhsp=true and autoprocess_hr=true cannot both be true)');
  }
  if (successor_no_timesheet_required === true && successor_autoprocess_hr !== true) {
    throw new Error('cloneContractForRatesChange: invalid successor route (no_timesheet_required=true requires autoprocess_hr=true)');
  }

  const now = nowIso();

  const payload = [{
    // Identity / linkage
    candidate_id: (Object.prototype.hasOwnProperty.call(ov, 'candidate_id') ? ov.candidate_id : contract.candidate_id),
    client_id:    (Object.prototype.hasOwnProperty.call(ov, 'client_id')    ? ov.client_id    : contract.client_id),
    role:         (Object.prototype.hasOwnProperty.call(ov, 'role')         ? ov.role         : contract.role),
    band:         (Object.prototype.hasOwnProperty.call(ov, 'band')         ? ov.band         : contract.band),
    display_site: (Object.prototype.hasOwnProperty.call(ov, 'display_site') ? ov.display_site : contract.display_site),
    ward_hint:    (Object.prototype.hasOwnProperty.call(ov, 'ward_hint')    ? ov.ward_hint    : contract.ward_hint),

    // Window
    start_date,
    end_date,

    // NEW: route/calc/group overrides copied forward (and overridable)
    is_nhsp: successor_is_nhsp,
    autoprocess_hr: successor_autoprocess_hr,
    requires_hr: successor_requires_hr,
    no_timesheet_required: successor_no_timesheet_required,
    daily_calc_of_invoices: successor_daily_calc_of_invoices,
    group_nightsat_sunbh: successor_group_nightsat_sunbh,
    self_bill: successor_self_bill,

    // Pay method + rates
    pay_method_snapshot: (Object.prototype.hasOwnProperty.call(ov, 'pay_method_snapshot')
      ? ov.pay_method_snapshot
      : contract.pay_method_snapshot),
    rates_json: (Object.prototype.hasOwnProperty.call(ov, 'rates_json')
      ? (ov.rates_json || {})
      : (contract.rates_json || {})),

    // Submission + week ending policy
    default_submission_mode: (Object.prototype.hasOwnProperty.call(ov, 'default_submission_mode')
      ? ov.default_submission_mode
      : contract.default_submission_mode),
    week_ending_weekday_snapshot: (ov.week_ending_weekday_snapshot != null
      ? Number(ov.week_ending_weekday_snapshot)
      : Number(contract.week_ending_weekday_snapshot ?? 0)),

    // Schedule template
    std_schedule_json: successorStdSchedule,
    std_hours_json:    successorStdHours,

    // Labels / flags
    bucket_labels_json: (Object.prototype.hasOwnProperty.call(ov, 'bucket_labels_json')
      ? ov.bucket_labels_json
      : (contract.bucket_labels_json || null)),

     // 🔹 NEW: configurable additional per-unit buckets (EX1–EX5)
    // ✅ If caller supplies overrides.additional_rates_json, it MUST be normalised
    //    to the same shape/rules as Contracts Create/Update/Replace.
    additional_rates_json: (Object.prototype.hasOwnProperty.call(ov, 'additional_rates_json')
      ? normaliseAdditionalRates(ov.additional_rates_json)
      : (contract.additional_rates_json || null)),


    // Contract-level flags (can be overridden if you pass them in overrides)
    auto_invoice: (Object.prototype.hasOwnProperty.call(ov, 'auto_invoice') ? boolOrNull(ov.auto_invoice, !!contract.auto_invoice) : contract.auto_invoice),
    require_reference_to_pay: (Object.prototype.hasOwnProperty.call(ov, 'require_reference_to_pay') ? boolOrNull(ov.require_reference_to_pay, !!contract.require_reference_to_pay) : contract.require_reference_to_pay),
    require_reference_to_invoice: (Object.prototype.hasOwnProperty.call(ov, 'require_reference_to_invoice') ? boolOrNull(ov.require_reference_to_invoice, !!contract.require_reference_to_invoice) : contract.require_reference_to_invoice),

    // Mileage (if present on contract / overrides)
    mileage_pay_rate: (Object.prototype.hasOwnProperty.call(ov, 'mileage_pay_rate')
      ? ov.mileage_pay_rate
      : contract.mileage_pay_rate),
    mileage_charge_rate: (Object.prototype.hasOwnProperty.call(ov, 'mileage_charge_rate')
      ? ov.mileage_charge_rate
      : contract.mileage_charge_rate),

    created_at: now,
    updated_at: now
  }];

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/contracts`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(payload)
    }
  );

  if (!res.ok) {
    const txt = await res.text().catch(() => '');
    throw new Error(`cloneContractForRatesChange: insert failed (${res.status}): ${txt}`);
  }

  const json = await res.json().catch(() => []);
  const row = Array.isArray(json) ? json[0] : json;
  if (!row || !row.id) {
    throw new Error('cloneContractForRatesChange: insert returned no row');
  }

  return row;
}


// ─────────────────────────────────────────────────────────────────────────────
// Helper: findOutstandingWeeksForContract
// A "week" is outstanding if:
//   - it has no timesheet, OR
//   - its current TSFIN is neither invoiced (locked_by_invoice_id) nor paid (paid_at_utc)
// Optional cutoffWeekEnding (YYYY-MM-DD or ISO) limits to week_ending_date >= cutoff.
// Returns an array of rows: { id, week_ending_date, additional_seq, status, timesheet_id, is_invoiced, is_paid }
// ─────────────────────────────────────────────────────────────────────────────



// ─────────────────────────────────────────────────────────────────────────────
// Helper: cloneContractForRatesChange
// Clone a contract row into a new one, applying overrides:
//   - overrides.start_date / end_date
//   - overrides.rates_json
//   - overrides.std_schedule_json / std_hours_json
//   - overrides.pay_method_snapshot, bucket_labels_json, mileage_* etc (optional)
// Returns the newly created contract row (successor).
// ─────────────────────────────────────────────────────────────────────────────



// ─────────────────────────────────────────────────────────────────────────────
// Helper: migrateOutstandingWeeksToNewContract
// Move a set of outstanding contract_weeks (and their timesheets) from one
// contract to another, and enqueue RATE_CHANGED TSFIN recomputes in outbox.
//   - originalId: source contract_id
//   - newId:      successor contract_id
//   - weekRows:   array of { id, timesheet_id, ... } (e.g. from findOutstandingWeeksForContract)
// Returns { week_ids, timesheet_ids }.
// ─────────────────────────────────────────────────────────────────────────────
async function migrateOutstandingWeeksToNewContract(env, originalId, newId, weekRows) {
  const weeks = Array.isArray(weekRows) ? weekRows : [];
  if (!weeks.length) {
    return { week_ids: [], timesheet_ids: [] };
  }

  const now = nowIso();

  const weekIds = weeks
    .map(w => w && w.id)
    .filter(Boolean)
    .map(String);

  const tsIds = Array.from(
    new Set(
      weeks
        .map(w => w && w.timesheet_id)
        .filter(Boolean)
        .map(String)
    )
  );

  // 1) Move contract_weeks to the new contract
  if (weekIds.length) {
    const inList = weekIds.map(enc).join(',');
    const url =
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?id=in.(${inList})`;
    const res = await fetch(url, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({ contract_id: newId, updated_at: now })
    });
    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      throw new Error(`migrateOutstandingWeeksToNewContract: PATCH contract_weeks failed (${res.status}): ${txt}`);
    }
  }

  // 2) Move timesheets (current rows only) to the new contract
  if (tsIds.length) {
    const inList = tsIds.map(enc).join(',');
    const url =
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=in.(${inList})` +
      `&is_current=eq.true`;
    const res = await fetch(url, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({ contract_id: newId, updated_at: now })
    });
    if (!res.ok) {
      const txt = await res.text().catch(() => '');
      throw new Error(`migrateOutstandingWeeksToNewContract: PATCH timesheets failed (${res.status}): ${txt}`);
    }
  }

  // 3) Enqueue TSFIN recompute for moved timesheets with reason = RATE_CHANGED
  if (tsIds.length) {
    const items = tsIds.map(tsid => ({
      timesheet_id: tsid,
      reason: 'RATE_CHANGED',
      attempt_count: 0,
      next_attempt_at: now,
      last_error: null,
      created_at: now
    }));

    const outboxUrl =
      `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox` +
      `?on_conflict=timesheet_id,reason`;

    await fetch(outboxUrl, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'resolution=ignore-duplicates' },
      body: JSON.stringify(items)
    }).catch(() => {
      // Best-effort; failures here shouldn't abort the migration, but will show up in logs.
    });
  }

  return { week_ids: weekIds, timesheet_ids: tsIds };
}

// ─────────────────────────────────────────────────────────────────────────────
// Helper: collectOutstandingWeeklyContractsForCandidate
// Used by both preview + mutate handlers for PAYE↔UMBRELLA flips.
// Returns an array of:
// {
//   contract_id, client_id, client_name, role, band,
//   date_range: { start_date, end_date },
//   pay_method_snapshot,
//   outstanding_weeks, first_outstanding_we, last_outstanding_we
// }
// ─────────────────────────────────────────────────────────────────────────────

async function findOutstandingWeeksForContract(env, contractId, cutoffWeekEnding) {
  if (!contractId) return [];

  let cutoffYmd = null;
  if (cutoffWeekEnding) {
    try {
      cutoffYmd = toYmd(cutoffWeekEnding);
    } catch {
      cutoffYmd = null;
    }
  }

  const map = await collectOutstandingWeeksByContract(env, [contractId], cutoffYmd);
  return map.get(String(contractId)) || [];
}



async function collectOutstandingWeeklyContractsForCandidate(env, candidateId, newMethod, originalMethod) {
  if (!candidateId) return [];

  const orig = (originalMethod || '').toUpperCase();
  const target = (newMethod || '').toUpperCase();

  if (!orig || (orig !== 'PAYE' && orig !== 'UMBRELLA')) return [];
  if (!target || (target !== 'PAYE' && target !== 'UMBRELLA')) return [];

  // 1) Load contracts for this candidate with pay_method_snapshot = originalMethod
  const url =
    `${env.SUPABASE_URL}/rest/v1/contracts` +
    `?candidate_id=eq.${enc(candidateId)}` +
    `&pay_method_snapshot=eq.${enc(orig)}` +
    `&select=id,client_id,role,band,start_date,end_date,pay_method_snapshot`;

  const { rows: conRows } = await sbFetch(env, url);
  const contracts = Array.isArray(conRows) ? conRows : [];
  if (!contracts.length) return [];

  const contractIds = contracts.map(c => c && c.id).filter(Boolean).map(String);
  if (!contractIds.length) return [];

  // 2) Bulk outstanding weeks for these contracts
  const outstandingByContract = await collectOutstandingWeeksByContract(env, contractIds, null);

  const summaries = [];
  const clientIds = new Set();

  for (const c of contracts) {
    if (!c || !c.id) continue;
    const cid = String(c.id);
    const weeks = outstandingByContract.get(cid) || [];
    if (!weeks.length) continue;

    const dates = weeks
      .map(w => w.week_ending_date)
      .filter(Boolean)
      .sort();
    if (!dates.length) continue;

    clientIds.add(c.client_id);

    summaries.push({
      contract_id: c.id,
      client_id: c.client_id || null,
      client_name: null, // filled in below
      role: c.role || null,
      band: c.band ?? null,
      date_range: { start_date: c.start_date || null, end_date: c.end_date || null },
      pay_method_snapshot: c.pay_method_snapshot || null,
      outstanding_weeks: weeks.length,
      first_outstanding_we: dates[0],
      last_outstanding_we: dates[dates.length - 1]
    });
  }

  if (!summaries.length) return [];

  // 3) Load client names in one go
  if (clientIds.size) {
    const idsList = Array.from(clientIds).filter(Boolean).map(String);
    if (idsList.length) {
      const clientsUrl =
        `${env.SUPABASE_URL}/rest/v1/clients` +
        `?id=in.(${idsList.map(enc).join(',')})` +
        `&select=id,name`;
      const { rows: cliRows } = await sbFetch(env, clientsUrl);
      const byId = new Map((cliRows || []).map(r => [String(r.id), r.name || null]));

      for (const s of summaries) {
        if (s.client_id) {
          s.client_name = byId.get(String(s.client_id)) || null;
        }
      }
    }
  }

  return summaries;
}



async function collectOutstandingWeeksByContract(env, contractIds, cutoffYmd = null) {
  const outMap = new Map();
  const ids = (contractIds || []).map(String).filter(Boolean);
  if (!ids.length) return outMap;

  // 1) Load contract_weeks for all contracts in one go
  let cwUrl =
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
    `?contract_id=in.(${ids.map(enc).join(',')})` +
    `&additional_seq=eq.0` +
    `&select=id,contract_id,week_ending_date,additional_seq,status,timesheet_id`;

  if (cutoffYmd) {
    cwUrl += `&week_ending_date=gte.${enc(cutoffYmd)}`;
  }

  cwUrl += `&order=contract_id.asc,week_ending_date.asc,additional_seq.asc`;

  const { rows: weekRows } = await sbFetch(env, cwUrl);
  const weeks = Array.isArray(weekRows) ? weekRows : [];
  if (!weeks.length) return outMap;

  // 2) Load current TSFIN rows for all attached timesheets in one go
  const tsIds = Array.from(
    new Set(
      weeks
        .map(w => w.timesheet_id)
        .filter(Boolean)
        .map(String)
    )
  );

  const finByTsId = new Map();
  if (tsIds.length) {
    const inList = tsIds.map(enc).join(',');
    const finQ =
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?is_current=eq.true` +
      `&timesheet_id=in.(${inList})` +
      `&select=timesheet_id,locked_by_invoice_id,paid_at_utc`;
    const { rows: finRows } = await sbFetch(env, finQ);
    for (const r of (finRows || [])) {
      if (r && r.timesheet_id) {
        finByTsId.set(String(r.timesheet_id), r);
      }
    }
  }

  // 3) Compute outstanding weeks and group by contract_id
  for (const w of weeks) {
    if (!w || !w.contract_id) continue;
    const cid = String(w.contract_id);
    const tsId = w.timesheet_id ? String(w.timesheet_id) : null;
    const fin = tsId ? (finByTsId.get(tsId) || null) : null;

    const isInvoiced = !!(fin && fin.locked_by_invoice_id);
    const isPaid     = !!(fin && fin.paid_at_utc);
    const isOutstanding = !tsId || (!isInvoiced && !isPaid);

    if (!isOutstanding) continue;

    const arr = outMap.get(cid) || [];
    arr.push({
      id: w.id,
      week_ending_date: w.week_ending_date,
      additional_seq: w.additional_seq,
      status: w.status,
      timesheet_id: w.timesheet_id || null,
      is_invoiced: isInvoiced,
      is_paid: isPaid
    });
    outMap.set(cid, arr);
  }

  return outMap;
}


// ─────────────────────────────────────────────────────────────────────────────
// Endpoint: GET /api/candidates/:id/pay-method-change-preview
// Preview which contracts would be affected by PAYE↔UMBRELLA flip.
// ─────────────────────────────────────────────────────────────────────────────

 async function handleCandidatePayMethodChangePreview(env, req, candidateId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized('Unauthorized'));
  if (!candidateId) return withCORS(env, req, badRequest('candidate_id required'));

  const urlObj = new URL(req.url);
  const rawNew = (urlObj.searchParams.get('new_method') || '').toUpperCase();
  const newMethod = rawNew === 'PAYE' || rawNew === 'UMBRELLA' ? rawNew : null;

  if (!newMethod) {
    return withCORS(env, req, badRequest('new_method must be PAYE or UMBRELLA'));
  }

  // Load candidate and normalise originalMethod
  const cand = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/candidates` +
    `?id=eq.${enc(candidateId)}&select=id,pay_method`
  );
  if (!cand) {
    return withCORS(env, req, notFound('Candidate not found'));
  }

  const originalMethod = String(cand.pay_method || '').toUpperCase() || null;
  if (!originalMethod || (originalMethod !== 'PAYE' && originalMethod !== 'UMBRELLA')) {
    return withCORS(env, req, badRequest('Candidate pay_method must be PAYE or UMBRELLA for this operation'));
  }
  if (originalMethod === newMethod) {
    return withCORS(env, req, badRequest('Candidate already has this pay method'));
  }

  const contracts = await collectOutstandingWeeklyContractsForCandidate(env, candidateId, newMethod, originalMethod);

  return withCORS(env, req, ok({
    candidate_id: cand.id,
    original_method: originalMethod,
    new_method: newMethod,
    contracts
  }));
}


// ─────────────────────────────────────────────────────────────────────────────
// Endpoint: POST /api/candidates/:id/pay-method-change
// Perform PAYE↔UMBRELLA flip across all relevant weekly contracts:
//   • For each affected contract: create successor with new pay_method_snapshot
//     and recomputed per-bucket pay so margin stays the same.
//   • Migrate outstanding weeks + timesheets.
//   • Update candidate.pay_method (and umbrella_id if desired).
// ─────────────────────────────────────────────────────────────────────────────
 async function handleCandidatePayMethodChange(env, req, candidateId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized('Unauthorized'));
  if (!candidateId) return withCORS(env, req, badRequest('candidate_id required'));

  // -------- Body parsing --------
  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const rawNew = String(body?.new_method || '').toUpperCase();
  const newMethod = rawNew === 'PAYE' || rawNew === 'UMBRELLA' ? rawNew : null;

  if (!newMethod) {
    return withCORS(env, req, badRequest('new_method must be PAYE or UMBRELLA'));
  }

  const contractIdsFilter = Array.isArray(body?.contract_ids)
    ? Array.from(new Set(body.contract_ids.map(String).filter(Boolean)))
    : null;
  const contractIdSet = contractIdsFilter && contractIdsFilter.length
    ? new Set(contractIdsFilter)
    : null;

  // -------- Load candidate & validate flip --------
  const cand = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/candidates` +
    `?id=eq.${enc(candidateId)}&select=id,pay_method,umbrella_id`
  );
  if (!cand) {
    return withCORS(env, req, notFound('Candidate not found'));
  }

  const originalMethod = String(cand.pay_method || '').toUpperCase() || null;
  if (!originalMethod || (originalMethod !== 'PAYE' && originalMethod !== 'UMBRELLA')) {
    return withCORS(env, req, badRequest('Candidate pay_method must be PAYE or UMBRELLA for this operation'));
  }
  if (originalMethod === newMethod) {
    return withCORS(env, req, badRequest('Candidate already has this pay method'));
  }

  // When moving TO umbrella, ensure an umbrella_id exists
  if (newMethod === 'UMBRELLA' && !cand.umbrella_id) {
    return withCORS(env, req, badRequest('Candidate must have an umbrella_id before moving to UMBRELLA'));
  }

  // -------- Load all relevant contracts in one go --------
  const conUrl =
    `${env.SUPABASE_URL}/rest/v1/contracts` +
    `?candidate_id=eq.${enc(candidateId)}` +
    `&pay_method_snapshot=eq.${enc(originalMethod)}` +
    `&select=*`;

  const { rows: conRows } = await sbFetch(env, conUrl);
  const allContracts = Array.isArray(conRows) ? conRows : [];
  if (!allContracts.length && !contractIdSet) {
    // No contracts at all with this snapshot → pure candidate flip
    try {
      const patch = {
        pay_method: newMethod,
        updated_at: nowIso()
      };
      if (newMethod === 'PAYE') patch.umbrella_id = null;
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candidateId)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
          body: JSON.stringify(patch)
        }
      );
    } catch (e) {
      return withCORS(env, req, badRequest(`Failed to update candidate pay_method: ${e?.message || e}`));
    }

    return withCORS(env, req, ok({
      candidate_id: cand.id,
      original_method: originalMethod,
      new_method: newMethod,
      old_contract_ids: [],
      new_contract_ids: [],
      affected_timesheet_ids: [],
      summary: { contracts_changed: 0, weeks_migrated: 0 }
    }));
  }

  let selectedContracts = allContracts;
  if (contractIdSet) {
    selectedContracts = allContracts.filter(c => c && c.id && contractIdSet.has(String(c.id)));
  }

  if (!selectedContracts.length) {
    // User asked for specific contract_ids but none match or have this snapshot
    try {
      const patch = {
        pay_method: newMethod,
        updated_at: nowIso()
      };
      if (newMethod === 'PAYE') patch.umbrella_id = null;
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candidateId)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify(patch)
        }
      );
    } catch (e) {
      return withCORS(env, req, badRequest(`Failed to update candidate pay_method: ${e?.message || e}`));
    }

    return withCORS(env, req, ok({
      candidate_id: cand.id,
      original_method: originalMethod,
      new_method: newMethod,
      old_contract_ids: [],
      new_contract_ids: [],
      affected_timesheet_ids: [],
      summary: { contracts_changed: 0, weeks_migrated: 0 }
    }));
  }

  const idsToLoad = Array.from(new Set(selectedContracts.map(c => String(c.id)).filter(Boolean)));

  // -------- Bulk outstanding weeks for all selected contracts --------
  const outstandingByContract = await collectOutstandingWeeksByContract(env, idsToLoad, null);

  // If no contracts have outstanding weeks, behave like pure candidate flip
  const anyOutstanding = idsToLoad.some(id => {
    const arr = outstandingByContract.get(String(id));
    return arr && arr.length;
  });

  if (!anyOutstanding) {
    try {
      const patch = {
        pay_method: newMethod,
        updated_at: nowIso()
      };
      if (newMethod === 'PAYE') patch.umbrella_id = null;
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candidateId)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify(patch)
        }
      );
    } catch (e) {
      return withCORS(env, req, badRequest(`Failed to update candidate pay_method: ${e?.message || e}`));
    }

    return withCORS(env, req, ok({
      candidate_id: cand.id,
      original_method: originalMethod,
      new_method: newMethod,
      old_contract_ids: [],
      new_contract_ids: [],
      affected_timesheet_ids: [],
      summary: { contracts_changed: 0, weeks_migrated: 0 }
    }));
  }

  const oldContractIds = [];
  const newContractIds = [];
  const allTsIds = [];
  const migrationErrors = [];  // track any contracts that failed migration
  let totalWeeksMigrated = 0;

  // Local helper to compute new pay for one bucket preserving margin
  function computeNewPayBucket(charge, payOld, oldMethod, newMethod, erniMult) {
    if (charge == null || payOld == null) return null;
    const ch = Number(charge);
    const po = Number(payOld);
    if (!Number.isFinite(ch) || !Number.isFinite(po)) return null;

    let margin;
    if (oldMethod === 'PAYE') {
      margin = ch - po * erniMult;
    } else {
      margin = ch - po;
    }

    if (newMethod === 'PAYE') {
      return (ch - margin) / erniMult;
    }
    // newMethod === 'UMBRELLA'
    return ch - margin;
  }

    // ERNI cache (global, from finance windows)
  // key: `ERNI__${anchorYmd}` -> erniMult
  const erniCache = new Map();

  const londonTodayYmd = () => {
    try {
      const s = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).format(new Date());
      const [dd, mm, yyyy] = s.split('/');
      return `${yyyy}-${mm}-${dd}`;
    } catch {
      // fallback (server TZ); best-effort only
      const d = new Date();
      const yyyy = d.getFullYear();
      const mm = String(d.getMonth() + 1).padStart(2, '0');
      const dd = String(d.getDate()).padStart(2, '0');
      return `${yyyy}-${mm}-${dd}`;
    }
  };

  async function getErniMultiplierForClient(env, clientId, activeYmd) {
    // For this operation, ERNI should reflect “today” (when we are changing the contracts),
    // not the historical shift/work date.
    const anchorYmd = londonTodayYmd();

    const key = `ERNI__${anchorYmd}`;
    if (erniCache.has(key)) return erniCache.get(key);

    let mult = 1;

    try {
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify({ p_date: anchorYmd })
        }
      );

      const txt = await res.text().catch(() => '');
      if (!res.ok) throw new Error(txt || `settings_finance_pick failed (${res.status})`);

      const j = txt ? JSON.parse(txt) : null;
      const row = Array.isArray(j) ? j[0] : j;

      let pct = row && row.erni_pct != null ? Number(row.erni_pct) : 0;

      // Support "15" vs "0.15" semantics
      if (!Number.isFinite(pct)) pct = 0;
      if (pct > 1) pct = pct / 100;

      mult = 1 + pct;
      if (!Number.isFinite(mult) || mult <= 0) mult = 1;

    } catch (e) {
      try { console.warn('[PAY-METHOD-CHANGE] getErniMultiplierForClient: fell back to 1', e?.message || e); } catch {}
      mult = 1;
    }

    erniCache.set(key, mult);
    return mult;
  }


  // -------- Process each selected contract --------
  for (const contract of selectedContracts) {
    if (!contract || !contract.id) continue;
    const contractIdStr = String(contract.id);

    const oldMethod = String(contract.pay_method_snapshot || '').toUpperCase();
    if (oldMethod !== originalMethod) {
      // It might have been changed in the meantime; skip to be safe.
      continue;
    }

    const outstandingWeeks = outstandingByContract.get(contractIdStr) || [];
    if (!outstandingWeeks.length) continue;

    let contractHadError = false;
    let contractMigratedWeeks = 0;
    let successor = null;

    try {
      // Earliest outstanding WE, start date = WE − 6 days
      const weDates = outstandingWeeks
        .map(w => w.week_ending_date)
        .filter(Boolean)
        .sort();
      const earliestWe = weDates[0];
      const successorStart = addDays(earliestWe, -6);

           // Compute ERNI multiplier from finance windows (effective “today”)
      const erniMult = await getErniMultiplierForClient(env, contract.client_id, earliestWe);


      // Parse rates_json
      let rj = contract.rates_json || {};
      if (typeof rj === 'string') {
        try { rj = JSON.parse(rj); } catch { rj = {}; }
      }
      if (!rj || typeof rj !== 'object') rj = {};

      const buckets = ['day', 'night', 'sat', 'sun', 'bh'];

      const charge = {
        day:   rj.charge_day   ?? null,
        night: rj.charge_night ?? null,
        sat:   rj.charge_sat   ?? null,
        sun:   rj.charge_sun   ?? null,
        bh:    rj.charge_bh    ?? null
      };

      const payOld = (oldMethod === 'PAYE')
        ? {
            day:   rj.paye_day   ?? null,
            night: rj.paye_night ?? null,
            sat:   rj.paye_sat   ?? null,
            sun:   rj.paye_sun   ?? null,
            bh:    rj.paye_bh    ?? null
          }
        : {
            day:   rj.umb_day   ?? null,
            night: rj.umb_night ?? null,
            sat:   rj.umb_sat   ?? null,
            sun:   rj.umb_sun   ?? null,
            bh:    rj.umb_bh    ?? null
          };

      // Build successor rates_json by copying existing and overwriting only
      // the pay buckets for the new method where we can compute margin.
      let newRates = { ...rj };

      for (const b of buckets) {
        const ch = charge[b];
        const po = payOld[b];
        const pn = computeNewPayBucket(ch, po, oldMethod, newMethod, erniMult);
        if (pn == null || !Number.isFinite(pn)) continue;

        const rounded = +(+pn).toFixed(2);
        if (newMethod === 'PAYE') {
          newRates[`paye_${b}`] = rounded;
        } else {
          newRates[`umb_${b}`] = rounded;
        }
      }

      // Prune incompatible buckets: keep only new method + charge_*
      const keepPrefixes =
        newMethod === 'PAYE'     ? ['paye_', 'charge_'] :
        newMethod === 'UMBRELLA' ? ['umb_',  'charge_'] :
                                   ['charge_'];
      const cleanedRates = {};
      for (const [key, val] of Object.entries(newRates)) {
        if (keepPrefixes.some(pre => key.startsWith(pre))) {
          cleanedRates[key] = val;
        }
      }
      newRates = cleanedRates;

      // 🔹 NEW: reprice additional_rates_json per-unit pay to preserve margin
      let extrasRaw = contract.additional_rates_json || null;
      if (typeof extrasRaw === 'string') {
        try { extrasRaw = JSON.parse(extrasRaw); } catch { extrasRaw = null; }
      }
      const extrasArr = Array.isArray(extrasRaw) ? extrasRaw : [];
      const newAdditionalRates = extrasArr.map((cfg) => {
        if (!cfg || typeof cfg !== 'object') return cfg;
        const ch = cfg.charge_rate;
        const po = cfg.pay_rate;
        if (ch == null || po == null) return cfg; // nothing to do

        const pn = computeNewPayBucket(ch, po, oldMethod, newMethod, erniMult);
        if (pn == null || !Number.isFinite(pn)) return cfg; // keep original pay_rate if we can't compute

        const rounded = +(+pn).toFixed(2);
        return {
          ...cfg,
          pay_rate: rounded
        };
      });

      // Prepare overrides for successor
      const overrides = {
        start_date: successorStart,
        end_date: contract.end_date,
        pay_method_snapshot: newMethod,
        rates_json: newRates,
        std_schedule_json: contract.std_schedule_json || null,
        std_hours_json: contract.std_hours_json || null,
        // carry repriced additional buckets into successor
        additional_rates_json: newAdditionalRates.length ? newAdditionalRates : (extrasArr.length ? extrasArr : null)
      };

      // Create successor contract
      try {
        successor = await cloneContractForRatesChange(env, contract, overrides);
      } catch (e) {
        contractHadError = true;
        try { console.warn('[PAY-METHOD-CHANGE] cloneContractForRatesChange failed', contract.id, e); } catch {}
      }

      if (!successor || !successor.id) {
        contractHadError = true;
      }

      // NEW: adjust old contract dates to wrap around kept weeks with TS
      let newStartDate = contract.start_date;
      let newEndDate = contract.end_date;

      if (!contractHadError) {
        let allWeeks = [];
        try {
          const { rows: cwRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?contract_id=eq.${enc(contract.id)}` +
            `&select=id,week_ending_date,timesheet_id`
          );
          allWeeks = Array.isArray(cwRows) ? cwRows : (cwRows ? [cwRows] : []);
        } catch (e) {
          try { console.warn('[PAY-METHOD-CHANGE] load contract_weeks failed', contract.id, e); } catch {}
          allWeeks = [];
        }

        // Weeks being moved (outstanding)
        const moveSet = new Set(
          (outstandingWeeks || [])
            .map(w => w && w.id)
            .filter(Boolean)
            .map(String)
        );

        // Weeks kept on the old contract
        const keptWeeks = (allWeeks || []).filter(w => {
          const wid = w && w.id ? String(w.id) : null;
          return wid && !moveSet.has(wid);
        });

        // Kept weeks that actually have timesheets
        const keptWithTimesheet = keptWeeks.filter(w => w && w.timesheet_id);

        if (keptWithTimesheet.length) {
          // Wrap old contract strictly around the kept TS weeks
          let firstWe = keptWithTimesheet[0].week_ending_date;
          let lastWe  = keptWithTimesheet[0].week_ending_date;
          for (const w of keptWithTimesheet) {
            if (w.week_ending_date < firstWe) firstWe = w.week_ending_date;
            if (w.week_ending_date > lastWe)  lastWe  = w.week_ending_date;
          }

          let wrappedStart = addDays(firstWe, -6); // first day of earliest kept week
          let wrappedEnd   = lastWe;               // last day (week_ending) of latest kept week

          // Clamp so we never move outside the original contract window
          if (wrappedStart < contract.start_date) wrappedStart = contract.start_date;
          if (wrappedEnd   > contract.end_date)   wrappedEnd   = contract.end_date;

          newStartDate = wrappedStart;
          newEndDate   = wrappedEnd;
        } else {
          // No kept TS weeks → fall back to old behaviour (end before successor)
          let truncatedEnd = addDays(successorStart, -1);
          if (truncatedEnd < contract.start_date) truncatedEnd = contract.start_date;
          newEndDate = truncatedEnd;
          // newStartDate remains contract.start_date
        }

        try {
          const patch = {};
          if (newStartDate !== contract.start_date) patch.start_date = newStartDate;
          if (newEndDate   !== contract.end_date)   patch.end_date   = newEndDate;
          if (Object.keys(patch).length) {
            patch.updated_at = nowIso();
            await fetch(
              `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contract.id)}`,
              {
                method: 'PATCH',
                headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
                body: JSON.stringify(patch)
              }
            );
          }
        } catch (e) {
          contractHadError = true;
          try { console.warn('[PAY-METHOD-CHANGE] update original contract dates failed', contract.id, e); } catch {}
        }
      }

      // Move outstanding weeks + timesheets
      if (!contractHadError) {
        try {
          const mig = await migrateOutstandingWeeksToNewContract(env, contract.id, successor.id, outstandingWeeks);
          contractMigratedWeeks = (mig.week_ids || []).length;
          totalWeeksMigrated   += contractMigratedWeeks;
          for (const tsid of (mig.timesheet_ids || [])) {
            allTsIds.push(tsid);
          }
        } catch (e) {
          contractHadError = true;
          try { console.warn('[PAY-METHOD-CHANGE] migrateOutstandingWeeksToNewContract failed', contract.id, e); } catch {}
        }
      }

      // Prune any future weeks beyond newEndDate without TS (non-fatal if fails)
      if (!contractHadError) {
        try {
          await fetch(
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?contract_id=eq.${enc(contract.id)}` +
            `&week_ending_date=gt.${enc(newEndDate)}` +
            `&timesheet_id=is.null`,
            {
              method: 'DELETE',
              headers: { ...sbHeaders(env), Prefer: 'return-minimal' }
            }
          );
        } catch (e) {
          try { console.warn('[PAY-METHOD-CHANGE] prune future empty weeks failed', contract.id, e); } catch {}
        }
      }
    } catch (e) {
      contractHadError = true;
      try { console.warn('[PAY-METHOD-CHANGE] unexpected error during contract migration', contract.id, e); } catch {}
    }

    if (contractHadError) {
      migrationErrors.push(contractIdStr);
      continue;
    }

    // Only record contracts that actually migrated at least one week
    if (successor && successor.id && contractMigratedWeeks > 0) {
      oldContractIds.push(contract.id);
      newContractIds.push(successor.id);
    }
  }

  const uniqueTsIds = Array.from(new Set(allTsIds.map(String)));

  // If any contract failed migration, DO NOT flip candidate pay_method
  if (migrationErrors.length > 0) {
    return withCORS(env, req, badRequest(
      `Failed to update all contracts for pay-method change. ` +
      `Contracts with errors: ${migrationErrors.join(', ')}`
    ));
  }

  // -------- Update candidate.pay_method (and umbrella_id if required) --------
  try {
    const patch = {
      pay_method: newMethod,
      updated_at: nowIso()
    };
    if (newMethod === 'PAYE') {
      patch.umbrella_id = null;
    }
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candidateId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(patch)
      }
    );
  } catch (e) {
    return withCORS(env, req, badRequest(`Failed to update candidate pay_method: ${e?.message || e}`));
  }

  return withCORS(env, req, ok({
    candidate_id: cand.id,
    original_method: originalMethod,
    new_method: newMethod,
    old_contract_ids: oldContractIds,
    new_contract_ids: newContractIds,
    affected_timesheet_ids: uniqueTsIds,
    summary: {
      contracts_changed: newContractIds.length,
      weeks_migrated: totalWeeksMigrated
    }
  }));
}
async function computeBucketRatesPreservingMargin(env, oldMethod, newMethod, oldRates) {
  const srcMethod = String(oldMethod || '').toUpperCase();
  const dstMethod = String(newMethod || '').toUpperCase();

  // Defensive clone + normalisation
  let base = oldRates || {};
  if (typeof base === 'string') {
    try { base = JSON.parse(base); } catch { base = {}; }
  }
  if (!base || typeof base !== 'object') base = {};

  const out = { ...base };

  // ─────────────────────────────────────────────────────────────
  // Fetch ERNI from finance windows (in-scope) via single RPC helper
  // (cached by loadFinanceGlobals to minimise subcalls)
  // ─────────────────────────────────────────────────────────────
  let erniMult = 1;
  try {
    const fin = await loadFinanceGlobals(env, null); // null => "today" in Europe/London on DB side
    let pct = fin && fin.erni_pct != null ? Number(fin.erni_pct) : 0;

    // Support 15 vs 0.15 semantics like elsewhere:
    // if > 1 we treat as a percentage (e.g. 15 → 0.15)
    if (!Number.isFinite(pct)) pct = 0;
    if (pct > 1) pct = pct / 100;

    erniMult = 1 + pct;  // ERNI_MULT = 1 + erni_pct
    if (!Number.isFinite(erniMult) || erniMult <= 0) erniMult = 1;
  } catch (e) {
    try { console.warn('[RATES] computeBucketRatesPreservingMargin: failed to load ERNI from finance windows, defaulting to 1', e); } catch {}
    erniMult = 1;
  }

  const buckets = ['day', 'night', 'sat', 'sun', 'bh'];

  const toNumOrNull = (v) => {
    if (v === null || v === undefined || v === '') return null;
    const n = Number(v);
    return Number.isFinite(n) ? n : null;
  };

  for (const b of buckets) {
    const chargeKey  = `charge_${b}`;
    const payPayeKey = `paye_${b}`;
    const payUmbKey  = `umb_${b}`;

    const charge = toNumOrNull(base[chargeKey]);
    if (charge == null) continue;

    const payOld =
      (srcMethod === 'PAYE')
        ? toNumOrNull(base[payPayeKey])
        : (srcMethod === 'UMBRELLA')
          ? toNumOrNull(base[payUmbKey])
          : null;

    // If we don’t have a valid old pay, we can’t preserve margin for this bucket.
    if (payOld == null) continue;

    // Compute margin under the original method
    let margin;
    if (srcMethod === 'PAYE') {
      // Margin(PAYE) = charge - pay * ERNI_MULT
      margin = charge - (payOld * erniMult);
    } else {
      // Margin(Umbrella) = charge - pay
      margin = charge - payOld;
    }

    // Derive new pay keeping margin constant
    let payNew;
    if (dstMethod === 'PAYE') {
      // New PAYE pay = (charge - margin) / ERNI_MULT
      payNew = (charge - margin) / erniMult;
    } else {
      // New Umbrella pay = charge - margin
      payNew = charge - margin;
    }

    if (!Number.isFinite(payNew)) continue;

    // Round to 2dp like elsewhere in the system
    const rounded = +(+payNew).toFixed(2);

    if (dstMethod === 'PAYE') {
      out[payPayeKey] = rounded;
    } else {
      out[payUmbKey] = rounded;
    }
  }

  return out;
}

// ─────────────────────────────────────────────────────────────────────────────
// Helper: computeBucketRatesPreservingMargin
// Given an existing rates_json and a PAYE↔UMBRELLA flip, compute new pay buckets
// so that per-bucket margin is preserved.
//
// oldMethod: 'PAYE' | 'UMBRELLA'
// newMethod: 'PAYE' | 'UMBRELLA'
// oldRates:  the existing rates_json (object or JSON string) with:
//            charge_day/night/sat/sun/bh and paye_*/umb_*
// erniMult:  numeric ERNI multiplier (1 + erni_pct). If invalid, falls back to 1.
//
// Returns: a NEW object (cloned from oldRates) with updated paye_* or umb_* buckets
//          for the newMethod; charges and the other method’s buckets are left as-is.
// ─────────────────────────────────────────────────────────────────────────────
// Compute new PAYE/UMBRELLA pay buckets so that per-bucket margin is preserved,
// always using the current ERNI percentage from settings_defaults.
//
// - oldMethod: 'PAYE' | 'UMBRELLA'
// - newMethod: 'PAYE' | 'UMBRELLA'
// - oldRates:  the existing rates_json (object or JSON string) with
//              charge_day/night/sat/sun/bh and paye_*/umb_*
//
// Returns: a NEW object cloned from oldRates with updated paye_* or umb_*
//          buckets for the new method. Charges and the other method’s buckets
//          are left as-is.
//
// NOTE: This helper is async because it fetches erni_pct from settings_defaults.
//


// ─────────────────────────────────────────────────────────────────────────────
// Helper: enqueueTsfinRecomputeForTimesheets
// Bulk-enqueue TSFIN recomputes for a list of timesheet IDs into ts_financials_outbox.
//
// timesheetIds: array of timesheet_id values
// reason:       string reason, e.g. 'RATE_CHANGED' (default)
//
// Uses the same pattern as enqueueTsfinRecomputeForClient / enqueueManualTsfinRecalc:
// inserts into ts_financials_outbox with on_conflict=timesheet_id,reason and
// Prefer: resolution=ignore-duplicates.
// ─────────────────────────────────────────────────────────────────────────────
async function enqueueTsfinRecomputeForTimesheets(env, timesheetIds, reason = 'RATE_CHANGED') {
  const ids = Array.isArray(timesheetIds)
    ? Array.from(new Set(timesheetIds.map(String).filter(Boolean)))
    : [];
  if (!ids.length) return;

  const now = nowIso();
  const rows = ids.map(tsid => ({
    timesheet_id: tsid,
    reason,
    attempt_count: 0,
    next_attempt_at: now,
    last_error: null,
    created_at: now
  }));

  try {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'resolution=ignore-duplicates' },
        body: JSON.stringify(rows)
      }
    );
  } catch (e) {
    // best-effort; log but don't throw
    try { console.warn('[TSFIN][enqueue] enqueueTsfinRecomputeForTimesheets failed', e); } catch {}
  }
}
























async function enqueueTsfinRecomputeForClient(env, client_id) {
  try {
    const urlList =
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?select=timesheet_id` +
      `&client_id=eq.${encodeURIComponent(client_id)}` +
      `&is_current=eq.true` +
      `&locked_by_invoice_id=is.null`;
    const { rows: tsfins } = await sbFetch(env, urlList);
    if (tsfins && tsfins.length) {
      const now = nowIso();
      const items = tsfins.map(r => ({
        timesheet_id: r.timesheet_id,
        reason: 'RATE_CHANGED',
        attempt_count: 0,
        next_attempt_at: now,
        last_error: null,
        created_at: now,
      }));
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
        {
          method: "POST",
          headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
          body: JSON.stringify(items)
        }
      );
    }
  } catch (_) { /* non-fatal */ }
}

// Finds READY_FOR_INVOICE snapshots for contracts with auto_invoice=true,
// groups by client, creates HOURS-only invoices and immediately issues them.
// Finds READY_FOR_INVOICE snapshots for contracts with auto_invoice=true,
// groups by client, creates HOURS-only invoices and immediately issues them.


async function runAutoInvoiceCycle(env) {
  try {
    const invMaxBatches   = parseInt(env.INVOICE_MAX_BATCHES || '10', 10);
    const invBatchSize    = parseInt(env.INVOICE_BATCH_SIZE  || '10', 10);
    const invEnqLimit     = parseInt(env.INVOICE_ENQUEUE_LIMIT || '500', 10);

    // Optional: allow caller to bypass enqueue step (default true)
    const invEnqueueFirst = String(env.INVOICE_ENQUEUE_FIRST || 'true').toLowerCase() !== 'false';

    // Actor for audit (optional)
    const invActorUserId  = (env.INVOICE_ACTOR_USER_ID && String(env.INVOICE_ACTOR_USER_ID).trim())
      ? String(env.INVOICE_ACTOR_USER_ID).trim()
      : null;

    for (let i = 0; i < invMaxBatches; i++) {
      // 1) enqueue auto-invoice jobs (cron-safe, client-led defaults, includes v_ts_invoice_precheck gating)
      if (invEnqueueFirst) {
        await sbRpc(env, 'invoice_enqueue_ready_for_invoice', { p_limit: invEnqLimit });
      }

      // 2) dequeue
      const dq = await sbRpc(env, 'invoice_dequeue_batch_ids', { p_limit: invBatchSize });
      const jobs = Array.isArray(dq) ? dq : (dq?.data || []);
      if (!jobs.length) break;

      const outboxIds = jobs.map(r => r?.outbox_id).filter(Boolean);
      if (!outboxIds.length) break;

      // 3) generate (NO issuing here; issuing happens when emailing)
      await sbRpc(env, 'invoice_generate_from_outbox_batch', {
        p_outbox_ids: outboxIds,
        p_actor_user_id: invActorUserId
      });
    }
  } catch (e) {
    console.warn('runAutoInvoiceCycle failed:', e?.message || e);
  }
}



// ─────────────────────────────────────────────────────────────────────────────
// Overrides: list by CLIENT (now supports optional rate_type filter)
// ─────────────────────────────────────────────────────────────────────────────
async function handleListOverridesByClient(env, req, clientId) {
  const user = await requireUser(env, req, ["admin"]);
  if (!user) return withCORS(env, req, unauthorized());

  const sp      = new URL(req.url).searchParams;
  const cid     = clientId || sp.get("client_id");
  const role    = sp.get("role");
  const band    = sp.get("band");
  const on      = sp.get("active_on");
  const rateType = sp.get("rate_type"); // optional filter
  const limit   = Math.min(Math.max(parseInt(sp.get('limit')  || '100', 10) || 100, 1), 500);
  const offset  = Math.max(parseInt(sp.get('offset') || '0',   10) || 0, 0);

  if (!cid) return withCORS(env, req, badRequest("client_id required"));

  try {
    let q = `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides` +
            `?select=*,candidate:candidates(id,display_name)` +
            `&client_id=eq.${encodeURIComponent(cid)}`;

    if (rateType) q += `&rate_type=eq.${encodeURIComponent(rateType)}`;

    const andParts = [];
    if (role) andParts.push(`or(role.eq.${encodeURIComponent(role)},role.is.null)`);
    if (band) andParts.push(`or(band.eq.${encodeURIComponent(band)},band.is.null)`);
    if (on) {
      andParts.push(`date_from=lte.${encodeURIComponent(on)}`);
      andParts.push(`or(date_to.gte.${encodeURIComponent(on)},date_to.is.null)`);
    }
    if (andParts.length) q += `&and=(${andParts.join(',')})`;

    q += `&order=date_from.desc,client_id.nullslast,role.nullslast,band.nullslast&limit=${limit}&offset=${offset}`;

    const { rows } = await sbFetch(env, q);

    const items = rows.map(r => ({
      ...r,
      candidate_name: r.candidate ? r.candidate.display_name : null
    }));

    return withCORS(env, req, ok({ items }));
  } catch {
    return withCORS(env, req, serverError("Failed to fetch candidate overrides for client"));
  }
}


// ─────────────────────────────────────────────────────────────────────────────
// Overrides: list by CANDIDATE (now supports optional rate_type filter)
// ─────────────────────────────────────────────────────────────────────────────
async function handleListOverridesByCandidate(env, req, candidateId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const sp       = new URL(req.url).searchParams;
  const cand     = candidateId || sp.get("candidate_id");
  const role     = sp.get("role");
  const band     = sp.get("band");
  const on       = sp.get("active_on");
  const rateType = sp.get("rate_type"); // optional filter
  const limit    = Math.min(Math.max(parseInt(sp.get('limit')  || '100', 10) || 100, 1), 500);
  const offset   = Math.max(parseInt(sp.get('offset') || '0',   10) || 0, 0);

  if (!cand) return withCORS(env, req, badRequest("candidate_id required"));

  try {
    let q = `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?select=*,client:clients(id,name)`;
    q += `&candidate_id=eq.${encodeURIComponent(cand)}`;
    if (rateType) q += `&rate_type=eq.${encodeURIComponent(rateType)}`;

    const andParts = [];
    if (role) andParts.push(`or(role.eq.${encodeURIComponent(role)},role.is.null)`);
    if (band) andParts.push(`or(band.eq.${encodeURIComponent(band)},band.is.null)`);
    if (on) {
      andParts.push(`date_from=lte.${encodeURIComponent(on)}`);
      andParts.push(`or(date_to.gte.${encodeURIComponent(on)},date_to.is.null)`);
    }
    if (andParts.length) q += `&and=(${andParts.join(',')})`;

    q += `&order=date_from.desc,client_id.nullslast,role.nullslast,band.nullslast&limit=${limit}&offset=${offset}`;

    const { rows } = await sbFetch(env, q);

    const items = rows.map(r => ({
      ...r,
      client_name: r.client ? r.client.name : null
    }));

    return withCORS(env, req, ok({ items }));
  } catch {
    return withCORS(env, req, serverError("Failed to fetch overrides for candidate"));
  }
}


// ─────────────────────────────────────────────────────────────────────────────
// Overrides: CREATE (now requires rate_type)
// ─────────────────────────────────────────────────────────────────────────────

// ─────────────────────────────────────────────────────────────────────────────
// Overrides: CREATE (require rate_type; enqueue RATE_CHANGED for candidate scope)
// ─────────────────────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────────────────────
// Overrides: CREATE (server enforces hard gate + server-side truncate)
// POST /api/rates/candidate-overrides
// - client_id REQUIRED
// - Gate: client must have an active default window for (role, band|null) at date_from
// - Truncate same-type incumbent (candidate, client, role, band, rate_type) to N−1
// - Insert new override
// - Enqueue RATE_CHANGED for current, unlocked TSFIN (candidate [+client], pay_method=rate_type)
// ─────────────────────────────────────────────────────────────────────────────
async function handleCreateOverride(env, req, candidateId, clientIdParam = null) {
  const user = await requireUser(env, req, ["admin"]);
  if (!user) return withCORS(env, req, unauthorized());

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  const candidate_id = candidateId || data.candidate_id;
  if (!candidate_id) return withCORS(env, req, badRequest("candidate_id required"));

  const rate_type = (data.rate_type || '').toUpperCase();
  if (rate_type !== 'PAYE' && rate_type !== 'UMBRELLA') {
    return withCORS(env, req, badRequest("rate_type must be 'PAYE' or 'UMBRELLA'"));
  }

  const client_id = clientIdParam || data.client_id || null;
  if (!client_id) return withCORS(env, req, badRequest("client_id required"));

  const role      = data.role || null;
  const band      = (data.band === '' ? null : data.band || null);
  const date_from = data.date_from || null;
  const date_to   = (data.date_to === '' ? null : data.date_to || null);

  if (!role)      return withCORS(env, req, badRequest("role required"));
  if (!date_from) return withCORS(env, req, badRequest("date_from required"));

  try {
    // Gate: require an active client default (unified window) for (client, role, band|null) at date_from
    {
      const gateQ =
        `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
        `?client_id=eq.${encodeURIComponent(client_id)}` +
        `&role=eq.${encodeURIComponent(role)}` +
        (band == null ? `&band=is.null` : `&band=eq.${encodeURIComponent(band)}`) +
        `&date_from=lte.${encodeURIComponent(date_from)}` +
        `&or=(date_to.gte.${encodeURIComponent(date_from)},date_to.is.null)` +
        `&select=id&limit=1`;
      const { rows: gateRows } = await sbFetch(env, gateQ);
      if (!gateRows || !gateRows.length) {
        return withCORS(env, req, badRequest("Client has no active default window for the selected role/band at the override start date."));
      }
    }

    // Server-side truncate of incumbent (same candidate+client+role+band+rate_type) active at date_from
    {
      const incQ =
        `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides` +
        `?candidate_id=eq.${encodeURIComponent(candidate_id)}` +
        `&client_id=eq.${encodeURIComponent(client_id)}` +
        `&rate_type=eq.${encodeURIComponent(rate_type)}` +
        (role ? `&role=eq.${encodeURIComponent(role)}` : `&role=is.null`) +
        (band == null ? `&band=is.null` : `&band=eq.${encodeURIComponent(band)}`) +
        `&date_from=lte.${encodeURIComponent(date_from)}` +
        `&or=(date_to.gte.${encodeURIComponent(date_from)},date_to.is.null)` +
        `&select=id,date_from,date_to&order=date_from.desc&limit=2`;

      const { rows: incumbents } = await sbFetch(env, incQ);
      if (incumbents.length > 1) {
        return withCORS(env, req, badRequest("Multiple incumbent overrides found. Please tidy overlaps first."));
      }
      if (incumbents.length === 1) {
        const inc = incumbents[0];
        if (String(inc.date_from) === String(date_from)) {
          return withCORS(env, req, badRequest("An override with the same start date already exists. Edit that override instead."));
        }
        const cut = dayBeforeYmd(date_from);
        if (inc.date_from && cut < inc.date_from) {
          return withCORS(env, req, badRequest("Proposed start would back-cut before the incumbent's start. Adjust dates."));
        }
        const p = await fetch(
          `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?id=eq.${encodeURIComponent(inc.id)}`,
          { method: "PATCH", headers: { ...sbHeaders(env), "Prefer": "return=representation" }, body: JSON.stringify({ date_to: cut, updated_at: nowIso() }) }
        );
        if (!p.ok) {
          const err = await p.text();
          return withCORS(env, req, badRequest(`Failed to truncate incumbent override: ${err}`));
        }
      }
    }

    const record = {
      candidate_id,
      client_id,
      role,
      band,
      date_from,
      date_to,
      rate_type,
      pay_day:   data.pay_day   ?? null,
      pay_night: data.pay_night ?? null,
      pay_sat:   data.pay_sat   ?? null,
      pay_sun:   data.pay_sun   ?? null,
      pay_bh:    data.pay_bh    ?? null,
      created_at: nowIso(),
    };

    const res = await fetch(`${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides`, {
      method: "POST",
      headers: { ...sbHeaders(env), Prefer: "return=representation" },
      body: JSON.stringify(record),
    });

    if (!res.ok) {
      const err = await res.text();
      return withCORS(env, req, badRequest(`Override creation failed: ${err}`));
    }

    const json = await res.json().catch(() => ({}));
    const override = Array.isArray(json) ? json[0] : json;

    // Enqueue recompute for this candidate (+client if provided), scoped by pay_method
    await enqueueTsfinRecomputeForCandidate(env, candidate_id, rate_type, client_id);

    return withCORS(env, req, ok({ override }));
  } catch {
    return withCORS(env, req, serverError("Failed to create override"));
  }

  function dayBeforeYmd(ymd) {
    if (!ymd) return null;
    const d = new Date(`${ymd}T00:00:00Z`);
    d.setUTCDate(d.getUTCDate() - 1);
    const y = d.getUTCFullYear();
    const m = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${y}-${m}-${dd}`;
  }
}

async function enqueueTsfinRecomputeForCandidate(env, candidate_id, rate_type, client_id /* optional */) {
  try {
    let q =
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?select=timesheet_id` +
      `&candidate_id=eq.${encodeURIComponent(candidate_id)}` +
      `&pay_method=eq.${encodeURIComponent(rate_type)}` +
      `&is_current=eq.true` +
      `&locked_by_invoice_id=is.null`;
    if (client_id) q += `&client_id=eq.${encodeURIComponent(client_id)}`;
    const { rows: tsfins } = await sbFetch(env, q);

    if (tsfins && tsfins.length) {
      const now = nowIso();
      const items = tsfins.map(r => ({
        timesheet_id: r.timesheet_id,
        reason: 'RATE_CHANGED',
        attempt_count: 0,
        next_attempt_at: now,
        last_error: null,
        created_at: now,
      }));
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
        {
          method: "POST",
          headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
          body: JSON.stringify(items)
        }
      );
    }
  } catch (_) { /* non-fatal */ }
}

async function handleUpdateClientDefault(env, req, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!id)   return withCORS(env, req, badRequest('id required'));

  // Parse body
  let body = {};
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  // Whitelist editable fields
  const allowed = [
    'client_id','role','band','date_from','date_to',
    'charge_day','charge_night','charge_sat','charge_sun','charge_bh',
    'paye_day','paye_night','paye_sat','paye_sun','paye_bh',
    'umb_day','umb_night','umb_sat','umb_sun','umb_bh'
  ];
  const patch = {};
  for (const k of allowed) if (k in body) patch[k] = body[k];

  if (Object.keys(patch).length === 0) {
    return withCORS(env, req, badRequest('No updatable fields supplied'));
  }

  try {
    // Ensure row exists (optional but yields clean 404)
    const getUrl = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?select=id&id=eq.${encodeURIComponent(id)}&limit=1`;
    const { rows: rowsGet } = await sbFetch(env, getUrl);
    if (!rowsGet || !rowsGet.length) {
      return withCORS(env, req, notFound(`Client default ${id} not found`));
    }

    // Update (PostgREST PATCH is fine for PUT semantics here)
    const updUrl = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?id=eq.${encodeURIComponent(id)}`;
    const res = await fetch(updUrl, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
      body: JSON.stringify(patch)
    });
    if (!res.ok) {
      const err = await res.text();
      // Map unique/constraint violations if needed
      return withCORS(env, req, badRequest(`Update failed: ${err}`));
    }
    const json = await res.json().catch(()=> []);
    const row  = Array.isArray(json) ? json[0] : json;
    return withCORS(env, req, ok(row || { ok: true }));
  } catch (e) {
    return withCORS(env, req, serverError('Failed to update client default'));
  }
}
function canonicalizeClientSettingsServer(beforeCs, csInput) {
  const before = (beforeCs && typeof beforeCs === 'object') ? beforeCs : {};
  const in0    = (csInput && typeof csInput === 'object') ? csInput : {};

  const TIME_KEYS = [
    'day_start','day_end',
    'night_start','night_end',
    'sat_start','sat_end',
    'sun_start','sun_end',
    'bh_start','bh_end'
  ];

  const asBool = (v) => {
    if (v === true) return true;
    if (v === false || v == null) return false;
    const s = String(v).trim().toLowerCase();
    return s === 'true' || s === 'yes' || s === 'y' || s === '1' || s === 'on';
  };

  const normTime = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    if (!s) return null;
    const m = s.match(/^(\d{2}:\d{2})/); // accepts "06:00:00"
    return m ? m[1] : s;
  };

  const normEmail = (v) => {
    if (v == null) return null;
    const s = String(v).trim();
    return s ? s : null;
  };

  // ✅ NEW: canonical invoice consolidation mode (server policy: preserve existing if missing/invalid)
  // Allowed: NONE | BY_WEEK | ANY_WEEK  (accept ALL -> ANY_WEEK)
  const normInvoiceConsol = (v) => {
    if (v == null) return null;
    const s = String(v).trim().toUpperCase();
    if (!s) return null;
    if (s === 'ALL') return 'ANY_WEEK';
    if (s === 'ANY') return 'ANY_WEEK';
    if (s === 'NONE' || s === 'BY_WEEK' || s === 'ANY_WEEK') return s;
    return '__INVALID__';
  };

  const out = {};

  // timezone_id (nullable; null => inherit global)
  if (Object.prototype.hasOwnProperty.call(in0, 'timezone_id')) out.timezone_id = (String(in0.timezone_id || '').trim() || null);
  else if (Object.prototype.hasOwnProperty.call(before, 'timezone_id')) out.timezone_id = (String(before.timezone_id || '').trim() || null);

  // time keys: only override when key is present (null allowed to clear/inherit global)
  for (const k of TIME_KEYS) {
    if (Object.prototype.hasOwnProperty.call(in0, k)) out[k] = normTime(in0[k]);
    else if (Object.prototype.hasOwnProperty.call(before, k)) out[k] = normTime(before[k]);
  }

  // booleans / flags (preserve if not provided)
  const BOOL_KEYS = [
    'hr_validation_required',
    'ts_reference_required',
    'pay_reference_required',
    'invoice_reference_required',
    'is_nhsp',
    'self_bill_no_invoices_sent',
    'daily_calc_of_invoices',
    'no_timesheet_required',
    'group_nightsat_sunbh',
    'auto_invoice_default',
    'requires_hr',
    'autoprocess_hr',
    'hr_attach_to_invoice',
    'ts_attach_to_invoice',
    'send_manual_invoices_to_different_email',

    // ✅ NEW: ref-to-issue
    'reference_number_required_to_issue_invoice'
  ];

  for (const k of BOOL_KEYS) {
    if (Object.prototype.hasOwnProperty.call(in0, k)) out[k] = asBool(in0[k]);
    else if (Object.prototype.hasOwnProperty.call(before, k)) out[k] = asBool(before[k]);
  }

  // manual invoices alt email routing
  if (Object.prototype.hasOwnProperty.call(in0, 'manual_invoices_alt_email_address')) {
    out.manual_invoices_alt_email_address = normEmail(in0.manual_invoices_alt_email_address);
  } else if (Object.prototype.hasOwnProperty.call(before, 'manual_invoices_alt_email_address')) {
    out.manual_invoices_alt_email_address = normEmail(before.manual_invoices_alt_email_address);
  }

  // week_ending_weekday
  if (Object.prototype.hasOwnProperty.call(in0, 'week_ending_weekday')) {
    const w = Number(in0.week_ending_weekday);
    out.week_ending_weekday = (Number.isInteger(w) && w >= 0 && w <= 6) ? w : 0;
  } else if (Object.prototype.hasOwnProperty.call(before, 'week_ending_weekday')) {
    const w = Number(before.week_ending_weekday);
    out.week_ending_weekday = (Number.isInteger(w) && w >= 0 && w <= 6) ? w : 0;
  } else {
    out.week_ending_weekday = 0;
  }

  // default_submission_mode
  if (Object.prototype.hasOwnProperty.call(in0, 'default_submission_mode')) {
    const d = String(in0.default_submission_mode || '').trim().toUpperCase();
    out.default_submission_mode = (d === 'MANUAL' || d === 'ELECTRONIC') ? d : 'ELECTRONIC';
  } else if (Object.prototype.hasOwnProperty.call(before, 'default_submission_mode')) {
    const d = String(before.default_submission_mode || '').trim().toUpperCase();
    out.default_submission_mode = (d === 'MANUAL' || d === 'ELECTRONIC') ? d : 'ELECTRONIC';
  } else {
    out.default_submission_mode = 'ELECTRONIC';
  }

  // ✅ NEW: invoice_consolidation_mode
  // Server policy: if missing -> preserve existing; if invalid -> preserve existing; else set normalized.
  {
    const hasIn = Object.prototype.hasOwnProperty.call(in0, 'invoice_consolidation_mode');
    const hasBefore = Object.prototype.hasOwnProperty.call(before, 'invoice_consolidation_mode');

    if (hasIn) {
      const nv = normInvoiceConsol(in0.invoice_consolidation_mode);
      if (nv && nv !== '__INVALID__') {
        out.invoice_consolidation_mode = nv;
      } else if (hasBefore) {
        const bv = normInvoiceConsol(before.invoice_consolidation_mode);
        if (bv && bv !== '__INVALID__') out.invoice_consolidation_mode = bv;
      }
      // If invalid and no before, omit (caller may default)
    } else if (hasBefore) {
      const bv = normInvoiceConsol(before.invoice_consolidation_mode);
      if (bv && bv !== '__INVALID__') out.invoice_consolidation_mode = bv;
    }
  }

  // policy: self-bill => auto-invoice forced false
  if (out.self_bill_no_invoices_sent) out.auto_invoice_default = false;

  // defaults for attach flags if still missing
  if (!Object.prototype.hasOwnProperty.call(out, 'hr_attach_to_invoice')) out.hr_attach_to_invoice = true;
  if (!Object.prototype.hasOwnProperty.call(out, 'ts_attach_to_invoice')) out.ts_attach_to_invoice = true;

  // if manual-invoice toggle off => clear email
  if (!out.send_manual_invoices_to_different_email) out.manual_invoices_alt_email_address = null;

  return out;
}


// ============================================================
// UPDATED: handleUpdateClient
// - Uses updated canonicalizeClientSettingsServer
// - Validates manual invoice alt email: if toggle ON, email must be present
// ============================================================



// ─────────────────────────────────────────────────────────────────────────────
// Overrides: UPDATE (targeting now supports rate_type in the WHERE side)
// Enqueue: RATE_CHANGED for current, unlocked TSFIN scoped by rate_type (if given)
// ─────────────────────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────────────────────
// Overrides: UPDATE (server enforces no-overlap; gate if date_from/role/band/client changes)
// PATCH /api/rates/candidate-overrides?candidate_id=...&client_id=...&role=...&band=...&rate_type=...
// - Require client_id not to become NULL
// - If start date / role / band / client changes: gate against client defaults at new start
// - If new start overlaps same-type incumbent (excluding the row itself), truncate incumbent to N−1
// - If later same-type window would overlap new (date_to null/too far), clamp date_to to day before next-start
// - Enqueue RATE_CHANGED for current, unlocked TSFIN (candidate, optional client, pay_method if known)
// ─────────────────────────────────────────────────────────────────────────────
async function handleUpdateOverride(env, req, candidateId, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const data = await parseJSONBody(req);
  if (!data) return withCORS(env, req, badRequest("Invalid JSON"));

  const sp   = new URL(req.url).searchParams;
  const cand = candidateId || sp.get("candidate_id");
  const cidQ = (clientId !== undefined && clientId !== null) ? clientId : sp.get("client_id");
  const roleQ = sp.get("role");
  const bandQ = sp.get("band");
  const rateTypeFilter = sp.get("rate_type");

  if (!cand) return withCORS(env, req, badRequest("candidate_id required"));
  if (!cidQ && !roleQ && !bandQ && !rateTypeFilter) {
    return withCORS(env, req, badRequest("Provide at least one of client_id, role, band, or rate_type to target an override"));
  }

  if (data.rate_type) {
    const rt = String(data.rate_type).toUpperCase();
    if (rt !== 'PAYE' && rt !== 'UMBRELLA') {
      return withCORS(env, req, badRequest("rate_type must be 'PAYE' or 'UMBRELLA'"));
    }
  }

  // Query target rows first
  let selectUrl = `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?candidate_id=eq.${encodeURIComponent(cand)}`;
  if (cidQ !== undefined && cidQ !== null) {
    if (String(cidQ).toLowerCase() === 'null') selectUrl += `&client_id=is.null`;
    else selectUrl += `&client_id=eq.${encodeURIComponent(cidQ)}`;
  }
  if (roleQ) {
    if (String(roleQ).toLowerCase() === 'null') selectUrl += `&role=is.null`;
    else selectUrl += `&role=eq.${encodeURIComponent(roleQ)}`;
  }
  if (bandQ) {
    if (String(bandQ).toLowerCase() === 'null') selectUrl += `&band=is.null`;
    else selectUrl += `&band=eq.${encodeURIComponent(bandQ)}`;
  }
  if (rateTypeFilter) {
    selectUrl += `&rate_type=eq.${encodeURIComponent(rateTypeFilter)}`;
  }
  selectUrl += `&select=id,candidate_id,client_id,role,band,date_from,date_to,rate_type`;

  try {
    const { rows: targets } = await sbFetch(env, selectUrl);
    if (!targets || !targets.length) {
      return withCORS(env, req, notFound("Override not found"));
    }

    const patched = [];

    for (const t of targets) {
      const newRow = {
        ...t,
        ...data,
        client_id: (data.client_id === '' ? null : (data.client_id ?? t.client_id)),
        role:      (data.role      === '' ? null : (data.role      ?? t.role)),
        band:      (data.band      === '' ? null : (data.band      ?? t.band)),
        date_from: (data.date_from === '' ? null : (data.date_from ?? t.date_from)),
        date_to:   (data.date_to   === '' ? null : (data.date_to   ?? t.date_to)),
        rate_type: (data.rate_type ? String(data.rate_type).toUpperCase() : t.rate_type)
      };

      if (!newRow.client_id) {
        return withCORS(env, req, badRequest("client_id cannot be NULL on overrides"));
      }
      if (!newRow.role) {
        return withCORS(env, req, badRequest("role required on overrides"));
      }
      if (!newRow.date_from) {
        return withCORS(env, req, badRequest("date_from required on overrides"));
      }
      // Gate against client defaults for (client, role, band|null) at new start
      {
        const gateQ =
          `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
          `?client_id=eq.${encodeURIComponent(newRow.client_id)}` +
          `&role=eq.${encodeURIComponent(newRow.role)}` +
          (newRow.band == null ? `&band=is.null` : `&band=eq.${encodeURIComponent(newRow.band)}`) +
          `&date_from=lte.${encodeURIComponent(newRow.date_from)}` +
          `&or=(date_to.gte.${encodeURIComponent(newRow.date_from)},date_to.is.null)` +
          `&select=id&limit=1`;
        const { rows: gateRows } = await sbFetch(env, gateQ);
        if (!gateRows || !gateRows.length) {
          return withCORS(env, req, badRequest("Client has no active default window for the updated role/band at the override start date."));
        }
      }

      // Truncate same-type incumbent (excluding this id) active at new start
      {
        const incQ =
          `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides` +
          `?candidate_id=eq.${encodeURIComponent(newRow.candidate_id)}` +
          `&client_id=eq.${encodeURIComponent(newRow.client_id)}` +
          `&rate_type=eq.${encodeURIComponent(newRow.rate_type)}` +
          (newRow.role ? `&role=eq.${encodeURIComponent(newRow.role)}` : `&role=is.null`) +
          (newRow.band == null ? `&band=is.null` : `&band=eq.${encodeURIComponent(newRow.band)}`) +
          `&date_from=lte.${encodeURIComponent(newRow.date_from)}` +
          `&or=(date_to.gte.${encodeURIComponent(newRow.date_from)},date_to.is.null)` +
          `&select=id,date_from,date_to&order=date_from.desc&limit=2`;
        const { rows: incs } = await sbFetch(env, incQ);

        const filtered = (incs || []).filter(r => String(r.id) !== String(t.id));
        if (filtered.length > 1) {
          return withCORS(env, req, badRequest("Multiple incumbent overrides found that would overlap. Please tidy overlaps first."));
        }
        if (filtered.length === 1) {
          const inc = filtered[0];
          if (String(inc.date_from) === String(newRow.date_from)) {
            return withCORS(env, req, badRequest("Another override already starts on the same date. Adjust dates or edit the other override."));
          }
          const cut = dayBeforeYmd(newRow.date_from);
          if (inc.date_from && cut < inc.date_from) {
            return withCORS(env, req, badRequest("Updated start would back-cut before the other override's start. Adjust dates."));
          }
          const p = await fetch(
            `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?id=eq.${encodeURIComponent(inc.id)}`,
            { method: "PATCH", headers: { ...sbHeaders(env), "Prefer": "return=representation" }, body: JSON.stringify({ date_to: cut, updated_at: nowIso() }) }
          );
          if (!p.ok) {
            const err = await p.text();
            return withCORS(env, req, badRequest(`Failed to truncate conflicting override: ${err}`));
          }
        }
      }

      // Clamp date_to if a later same-type override would overlap
      {
        let laterQ =
          `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides` +
          `?candidate_id=eq.${encodeURIComponent(newRow.candidate_id)}` +
          `&client_id=eq.${encodeURIComponent(newRow.client_id)}` +
          `&rate_type=eq.${encodeURIComponent(newRow.rate_type)}` +
          (newRow.role ? `&role=eq.${encodeURIComponent(newRow.role)}` : `&role=is.null`) +
          (newRow.band == null ? `&band=is.null` : `&band=eq.${encodeURIComponent(newRow.band)}`) +
          `&date_from=gt.${encodeURIComponent(newRow.date_from)}` +
          `&select=id,date_from&order=date_from.asc&limit=1`;
        const { rows: nexts } = await sbFetch(env, laterQ);
        if (nexts && nexts.length === 1) {
          const nextStart = nexts[0].date_from;
          const clampTo = dayBeforeYmd(nextStart);
          if (!newRow.date_to || newRow.date_to > clampTo) {
            newRow.date_to = clampTo;
          }
        }
      }

      // Persist this row by id
      const patch = {
        client_id: newRow.client_id,
        role:      newRow.role,
        band:      newRow.band,
        date_from: newRow.date_from,
        date_to:   newRow.date_to,
        rate_type: newRow.rate_type,
        pay_day:   newRow.pay_day   ?? null,
        pay_night: newRow.pay_night ?? null,
        pay_sat:   newRow.pay_sat   ?? null,
        pay_sun:   newRow.pay_sun   ?? null,
        pay_bh:    newRow.pay_bh    ?? null,
        updated_at: nowIso()
      };

      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?id=eq.${encodeURIComponent(t.id)}`,
        { method: "PATCH", headers: { ...sbHeaders(env), "Prefer": "return=representation" }, body: JSON.stringify(patch) }
      );

      if (!res.ok) {
        const err = await res.text();
        return withCORS(env, req, badRequest(`Override update failed: ${err}`));
      }

      const json = await res.json().catch(() => []);
      patched.push(Array.isArray(json) ? json[0] : json);
    }

    // Enqueue recompute for affected TSFIN (if a unique rate_type emerged, use it; else enqueue both)
    const rt =
      (rateTypeFilter && rateTypeFilter.toUpperCase()) ||
      (data.rate_type && String(data.rate_type).toUpperCase()) ||
      (patched[0] && patched[0].rate_type && String(patched[0].rate_type).toUpperCase()) ||
      null;

    if (rt) {
      await enqueueTsfinRecomputeForCandidate(env, cand, rt, (cidQ && String(cidQ).toLowerCase() !== 'null') ? cidQ : null);
    } else {
      await enqueueTsfinRecomputeForCandidate(env, cand, 'PAYE',     (cidQ && String(cidQ).toLowerCase() !== 'null') ? cidQ : null);
      await enqueueTsfinRecomputeForCandidate(env, cand, 'UMBRELLA', (cidQ && String(cidQ).toLowerCase() !== 'null') ? cidQ : null);
    }

    return withCORS(env, req, ok({ override: patched[0] || null }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to update override"));
  }

  function dayBeforeYmd(ymd) {
    if (!ymd) return null;
    const d = new Date(`${ymd}T00:00:00Z`);
    d.setUTCDate(d.getUTCDate() - 1);
    const y = d.getUTCFullYear();
    const m = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd = String(d.getUTCDate()).padStart(2, '0');
    return `${y}-${m}-${dd}`;
  }
}



// ─────────────────────────────────────────────────────────────────────────────
// Overrides: DELETE (targeting now supports rate_type in the WHERE side)
// Enqueue: RATE_CHANGED for current, unlocked TSFIN scoped by rate_type (if given)
// ─────────────────────────────────────────────────────────────────────────────
async function handleDeleteOverride(env, req, candidateId, clientId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const sp   = new URL(req.url).searchParams;

  // Prefer explicit override id (path or ?id=)
  const overrideId = sp.get('id') || null;

  // Back-compat inputs (used only if no id is supplied)
  const cand = candidateId || sp.get("candidate_id");
  const cid  = (clientId !== undefined && clientId !== null) ? clientId : sp.get("client_id");
  const role = sp.get("role");
  const band = sp.get("band");
  const rateTypeFilter = sp.get("rate_type"); // optional

  try {
    let targetRow = null;

    if (overrideId) {
      // Fetch the row first (for enqueue metadata + 404 handling)
      const qGet = `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?select=id,candidate_id,rate_type&id=eq.${encodeURIComponent(overrideId)}&limit=1`;
      const { rows: getRows } = await sbFetch(env, qGet);
      if (!getRows || !getRows.length) {
        return withCORS(env, req, notFound(`Override ${overrideId} not found`));
      }
      targetRow = getRows[0];

      // Delete by id (single row)
      const delUrl = `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?id=eq.${encodeURIComponent(overrideId)}`;
      const delRes = await fetch(delUrl, { method: "DELETE", headers: sbHeaders(env) });
      if (!delRes.ok) {
        const err = await delRes.text();
        return withCORS(env, req, badRequest(`Override delete failed: ${err}`));
      }
    } else {
      // Legacy path: delete via candidate + filters — must resolve to exactly ONE row
      if (!cand) return withCORS(env, req, badRequest("candidate_id required when no override id is provided"));
      if (!cid && !role && !band && !rateTypeFilter) {
        return withCORS(env, req, badRequest("Provide at least one of client_id, role, band, or rate_type to target a single override for delete"));
      }

      // Build a select to find exactly one row
      let sel = `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?select=id,candidate_id,rate_type&candidate_id=eq.${encodeURIComponent(cand)}`;
      if (cid !== undefined && cid !== null) {
        if (String(cid).toLowerCase() === 'null') sel += `&client_id=is.null`;
        else sel += `&client_id=eq.${encodeURIComponent(cid)}`;
      }
      if (role) {
        if (String(role).toLowerCase() === 'null') sel += `&role=is.null`;
        else sel += `&role=eq.${encodeURIComponent(role)}`;
      }
      if (band) {
        if (String(band).toLowerCase() === 'null') sel += `&band=is.null`;
        else sel += `&band=eq.${encodeURIComponent(band)}`;
      }
      if (rateTypeFilter) sel += `&rate_type=eq.${encodeURIComponent(rateTypeFilter)}`;

      // Request up to 2 rows to detect ambiguity
      sel += `&limit=2`;
      const { rows: found } = await sbFetch(env, sel);
      const n = (found || []).length;

      if (!n) return withCORS(env, req, notFound("No matching candidate override to delete"));
      if (n > 1) return withCORS(env, req, badRequest("Delete is ambiguous — filters match multiple overrides"));

      targetRow = found[0];

      // Delete that single id
      const delUrl = `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides?id=eq.${encodeURIComponent(targetRow.id)}`;
      const delRes = await fetch(delUrl, { method: "DELETE", headers: sbHeaders(env) });
      if (!delRes.ok) {
        const err = await delRes.text();
        return withCORS(env, req, badRequest(`Override delete failed: ${err}`));
      }
    }

    // ── Best-effort enqueue recompute for affected TSFIN (current & unlocked), scoped by pay method
    try {
      const enqRateType = targetRow?.rate_type ? String(targetRow.rate_type).toUpperCase() : null;
      const enqCandId   = targetRow?.candidate_id || cand || null;

      if (enqCandId) {
        let qTsfin = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
                     `?select=timesheet_id` +
                     `&candidate_id=eq.${encodeURIComponent(enqCandId)}` +
                     `&is_current=eq.true` +
                     `&locked_by_invoice_id=is.null`;
        if (enqRateType) qTsfin += `&pay_method=eq.${encodeURIComponent(enqRateType)}`;

        const { rows: tsfins } = await sbFetch(env, qTsfin);
        const toEnqueue = (tsfins || []).map(r => ({ timesheet_id: r.timesheet_id, reason: 'RATE_CHANGED' }));
        if (toEnqueue.length) {
          await fetch(`${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`, {
            method: "POST",
            headers: { ...sbHeaders(env), "Prefer": "resolution=ignore-duplicates" },
            body: JSON.stringify(toEnqueue)
          });
        }
      }
    } catch (_) { /* best-effort enqueue; ignore failures */ }

    return withCORS(env, req, ok({ ok: true, deleted: 1, id: targetRow?.id || overrideId || null }));
  } catch {
    return withCORS(env, req, serverError("Failed to delete override"));
  }
}



async function handleDeleteClientDefault(env, req, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!id) return withCORS(env, req, badRequest("id required"));

  try {
    // Optional: fetch first to confirm existence (and to return a 404 cleanly)
    const getUrl = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?select=id,client_id,role,band,date_from,date_to&id=eq.${encodeURIComponent(id)}&limit=1`;
    const { rows: rowsGet } = await sbFetch(env, getUrl);
    if (!rowsGet || !rowsGet.length) {
      return withCORS(env, req, notFound(`Client default rate ${id} not found`));
    }

    // Hard delete the window
    const delUrl = `${env.SUPABASE_URL}/rest/v1/rates_client_defaults?id=eq.${encodeURIComponent(id)}`;
    const delRes = await fetch(delUrl, { method: 'DELETE', headers: sbHeaders(env) });
    if (!delRes.ok) {
      const err = await delRes.text();
      // 409 when FK/constraint prevents deletion
      const isConstraint = /foreign key|constraint|violat/i.test(err || '');
      return withCORS(env, req, isConstraint ? conflict(`Delete blocked: ${err}`) : badRequest(`Client default delete failed: ${err}`));
    }

    // (Optional) You could enqueue TSFIN recomputes for all candidates at this client/role/band,
    // but since this is a client-default change, your existing pipelines may already refresh on next resolve.

    // Return success
    return withCORS(env, req, ok({ ok: true, deleted: 1, id }));
  } catch (e) {
    return withCORS(env, req, serverError("Failed to delete client default rate"));
  }
}

// ─────────────────────────────────────────────────────────────────────────────
// Rates: resolve-preview (now derives rate_type from candidate.pay_method
// if not provided; PAY from override/def filtered by rate_type; CHARGE
// from client defaults without rate_type filtering)
// ─────────────────────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────────────────────
// Rates: resolve-preview (UNIFIED DEFAULTS)
// - Derive rate_type from candidate if not provided
// - PAY: candidate override (same type) if present (exact band → else band-null); else from unified client default (paye_* or umb_*)
// - CHARGE: always from unified client default (exact band → else band-null)
// - Return both PAY and CHARGE even when override is used
// ─────────────────────────────────────────────────────────────────────────────
async function handleResolveRate(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const payload = req.method === "GET"
    ? Object.fromEntries(new URL(req.url).searchParams)
    : await parseJSONBody(req);

  const client_id    = payload.client_id;
  const candidate_id = payload.candidate_id;
  const role         = payload.role || null;
  const band         = (payload.band === '' ? null : payload.band || null);
  const date         = payload.date || payload.on || null;

  if (!client_id || !candidate_id) {
    return withCORS(env, req, badRequest("client_id and candidate_id are required"));
  }
  if (!date) {
    return withCORS(env, req, badRequest("date (YYYY-MM-DD) is required"));
  }

  // Determine effective rate_type
  let rate_type = (payload.rate_type || '').toUpperCase();
  if (rate_type !== 'PAYE' && rate_type !== 'UMBRELLA') {
    try {
      const { rows: cand } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${encodeURIComponent(candidate_id)}&select=pay_method&limit=1`
      );
      const pm = (cand && cand[0] && (cand[0].pay_method || '')).toUpperCase();
      rate_type = (pm === 'PAYE' || pm === 'UMBRELLA') ? pm : 'UMBRELLA';
    } catch {
      rate_type = 'UMBRELLA';
    }
  }

  try {
    // 1) Try candidate override pay (exact band → band-null)
    const override = await fetchActiveOverride(env, { candidate_id, client_id, role, band, date, rate_type });

    // 2) Charge from unified client default (exact band → band-null)
    const windowCharge = await fetchUnifiedDefaultWindow(env, { client_id, role, band, date });
    const charge = windowCharge ? pickCharge(windowCharge) : null;

    if (override) {
      return withCORS(env, req, ok({
        source: "candidate_override",
        rate_type,
        charge,
        pay: pickPay(windowCharge /* may be null */, override, rate_type, /* preferOverride */ true)
      }));
    }

    // 3) No override → pay from unified defaults (if any)
    const windowPay = windowCharge || await fetchUnifiedDefaultWindow(env, { client_id, role, band, date }); // reuse if same
    if (windowPay) {
      return withCORS(env, req, ok({
        source: "client_defaults",
        rate_type,
        charge: pickCharge(windowPay),
        pay:    pickPay(windowPay, null, rate_type, /* preferOverride */ false)
      }));
    }

    return withCORS(env, req, notFound("No applicable client default was found for pay/charge resolution."));
  } catch {
    return withCORS(env, req, serverError("Failed to resolve rates"));
  }

  // Helpers (local)
  function pickCharge(w) {
    if (!w) return null;
    return {
      day:   w.charge_day,
      night: w.charge_night,
      sat:   w.charge_sat,
      sun:   w.charge_sun,
      bh:    w.charge_bh
    };
  }

  function pickPay(windowRow, overrideRow, rt, preferOverride) {
    if (preferOverride && overrideRow) {
      return {
        day:   overrideRow.pay_day,
        night: overrideRow.pay_night,
        sat:   overrideRow.pay_sat,
        sun:   overrideRow.pay_sun,
        bh:    overrideRow.pay_bh
      };
    }
    if (!windowRow) return null;
    if (rt === 'PAYE') {
      return {
        day: windowRow.paye_day, night: windowRow.paye_night, sat: windowRow.paye_sat, sun: windowRow.paye_sun, bh: windowRow.paye_bh
      };
    }
    return {
      day: windowRow.umb_day, night: windowRow.umb_night, sat: windowRow.umb_sat, sun: windowRow.umb_sun, bh: windowRow.umb_bh
    };
  }
}

// 1) Candidate override PAY (exact band → band-null)
async function fetchActiveOverride(env, { candidate_id, client_id, role, band, date, rate_type }) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L = (...a) => { if (LOG) console.log('[TSFIN][DAILY][fetchActiveOverride]', ...a); };

  const enc = encodeURIComponent;
  const norm = (s) => String(s || '').trim();
  const roleN = role ? norm(role).replace(/\s+/g, ' ').trim().toUpperCase() : null;

  const normBand = (v) => {
    const s = norm(v);
    if (!s) return null;
    let m = s.match(/^\s*band\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*b\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*([0-9]+)\s*$/);
    if (m && m[1]) return `Band ${parseInt(m[1], 10)}`;
    return s;
  };

  const bandN = normBand(band);

  if (!candidate_id || !date || !rate_type) {
    L('early return (missing candidate/date/rate_type)', { candidate_id, date, rate_type });
    return null;
  }

  const andParts = [
    `candidate_id.eq.${enc(candidate_id)}`,
    `rate_type.eq.${enc(rate_type)}`,
    `date_from.lte.${enc(date)}`,
    `or(date_to.is.null,date_to.gte.${enc(date)})`,
  ];

  if (client_id) andParts.push(`or(client_id.eq.${enc(client_id)},client_id.is.null)`);
  if (roleN)      andParts.push(`or(role.eq.${enc(roleN)},role.is.null)`);

  if (bandN != null) andParts.push(`or(band.eq.${enc(bandN)},band.is.null)`);
  else               andParts.push(`band.is.null`);

  const q =
    `${env.SUPABASE_URL}/rest/v1/rates_candidate_overrides` +
    `?select=*` +
    `&and=(${andParts.join(',')})` +
    `&order=client_id.nullslast,role.nullslast,band.nullslast,date_from.desc` +
    `&limit=1`;

  L('query', { q, roleN, bandN, client_id, candidate_id, date, rate_type });

  const { rows } = await sbFetch(env, q);
  const hit = rows && rows[0] ? rows[0] : null;

  L('result', hit ? { id: hit.id, client_id: hit.client_id, role: hit.role, band: hit.band, rate_type: hit.rate_type } : null);
  return hit;
}
// ─────────────────────────────────────────────────────────────────────────────
// Rates: RESOLUTION HELPER (ENABLED-ONLY)
// fetchUnifiedDefaultWindow → now ignores disabled rows for both exact-band and band-null
// ─────────────────────────────────────────────────────────────────────────────

// 2) Client default window for CHARGE (and PAY if needed)
// NOTE: this is used by resolveRates; included here because role/band normalisation must match.




async function fetchUnifiedDefaultWindow(env, { client_id, role, band, date }) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L = (...a) => { if (LOG) console.log('[TSFIN][DAILY][fetchUnifiedDefaultWindow]', ...a); };

  const norm = (s) => String(s || '').trim();
  const normRole = (s) => norm(s).replace(/\s+/g, ' ').trim().toUpperCase();

  const normBand = (v) => {
    const s = norm(v);
    if (!s) return null;
    let m = s.match(/^\s*band\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*b\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*([0-9]+)\s*$/);
    if (m && m[1]) return `Band ${parseInt(m[1], 10)}`;
    return s;
  };

  const roleN = role ? normRole(role) : null;
  const bandN = normBand(band);

  if (!client_id || !roleN || !date) {
    L('early return (missing client/role/date)', { client_id, roleN, date });
    return null;
  }

  let qExact =
    `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
    `?client_id=eq.${encodeURIComponent(client_id)}` +
    `&role=eq.${encodeURIComponent(roleN)}` +
    (bandN == null ? `&band=is.null` : `&band=eq.${encodeURIComponent(bandN)}`) +
    `&date_from=lte.${encodeURIComponent(date)}` +
    `&or=(date_to.gte.${encodeURIComponent(date)},date_to.is.null)` +
    `&disabled_at_utc=is.null` +
    `&select=*` +
    `&order=date_from.desc&limit=1`;

  L('query exact', { qExact, roleN, bandN, date });

  const { rows: exact } = await sbFetch(env, qExact);
  if (exact && exact[0]) {
    L('hit exact', { id: exact[0].id, role: exact[0].role, band: exact[0].band, date_from: exact[0].date_from, date_to: exact[0].date_to });
    return exact[0];
  }

  if (bandN != null) {
    let qNull =
      `${env.SUPABASE_URL}/rest/v1/rates_client_defaults` +
      `?client_id=eq.${encodeURIComponent(client_id)}` +
      `&role=eq.${encodeURIComponent(roleN)}` +
      `&band=is.null` +
      `&date_from=lte.${encodeURIComponent(date)}` +
      `&or=(date_to.gte.${encodeURIComponent(date)},date_to.is.null)` +
      `&disabled_at_utc=is.null` +
      `&select=*` +
      `&order=date_from.desc&limit=1`;

    L('query band-null fallback', { qNull });

    const { rows: nullRows } = await sbFetch(env, qNull);
    if (nullRows && nullRows[0]) {
      L('hit band-null fallback', { id: nullRows[0].id, role: nullRows[0].role, band: nullRows[0].band, date_from: nullRows[0].date_from, date_to: nullRows[0].date_to });
      return nullRows[0];
    }
  }

  L('miss');
  return null;
}

async function handleRelatedList(env, req, entity, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const url = new URL(req.url);
  const type = (matchPath(url.pathname, '/api/related/:entity/:id/:type') || {}).type;
  const limit  = Math.max(1, Math.min(100, parseInt(url.searchParams.get('limit')  || '20', 10)));
  const offset = Math.max(0, parseInt(url.searchParams.get('offset') || '0', 10));

  const okList = (items, total = undefined) =>
    withCORS(env, req, ok({ items, ...(typeof total === 'number' ? { total } : {}) }));

  const enc = encodeURIComponent;

  // Helpers for week-ending (Sunday) computation – for a few legacy branches
  const MS_DAY = 24 * 60 * 60 * 1000;
  const toISODate = (d) => {
    const y = d.getUTCFullYear();
    const m = String(d.getUTCMonth() + 1).padStart(2, '0');
    const day = String(d.getUTCDate()).padStart(2, '0');
    return `${y}-${m}-${day}`;
  };
  const parseDate = (s) => {
    if (!s) return null;
    const m = String(s).match(/^(\d{4})-(\d{2})-(\d{2})$/);
    if (m) return new Date(Date.UTC(+m[1], +m[2] - 1, +m[3]));
    const d = new Date(s);
    return isNaN(d.getTime()) ? null : d;
  };
  const computeWeekEndingSunday = (baseStr) => {
    const d = parseDate(baseStr);
    if (!d) return null;
    const dow = d.getUTCDay(); // 0=Sun
    const add = (7 - dow) % 7; // if already Sunday (0), add 0
    const sunday = new Date(d.getTime() + add * MS_DAY);
    return toISODate(sunday);
  };
  const computeWEFromRow = (r) => {
    const base =
      r.week_ending_date ||
      r.worked_date ||
      r.worked_from_date ||
      r.shift_date ||
      r.created_at_utc ||
      r.created_at ||
      null;
    const we = computeWeekEndingSunday(base);
    return we || null;
  };

  // RPC unwrap helper: supports PostgREST returning {fnname: ...} or [ {fnname: ...} ] or raw object.
  const unwrapRpcJsonb = (r, fnName) => {
    if (r == null) return null;

    // sbRpc sometimes returns { data: ... }
    if (r && typeof r === 'object' && !Array.isArray(r) && Object.prototype.hasOwnProperty.call(r, 'data')) {
      return unwrapRpcJsonb(r.data, fnName);
    }

    if (Array.isArray(r)) {
      if (r.length === 0) return null;
      if (r.length === 1) {
        const o = r[0];
        if (o && typeof o === 'object' && fnName && Object.prototype.hasOwnProperty.call(o, fnName)) return o[fnName];
        // single-row direct object
        return o;
      }
      return r;
    }

    if (r && typeof r === 'object' && fnName && Object.prototype.hasOwnProperty.call(r, fnName)) {
      return r[fnName];
    }

    return r;
  };

  const uuidLike = (s) => /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(String(s || '').trim());

  // ─────────────────────────────────────────────────────────────
  // SEGMENTS-safe fallback helpers (used only if RPC path not taken)
  // ─────────────────────────────────────────────────────────────
  const fetchAllInvoiceLines = async (filterQs, selectCsv) => {
    const chunk = 1000;
    let off = 0;
    const acc = [];

    while (true) {
      const api =
        `${env.SUPABASE_URL}/rest/v1/invoice_lines` +
        `?${filterQs}` +
        `&select=${selectCsv}` +
        `&limit=${chunk}&offset=${off}`;

      const { rows } = await sbFetch(env, api);
      const batch = rows || [];
      acc.push(...batch);

      if (batch.length < chunk) break;
      off += chunk;

      // hard safety
      if (off > 500000) break;
    }

    return acc;
  };

  const distinctInvoiceIdsForTimesheetIds = async (tsIds) => {
    const out = new Set();
    const ids = Array.isArray(tsIds) ? tsIds.map(String).filter(Boolean) : [];
    if (!ids.length) return out;

    const chunkSize = 200;
    for (let i = 0; i < ids.length; i += chunkSize) {
      const chunk = ids.slice(i, i + chunkSize);
      const filterQs = `timesheet_id=in.(${chunk.map(enc).join(',')})&invoice_id=not.is.null`;
      const rows = await fetchAllInvoiceLines(filterQs, 'invoice_id');
      for (const r of (rows || [])) {
        const invId = r?.invoice_id != null ? String(r.invoice_id).trim() : '';
        if (invId) out.add(invId);
      }
    }
    return out;
  };

  const distinctTimesheetIdsForInvoiceId = async (invoiceId) => {
    const out = new Set();
    const invId = String(invoiceId || '').trim();
    if (!invId) return out;

    const filterQs = `invoice_id=eq.${enc(invId)}&timesheet_id=not.is.null`;
    const rows = await fetchAllInvoiceLines(filterQs, 'timesheet_id');
    for (const r of (rows || [])) {
      const tsId = r?.timesheet_id != null ? String(r.timesheet_id).trim() : '';
      if (tsId) out.add(tsId);
    }
    return out;
  };

  const fetchInvoicesByIds = async (invoiceIds) => {
    const ids = Array.isArray(invoiceIds) ? invoiceIds.map(String).filter(Boolean) : [];
    if (!ids.length) return [];

    const sel = [
      'id','invoice_no','client_id','issued_at_utc','due_at_utc',
      'status','subtotal_ex_vat','vat_amount','total_inc_vat',
      'invoice_pdf_r2_key','header_snapshot_json','on_hold_reason','paid_at_utc'
    ].join(',');

    const acc = [];
    const chunkSize = 200;
    for (let i = 0; i < ids.length; i += chunkSize) {
      const chunk = ids.slice(i, i + chunkSize);
      const invUrl =
        `${env.SUPABASE_URL}/rest/v1/invoices` +
        `?id=in.(${chunk.map(enc).join(',')})` +
        `&select=${enc(sel)}`;
      const { rows } = await sbFetch(env, invUrl);
      acc.push(...(rows || []));
    }

    // Sort to match RPC ordering: issued_at_utc desc nulls last, id desc
    acc.sort((a, b) => {
      const aTs = a?.issued_at_utc ? String(a.issued_at_utc) : '';
      const bTs = b?.issued_at_utc ? String(b.issued_at_utc) : '';

      const aHas = !!aTs;
      const bHas = !!bTs;

      if (aHas && bHas) {
        if (aTs !== bTs) return (aTs > bTs ? -1 : 1);
      } else if (aHas !== bHas) {
        // nulls last
        return aHas ? -1 : 1;
      }

      const aId = a?.id ? String(a.id) : '';
      const bId = b?.id ? String(b.id) : '';
      if (aId === bId) return 0;
      return aId > bId ? -1 : 1;
    });

    return acc;
  };

  const fetchTimesheetSummaryByIds = async (tsIds) => {
    const ids = Array.isArray(tsIds) ? tsIds.map(String).filter(Boolean) : [];
    if (!ids.length) return [];

    const acc = [];
    const chunkSize = 200;
    for (let i = 0; i < ids.length; i += chunkSize) {
      const chunk = ids.slice(i, i + chunkSize);
      const tsUrl =
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
        `?select=*` +
        `&timesheet_id=in.(${chunk.map(enc).join(',')})`;
      const { rows } = await sbFetch(env, tsUrl);
      acc.push(...(rows || []));
    }

    // Sort to match RPC ordering: week_ending_date desc nulls last, client_name asc, candidate_name asc, timesheet_id::text
    acc.sort((a, b) => {
      const aWe = a?.week_ending_date ? String(a.week_ending_date) : '';
      const bWe = b?.week_ending_date ? String(b.week_ending_date) : '';

      const aHas = !!aWe;
      const bHas = !!bWe;

      if (aHas && bHas && aWe !== bWe) return aWe > bWe ? -1 : 1;
      if (aHas !== bHas) return aHas ? -1 : 1; // nulls last

      const aCli = a?.client_name ? String(a.client_name) : '';
      const bCli = b?.client_name ? String(b.client_name) : '';
      if (aCli !== bCli) return aCli < bCli ? -1 : 1;

      const aCand = a?.candidate_name ? String(a.candidate_name) : '';
      const bCand = b?.candidate_name ? String(b.candidate_name) : '';
      if (aCand !== bCand) return aCand < bCand ? -1 : 1;

      const aId = a?.timesheet_id ? String(a.timesheet_id) : '';
      const bId = b?.timesheet_id ? String(b.timesheet_id) : '';
      if (aId === bId) return 0;
      return aId < bId ? -1 : 1;
    });

    return acc;
  };

  try {
    // ------------------------------------------------------------
    // ✅ SEGMENTS-safe list types via single-call RPC (related_list_v2)
    // ------------------------------------------------------------
    // This covers:
    // - timesheet -> invoice(s)
    // - invoice -> timesheets
    // - candidate -> invoices
    // - umbrella -> invoices
    //
    // Normalize some legacy single/plural cases:
    // - candidate/umbrella: allow "invoice" as alias for "invoices"
    const entityU = String(entity || '').toLowerCase();
    const rawTypeU = String(type || '').toLowerCase();

    const typeU =
      (entityU === 'candidate' || entityU === 'umbrella') && rawTypeU === 'invoice'
        ? 'invoices'
        : rawTypeU;

    const rpcSupported =
      uuidLike(id) &&
      (
        (entityU === 'timesheet' && (typeU === 'invoice' || typeU === 'invoices')) ||
        (entityU === 'invoice' && typeU === 'timesheets') ||
        (entityU === 'candidate' && typeU === 'invoices') ||
        (entityU === 'umbrella' && typeU === 'invoices')
      );

    if (rpcSupported) {
      const r = await sbRpc(env, 'related_list_v2', {
        p_entity: entityU,
        p_id: id,
        p_type: typeU,
        p_limit: limit,
        p_offset: offset
      });

      const payload = unwrapRpcJsonb(r, 'related_list_v2') || null;

      const items = Array.isArray(payload?.items) ? payload.items : [];
      const total =
        (typeof payload?.total === 'number')
          ? payload.total
          : (Array.isArray(payload?.items) ? payload.items.length : 0);

      return okList(items, total);
    }

    // ───────────────────────── CANDIDATE ─────────────────────────
    if (entity === 'candidate') {
      // ---- Candidate → Timesheets (use v_timesheets_summary full shape) ----
      if (typeU === 'timesheets') {
        const tsUrl =
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?select=*` +
          `&candidate_id=eq.${enc(id)}` +
          `&order=week_ending_date.desc,client_name.asc,candidate_name.asc` +
          `&limit=${limit}&offset=${offset}`;

        const { rows, total } = await sbFetch(env, tsUrl, true);
        return okList(rows || [], total ?? (rows || []).length);
      }

      // ---- Candidate → Invoices (SEGMENTS-safe fallback via invoice_lines) ----
      if (typeU === 'invoices') {
        // Gather candidate timesheet ids:
        const tsIdSet = new Set();

        // current TSFIN timesheets
        try {
          const finQ =
            `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
            `?candidate_id=eq.${enc(id)}` +
            `&is_current=eq.true` +
            `&timesheet_id=not.is.null` +
            `&select=timesheet_id`;
          const fin = await sbFetch(env, finQ);
          (fin.rows || []).forEach(r => {
            if (r?.timesheet_id) tsIdSet.add(String(r.timesheet_id));
          });
        } catch {}

        // timesheets via contracts (covers stale/non-current TSFIN)
        try {
          const conQ =
            `${env.SUPABASE_URL}/rest/v1/contracts` +
            `?candidate_id=eq.${enc(id)}` +
            `&select=id`;
          const conR = await sbFetch(env, conQ);
          const contractIds = (conR.rows || []).map(r => r.id).filter(Boolean);

          if (contractIds.length) {
            const chunkSize = 200;
            for (let i = 0; i < contractIds.length; i += chunkSize) {
              const chunk = contractIds.slice(i, i + chunkSize);
              const tsQ =
                `${env.SUPABASE_URL}/rest/v1/timesheets` +
                `?contract_id=in.(${chunk.map(enc).join(',')})` +
                `&timesheet_id=not.is.null` +
                `&select=timesheet_id`;
              const tsR = await sbFetch(env, tsQ);
              (tsR.rows || []).forEach(r => {
                if (r?.timesheet_id) tsIdSet.add(String(r.timesheet_id));
              });
            }
          }
        } catch {}

        const tsIds = Array.from(tsIdSet);
        if (!tsIds.length) return okList([], 0);

        const invSet = await distinctInvoiceIdsForTimesheetIds(tsIds);
        const invIds = Array.from(invSet);
        if (!invIds.length) return okList([], 0);

        const allInv = await fetchInvoicesByIds(invIds);
        const total = allInv.length;
        const page = allInv.slice(offset, offset + limit);
        return okList(page, total);
      }

      // ---- Candidate → Clients (TSFIN + Contracts, then full client rows) ----
      if (typeU === 'clients') {
        // TSFIN clients
        const finQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?candidate_id=eq.${enc(id)}` +
          `&is_current=eq.true` +
          `&select=client_id`;
        const fin  = await sbFetch(env, finQ);
        const finCliIds = new Set(
          (fin.rows || []).map(r => r.client_id).filter(Boolean)
        );

        // Contracts clients
        const ctrQ =
          `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?candidate_id=eq.${enc(id)}` +
          `&select=client_id`;
        const ctr = await sbFetch(env, ctrQ);
        const contractCliIds = new Set(
          (ctr.rows || []).map(r => r.client_id).filter(Boolean)
        );

        const cliIds = [...new Set([...finCliIds, ...contractCliIds])];
        const total  = cliIds.length;
        const pageIds = cliIds.slice(offset, offset + limit);
        if (!pageIds.length) return okList([], total);

        const clUrl =
          `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=in.(${pageIds.map(enc).join(',')})` +
          `&select=*` +
          `&order=name.asc`;

        const { rows } = await sbFetch(env, clUrl);
        return okList(rows || [], total);
      }

      // ---- Candidate → Umbrella (single, full umbrella row) ----
      if (typeU === 'umbrella') {
        const candQ =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(id)}` +
          `&select=pay_method,umbrella_id&limit=1`;
        const candR = await sbFetch(env, candQ);
        const cand = (candR.rows || [])[0];
        if (!cand || cand.pay_method !== 'UMBRELLA' || !cand.umbrella_id) {
          return okList([], 0);
        }

        const umbUrl =
          `${env.SUPABASE_URL}/rest/v1/umbrellas` +
          `?id=eq.${enc(cand.umbrella_id)}&select=*`;
        const umbR = await sbFetch(env, umbUrl);
        const u = (umbR.rows || [])[0];
        return okList(u ? [u] : [], u ? 1 : 0);
      }

      // ---- Candidate → Contracts (full contracts summary shape) ----
      if (typeU === 'contracts') {
        const selectParts = [
          '*',
          'candidate:candidates(display_name,first_name,last_name)',
          'client:clients(name)'
        ];
        let api =
          `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?select=${selectParts.join(',')}` +
          `&candidate_id=eq.${enc(id)}` +
          `&order=start_date.desc&order=created_at.desc` +
          `&limit=${limit}&offset=${offset}`;

        let rows = [];
        try {
          ({ rows } = await sbFetch(env, api));
        } catch (err) {
          console.error('[RELATED][contracts][candidate] list failed', err);
          return okList([], 0);
        }

        const out = (rows || []).map(r => {
          const candidateDisplay =
            r?.candidate?.display_name ||
            ([r?.candidate?.first_name, r?.candidate?.last_name].filter(Boolean).join(' ') || null);
          const clientName = r?.client?.name || null;
          const { cw_active, cw_open, candidate, client, ...rest } = (r || {});
          return {
            ...rest,
            candidate_display: candidateDisplay,
            client_name: clientName
          };
        });

        return okList(out, out.length);
      }

      return withCORS(env, req, badRequest("Unsupported type for candidate"));
    }

    // ───────────────────────── TIMESHEET ─────────────────────────
    if (entity === 'timesheet') {
      // Timesheet → Candidate (full candidate row)
      if (typeU === 'candidate') {
        // First try TSFIN by timesheet_id
        const curQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(id)}&is_current=eq.true&select=candidate_id&limit=1`;
        const cur = await sbFetch(env, curQ);
        const curRows = cur.rows || [];
        let candId = (curRows[0] && curRows[0].candidate_id) || null;

        // Fallback: treat id as contract_week.id → contracts → candidate
        if (!candId) {
          const cwQ =
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?id=eq.${enc(id)}&select=contract_id&limit=1`;
          const cwR = await sbFetch(env, cwQ);
          const cwRow = (cwR.rows || [])[0] || null;
          if (cwRow && cwRow.contract_id) {
            const conQ =
              `${env.SUPABASE_URL}/rest/v1/contracts` +
              `?id=eq.${enc(cwRow.contract_id)}&select=candidate_id&limit=1`;
            const conR = await sbFetch(env, conQ);
            const con = (conR.rows || [])[0] || null;
            candId = con && con.candidate_id ? con.candidate_id : null;
          }
        }

        if (!candId) return okList([], 0);

        const candUrl =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(candId)}&select=*`;
        const cr = await sbFetch(env, candUrl);
        const c = (cr.rows || [])[0];
        return okList(c ? [c] : [], c ? 1 : 0);
      }

      // Timesheet → Invoice(s) (SEGMENTS-safe fallback via invoice_lines)
      if (typeU === 'invoice' || typeU === 'invoices') {
        // If id is actually a contract_week.id (planned week), return none.
        try {
          const tQ =
            `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?timesheet_id=eq.${enc(id)}&select=timesheet_id&limit=1`;
          const tR = await sbFetch(env, tQ);
          const hasTs = !!((tR.rows || [])[0]?.timesheet_id);
          if (!hasTs) return okList([], 0);
        } catch {}

        const invSet = await distinctInvoiceIdsForTimesheetIds([String(id)]);
        const invIds = Array.from(invSet);
        if (!invIds.length) return okList([], 0);

        const allInv = await fetchInvoicesByIds(invIds);
        const total = allInv.length;
        const page = allInv.slice(offset, offset + limit);
        return okList(page, total);
      }

      // Timesheet → Client (full client row)
      if (typeU === 'client') {
        // First try TSFIN by timesheet_id
        const curQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(id)}&is_current=eq.true&select=client_id&limit=1`;
        const cur = await sbFetch(env, curQ);
        const curRows = cur.rows || [];
        let clientId = (curRows[0] && curRows[0].client_id) || null;

        // Fallback: treat id as contract_week.id → contracts → client
        if (!clientId) {
          const cwQ =
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?id=eq.${enc(id)}&select=contract_id&limit=1`;
          const cwR = await sbFetch(env, cwQ);
          const cwRow = (cwR.rows || [])[0] || null;
          if (cwRow && cwRow.contract_id) {
            const conQ =
              `${env.SUPABASE_URL}/rest/v1/contracts` +
              `?id=eq.${enc(cwRow.contract_id)}&select=client_id&limit=1`;
            const conR = await sbFetch(env, conQ);
            const con  = (conR.rows || [])[0] || null;
            clientId   = con && con.client_id ? con.client_id : null;
          }
        }

        if (!clientId) return okList([], 0);

        const cliUrl =
          `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=eq.${enc(clientId)}&select=*`;
        const cr = await sbFetch(env, cliUrl);
        const c = (cr.rows || [])[0];
        return okList(c ? [c] : [], c ? 1 : 0);
      }

      // Timesheet → Umbrella (full umbrella row)
      if (typeU === 'umbrella') {
        // First try candidate from TSFIN
        const curQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(id)}&is_current=eq.true&select=candidate_id&limit=1`;
        const cur = await sbFetch(env, curQ);
        const curRows = cur.rows || [];
        let candId = (curRows[0] && curRows[0].candidate_id) || null;

        // Fallback: treat id as contract_week.id → contracts → candidate
        if (!candId) {
          const cwQ =
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?id=eq.${enc(id)}&select=contract_id&limit=1`;
          const cwR = await sbFetch(env, cwQ);
          const cwRow = (cwR.rows || [])[0] || null;
          if (cwRow && cwRow.contract_id) {
            const conQ =
              `${env.SUPABASE_URL}/rest/v1/contracts` +
              `?id=eq.${enc(cwRow.contract_id)}&select=candidate_id&limit=1`;
            const conR = await sbFetch(env, conQ);
            const con = (conR.rows || [])[0] || null;
            candId    = con && con.candidate_id ? con.candidate_id : null;
          }
        }

        if (!candId) return okList([], 0);

        const candQ =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(candId)}&select=pay_method,umbrella_id&limit=1`;
        const candR = await sbFetch(env, candQ);
        const cand = (candR.rows || [])[0];
        if (!cand || cand.pay_method !== 'UMBRELLA' || !cand.umbrella_id) {
          return okList([], 0);
        }

        const umbUrl =
          `${env.SUPABASE_URL}/rest/v1/umbrellas` +
          `?id=eq.${enc(cand.umbrella_id)}&select=*`;
        const umbR = await sbFetch(env, umbUrl);
        const u = (umbR.rows || [])[0];
        return okList(u ? [u] : [], u ? 1 : 0);
      }

      // Timesheet → Contract (full contracts summary shape for the one contract)
      if (typeU === 'contract') {
        // First try real timesheets row
        const tsQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(id)}&select=contract_id&limit=1`;
        const tsR = await sbFetch(env, tsQ);
        const tsRows = tsR.rows || [];
        let contractId = (tsRows[0] && tsRows[0].contract_id) || null;

        // Fallback: treat id as contract_week.id → contract_weeks → contract_id
        if (!contractId) {
          const cwQ =
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?id=eq.${enc(id)}&select=contract_id&limit=1`;
          const cwR = await sbFetch(env, cwQ);
          const cwRow = (cwR.rows || [])[0] || null;
          if (cwRow && cwRow.contract_id) {
            contractId = cwRow.contract_id;
          }
        }

        if (!contractId) return okList([], 0);

        const selectParts = [
          '*',
          'candidate:candidates(display_name,first_name,last_name)',
          'client:clients(name)'
        ];
        const api =
          `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?id=eq.${enc(contractId)}` +
          `&select=${selectParts.join(',')}`;

        const { rows } = await sbFetch(env, api);
        const out = (rows || []).map(r => {
          const candidateDisplay =
            r?.candidate?.display_name ||
            ([r?.candidate?.first_name, r?.candidate?.last_name].filter(Boolean).join(' ') || null);
          const clientName = r?.client?.name || null;
          const { cw_active, cw_open, candidate, client, ...rest } = (r || {});
          return {
            ...rest,
            candidate_display: candidateDisplay,
            client_name: clientName
          };
        });

        return okList(out, out.length);
      }

      // Timesheet → Series (Adjustments) – keep existing CW + TSFIN logic
      if (typeU === 'series') {
        const cwQ =
          `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?timesheet_id=eq.${enc(id)}` +
          `&select=contract_id,week_ending_date,additional_seq,is_adjustment,status&limit=1`;
        const cwr = await sbFetch(env, cwQ);
        const cwRow = (cwr.rows || [])[0] || null;
        if (!cwRow || !cwRow.contract_id || !cwRow.week_ending_date) {
          return okList([], 0);
        }

        const sibQ =
          `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?contract_id=eq.${enc(cwRow.contract_id)}` +
          `&week_ending_date=eq.${enc(cwRow.week_ending_date)}` +
          `&timesheet_id=not.is.null` +
          `&select=timesheet_id,additional_seq,is_adjustment,status`;
        const sibR = await sbFetch(env, sibQ);
        const cwSiblings = sibR.rows || [];
        if (!cwSiblings.length) return okList([], 0);

        const tsIds = [...new Set(cwSiblings.map(r => r.timesheet_id).filter(Boolean))];
        if (!tsIds.length) return okList([], 0);

        const finQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=in.(${tsIds.map(enc).join(',')})` +
          `&is_current=eq.true` +
          `&select=timesheet_id,total_hours,total_pay_ex_vat,processing_status,basis`;
        const finR = await sbFetch(env, finQ);
        const finRows = finR.rows || [];
        const finByTs = {};
        finRows.forEach(r => { finByTs[r.timesheet_id] = r; });

        let items = cwSiblings.map(r => {
          const f = finByTs[r.timesheet_id] || {};
          return {
            timesheet_id:     r.timesheet_id,
            is_current:       String(r.timesheet_id) === String(id),
            additional_seq:   r.additional_seq,
            is_adjustment:    !!r.is_adjustment,
            contract_week_status: r.status || null,
            total_hours:      f.total_hours ?? null,
            total_pay_ex_vat: f.total_pay_ex_vat ?? null,
            processing_status:f.processing_status || null,
            basis:            f.basis || null
          };
        });

        // Exclude the current TS itself so list = "other adjustments"
        items = items.filter(it => String(it.timesheet_id) !== String(id));

        items.sort((a, b) => {
          const aSeq = a.additional_seq == null ? 0 : a.additional_seq;
          const bSeq = b.additional_seq == null ? 0 : b.additional_seq;
          if (aSeq === bSeq) return 0;
          return aSeq < bSeq ? -1 : 1;
        });

        const total = items.length;
        const page  = items.slice(offset, offset + limit);
        return okList(page, total);
      }

      return withCORS(env, req, badRequest("Unsupported type for timesheet"));
    }

    // ───────────────────────── INVOICE ─────────────────────────
    if (entity === 'invoice') {
      // Invoice → Timesheets (SEGMENTS-safe fallback via invoice_lines)
      if (typeU === 'timesheets') {
        const tsSet = await distinctTimesheetIdsForInvoiceId(id);
        const tsIds = Array.from(tsSet);
        if (!tsIds.length) return okList([], 0);

        const allRows = await fetchTimesheetSummaryByIds(tsIds);
        const total = allRows.length;
        const page = allRows.slice(offset, offset + limit);
        return okList(page, total);
      }

      // NOTE: candidates/umbrellas branches remain legacy (TSFIN-based) and are out of scope for the v2 list RPC.
      if (typeU === 'candidates') {
        const finQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?locked_by_invoice_id=eq.${enc(id)}` +
          `&is_current=eq.true&select=candidate_id`;
        const fin  = await sbFetch(env, finQ);
        const candIds = [...new Set((fin.rows || []).map(r => r.candidate_id).filter(Boolean))];
        const total   = candIds.length;
        const pageIds = candIds.slice(offset, offset + limit);
        if (!pageIds.length) return okList([], total);

        const candUrl =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=in.(${pageIds.map(enc).join(',')})` +
          `&select=*` +
          `&order=display_name.asc`;
        const cr = await sbFetch(env, candUrl);
        return okList(cr.rows || [], total);
      }

      if (typeU === 'client') {
        const invQ =
          `${env.SUPABASE_URL}/rest/v1/invoices` +
          `?id=eq.${enc(id)}&select=client_id&limit=1`;
        const ir = await sbFetch(env, invQ);
        const clientId = (ir.rows || [])[0]?.client_id;
        if (!clientId) return okList([], 0);

        const cliUrl =
          `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=eq.${enc(clientId)}&select=*`;
        const cr = await sbFetch(env, cliUrl);
        const c = (cr.rows || [])[0];
        return okList(c ? [c] : [], c ? 1 : 0);
      }

      if (typeU === 'umbrellas') {
        const finQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?locked_by_invoice_id=eq.${enc(id)}` +
          `&is_current=eq.true&select=candidate_id`;
        const fin  = await sbFetch(env, finQ);
        const candIds = [...new Set((fin.rows || []).map(r => r.candidate_id).filter(Boolean))];
        if (!candIds.length) return okList([], 0);

        const candList = candIds.map(enc).join(',');
        const candQ =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=in.(${candList})&select=umbrella_id,pay_method`;
        const cr = await sbFetch(env, candQ);
        const umbIds = [...new Set(
          (cr.rows || [])
            .filter(r => r.pay_method === 'UMBRELLA' && r.umbrella_id)
            .map(r => r.umbrella_id)
        )];
        const total   = umbIds.length;
        const pageIds = umbIds.slice(offset, offset + limit);
        if (!pageIds.length) return okList([], total);

        const umbUrl =
          `${env.SUPABASE_URL}/rest/v1/umbrellas` +
          `?id=in.(${pageIds.map(enc).join(',')})&select=*` +
          `&order=name.asc`;
        const ur = await sbFetch(env, umbUrl);
        return okList(ur.rows || [], total);
      }

      return withCORS(env, req, badRequest("Unsupported type for invoice"));
    }

    // ───────────────────────── CLIENT ─────────────────────────
    if (entity === 'client') {
      if (typeU === 'timesheets') {
        const tsUrl =
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?select=*` +
          `&client_id=eq.${enc(id)}` +
          `&order=week_ending_date.desc,client_name.asc,candidate_name.asc` +
          `&limit=${limit}&offset=${offset}`;
        const { rows, total } = await sbFetch(env, tsUrl, true);
        return okList(rows || [], total ?? (rows || []).length);
      }

      if (typeU === 'invoices') {
        const sel = [
          'id','invoice_no','client_id','issued_at_utc','due_at_utc',
          'status','subtotal_ex_vat','vat_amount','total_inc_vat',
          'invoice_pdf_r2_key','header_snapshot_json','on_hold_reason','paid_at_utc'
        ].join(',');
        const invUrl =
          `${env.SUPABASE_URL}/rest/v1/invoices` +
          `?client_id=eq.${enc(id)}` +
          `&select=${enc(sel)}` +
          `&order=issued_at_utc.desc` +
          `&limit=${limit}&offset=${offset}`;
        const { rows, total } = await sbFetch(env, invUrl, true);
        return okList(rows || [], total ?? (rows || []).length);
      }

      if (typeU === 'candidates') {
        // Union candidates from TSFIN + contracts (to match counts)
        const finQ =
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?client_id=eq.${enc(id)}` +
          `&is_current=eq.true&select=candidate_id`;
        const fin  = await sbFetch(env, finQ);
        const candFromTsfin = new Set(
          (fin.rows || []).map(r => r.candidate_id).filter(Boolean)
        );

        const ctrQ =
          `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?client_id=eq.${enc(id)}` +
          `&select=candidate_id`;
        const ctr = await sbFetch(env, ctrQ);
        const candFromContracts = new Set(
          (ctr.rows || []).map(r => r.candidate_id).filter(Boolean)
        );

        const candIds = [...new Set([...candFromTsfin, ...candFromContracts])];
        const total   = candIds.length;
        const pageIds = candIds.slice(offset, offset + limit);
        if (!pageIds.length) return okList([], total);

        const candUrl =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=in.(${pageIds.map(enc).join(',')})` +
          `&select=*` +
          `&order=display_name.asc`;
        const cr = await sbFetch(env, candUrl);
        return okList(cr.rows || [], total);
      }

      if (typeU === 'contracts') {
        const selectParts = [
          '*',
          'candidate:candidates(display_name,first_name,last_name)',
          'client:clients(name)'
        ];
        const api =
          `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?client_id=eq.${enc(id)}` +
          `&select=${selectParts.join(',')}` +
          `&order=start_date.desc&order=created_at.desc` +
          `&limit=${limit}&offset=${offset}`;
        let rows = [];
        try {
          ({ rows } = await sbFetch(env, api));
        } catch (err) {
          console.error('[RELATED][contracts][client] list failed', err);
          return okList([], 0);
        }
        const out = (rows || []).map(r => {
          const candidateDisplay =
            r?.candidate?.display_name ||
            ([r?.candidate?.first_name, r?.candidate?.last_name].filter(Boolean).join(' ') || null);
          const clientName = r?.client?.name || null;
          const { cw_active, cw_open, candidate, client, ...rest } = (r || {});
          return {
            ...rest,
            candidate_display: candidateDisplay,
            client_name: clientName
          };
        });
        return okList(out, out.length);
      }

      return withCORS(env, req, badRequest("Unsupported type for client"));
    }

    // ───────────────────────── CONTRACT ─────────────────────────
    if (entity === 'contract') {
      // Load base contract so we know candidate/client once
      const conUrl =
        `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?id=eq.${enc(id)}&select=candidate_id,client_id&limit=1`;
      const conRes = await sbFetch(env, conUrl);
      const conRow = (conRes.rows || [])[0] || null;
      const candId  = conRow?.candidate_id || null;
      const clientId= conRow?.client_id    || null;

      if (typeU === 'candidate') {
        if (!candId) return okList([], 0);
        const candUrl =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(candId)}&select=*`;
        const cr = await sbFetch(env, candUrl);
        const c  = (cr.rows || [])[0];
        return okList(c ? [c] : [], c ? 1 : 0);
      }

      if (typeU === 'client') {
        if (!clientId) return okList([], 0);
        const cliUrl =
          `${env.SUPABASE_URL}/rest/v1/clients` +
          `?id=eq.${enc(clientId)}&select=*`;
        const cr = await sbFetch(env, cliUrl);
        const c  = (cr.rows || [])[0];
        return okList(c ? [c] : [], c ? 1 : 0);
      }

      if (typeU === 'timesheets') {
        // All TS/contract-weeks for this contract via v_timesheets_summary
        const tsUrl =
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?select=*` +
          `&contract_id=eq.${enc(id)}` +
          `&order=week_ending_date.desc,client_name.asc,candidate_name.asc` +
          `&limit=${limit}&offset=${offset}`;
        const { rows, total } = await sbFetch(env, tsUrl, true);
        return okList(rows || [], total ?? (rows || []).length);
      }

      if (typeU === 'umbrella') {
        if (!candId) return okList([], 0);
        const candQ =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(candId)}&select=pay_method,umbrella_id&limit=1`;
        const candR = await sbFetch(env, candQ);
        const cand = (candR.rows || [])[0];
        if (!cand || cand.pay_method !== 'UMBRELLA' || !cand.umbrella_id) {
          return okList([], 0);
        }
        const umbUrl =
          `${env.SUPABASE_URL}/rest/v1/umbrellas` +
          `?id=eq.${enc(cand.umbrella_id)}&select=*`;
        const umbR = await sbFetch(env, umbUrl);
        const u = (umbR.rows || [])[0];
        return okList(u ? [u] : [], u ? 1 : 0);
      }

      return withCORS(env, req, badRequest("Unsupported type for contract"));
    }

    // ───────────────────────── UMBRELLA ─────────────────────────
    if (entity === 'umbrella') {
      if (typeU === 'candidates') {
        const candUrl =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?umbrella_id=eq.${enc(id)}` +
          `&select=*` +
          `&order=display_name.asc` +
          `&limit=${limit}&offset=${offset}`;

        const { rows, total } = await sbFetch(env, candUrl, true);
        return okList(rows || [], total ?? (rows || []).length);
      }

      if (typeU === 'timesheets') {
        const candQ =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?umbrella_id=eq.${enc(id)}&select=id`;
        const candR = await sbFetch(env, candQ);
        const candIds = (candR.rows || []).map(r => r.id);
        if (!candIds.length) return okList([], 0);

        const tsUrl =
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?select=*` +
          `&candidate_id=in.(${candIds.map(enc).join(',')})` +
          `&order=week_ending_date.desc,client_name.asc,candidate_name.asc` +
          `&limit=${limit}&offset=${offset}`;
        const { rows, total } = await sbFetch(env, tsUrl, true);
        return okList(rows || [], total ?? (rows || []).length);
      }

      // Umbrella → Invoices (SEGMENTS-safe fallback via invoice_lines)
      if (typeU === 'invoices') {
        // candidate ids under umbrella + pay_method=UMBRELLA
        const candUrl =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?umbrella_id=eq.${enc(id)}` +
          `&pay_method=eq.UMBRELLA` +
          `&select=id`;
        const candR = await sbFetch(env, candUrl);
        const candIds = (candR.rows || []).map(r => r.id).filter(Boolean);
        if (!candIds.length) return okList([], 0);

        // timesheet ids from current TSFIN for those candidates
        const tsIdSet = new Set();
        const chunkSize = 200;
        for (let i = 0; i < candIds.length; i += chunkSize) {
          const chunk = candIds.slice(i, i + chunkSize);
          const finQ =
            `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
            `?is_current=eq.true` +
            `&timesheet_id=not.is.null` +
            `&candidate_id=in.(${chunk.map(enc).join(',')})` +
            `&select=timesheet_id`;
          const finR = await sbFetch(env, finQ);
          (finR.rows || []).forEach(r => {
            if (r?.timesheet_id) tsIdSet.add(String(r.timesheet_id));
          });
        }

        const tsIds = Array.from(tsIdSet);
        if (!tsIds.length) return okList([], 0);

        const invSet = await distinctInvoiceIdsForTimesheetIds(tsIds);
        const invIds = Array.from(invSet);
        if (!invIds.length) return okList([], 0);

        const allInv = await fetchInvoicesByIds(invIds);
        const total = allInv.length;
        const page = allInv.slice(offset, offset + limit);
        return okList(page, total);
      }

      return withCORS(env, req, badRequest("Unsupported type for umbrella"));
    }

    // ───────────────────────── REMITTANCE ─────────────────────────
    if (entity === 'remittance') {
      if (typeU === 'timesheets') {
        const audQ =
          `${env.SUPABASE_URL}/rest/v1/audit_events` +
          `?correlation_id=eq.${enc(id)}` +
          `&reason=eq.REMITTANCE` +
          `&object_type=eq.timesheet` +
          `&select=object_id_text,ts_utc` +
          `&order=ts_utc.desc`;
        const audR = await sbFetch(env, audQ);
        const tsIds = [...new Set((audR.rows || []).map(r => r.object_id_text).filter(Boolean))];
        const total   = tsIds.length;
        const pageIds = tsIds.slice(offset, offset + limit);
        if (!pageIds.length) return okList([], total);

        const tsUrl =
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?select=*` +
          `&timesheet_id=in.(${pageIds.map(enc).join(',')})` +
          `&order=week_ending_date.desc,client_name.asc,candidate_name.asc`;
        const { rows } = await sbFetch(env, tsUrl);
        return okList(rows || [], total);
      }

      if (typeU === 'candidate') {
        const audQ =
          `${env.SUPABASE_URL}/rest/v1/audit_events` +
          `?correlation_id=eq.${enc(id)}` +
          `&reason=eq.REMITTANCE` +
          `&object_type=eq.candidate` +
          `&select=object_id_text&limit=1`;
        const audR = await sbFetch(env, audQ);
        let candId = (audR.rows || [])[0]?.object_id_text;

        if (!candId) {
          const mq =
            `${env.SUPABASE_URL}/rest/v1/mail_outbox` +
            `?id=eq.${enc(id)}&select=reference&limit=1`;
          const mr = await sbFetch(env, mq);
          const ref = (mr.rows || [])[0]?.reference || '';
          const m = ref.match(/^remit:candidate:([0-9a-fA-F-]{36}):/);
          if (m) candId = m[1];
        }

        if (!candId) return okList([], 0);

        const candUrl =
          `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(candId)}&select=*`;
        const cr = await sbFetch(env, candUrl);
        const c  = (cr.rows || [])[0];
        return okList(c ? [c] : [], c ? 1 : 0);
      }

      return withCORS(env, req, badRequest("Unsupported type for remittance"));
    }

    return withCORS(env, req, badRequest("Unsupported entity"));
  } catch (e) {
    console.error('handleRelatedList error', e);
    return withCORS(env, req, serverError("Failed to load related list"));
  }
}


// UPDATED: handleRelatedCounts — now uses related_counts_v2 RPC for UUID-like ids (segment-safe) and falls back to legacy for remittance/non-UUID ids
async function handleRelatedCounts(env, req, entity, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const enc = encodeURIComponent;
  const countOrLen = (res) => (typeof res.count === 'number' ? res.count : (res.rows?.length || 0));
  const uuidLike = (s) => /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(String(s || '').trim());

  // RPC unwrap helper: supports PostgREST returning {fnname: ...} or [ {fnname: ...} ] or raw object.
  const unwrapRpcJsonb = (r, fnName) => {
    if (r == null) return null;
    if (r && typeof r === 'object' && !Array.isArray(r) && Object.prototype.hasOwnProperty.call(r, 'data')) {
      return unwrapRpcJsonb(r.data, fnName);
    }
    if (Array.isArray(r)) {
      if (r.length === 0) return null;
      if (r.length === 1) {
        const o = r[0];
        if (o && typeof o === 'object' && fnName && Object.prototype.hasOwnProperty.call(o, fnName)) return o[fnName];
        return o;
      }
      return r;
    }
    if (r && typeof r === 'object' && fnName && Object.prototype.hasOwnProperty.call(r, fnName)) {
      return r[fnName];
    }
    return r;
  };

  try {
    // Prefer single-call, segment-safe RPC for UUID-like ids.
    // We keep remittance legacy behaviour because existing code treats the id as correlation_id (text),
    // not necessarily a UUID.
    const entityU = String(entity || '').toLowerCase();

    if (entityU !== 'remittance' && uuidLike(id)) {
      const r = await sbRpc(env, 'related_counts_v2', { p_entity: entityU, p_id: id });
      const payload = unwrapRpcJsonb(r, 'related_counts_v2');
      if (payload && typeof payload === 'object') {
        return withCORS(env, req, ok(payload));
      }
      // If RPC returns null/unexpected, fall through to legacy.
    }

    // ===== CANDIDATE =====
    if (entity === 'candidate') {
      // Base: TSFIN rows for this candidate
      const tsq = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?candidate_id=eq.${enc(id)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,client_id,locked_by_invoice_id`;
      const tsfin = await sbFetch(env, tsq, { preferExactCount: true });
      const tsRows = tsfin.rows || [];

      const baseTsCount = countOrLen(tsfin);
      const invDistinct = new Set(tsRows.map(r => r.locked_by_invoice_id).filter(Boolean));
      const cliDistinct = new Set(tsRows.map(r => r.client_id).filter(Boolean));
      const tsIdsFromFin = new Set(tsRows.map(r => r.timesheet_id).filter(Boolean));

      // UNION IN: contract_weeks for this candidate's contracts, without double-counting TSFIN
      let extraTimesheets = 0;
      const extraClientIds = new Set();
      let contractsTotal   = 0;

      try {
        // All contracts for this candidate
        const conQ = `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?candidate_id=eq.${enc(id)}` +
          `&select=id,client_id`;
        const conRes = await sbFetch(env, conQ);
        const conRows = conRes.rows || [];
        const contractIds = [];

        contractsTotal = conRows.length;

        for (const r of conRows) {
          if (r.client_id && !cliDistinct.has(r.client_id)) {
            extraClientIds.add(r.client_id);
          }
          if (r.id) contractIds.push(r.id);
        }

        if (contractIds.length) {
          const cwQ = `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?contract_id=in.(${contractIds.map(enc).join(',')})` +
            `&select=id,timesheet_id`;
          const cwRes = await sbFetch(env, cwQ);
          const cwRows = cwRes.rows || [];

          // Treat each contract_week as a "timesheet" unless it already has a TSFIN
          extraTimesheets = cwRows.filter(cw =>
            !cw.timesheet_id || !tsIdsFromFin.has(cw.timesheet_id)
          ).length;
        }
      } catch (e) {
        console.warn('[relatedCounts][candidate] contract_weeks union failed', e);
      }

      const timesheetsTotal = baseTsCount + extraTimesheets;
      const clientsTotal    = cliDistinct.size + extraClientIds.size;

      // umbrella 0/1
      const cq  = `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?id=eq.${enc(id)}` +
        `&select=pay_method,umbrella_id&limit=1`;
      const c   = await sbFetch(env, cq);
      const cand = (c.rows || [])[0] || {};
      const umbrella = (cand.pay_method === 'UMBRELLA' && cand.umbrella_id) ? 1 : 0;

      return withCORS(env, req, ok({
        timesheets: timesheetsTotal,
        invoices:   invDistinct.size,
        clients:    clientsTotal,
        contracts:  contractsTotal,
        umbrella
      }));
    }

    // ===== TIMESHEET =====
    if (entity === 'timesheet') {
      // First attempt: treat id as a real timesheet_id in TSFIN
      const curq = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(id)}` +
        `&is_current=eq.true` +
        `&select=candidate_id,client_id,locked_by_invoice_id`;
      const cur  = await sbFetch(env, curq);
      const curRows = cur.rows || [];

      // Fallback path: id may actually be a contract_week.id (planned week with no TS yet)
      if (!curRows.length) {
        try {
          const cwQ = `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?id=eq.${enc(id)}` +
            `&select=contract_id&limit=1`;
          const cwR = await sbFetch(env, cwQ);
          const cwRow = (cwR.rows || [])[0] || null;

          if (!cwRow || !cwRow.contract_id) {
            // Nothing we can infer
            return withCORS(env, req, ok({
              candidate: 0,
              client:    0,
              invoice:   0,
              umbrella:  0,
              contract:  0,
              series:    0
            }));
          }

          // Use the contract to infer candidate/client
          const conQ = `${env.SUPABASE_URL}/rest/v1/contracts` +
            `?id=eq.${enc(cwRow.contract_id)}` +
            `&select=candidate_id,client_id&limit=1`;
          const conR  = await sbFetch(env, conQ);
          const con   = (conR.rows || [])[0] || {};
          const candId   = con.candidate_id || null;
          const clientId = con.client_id    || null;

          let umbrella = 0;
          if (candId) {
            const cq = `${env.SUPABASE_URL}/rest/v1/candidates` +
              `?id=eq.${enc(candId)}` +
              `&select=pay_method,umbrella_id&limit=1`;
            const cR = await sbFetch(env, cq);
            const cand = (cR.rows || [])[0] || {};
            if (cand.pay_method === 'UMBRELLA' && cand.umbrella_id) {
              umbrella = 1;
            }
          }

          return withCORS(env, req, ok({
            candidate: candId ? 1 : 0,
            client:    clientId ? 1 : 0,
            invoice:   0,
            umbrella,
            contract:  1,
            series:    0
          }));
        } catch (e) {
          console.warn('[relatedCounts][timesheet] fallback contract_week lookup failed', e);
          return withCORS(env, req, ok({
            candidate: 0,
            client:    0,
            invoice:   0,
            umbrella:  0,
            contract:  0,
            series:    0
          }));
        }
      }

      // Normal path: real TSFIN row found
      const row  = curRows[0] || {};
      const hasCandidate = row.candidate_id ? 1 : 0;
      const hasClient    = row.client_id ? 1 : 0;
      const hasInvoice   = row.locked_by_invoice_id ? 1 : 0;

      // umbrella 0/1: prefer candidate's current pay context
      let umbrella = 0;
      if (row.candidate_id) {
        const cq = `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(row.candidate_id)}` +
          `&select=pay_method,umbrella_id&limit=1`;
        const c  = await sbFetch(env, cq);
        const cand = (c.rows || [])[0] || {};
        umbrella = (cand.pay_method === 'UMBRELLA' && cand.umbrella_id) ? 1 : 0;
      }

      // Contract + "series" (base + adjustments for same contract/week)
      let hasContract = 0;
      let seriesCount = 0;
      try {
        const cwq = `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?timesheet_id=eq.${enc(id)}` +
          `&select=contract_id,week_ending_date&limit=1`;
        const cwr = await sbFetch(env, cwq);
        const cwRow = (cwr.rows || [])[0] || null;

        if (cwRow && cwRow.contract_id) {
          hasContract = 1;

          const sibQ = `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?contract_id=eq.${enc(cwRow.contract_id)}` +
            `&week_ending_date=eq.${enc(cwRow.week_ending_date)}` +
            `&timesheet_id=not.is.null` +
            `&select=id`;
          const sibR = await sbFetch(env, sibQ, { preferExactCount: true });
          const totalInSeries = typeof sibR.count === 'number'
            ? sibR.count
            : (sibR.rows || []).length;

          // "series" = number of OTHER timesheets in this chain (shown as "Adjustments" in UI)
          seriesCount = totalInSeries > 0 ? Math.max(totalInSeries - 1, 0) : 0;
        }
      } catch (e) {
        console.warn('[relatedCounts][timesheet] contract/series lookup failed', e);
      }

      return withCORS(env, req, ok({
        candidate:  hasCandidate,
        client:     hasClient,
        invoice:    hasInvoice,
        umbrella,
        contract:   hasContract,
        series:     seriesCount
      }));
    }

    // ===== INVOICE =====
    if (entity === 'invoice') {
      const tsq = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?locked_by_invoice_id=eq.${enc(id)}` +
        `&is_current=eq.true` +
        `&select=candidate_id,client_id,id`;
      const tsfin = await sbFetch(env, tsq, { preferExactCount: true });
      const rows  = tsfin.rows || [];
      const candDistinct = new Set(rows.map(r => r.candidate_id).filter(Boolean));
      const clientId = (rows[0] && rows[0].client_id) ? 1 : 1; // invoices always have a single client header

      // umbrellas on this invoice (candidates with umbrella pay)
      let umbCount = 0;
      if (candDistinct.size) {
        const ids = Array.from(candDistinct).map(enc).join(',');
        const cq  = `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=in.(${ids})&select=umbrella_id,pay_method`;
        const cr  = await sbFetch(env, cq);
        const umbDistinct = new Set(
          (cr.rows || [])
            .filter(r => r.pay_method === 'UMBRELLA' && r.umbrella_id)
            .map(r => r.umbrella_id)
        );
        umbCount = umbDistinct.size;
      }

      return withCORS(env, req, ok({
        timesheets: countOrLen(tsfin),
        candidates: candDistinct.size,
        client:     clientId,
        umbrellas:  umbCount
      }));
    }

    // ===== CLIENT =====
    if (entity === 'client') {
      // Base: TSFIN rows for this client
      const tsq = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?client_id=eq.${enc(id)}` +
        `&is_current=eq.true` +
        `&select=timesheet_id,candidate_id,id`;
      const tsfin = await sbFetch(env, tsq, { preferExactCount: true });
      const rows  = tsfin.rows || [];

      const baseTsCount = countOrLen(tsfin);
      const candDistinct = new Set(rows.map(r => r.candidate_id).filter(Boolean));
      const tsIdsFromFin = new Set(rows.map(r => r.timesheet_id).filter(Boolean));

      let extraTimesheets = 0;
      const extraCandIds  = new Set();
      let contractsTotal  = 0;

      try {
        // All contracts for this client
        const conQ = `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?client_id=eq.${enc(id)}` +
          `&select=id,candidate_id`;
        const conRes = await sbFetch(env, conQ);
        const conRows = conRes.rows || [];
        const contractIds = [];

        contractsTotal = conRows.length;

        for (const r of conRows) {
          if (r.candidate_id && !candDistinct.has(r.candidate_id)) {
            extraCandIds.add(r.candidate_id);
          }
          if (r.id) contractIds.push(r.id);
        }

        if (contractIds.length) {
          const cwQ = `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
            `?contract_id=in.(${contractIds.map(enc).join(',')})` +
            `&select=id,timesheet_id`;
          const cwRes = await sbFetch(env, cwQ);
          const cwRows = cwRes.rows || [];

          // Extra "timesheets" for planned weeks not already represented by TSFIN
          extraTimesheets = cwRows.filter(cw =>
            !cw.timesheet_id || !tsIdsFromFin.has(cw.timesheet_id)
          ).length;
        }
      } catch (e) {
        console.warn('[relatedCounts][client] contract_weeks union failed', e);
      }

      const timesheetsTotal = baseTsCount + extraTimesheets;
      const candidatesTotal = candDistinct.size + extraCandIds.size;

      const invq = `${env.SUPABASE_URL}/rest/v1/invoices` +
        `?client_id=eq.${enc(id)}` +
        `&select=id`;
      const inv  = await sbFetch(env, invq, { preferExactCount: true });

      return withCORS(env, req, ok({
        timesheets: timesheetsTotal,
        invoices:   countOrLen(inv),
        candidates: candidatesTotal,
        contracts:  contractsTotal
      }));
    }

    // ===== CONTRACT =====
    if (entity === 'contract') {
      // Base contract → candidate/client ids
      const conQ = `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?id=eq.${enc(id)}` +
        `&select=candidate_id,client_id&limit=1`;
      const conRes = await sbFetch(env, conQ);
      const conRow = (conRes.rows || [])[0] || null;

      const candId   = conRow && conRow.candidate_id ? conRow.candidate_id : null;
      const clientId = conRow && conRow.client_id    ? conRow.client_id    : null;

      // Timesheets/contract-weeks for this contract via v_timesheets_summary
      let timesheetsTotal = 0;
      try {
        const tsUrl =
          `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?select=timesheet_id` +
          `&contract_id=eq.${enc(id)}`;
        const tsRes = await sbFetch(env, tsUrl, { preferExactCount: true });
        timesheetsTotal = countOrLen(tsRes);
      } catch (e) {
        console.warn('[relatedCounts][contract] v_timesheets_summary lookup failed', e);
        timesheetsTotal = 0;
      }

      // Umbrella 0/1 based on contract's candidate pay method
      let umbrella = 0;
      if (candId) {
        try {
          const cq = `${env.SUPABASE_URL}/rest/v1/candidates` +
            `?id=eq.${enc(candId)}` +
            `&select=pay_method,umbrella_id&limit=1`;
          const cr = await sbFetch(env, cq);
          const cand = (cr.rows || [])[0] || {};
          if (cand.pay_method === 'UMBRELLA' && cand.umbrella_id) {
            umbrella = 1;
          }
        } catch (e) {
          console.warn('[relatedCounts][contract] umbrella lookup failed', e);
          umbrella = 0;
        }
      }

      return withCORS(env, req, ok({
        candidate:  candId   ? 1 : 0,
        client:     clientId ? 1 : 0,
        timesheets: timesheetsTotal,
        umbrella
      }));
    }

    // ===== UMBRELLA =====
    if (entity === 'umbrella') {
      const cq = `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?umbrella_id=eq.${enc(id)}&select=id`;
      const cand = await sbFetch(env, cq, { preferExactCount: true });
      const candIds = (cand.rows || []).map(r => r.id);

      let baseTsCount = 0;
      let extraTimesheets = 0;
      let invCount = 0;

      if (candIds.length) {
        const ids = candIds.map(enc).join(',');

        // Base: TSFIN rows for umbrella's candidates
        const tsq = `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?candidate_id=in.(${ids})` +
          `&is_current=eq.true` +
          `&select=timesheet_id,locked_by_invoice_id,id`;
        const ts  = await sbFetch(env, tsq, { preferExactCount: true });
        const tsRows = ts.rows || [];

        baseTsCount = countOrLen(ts);

        const tsIdsFromFin = new Set(
          tsRows.map(r => r.timesheet_id).filter(Boolean)
        );
        const invDistinct = new Set(
          tsRows.map(r => r.locked_by_invoice_id).filter(Boolean)
        );
        invCount = invDistinct.size;

        // UNION IN: contract_weeks for contracts held by these candidates,
        // without double-counting TSFIN
        try {
          const ctrQ = `${env.SUPABASE_URL}/rest/v1/contracts` +
            `?candidate_id=in.(${ids})` +
            `&select=id`;
          const ctrR = await sbFetch(env, ctrQ);
          const contractIds = (ctrR.rows || [])
            .map(r => r.id)
            .filter(Boolean);

          if (contractIds.length) {
            const cwQ = `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
              `?contract_id=in.(${contractIds.map(enc).join(',')})` +
              `&select=id,timesheet_id`;
            const cwR = await sbFetch(env, cwQ);
            const cwRows = cwR.rows || [];

            extraTimesheets = cwRows.filter(cw =>
              !cw.timesheet_id || !tsIdsFromFin.has(cw.timesheet_id)
            ).length;
          }
        } catch (e) {
          console.warn('[relatedCounts][umbrella] contract_weeks union failed', e);
        }
      }

      const timesheetsTotal = baseTsCount + extraTimesheets;

      return withCORS(env, req, ok({
        candidates: countOrLen(cand),
        timesheets: timesheetsTotal,
        invoices:   invCount
      }));
    }

    // ===== REMITTANCE ===== (kept for completeness)
    if (entity === 'remittance') {
      const base = `correlation_id=eq.${enc(id)}&reason=eq.REMITTANCE`;
      const tsAudQ = `${env.SUPABASE_URL}/rest/v1/audit_events` +
        `?${base}&object_type=eq.timesheet&select=object_id_text`;
      const tsAud  = await sbFetch(env, tsAudQ);
      const tsDistinct = new Set(
        (tsAud.rows || []).map(r => r.object_id_text).filter(Boolean)
      );

      const candAudQ = `${env.SUPABASE_URL}/rest/v1/audit_events` +
        `?${base}&object_type=eq.candidate&select=id`;
      const candAud  = await sbFetch(env, candAudQ);
      const hasCand  = (candAud.rows || []).length > 0 ? 1 : 0;

      return withCORS(env, req, ok({
        timesheets: tsDistinct.size,
        candidate:  hasCand
      }));
    }

    return withCORS(env, req, badRequest("Unsupported entity"));
  } catch (e) {
    console.error('handleRelatedCounts error', e);
    return withCORS(env, req, serverError("Failed to load related counts"));
  }
}


// ====================== OUTBOX: GET ONE (full email) ======================
/**
 * @openapi
 * /api/outbox/{mail_id}:
 *   get:
 *     summary: Get a full email from the outbox (headers, body, attachments)
 *     tags: [Email]
 *     security:
 *       - bearerAuth: []
 *     parameters:
 *       - in: path
 *         name: mail_id
 *         required: true
 *         schema:
 *           type: string
 *           description: mail_outbox.id (UUID)
 *     responses:
 *       200:
 *         description: Full outbox message
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 id: { type: string }
 *                 type: { type: string, enum: [INVOICE, REMITTANCE, TSO_FAILURE, BROADCAST] }
 *                 to: { type: string }
 *                 cc: { type: string, nullable: true }
 *                 subject: { type: string }
 *                 body_html: { type: string, nullable: true }
 *                 body_text: { type: string, nullable: true }
 *                 attachments:
 *                   type: array
 *                   items:
 *                     type: object
 *                     properties:
 *                       r2_key:   { type: string }
 *                       filename: { type: string }
 *                 status: { type: string, enum: [QUEUED, SENT, FAILED] }
 *                 created_at_utc: { type: string, format: date-time }
 *                 sent_at:        { type: string, format: date-time, nullable: true }
 *                 failed_at:      { type: string, format: date-time, nullable: true }
 *                 last_error: { type: string, nullable: true }
 *                 reference:  { type: string, nullable: true }
 *                 provider_message_id: { type: string, nullable: true }
 *       404:
 *         description: Not found
 */
async function handleOutboxGet(env, req, mailId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const q = `${env.SUPABASE_URL}/rest/v1/mail_outbox?id=eq.${encodeURIComponent(mailId)}&select=id,type,to,cc,subject,body_html,body_text,attachments,status,last_error,created_at_utc,sent_at,failed_at,reference,provider_message_id&limit=1`;
    const res = await sbFetch(env, q);
    const row = (res.rows || [])[0];
    if (!row) return withCORS(env, req, notFound("Outbox message not found"));
    return withCORS(env, req, ok(row));
  } catch (e) {
    console.error('handleOutboxGet error', e);
    return withCORS(env, req, serverError("Failed to fetch outbox message"));
  }
}



// ====================== FILES (R2, SIGNED) ======================
/**
 * @openapi
 * /api/files/presign-upload:
 *   post:
 *     summary: Get pre-signed upload URL (tokened)
 *     tags: [Files]
 *     security:
 *       - bearerAuth: []
 * /api/files/upload:
 *   put:
 *     summary: Upload to R2 using pre-signed URL
 *     tags: [Files]
 * /api/files/presign-download:
 *   post:
 *     summary: Get pre-signed download URL (short-lived)
 *     tags: [Files]
 *     security:
 *       - bearerAuth: []
 * /api/files/download:
 *   get:
 *     summary: Download file by signed token
 *     tags: [Files]
 */
async function handleFilePresignUpload(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) {
    try {
      console.warn('[FILES_PRESIGN_UPLOAD] unauthorized', {
        origin: req.headers.get('origin') || null,
        hasCookie: !!req.headers.get('cookie'),
        url: req.url
      });
    } catch {}
    return withCORS(env, req, unauthorized());
  }

  let data;
  try {
    data = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest("Invalid JSON"));
  }

  if (!data || !data.content_type) return withCORS(env, req, badRequest("content_type required"));

  const filename = data.filename || "";
  const contentType = String(data.content_type);

  let ext = "";
  if (filename && filename.includes(".")) {
    ext = filename.substring(filename.lastIndexOf("."));
  } else {
    const ctMap = {
      "image/png": ".png",
      "image/jpeg": ".jpg",
      "image/gif": ".gif",
      "application/pdf": ".pdf",
      "text/plain": ".txt",
      "text/csv": ".csv",
      "application/vnd.ms-excel": ".xls",
      "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet": ".xlsx"
    };
    if (contentType in ctMap) ext = ctMap[contentType];
  }

  const dateTag = new Date().toISOString().slice(0, 10).replace(/-/g, "");
  const randBytes = crypto.getRandomValues(new Uint8Array(8));
  let randHex = "";
  randBytes.forEach(b => randHex += b.toString(16).padStart(2, "0"));

  // ✅ FIX: canonical key WITHOUT leading slash
  const fileKey = `files/${dateTag}/file_${randHex}${ext || ""}`;

  const expiresSec = Math.min(parseInt(env.PRESIGN_EXPIRES_SECONDS || "600", 10), 900);
  const exp = Math.floor(Date.now() / 1000) + expiresSec;

  const token = await createToken(env.UPLOAD_TOKEN_SECRET, { typ: "file_upload", key: fileKey, exp });

  const baseUrl = new URL(req.url);
  baseUrl.pathname = "/api/files/upload";
  baseUrl.search = "";
  baseUrl.searchParams.set("key", fileKey);
  baseUrl.searchParams.set("token", token);

  return withCORS(env, req, ok({
    key: fileKey,
    upload_url: baseUrl.toString(),
    token,
    expires_at: new Date(exp * 1000).toISOString(),
    max_bytes: parseInt(env.FILE_MAX_BYTES || "5000000", 10),
    content_type: contentType
  }));
}
async function handleFileUpload(env, req, url) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const rawKey = url.searchParams.get("key") || "";
  const token = url.searchParams.get("token") || "";

  // ✅ FIX: normalize key (accept both "/files/..." and "files/...")
  const key = String(rawKey || '').replace(/^\/+/, '').trim();

  let ver;
  try {
    ver = await verifyToken(env.UPLOAD_TOKEN_SECRET, token);
  } catch (e) {
    if (LOG) {
      console.warn('[FILES_UPLOAD]', JSON.stringify({
        stage: 'verifyToken_throw',
        key_raw: rawKey,
        key,
        err: e?.message || String(e)
      }));
    }
    return withCORS(env, req, unauthorized("Invalid token"));
  }

  if (!ver || !ver.ok) {
    if (LOG) {
      console.warn('[FILES_UPLOAD]', JSON.stringify({
        stage: 'invalid_token',
        key_raw: rawKey,
        key
      }));
    }
    return withCORS(env, req, unauthorized("Invalid token"));
  }

  const p = ver.payload || {};
  const pKey = String(p.key || '').replace(/^\/+/, '').trim();

  if (p.typ !== "file_upload" || pKey !== key) {
    if (LOG) {
      console.warn('[FILES_UPLOAD]', JSON.stringify({
        stage: 'token_mismatch',
        key_raw: rawKey,
        key,
        payload_typ: p.typ || null,
        payload_key: p.key || null,
        payload_key_norm: pKey
      }));
    }
    return withCORS(env, req, unauthorized("Token mismatch"));
  }

  // ✅ FIX: validate canonical key format (no leading slash)
  const keyOk = /^files\/\d{8}\/file_[0-9a-f]{16}(\.[A-Za-z0-9]{3,10})?$/.test(key);
  if (!keyOk) {
    if (LOG) {
      console.warn('[FILES_UPLOAD]', JSON.stringify({
        stage: 'bad_key',
        key_raw: rawKey,
        key
      }));
    }
    return withCORS(env, req, badRequest("Invalid key"));
  }

  const ct = req.headers.get("content-type") || "";
  const allowedTypes = /^(image\/|application\/pdf|text\/|application\/vnd\.openxmlformats|application\/vnd\.ms-excel)/i;
  if (!allowedTypes.test(ct)) {
    if (LOG) {
      console.warn('[FILES_UPLOAD]', JSON.stringify({
        stage: 'blocked_type',
        key,
        content_type: ct
      }));
    }
    return withCORS(env, req, unsupported("File type not allowed"));
  }

  const maxBytes = parseInt(env.FILE_MAX_BYTES || "5000000", 10);
  const contentLength = parseInt(req.headers.get("content-length") || "0", 10);
  if (contentLength > maxBytes) {
    if (LOG) {
      console.warn('[FILES_UPLOAD]', JSON.stringify({
        stage: 'too_large_header',
        key,
        content_length: contentLength,
        max_bytes: maxBytes
      }));
    }
    return withCORS(env, req, tooLarge(`Max ${maxBytes} bytes`));
  }

  // Read body
  let bodyBuf;
  try {
    bodyBuf = await req.arrayBuffer();
  } catch (e) {
    if (LOG) {
      console.error('[FILES_UPLOAD]', JSON.stringify({
        stage: 'read_body_failed',
        key,
        err: e?.message || String(e)
      }));
    }
    return withCORS(env, req, serverError('Failed to read upload body'));
  }

  const actualLen = bodyBuf.byteLength;

  // ✅ FIX: enforce actual length too (covers missing/0 content-length)
  if (actualLen > maxBytes) {
    if (LOG) {
      console.warn('[FILES_UPLOAD]', JSON.stringify({
        stage: 'too_large_body',
        key,
        actual_body_length: actualLen,
        max_bytes: maxBytes
      }));
    }
    return withCORS(env, req, tooLarge(`Max ${maxBytes} bytes`));
  }

  if (LOG) {
    console.log('[FILES_UPLOAD]', JSON.stringify({
      stage: 'before_put',
      key,
      content_type: ct,
      header_content_length: contentLength,
      actual_body_length: actualLen
    }));
  }

  // ✅ FIX: always put to R2 using canonical key
  const putRes = await r2Put(env, key, bodyBuf, {
    httpMetadata: { contentType: ct },
    customMetadata: {}
  });

  if (LOG) {
    console.log('[FILES_UPLOAD]', JSON.stringify({
      stage: 'after_put',
      key,
      etag: putRes?.etag || null
    }));
  }

  return withCORS(env, req, ok({ ok: true, key, etag: putRes?.etag, size: actualLen || undefined }));
}


async function handleFilePresignDownload(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) {
    try {
      console.warn('[FILES_PRESIGN_DOWNLOAD] unauthorized', {
        origin: req.headers.get('origin') || null,
        hasCookie: !!req.headers.get('cookie'),
        url: req.url
      });
    } catch {}
    return withCORS(env, req, unauthorized());
  }

  let data;
  try {
    data = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest("Invalid JSON"));
  }

  if (!data || !data.key) return withCORS(env, req, badRequest("key is required"));

  // ✅ FIX: normalise keys coming from DB/UI (often stored as "/files/....")
  let key = String(data.key || '').trim();
  key = key.replace(/^\/+/, '');
  if (!key) return withCORS(env, req, badRequest("key is required"));

  const head = await r2Head(env, key);
  if (!head) return withCORS(env, req, notFound("File not found"));

  const exp = Math.floor(Date.now() / 1000) + 300;

  // Keep your existing scheme, but the download handler will accept both file_dl and dl
  const token = await createToken(env.UPLOAD_TOKEN_SECRET, { typ: "file_dl", key, exp });

  const baseUrl = new URL(req.url);
  baseUrl.pathname = "/api/files/download";
  baseUrl.search = "";
  baseUrl.searchParams.set("key", key);
  baseUrl.searchParams.set("token", token);

  const signed = baseUrl.toString();

  return withCORS(env, req, ok({
    url: signed,
    signed_url: signed,
    download_url: signed,
    key,
    expires_at: new Date(exp * 1000).toISOString()
  }));
}

async function handleFileDownload(env, req, url) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);

  const rawKey = url.searchParams.get("key") || "";
  const token  = url.searchParams.get("token") || "";

  if (!rawKey || !token) {
    if (LOG) {
      console.warn('[FILES_DOWNLOAD]', JSON.stringify({
        stage: 'missing_params',
        has_key: !!rawKey,
        has_token: !!token
      }));
    }
    return withCORS(env, req, badRequest("key and token are required"));
  }

  // ✅ FIX: normalize key consistently
  const key = String(rawKey || '').replace(/^\/+/, '').trim();

  let ver;
  try {
    ver = await verifyToken(env.UPLOAD_TOKEN_SECRET, token);
  } catch (e) {
    if (LOG) {
      console.warn('[FILES_DOWNLOAD]', JSON.stringify({
        stage: 'verifyToken_throw',
        key_raw: rawKey,
        key,
        err: e?.message || String(e)
      }));
    }
    return withCORS(env, req, unauthorized("Invalid token"));
  }

  if (!ver || !ver.ok) {
    if (LOG) {
      console.warn('[FILES_DOWNLOAD]', JSON.stringify({
        stage: 'invalid_token',
        key_raw: rawKey,
        key
      }));
    }
    return withCORS(env, req, unauthorized("Invalid token"));
  }

  const p = ver.payload || {};
  const pKey = String(p.key || '').replace(/^\/+/, '').trim();
  const typ  = String(p.typ || '');

  // ✅ FIX: accept both dl and file_dl (backwards compatible)
  const typOk = (typ === 'file_dl' || typ === 'dl');

  if (!typOk || pKey !== key) {
    if (LOG) {
      console.warn('[FILES_DOWNLOAD]', JSON.stringify({
        stage: 'claims_mismatch',
        key_raw: rawKey,
        key,
        payload_typ: typ || null,
        payload_key: p.key || null,
        payload_key_norm: pKey
      }));
    }
    return withCORS(env, req, unauthorized("Token mismatch"));
  }

  const obj = await r2Get(env, key);
  if (!obj) {
    if (LOG) {
      console.warn('[FILES_DOWNLOAD]', JSON.stringify({
        stage: 'not_found',
        key
      }));
    }
    return withCORS(env, req, notFound("Not found"));
  }

  let contentType = "application/octet-stream";
  if (obj.httpMetadata?.contentType) contentType = obj.httpMetadata.contentType;

  const headers = new Headers({
    "content-type": contentType,
    "cache-control": "no-store",
    "x-content-type-options": "nosniff"
  });

  const dispName = obj.customMetadata?.originalName || key.split("/").pop() || "download.bin";

  // ✅ FIX: inline so iframe preview works
  headers.set("Content-Disposition", `inline; filename="${String(dispName).replace(/[/\\]/g, "_").replace(/[\r\n"]/g, "")}"`);

  return withCORS(env, req, new Response(obj.body, { status: 200, headers }));
}



// ---------------------- Health ----------------------
async function handleHealth(env) {
  try { await env.R2.head("__healthcheck__" + Date.now()); } catch {}
  return new Response("ok", { status: 200, headers: TEXT_PLAIN });
}
async function handleReady(env) {
  const missing = [];
  for (const k of ["SUPABASE_URL", "SUPABASE_SERVICE_ROLE_KEY"]) if (!env[k]) missing.push(k);
  if (!env.R2) missing.push("R2");
  for (const k of ["SESSION_TOKEN_SECRET","UPLOAD_TOKEN_SECRET"]) if (!env[k]) missing.push(k);
  if (missing.length) return new Response("missing: " + missing.join(","), { status: 503, headers: TEXT_PLAIN });
  return new Response("ready", { status: 200, headers: TEXT_PLAIN });
}
function handleVersion() {
  return new Response(JSON.stringify({ version: "1.2.0", built_at: new Date().toISOString() }), { status: 200, headers: JSON_HEADERS });
}

/*
  CloudTMS – Timesheet Financials: worker + API additions (drop‑in)
  -----------------------------------------------------------------
  Purpose
    - Drain `ts_financials_outbox` (via Supabase RPC) and compute/store `timesheets_financials` snapshots.
    - Provide minimal API endpoints to:
        • Manually drain the queue once (/api/tsfin/queue/drain)
        • Recompute a timesheet (/api/tsfin/recompute)
        • Read current snapshot(s) (/api/tsfin/financials)
        • Promote READY_FOR_HR → READY_FOR_INVOICE (/api/tsfin/mark-ready)
        • Invoice creation & locking based on financial snapshots (replacement for old invoices)
        • Credit-note flow that unlocks and marks snapshots stale
    - All business math lives here; DB remains source-of-truth for raw timesheets and the outbox.

  Integration notes
    - Keep your existing Worker file intact. Import (or paste) these functions and wire routes.
    - This code uses the same helper style as your Worker: sbFetch/sbHeaders/withCORS/ok/badRequest/unauthorized.
    - Where your base file already defines helpers with the same names, delete the duplicates below.

  Router wiring (example)
    // Queue/worker
    if (req.method === 'POST' && p === '/tsfin/queue/drain')     return withCORS(env, req, await handleTsfinDrain(env, req));
    if (req.method === 'POST' && p === '/tsfin/recompute')       return withCORS(env, req, await handleTsfinRecompute(env, req));
    if (req.method === 'GET'  && p === '/tsfin/financials')      return withCORS(env, req, await handleTsfinFinancials(env, req));
    if (req.method === 'POST' && p === '/tsfin/mark-ready')      return withCORS(env, req, await handleTsfinMarkReady(env, req));

    // Invoices (replace your old handlers if present)
    if (req.method === 'GET'  && p === '/invoices')              return withCORS(env, req, await handleListInvoices(env, req));
    if (req.method === 'POST' && p === '/invoices')              return withCORS(env, req, await handleCreateInvoiceTsfin(env, req));
    if (req.method === 'GET'  && p.startsWith('/invoices/'))     return withCORS(env, req, await handleGetInvoice(env, req, p.split('/')[2]));
    if (req.method === 'POST' && p.endsWith('/credit-note'))     return withCORS(env, req, await handleCreateCreditNoteTsfin(env, req, p.split('/')[2]));

    // Finance preview (replace your old preview if desired to use snapshots)
    if (req.method === 'POST' && p === '/timesheets/finance-preview') return withCORS(env, req, await handleFinancePreviewTsfin(env, req));
*/

// ---------------------------
// Shared type mirrors
// ---------------------------
/** @typedef {'NEW_AUTHORISED'|'VERSION_ROTATED'|'REVOKED'|'RATE_CHANGED'|'POLICY_CHANGED'|'CONTEXT_CHANGED'|'MANUAL'} TsFinReason */
/** @typedef {'UNASSIGNED'|'ASSIGNED'} CandidateAssignment */
/** @typedef {'UNASSIGNED'|'CLIENT_UNRESOLVED'|'RATE_MISSING'|'PAY_CHANNEL_MISSING'|'READY_FOR_HR'|'READY_FOR_INVOICE'} ProcessingStatus */
/** @typedef {'PAYE'|'UMBRELLA'} PayMethod */

// ---------------------------
// Minimal helpers (reuse your base ones if present)
// ---------------------------

function asNumber(x, d = 0) {
  if (x === null || x === undefined) return d;
  const n = typeof x === 'number' ? x : Number(x);
  return Number.isFinite(n) ? n : d;
}

// Alias used throughout TSFIN maths
function asNumberLocal(x, d = 0) {
  return asNumber(x, d);
}


function ymd(iso) {
  const d = new Date(iso);
  const y = d.getUTCFullYear();
  const m = String(d.getUTCMonth() + 1).padStart(2, '0');
  const da = String(d.getUTCDate()).padStart(2, '0');
  return `${y}-${m}-${da}`;
}

// --- Basic UK DST handling (same style as your base file) ---
function isBSTLocal(ymdStr) {
  const [y, m, d] = ymdStr.split('-').map(Number);
  const lastSunday = (year, month) => {
    const dt = new Date(Date.UTC(year, month, 0));
    const dow = dt.getUTCDay();
    dt.setUTCDate(dt.getUTCDate() - dow);
    return dt.getUTCDate();
  };
  const lastSunMar = lastSunday(y, 3);
  const lastSunOct = lastSunday(y, 10);
  const n = Date.UTC(y, m - 1, d);
  const bstStart = Date.UTC(y, 2, lastSunMar, 1);
  const bstEnd = Date.UTC(y, 9, lastSunOct, 1);
  return n >= bstStart && n < bstEnd;
}

function toLocalParts(iso, tz) {
  // For Europe/London only; treat other tz as UTC fallback.
  const inYmd = ymd(iso);
  const offset = (tz === 'Europe/London' && isBSTLocal(inYmd)) ? 1 : 0; // hours ahead of UTC
  const d = new Date(iso);
  let hh = d.getUTCHours() + offset;
  let mm = d.getUTCMinutes();
  let y = d.getUTCFullYear();
  let m = d.getUTCMonth() + 1;
  let da = d.getUTCDate();
  if (hh >= 24) {
    hh -= 24;
    const dt = new Date(Date.UTC(y, m - 1, da));
    dt.setUTCDate(dt.getUTCDate() + 1);
    y = dt.getUTCFullYear(); m = dt.getUTCMonth() + 1; da = dt.getUTCDate();
  }
  const ymdStr = `${y}-${String(m).padStart(2, '0')}-${String(da).padStart(2, '0')}`;
  return { ymd: ymdStr, hh, mm };
}

// ---------------------------
// Supabase helpers (RPC + REST)
// ---------------------------

// === REPLACE: sbFetch (supports GET + POST/PATCH/DELETE + optional exact count)
// BACKEND — UPDATED
// sbFetch: now supports init (POST/PATCH/DELETE) and optional exact count. (UPDATED, not new)
async function sbFetch(env, url, third, fourth) {
  let includeCount = false;
  let init = {};

  if (typeof third === 'boolean') {
    includeCount = third;
  } else if (third && typeof third === 'object') {
    const { preferExactCount, ...rest } = third;
    if (typeof preferExactCount === 'boolean') includeCount = preferExactCount;
    init = { ...rest };
  }

  if (fourth && typeof fourth === 'object') {
    init = { ...init, ...fourth };
  }

  const callerPrefer = init.headers && (init.headers.Prefer || init.headers['Prefer']);
  const headers = {
    ...sbHeaders(env),
    ...(callerPrefer ? {} : (includeCount ? { Prefer: 'count=exact' } : {})),
    ...(init.headers || {})
  };

  const res = await fetch(url, { ...init, headers });
  const text = await res.text();

  let json;
  try { json = text ? JSON.parse(text) : null; } catch { json = null; }

  if (!res.ok) throw new Error(`Supabase fetch failed ${res.status}: ${text}`);

  let rows;
  if (Array.isArray(json)) rows = json;
  else if (json === null) rows = [];
  else if (typeof json === 'object' && Array.isArray(json.rows)) rows = json.rows;
  else rows = [json];

  const cr = res.headers.get('content-range');
  const m = cr && /\/(\d+)$/.exec(cr);
  const total = m ? parseInt(m[1], 10) : undefined;

  return { rows, total };
}

async function sbRpc(env, fn, args, opts) {
  const url = `${env.SUPABASE_URL}/rest/v1/rpc/${encodeURIComponent(fn)}`;

  const timeoutMs =
    (opts && Number.isFinite(Number(opts.timeoutMs)) && Number(opts.timeoutMs) > 0)
      ? Number(opts.timeoutMs)
      : null;

  const controller = timeoutMs ? new AbortController() : null;
  const t = timeoutMs ? setTimeout(() => {
    try { controller.abort(new Error(`RPC ${fn} timed out after ${timeoutMs}ms`)); } catch {}
  }, timeoutMs) : null;

  let res;
  let txt = '';
  let json = null;

  try {
    res = await fetch(url, {
      method: 'POST',
      headers: sbHeaders(env),
      body: JSON.stringify(args || {}),
      signal: controller ? controller.signal : undefined
    });

    txt = await res.text().catch(() => '');
    try { json = txt ? JSON.parse(txt) : null; } catch { json = null; }

    if (!res.ok) {
      const err = new Error(`RPC ${fn} failed ${res.status}: ${txt}`);
      err.status = res.status;
      err.body = txt;
      err.json = json;
      throw err;
    }

    return json;
  } catch (e) {
    // Preserve existing behaviour: throw the error.
    // If this was an abort, normalize the message but keep it obvious.
    if (e && (e.name === 'AbortError' || /timed out/i.test(String(e.message || '')))) {
      const err = new Error(`RPC ${fn} failed 408: ${timeoutMs ? `timeout after ${timeoutMs}ms` : 'timeout'}`);
      err.status = 408;
      err.body = '';
      err.json = null;
      throw err;
    }
    throw e;
  } finally {
    if (t) clearTimeout(t);
  }
}


// ---------------------------
// Context loaders
// ---------------------------
async function loadCurrentTimesheet(env, timesheet_id) {
  const enc = encodeURIComponent;

  if (!timesheet_id) return null;

  // NEW: stale-safe resolve (accept historical/stale ids)
  let currentId = timesheet_id;
  try {
    const resolved = await resolveTimesheetToCurrent(env, timesheet_id);
    if (resolved && resolved.current_timesheet_id) {
      currentId = resolved.current_timesheet_id;
    }
  } catch {
    // If resolve fails, fall back to direct lookup
    currentId = timesheet_id;
  }

  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );

  return (rows && rows[0]) ? rows[0] : null;
}

async function loadCandidate(env, key_norm) {
  if (!key_norm) return null;
  const { rows } = await sbFetch(env, `${env.SUPABASE_URL}/rest/v1/candidates?key_norm=eq.${encodeURIComponent(key_norm)}&active=eq.true&select=*`);
  return rows[0] || null;
}
async function loadPolicy(env, client_id, workedDateYmd) {
  // ─────────────────────────────────────────────────────────────
  // Contract-driven compliance:
  // This function returns ONLY client-level TIME + FINANCE POLICY.
  // It MUST NOT return contract-driven route/HR flags such as:
  //   requires_hr, autoprocess_hr, no_timesheet_required, daily_calc_of_invoices, is_nhsp, etc.
  //
  // Helpers are attached onto env to resolve contract/effective flags elsewhere.
  // ─────────────────────────────────────────────────────────────

  // ─────────────────────────────────────────────────────────────
  // Request-scoped cache (reduces subrequests drastically)
  // - settings_defaults fetched once per request (NON-FINANCE ONLY)
  // - finance window fetched once per anchor date (via settings_finance_pick)
  // - client_settings fetched once per client_id per request (all rows)
  // - resolved policy cached per (client_id|workedDateYmd)
  // ─────────────────────────────────────────────────────────────
  env.__POLICY_CACHE = env.__POLICY_CACHE || {
    defaults: null,              // NON-FINANCE defaults from settings_defaults (time/BH/attach/timezone)
    financeByDate: new Map(),    // ymd -> finance window row (vat/erni/wtr/apply/margin_includes)
    csRowsByClient: new Map(),   // client_id -> client_settings rows (ordered)
    policyByKey: new Map()       // `${client_id}|${workedDateYmd||''}` -> final policy object
  };

  // ─────────────────────────────────────────────────────────────
  // Helpers (env-scoped) for contract/effective flags (NOT returned by loadPolicy)
  // ─────────────────────────────────────────────────────────────
  env.__EFFECTIVE_FLAGS_CACHE = env.__EFFECTIVE_FLAGS_CACHE || {
    contractById: new Map(),     // contract_id -> contract row (select=*)
    tsEffById: new Map()         // timesheet_id -> effective flags (from v_timesheets_summary)
  };

  if (typeof env.__loadContractRow !== 'function') {
    env.__loadContractRow = async (contract_id) => {
      const k = String(contract_id || '');
      if (!k) return null;
      const c = env.__EFFECTIVE_FLAGS_CACHE.contractById;
      if (c.has(k)) return c.get(k);

      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contracts` +
          `?id=eq.${encodeURIComponent(k)}` +
          `&select=*` +
          `&limit=1`
      );

      const row = rows?.[0] || null;
      c.set(k, row);
      return row;
    };
  }

  if (typeof env.__loadTimesheetEffectiveFlags !== 'function') {
    env.__loadTimesheetEffectiveFlags = async (timesheet_id) => {
      const k = String(timesheet_id || '');
      if (!k) return null;
      const c = env.__EFFECTIVE_FLAGS_CACHE.tsEffById;
      if (c.has(k)) return c.get(k);

      // These columns are known contract-resolved “effective” fields.
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?timesheet_id=eq.${encodeURIComponent(k)}` +
          `&select=route_type,client_requires_hr,client_autoprocess_hr,client_no_timesheet_required` +
          `&limit=1`
      );

      const row = rows?.[0] || null;
      c.set(k, row);
      return row;
    };
  }

  const cache = env.__POLICY_CACHE;
  const key = `${String(client_id || '')}|${String(workedDateYmd || '')}`;

  // Cache hit
  if (cache.policyByKey.has(key)) {
    return cache.policyByKey.get(key);
  }

  // Helper: numeric fields
  const asNumber = (v) => {
    const n = Number(v);
    return Number.isFinite(n) ? n : 0;
  };

  const asYmd = (v) => {
    if (!v) return null;
    const ss = String(v).slice(0, 10);
    return /^\d{4}-\d{2}-\d{2}$/.test(ss) ? ss : null;
  };

  const londonTodayYmd = () => {
    try {
      const s = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).format(new Date());
      const [dd, mm, yyyy] = s.split('/');
      return `${yyyy}-${mm}-${dd}`;
    } catch {
      const d = new Date();
      const yyyy = d.getFullYear();
      const mm = String(d.getMonth() + 1).padStart(2, '0');
      const dd = String(d.getDate()).padStart(2, '0');
      return `${yyyy}-${mm}-${dd}`;
    }
  };

  const normaliseJsonObj = (v) => {
    if (!v) return null;
    if (typeof v === 'object') return v;
    if (typeof v === 'string') {
      try {
        const p = JSON.parse(v);
        return (p && typeof p === 'object') ? p : null;
      } catch {
        return null;
      }
    }
    return null;
  };

  // Helper: normalise bh_list: can be array or JSON string
  const normaliseBhList = (val) => {
    if (!val) return [];
    if (Array.isArray(val)) return val;
    if (typeof val === 'string') {
      try {
        const parsed = JSON.parse(val);
        return Array.isArray(parsed) ? parsed : [];
      } catch {
        return [];
      }
    }
    return [];
  };

  // 1) Load NON-FINANCE settings_defaults once
  let def = cache.defaults;
  if (!def) {
    const { rows: defRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=` +
        [
          // NON-FINANCE defaults used by loadPolicy
          'timezone_id',

          'day_start','day_end',
          'night_start','night_end',
          'sat_start','sat_end',
          'sun_start','sun_end',
          'bh_start','bh_end',

          // Global-only BH list
          'bh_list',

          // fallback defaults (client-level attach toggles)
          'hr_attach_to_invoice',
          'ts_attach_to_invoice',
        ].join(',')
    );
    def = defRows?.[0] || {};
    cache.defaults = def;
  }

  // 2) Load all client_settings rows once per client_id (ordered newest first)
  let csRows = null;
  if (client_id) {
    const cid = String(client_id);
    csRows = cache.csRowsByClient.get(cid) || null;

    if (!csRows) {
      const { rows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_settings` +
          `?client_id=eq.${encodeURIComponent(cid)}` +
          `&select=` + [
            // ordering/picking
            'effective_from',
            'created_at',

            // time policy (overrides)
            'timezone_id',
            'day_start','day_end',
            'night_start','night_end',
            'sat_start','sat_end',
            'sun_start','sun_end',
            'bh_start','bh_end',

            // finance overrides (client-level)
            'vat_rate_pct',
            'holiday_pay_pct',
            'apply_holiday_to',
            'apply_erni_to',
            'margin_includes',

            // attach defaults (client-level)
            'hr_attach_to_invoice',
            'ts_attach_to_invoice',
          ].join(',') +
          `&order=effective_from.desc.nullslast,created_at.desc` +
          `&limit=250`
      );

      csRows = Array.isArray(rows) ? rows : [];
      cache.csRowsByClient.set(cid, csRows);
    }
  }

  // 3) Pick the effective client_settings row for this workedDateYmd
  const pickEffectiveClientSettingsRow = (rows, ymd) => {
    if (!Array.isArray(rows) || !rows.length) return null;
    const w = asYmd(ymd);

    // If no date, treat newest row as effective
    if (!w) return rows[0] || null;

    for (const row of rows) {
      if (!row) continue;

      const ef = asYmd(row.effective_from); // date or null
      if (ef == null) {
        // effective_from IS NULL is allowed as fallback
        return row;
      }
      // Compare as YYYY-MM-DD strings
      if (ef <= w) return row;
    }
    return rows[0] || null;
  };

  const cs = (client_id && csRows) ? pickEffectiveClientSettingsRow(csRows, workedDateYmd) : null;

  // 4) Finance windows (global) via settings_finance_pick, anchored by workedDateYmd (or today)
  const anchorYmd = asYmd(workedDateYmd) || londonTodayYmd();

  const pickFinanceForDate = async (ymd) => {
    const k = String(ymd || '');
    if (cache.financeByDate.has(k)) return cache.financeByDate.get(k);

    let row = null;
    try {
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify({ p_date: k || null })
        }
      );

      const txt = await res.text().catch(() => '');
      if (res.ok) {
        const j = txt ? JSON.parse(txt) : null;
        const r0 = Array.isArray(j) ? (j[0] || null) : (j || null);

        // defensive: some PostgREST shapes wrap the row under function name
        row = (r0 && typeof r0 === 'object' && r0.settings_finance_pick)
          ? r0.settings_finance_pick
          : r0;
      }
    } catch {
      row = null;
    }

    cache.financeByDate.set(k, row);
    return row;
  };

  const finance = await pickFinanceForDate(anchorYmd);

  const tz = cs?.timezone_id || def?.timezone_id || 'Europe/London';

  // ✅ BH list is GLOBAL-ONLY (never client-derived)
  const bh = normaliseBhList(def?.bh_list);

  // Attach-policy flags are client-level (no contract overrides exist here)
  const hr_attach_to_invoice =
    cs && Object.prototype.hasOwnProperty.call(cs, 'hr_attach_to_invoice')
      ? cs.hr_attach_to_invoice !== false
      : def?.hr_attach_to_invoice !== false; // default true if unset

  const ts_attach_to_invoice =
    cs && Object.prototype.hasOwnProperty.call(cs, 'ts_attach_to_invoice')
      ? cs.ts_attach_to_invoice !== false
      : def?.ts_attach_to_invoice !== false; // default true if unset

  const financeMarginIncludes = normaliseJsonObj(finance?.margin_includes) || {};
  const csMarginIncludes      = normaliseJsonObj(cs?.margin_includes) || {};

  const out = {
    timezone_id: tz,

    day_start:   cs?.day_start   || def?.day_start   || '06:00:00',
    day_end:     cs?.day_end     || def?.day_end     || '20:00:00',
    night_start: cs?.night_start || def?.night_start || '20:00:00',
    night_end:   cs?.night_end   || def?.night_end   || '06:00:00',
    sat_start:   cs?.sat_start   || def?.sat_start   || '00:00:00',
    sat_end:     cs?.sat_end     || def?.sat_end     || '00:00:00',
    sun_start:   cs?.sun_start   || def?.sun_start   || '00:00:00',
    sun_end:     cs?.sun_end     || def?.sun_end     || '00:00:00',

    // BH window (00:00–00:00 means “full BH day”)
    bh_start:    cs?.bh_start    || def?.bh_start    || '00:00:00',
    bh_end:      cs?.bh_end      || def?.bh_end      || '00:00:00',

    // Finance:
    // - VAT & holiday pay can be overridden per client via client_settings
    // - otherwise use global finance window in-scope for anchorYmd
    vat_rate_pct: asNumber(cs?.vat_rate_pct ?? finance?.vat_rate_pct ?? 20),
    holiday_pay_pct: asNumber(cs?.holiday_pay_pct ?? finance?.holiday_pay_pct ?? 12.07),

    // ERNI is global-only (finance windows)
    erni_pct: asNumber(finance?.erni_pct ?? 13.8),

    // apply flags: prefer client override, else finance window, else fallback
    apply_holiday_to: cs?.apply_holiday_to || finance?.apply_holiday_to || 'PAYE_ONLY',
    apply_erni_to:    cs?.apply_erni_to    || finance?.apply_erni_to    || 'PAYE_ONLY',

    // margin_includes: prefer client override object, else finance window object
    margin_includes: {
      expenses: !!(csMarginIncludes?.expenses ?? financeMarginIncludes?.expenses ?? false),
    },

    bh_list: bh,

    // Client-level attach policy (still valid here)
    hr_attach_to_invoice,
    ts_attach_to_invoice,

    // Optional: expose anchor date used for finance selection (handy for debugging)
    // finance_anchor_ymd: anchorYmd
  };

  // Store in cache and return
  cache.policyByKey.set(key, out);
  return out;
}

// ======================= TSFIN RPC WRAPPERS =======================
// Thin wrappers around Supabase RPCs for the TSFIN batch pipeline.
// Logging: enabled when (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true)

const _tsfinRpcLog = (label, obj) => {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  if (!LOG) return;
  try { console.log(`[TSFIN][RPC] ${label}`, obj || {}); } catch {}
};

const _asPosIntOrNull = (v) => {
  const n = Number(v);
  if (!Number.isFinite(n)) return null;
  const i = Math.floor(n);
  return (i > 0) ? i : null;
};

const _asArray = (v) => (Array.isArray(v) ? v : (v == null ? [] : [v]));

async function rpcTsfinDequeueSpecific(env, { timesheetIds = [], limit = null } = {}) {
  if (!Array.isArray(timesheetIds) || timesheetIds.length === 0) return [];
  const p_limit = _asPosIntOrNull(limit);

  const args = { p_timesheet_ids: timesheetIds };
  if (p_limit != null) args.p_limit = p_limit;

  _tsfinRpcLog('tsfin_dequeue_specific -> call', { count: timesheetIds.length, p_limit });
  try {
    const res = await sbRpc(env, 'tsfin_dequeue_specific', args);
    const rows = _asArray(res);
    _tsfinRpcLog('tsfin_dequeue_specific -> ok', { rows: rows.length });
    return rows; // [{id, timesheet_id, reason, attempt_count, next_attempt_at, last_error, created_at}, ...]
  } catch (e) {
    _tsfinRpcLog('tsfin_dequeue_specific -> fail', { err: String(e?.message || e) });
    throw e;
  }
}

async function rpcTsfinDequeueBatchIds(env, { limit = 50 } = {}) {
  const p_limit = _asPosIntOrNull(limit) ?? 50;
  const args = { p_limit };

  _tsfinRpcLog('tsfin_dequeue_batch_ids -> call', { p_limit });
  try {
    const res = await sbRpc(env, 'tsfin_dequeue_batch_ids', args);
    const rows = _asArray(res);
    _tsfinRpcLog('tsfin_dequeue_batch_ids -> ok', { rows: rows.length });
    return rows; // [{outbox_id, timesheet_id, reason, attempt_count, next_attempt_at, created_at}, ...]
  } catch (e) {
    _tsfinRpcLog('tsfin_dequeue_batch_ids -> fail', { err: String(e?.message || e) });
    throw e;
  }
}

async function rpcTsfinLoadContextBatch(env, { timesheetIds = [] } = {}) {
  if (!Array.isArray(timesheetIds) || timesheetIds.length === 0) return [];
  const args = { p_timesheet_ids: timesheetIds };

  _tsfinRpcLog('tsfin_load_context_batch -> call', { count: timesheetIds.length });
  try {
    const res = await sbRpc(env, 'tsfin_load_context_batch', args);
    const rows = _asArray(res);
    _tsfinRpcLog('tsfin_load_context_batch -> ok', { rows: rows.length });
    return rows;
    // [{
    //   effective_timesheet_id,
    //   out_timesheet, out_cur_fin, out_candidate, out_umbrella,
    //   out_client_id, out_effective_flags, out_policy
    // }, ...]
  } catch (e) {
    _tsfinRpcLog('tsfin_load_context_batch -> fail', { err: String(e?.message || e) });
    throw e;
  }
}

async function rpcTsfinResolveRatesBatch(env, { items = [] } = {}) {
  // items is an array of objects {k, candidate_id, client_id, role, band, date, rate_type}
  if (!Array.isArray(items) || items.length === 0) return [];
  const args = { p_items: items };

  _tsfinRpcLog('tsfin_resolve_rates_batch -> call', { count: items.length });
  try {
    const res = await sbRpc(env, 'tsfin_resolve_rates_batch', args);
    const rows = _asArray(res);
    _tsfinRpcLog('tsfin_resolve_rates_batch -> ok', { rows: rows.length });
    return rows;
    // [{k, source_kind, override_id, default_id, pay_day.., charge_day.., ...}, ...]
  } catch (e) {
    _tsfinRpcLog('tsfin_resolve_rates_batch -> fail', { err: String(e?.message || e) });
    throw e;
  }
}

async function rpcTsfinWriteSnapshotsAndComplete(env, { rows = [] } = {}) {
  // rows is an array: [{outbox_id, timesheet_id, snapshot}, ...]
  if (!Array.isArray(rows) || rows.length === 0) {
    return { ok_count: 0, fail_count: 0, errors: [] };
  }
  const args = { p_rows: rows };

  _tsfinRpcLog('tsfin_write_snapshots_and_complete -> call', { count: rows.length });
  try {
    const res = await sbRpc(env, 'tsfin_write_snapshots_and_complete', args);
    // PostgREST returns table results as an array of rows (usually 1 row here).
    const out = Array.isArray(res) ? (res[0] || null) : res;
    const ok_count = Number(out?.ok_count || 0) || 0;
    const fail_count = Number(out?.fail_count || 0) || 0;
    const errors = out?.errors ?? [];
    _tsfinRpcLog('tsfin_write_snapshots_and_complete -> ok', { ok_count, fail_count });
    return { ok_count, fail_count, errors };
  } catch (e) {
    _tsfinRpcLog('tsfin_write_snapshots_and_complete -> fail', { err: String(e?.message || e) });
    throw e;
  }
}

async function rpcEnqueueTsfinForOccKey(env, {
  occKey,
  reason = 'CONTEXT_CHANGED',
  priority = true,
  limit = 500
} = {}) {
  const p_occ_key_norm = String(occKey || '').trim();
  if (!p_occ_key_norm) return 0;

  const p_limit = _asPosIntOrNull(limit) ?? 500;
  const args = {
    p_occ_key_norm,
    p_reason: reason,        // ts_fin_reason_enum (string)
    p_priority: !!priority,
    p_limit
  };

  _tsfinRpcLog('enqueue_tsfin_for_occ_key -> call', { p_occ_key_norm, reason, priority: !!priority, p_limit });
  try {
    const res = await sbRpc(env, 'enqueue_tsfin_for_occ_key', args);
    const n = Number(res);
    const cnt = Number.isFinite(n) ? n : 0;
    _tsfinRpcLog('enqueue_tsfin_for_occ_key -> ok', { enqueued: cnt });
    return cnt; // integer
  } catch (e) {
    _tsfinRpcLog('enqueue_tsfin_for_occ_key -> fail', { err: String(e?.message || e) });
    throw e;
  }
}

async function rpcEnqueueTsfinForHospitalNorm(env, {
  hospitalNorm,
  reason = 'CONTEXT_CHANGED',
  priority = true,
  limit = 500
} = {}) {
  const p_hospital_norm = String(hospitalNorm || '').trim();
  if (!p_hospital_norm) return 0;

  const p_limit = _asPosIntOrNull(limit) ?? 500;
  const args = {
    p_hospital_norm,
    p_reason: reason,        // ts_fin_reason_enum (string)
    p_priority: !!priority,
    p_limit
  };

  _tsfinRpcLog('enqueue_tsfin_for_hospital_norm -> call', { p_hospital_norm, reason, priority: !!priority, p_limit });
  try {
    const res = await sbRpc(env, 'enqueue_tsfin_for_hospital_norm', args);
    const n = Number(res);
    const cnt = Number.isFinite(n) ? n : 0;
    _tsfinRpcLog('enqueue_tsfin_for_hospital_norm -> ok', { enqueued: cnt });
    return cnt; // integer
  } catch (e) {
    _tsfinRpcLog('enqueue_tsfin_for_hospital_norm -> fail', { err: String(e?.message || e) });
    throw e;
  }
}




// ---------------------------
// Classification helpers
// ---------------------------
function hhmmToMin(hhmm) {
  const [h, m] = (hhmm || '00:00:00').split(':').map((x) => parseInt(x, 10) || 0);
  return h * 60 + m;
}

function subtractBreak(segments, breakStartIso, breakEndIso, breakMin) {
  if (breakStartIso && breakEndIso) {
    const bs = new Date(breakStartIso).getTime();
    const be = new Date(breakEndIso).getTime();
    const out = [];
    for (const [a, b] of segments) {
      const A = new Date(a).getTime();
      const B = new Date(b).getTime();
      if (B <= bs || A >= be) { out.push([a, b]); continue; }
      if (A < bs) out.push([a, new Date(bs).toISOString()]);
      if (B > be) out.push([new Date(be).toISOString(), b]);
    }
    return out;
  }
  if (!breakMin || breakMin <= 0) return segments;
  if (!segments.length) return segments;
  let [a, b] = segments[0];
  const total = minutesBetween(a, b);
  if (breakMin >= total) return [];
  const startCut = Math.floor((total - breakMin) / 2);
  const mid = new Date(new Date(a).getTime() + startCut * 60000).toISOString();
  const midEnd = new Date(new Date(mid).getTime() + breakMin * 60000).toISOString();
  return [[a, mid], [midEnd, b]];
}

function classifyMinutes(env, policy, segments) {
  const out = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
  const tz = policy.timezone_id || 'Europe/London';

  // Normalise string times into minutes and BH set
  const dayStartMin = hhmmToMin(policy.day_start);
  const dayEndMin   = hhmmToMin(policy.day_end);
  const satStartMin = hhmmToMin(policy.sat_start || '00:00');
  const satEndMin   = hhmmToMin(policy.sat_end   || '00:00');
  const sunStartMin = hhmmToMin(policy.sun_start || '00:00');
  const sunEndMin   = hhmmToMin(policy.sun_end   || '00:00');

  // NEW: BH hours (00:00–00:00 means full BH day)
  const bhStartMin  = hhmmToMin(policy.bh_start || '00:00');
  const bhEndMin    = hhmmToMin(policy.bh_end   || '00:00');

  const bhSet       = new Set(policy.bh_list || []);

  const normPolicy = {
    dayStart: dayStartMin,
    dayEnd:   dayEndMin,
    satStart: satStartMin,
    satEnd:   satEndMin,
    sunStart: sunStartMin,
    sunEnd:   sunEndMin,
    bhStart:  bhStartMin,
    bhEnd:    bhEndMin,
    bhList:   bhSet
  };

  for (const [isoA, isoB] of segments) {
    let cur = new Date(isoA);
    const end = new Date(isoB);

    while (cur < end) {
      const { ymd: curYmd, hh, mm } = toLocalParts(cur.toISOString(), tz);
      const dayEnd = new Date(Date.UTC(cur.getUTCFullYear(), cur.getUTCMonth(), cur.getUTCDate() + 1));
      const sliceEnd = end < dayEnd ? end : dayEnd;
      const mins = minutesBetween(cur.toISOString(), sliceEnd.toISOString());

      const fromMin = hh * 60 + mm;
      const toMin   = fromMin + mins;

      segmentChunkIntoBuckets(curYmd, fromMin, toMin, normPolicy, out);

      cur = sliceEnd;
    }
  }

  return {
    hours_day:  round2(out.day   / 60),
    hours_night:round2(out.night / 60),
    hours_sat:  round2(out.sat   / 60),
    hours_sun:  round2(out.sun   / 60),
    hours_bh:   round2(out.bh    / 60),
  };
}
// 3) Resolve combined PAY/CHARGE view




// ---------------------------
// Rates resolution
// ---------------------------

// ─────────────────────────────────────────────────────────────────────────────
// Internal resolution used by worker (now derives rate_type from candidate,
// filters PAY by rate_type; selects CHARGE without rate_type)
// ─────────────────────────────────────────────────────────────────────────────
// ─────────────────────────────────────────────────────────────────────────────
// Internal resolver used by the worker (UNIFIED DEFAULTS)
// - Same logic as handleResolveRate but returns a plain object (no HTTP response)
// ─────────────────────────────────────────────────────────────────────────────
async function resolveRates(env, { candidate_id, client_id, role, band, dateYmd }) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L = (...a) => { if (LOG) console.log('[TSFIN][DAILY][resolveRates]', ...a); };

  const norm = (s) => String(s || '').trim();
  const normRole = (s) => norm(s).replace(/\s+/g, ' ').trim().toUpperCase();

  const normBand = (v) => {
    const s = norm(v);
    if (!s) return null;
    let m = s.match(/^\s*band\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*b\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*([0-9]+)\s*$/);
    if (m && m[1]) return `Band ${parseInt(m[1], 10)}`;
    return s;
  };

  const roleN = role ? normRole(role) : null;
  const bandN = normBand(band);

  L('ENTRY', { candidate_id, client_id, role_in: role, roleN, band_in: band, bandN, dateYmd });

  // Determine effective rate_type from candidate if available
  let rate_type = null;
  if (candidate_id) {
    try {
      const { rows: cand } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?id=eq.${encodeURIComponent(candidate_id)}` +
        `&select=pay_method&limit=1`
      );
      const pm = (cand && cand[0] && (cand[0].pay_method || '')).toUpperCase();
      rate_type = (pm === 'PAYE' || pm === 'UMBRELLA') ? pm : 'UMBRELLA';
      L('candidate pay_method', { pm, rate_type });
    } catch (e) {
      rate_type = 'UMBRELLA';
      L('candidate pay_method lookup failed -> UMBRELLA', { err: String(e?.message || e) });
    }
  } else {
    rate_type = 'UMBRELLA';
    L('no candidate -> UMBRELLA');
  }

  if (!client_id || !roleN || !dateYmd) {
    L('insufficient inputs -> NONE', { client_id, roleN, dateYmd });
    return { source: { kind: 'NONE', id: null, rate_type }, pay: null, charge: null };
  }

  // 1) Candidate override PAY (exact band → band-null)
  let override = null;
  if (candidate_id) {
    override = await fetchActiveOverride(env, {
      candidate_id,
      client_id,
      role: roleN,
      band: bandN,
      date: dateYmd,
      rate_type
    });
    L('override', override ? { id: override.id, role: override.role, band: override.band, rate_type: override.rate_type } : null);
  }

  // 2) Client default window for CHARGE (and PAY if needed)
  const windowDef = await fetchUnifiedDefaultWindow(env, {
    client_id,
    role: roleN,
    band: bandN,
    date: dateYmd
  });
  L('client default window', windowDef ? { id: windowDef.id, role: windowDef.role, band: windowDef.band } : null);

  const charge = windowDef
    ? { day: windowDef.charge_day, night: windowDef.charge_night, sat: windowDef.charge_sat, sun: windowDef.charge_sun, bh: windowDef.charge_bh }
    : null;

  const pay = override
    ? { day: override.pay_day, night: override.pay_night, sat: override.pay_sat, sun: override.pay_sun, bh: override.pay_bh }
    : (windowDef
        ? (rate_type === 'PAYE'
            ? { day: windowDef.paye_day, night: windowDef.paye_night, sat: windowDef.paye_sat, sun: windowDef.paye_sun, bh: windowDef.paye_bh }
            : { day: windowDef.umb_day, night: windowDef.umb_night, sat: windowDef.umb_sat, sun: windowDef.umb_sun, bh: windowDef.umb_bh }
          )
        : null
      );

  const out = {
    source: override
      ? { kind: 'CANDIDATE_OVERRIDE', id: override.id, rate_type }
      : (windowDef
          ? { kind: 'CLIENT_DEFAULT', id: windowDef.id, rate_type }
          : { kind: 'NONE', id: null, rate_type }
        ),
    pay,
    charge
  };

  L('EXIT', { source: out.source, pay: out.pay, charge: out.charge });
  return out;
}

function anyMissingRates(hours, pay, charge) {
  const buckets = ['day', 'night', 'sat', 'sun', 'bh'];
  for (const b of buckets) {
    if (hours[b] > 0) {
      if (!charge || charge[b] == null) return true;
      if (!pay || pay[b] == null) return true;
    }
  }
  return false;
}

// ---------------------------
// Snapshot writer
// ---------------------------
async function writeSnapshot(env, snapshot) {
  // NOTE:
  // snapshot may now include:
  // - basis: 'SELF_REPORTED' | 'HR_VALIDATED' | 'OVERRIDDEN' | 'CONTRACT_WEEKLY' | 'NHSP' | 'NHSP_ADJUSTMENT'
  // - nhsp_import_id: uuid, linking this TSFIN to an NHSP hr_import
  // - invoice_breakdown_json: either AGGREGATE or per-shift breakdown for NHSP/autoproc

  if (!snapshot || !snapshot.timesheet_id) {
    throw new Error('writeSnapshot: snapshot.timesheet_id is required');
  }

  const nowIso = new Date().toISOString();

  // Always insert a "current" snapshot row, and ensure timestamps exist.
  // (We keep any caller-supplied created_at/updated_at if they provided them.)
  const snap = { ...snapshot };
  snap.is_current = true;
  if (!snap.created_at) snap.created_at = nowIso;
  if (!snap.updated_at) snap.updated_at = nowIso;

  // Use the correct argument name for the Postgres function:
  await sbRpc(env, 'tsfin_prepare_write', {
    p_timesheet_id: snap.timesheet_id
  });

  const res = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets_financials`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify(snap)
  });

  if (!res.ok) {
    const txt = await res.text();
    throw new Error(`timesheets_financials insert failed: ${txt}`);
  }

  const json = await res.json().catch(() => ([]));
  return Array.isArray(json) ? json[0] : json;
}

// ---------- helpers used by patch handlers ----------
const toNum = (v) => (v === null || v === undefined ? null : Number(v));
const nonneg = (n) => (n === null || n === undefined ? true : Number(n) >= 0);


async function fetchCurrentTsfin(env, timesheetId) {
  const q =
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?timesheet_id=eq.${encodeURIComponent(timesheetId)}` +
    `&is_current=eq.true` +
    `&select=` + [
      'timesheet_id','timesheet_version','candidate_id','client_id',
      'processing_status','locked_by_invoice_id','is_current',
      'invoice_breakdown_json',

      // ✅ NEW: category expense columns (required for patchTsfinCommon correctness)
      'travel_pay_ex_vat','travel_charge_ex_vat',
      'accommodation_pay_ex_vat','accommodation_charge_ex_vat',
      'other_pay_ex_vat','other_charge_ex_vat',

      // legacy totals + notes/meta (still used)
      'expenses_pay_ex_vat','expenses_charge_ex_vat','expenses_description','expenses_evidence_r2_key',
      'expenses_evidence_manifest',

      // mileage
      'mileage_pay_ex_vat','mileage_charge_ex_vat','mileage_units',
      'mileage_evidence_r2_key','mileage_evidence_manifest',
      'mileage_pay_rate','mileage_charge_rate',

      'po_number'
    ].join(',');

  const { rows } = await sbFetch(env, q);
  return (rows || [])[0] || null;
}

async function enqueueManualTsfinRecalc(env, timesheetId) {
  const id = (globalThis.crypto?.randomUUID?.() || `${Date.now()}-${Math.random()}`).toString();
  const body = [{
    id,
    timesheet_id: timesheetId,
    reason: 'MANUAL',
    attempt_count: 0,
    next_attempt_at: nowIso(),
    last_error: null,
    created_at: nowIso(),
  }];
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/ts_financials_outbox?on_conflict=timesheet_id,reason`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), 'Prefer': 'resolution=merge-duplicates' },
      body: JSON.stringify(body),
    }
  );
}

async function insertAuditEvent(env, req, args) {
  const user = await requireUser(env, req, ['admin']).catch(() => null);
  const ip = req.headers.get('CF-Connecting-IP') || req.headers.get('x-forwarded-for') || null;
  const ua = req.headers.get('user-agent') || null;
  const correlation_id = (globalThis.crypto?.randomUUID?.() || `${Date.now()}-${Math.random()}`).toString();

  const payload = [{
    actor_user_id: user?.id ?? user?.user_id ?? null,
    actor_display: user?.email ?? null,
    actor_role_at_time: user?.role ?? null,
    object_type: args.object_type,
    object_id_text: args.object_id_text,
    action: args.action,
    before_json: args.before_json ?? null,
    after_json: args.after_json ?? null,
    reason: args.reason ?? null,
    ip,
    user_agent: ua,
    correlation_id,
  }];

  await fetch(`${env.SUPABASE_URL}/rest/v1/audit_events`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=minimal' },
    body: JSON.stringify(payload),
  });
}
// 5) patchTsfinCommon(...) (now validates + writes mileage_units; audit includes it)


/**
 * Shared patcher (JS)
 */

// -------------------- public handlers --------------------



async function handleTsfinPatchPO(env, req, timesheetId) {
  const body = await parseJSONBody(req).catch(() => ({}));
  return withCORS(env, req, await patchTsfinCommon(env, req, timesheetId, {
    expected_timesheet_id: body?.expected_timesheet_id,
    reason: body?.reason ?? null,
    po: { number: body?.number }
  }));
}

 async function computeWeeklyAdditionalFromTs(env, ts, cw, contract, policyOverride = null) {
    let additional_units_json = {};
    let additional_pay_ex_vat = 0;
    let additional_charge_ex_vat = 0;

    const cfgArrRaw = contract?.additional_rates_json;
    if (!Array.isArray(cfgArrRaw) || !cfgArrRaw.length) {
      return {
        additional_units_json,
        additional_pay_ex_vat,
        additional_charge_ex_vat,
        additional_margin_ex_vat: 0,
      };
    }

    let cfgArr = cfgArrRaw;
    if (typeof cfgArrRaw === "string") {
      try { cfgArr = JSON.parse(cfgArrRaw); } catch { cfgArr = []; }
    }
    if (!Array.isArray(cfgArr)) cfgArr = [];

    let unitsWeek = ts?.additional_units_week || {};
    let unitsPerDay = ts?.additional_units_per_day || {};
    if (typeof unitsWeek === "string") { try { unitsWeek = JSON.parse(unitsWeek); } catch { unitsWeek = {}; } }
    if (typeof unitsPerDay === "string") { try { unitsPerDay = JSON.parse(unitsPerDay); } catch { unitsPerDay = {}; } }
    if (!unitsWeek || typeof unitsWeek !== "object") unitsWeek = {};
    if (!unitsPerDay || typeof unitsPerDay !== "object") unitsPerDay = {};

    const weekEnd = cw?.week_ending_date || null;
    const dates = [];
    try {
      if (weekEnd) {
        const weDate = new Date(`${weekEnd}T00:00:00Z`);
        for (let i = 6; i >= 0; i--) {
          const d = new Date(weDate);
          d.setUTCDate(weDate.getUTCDate() - i);
          dates.push(toYmd(d));
        }
      }
    } catch {}

    // ✅ Prefer SQL policy bh_list (no REST); fallback to empty set
    const bhList = Array.isArray(policyOverride?.bh_list) ? policyOverride.bh_list : [];
    const bhSet = new Set(bhList.map(String));

    const dow = (ymd) => {
      try { return new Date(`${ymd}T00:00:00Z`).getUTCDay(); } catch { return null; }
    };

    const freqEnum = new Set([
      "ONE_PER_WEEK",
      "ONE_PER_DAY",
      "WEEKENDS_AND_BH_ONLY",
      "WEEKDAYS_EXCL_BH_ONLY",
    ]);

    for (const cfg of cfgArr) {
      if (!cfg || !cfg.code) continue;
      const code = String(cfg.code).toUpperCase();

      const freqRaw = (cfg.frequency || "").toString().toUpperCase();
      const freq = freqEnum.has(freqRaw) ? freqRaw : "ONE_PER_WEEK";

      const weekUnits = Number((unitsWeek && unitsWeek[code]) || 0) || 0;
      const perDayRaw =
        unitsPerDay && typeof unitsPerDay[code] === "object"
          ? unitsPerDay[code]
          : {};

      let unitCount = 0;
      const perDayOut = {};

      if (freq === "ONE_PER_WEEK") {
        unitCount = weekUnits;
      } else {
        for (const ymd of dates) {
          const u = Number(perDayRaw?.[ymd] || 0) || 0;
          if (!u) continue;

          const d = dow(ymd);
          const isBh = bhSet.has(String(ymd));

          let include = false;
          if (freq === "ONE_PER_DAY") include = true;
          else if (freq === "WEEKENDS_AND_BH_ONLY") include = isBh || d === 0 || d === 6;
          else if (freq === "WEEKDAYS_EXCL_BH_ONLY") include = !isBh && d != null && d >= 1 && d <= 5;

          if (!include) continue;
          unitCount += u;
          perDayOut[ymd] = (perDayOut[ymd] || 0) + u;
        }
      }

      if (!unitCount || !Number.isFinite(unitCount) || unitCount <= 0) continue;

      const payRate = Number(cfg.pay_rate ?? 0) || 0;
      const chargeRate = Number(cfg.charge_rate ?? 0) || 0;

      const payEx = round2(unitCount * payRate);
      const chgEx = round2(unitCount * chargeRate);

      additional_units_json[code] = {
        bucket_name: cfg.bucket_name || null,
        unit_name: cfg.unit_name || null,
        frequency: freq,
        unit_count: unitCount,
        pay_rate: payRate,
        charge_rate: chargeRate,
        pay_ex_vat: payEx,
        charge_ex_vat: chgEx,
        days: Object.keys(perDayOut).length ? perDayOut : undefined,
      };

      additional_pay_ex_vat += payEx;
      additional_charge_ex_vat += chgEx;
    }

 additional_pay_ex_vat = round2(additional_pay_ex_vat);
additional_charge_ex_vat = round2(additional_charge_ex_vat);

// ERNI applies based on SQL policyOverride + PAYE
const applyTo = String(policyOverride?.apply_erni_to || 'PAYE_ONLY').toUpperCase();
const erniPctRaw = Number(policyOverride?.erni_pct ?? 0);

let erniMult = 1;
if (Number.isFinite(erniPctRaw) && erniPctRaw > 0) {
  const p = erniPctRaw > 1 ? (erniPctRaw / 100) : erniPctRaw;
  erniMult = 1 + p;
}

const payMethodUpper = String(
  (contract?.pay_method_snapshot || contract?.pay_method || '')
).toUpperCase();

const erniApplies =
  (applyTo === 'ALL') ||
  (applyTo === 'PAYE_ONLY' && payMethodUpper === 'PAYE');

const addPayCostEx = round2(erniApplies ? (additional_pay_ex_vat * erniMult) : additional_pay_ex_vat);
const additional_margin_ex_vat = round2(additional_charge_ex_vat - addPayCostEx);

return {
  additional_units_json,
  additional_pay_ex_vat,
  additional_charge_ex_vat,
  additional_margin_ex_vat,
};

  }

async function rpcTsfinRepairMergeSegmentsLocked(env, {
  timesheetId,
  newSegments,
  actorUserId = null,
  correlationId = null
} = {}) {
  const p_timesheet_id = timesheetId ? String(timesheetId).trim() : '';
  if (!p_timesheet_id) throw new Error('rpcTsfinRepairMergeSegmentsLocked: timesheetId is required');

  const p_new_segments = Array.isArray(newSegments) ? newSegments : null;
  if (!p_new_segments) throw new Error('rpcTsfinRepairMergeSegmentsLocked: newSegments must be an array');

  const args = {
    p_timesheet_id,
    p_new_segments
  };
  if (actorUserId != null) args.p_actor_user_id = actorUserId;
  if (correlationId != null) args.p_correlation_id = String(correlationId);

  const unwrapRpcJsonb = (r, fnName) => {
    if (r == null) return null;
    if (Array.isArray(r)) {
      if (r.length === 0) return null;
      if (r.length === 1) {
        const o = r[0];
        if (o && typeof o === 'object' && fnName && Object.prototype.hasOwnProperty.call(o, fnName)) return o[fnName];
        return o;
      }
      return r;
    }
    if (r && typeof r === 'object' && fnName && Object.prototype.hasOwnProperty.call(r, fnName)) {
      return r[fnName];
    }
    return r;
  };

  _tsfinRpcLog('tsfin_repair_merge_segments_locked -> call', { timesheet_id: p_timesheet_id, seg_count: p_new_segments.length });
  try {
    const res = await sbRpc(env, 'tsfin_repair_merge_segments_locked', args);
    const out = unwrapRpcJsonb(res, 'tsfin_repair_merge_segments_locked');
    _tsfinRpcLog('tsfin_repair_merge_segments_locked -> ok', {
      ok: out?.ok === true,
      old_invalid_count: out?.old_invalid_count ?? null,
      new_invalid_count: out?.new_invalid_count ?? null,
      preserved_locked_count: out?.preserved_locked_count ?? null
    });
    return out;
  } catch (e) {
    _tsfinRpcLog('tsfin_repair_merge_segments_locked -> fail', { err: String(e?.message || e) });
    throw e;
  }
}

async function runTsfinWorkerOnce(env, { limit = 50, onlyTimesheetIds = null } = {}) {
  // Local helpers used by both branches
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);
  const enc = encodeURIComponent;

  const chunk = (arr, n) => {
    const out = [];
    for (let i = 0; i < (arr?.length || 0); i += n) out.push(arr.slice(i, i + n));
    return out;
  };

  // Helper: derive Mon–Sun week start from a week-ending date (ymd)
  const computeWeekStartFromWeekEnding = (weYmd) => {
    if (!weYmd) return null;
    const d = new Date(`${weYmd}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return weYmd;
    d.setUTCDate(d.getUTCDate() - 6);
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  // ─────────────────────────────────────────────────────────────
  // Weekly helpers (contract-driven)
  // ─────────────────────────────────────────────────────────────

  // ✅ Updated: accepts policyOverride so it never triggers REST in resolveBucketsFromSchedule
  async function computeWeeklyHours(env, ts, contract, policyOverride = null) {
    const zeroHours = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };

    if (Array.isArray(ts.actual_schedule_json) && ts.actual_schedule_json.length) {
      const minsByBucket = await resolveBucketsFromSchedule(env, contract, ts.actual_schedule_json, policyOverride);
      const hours = {
        day: +(asNumberLocal(minsByBucket.day) / 60).toFixed(2),
        night: +(asNumberLocal(minsByBucket.night) / 60).toFixed(2),
        sat: +(asNumberLocal(minsByBucket.sat) / 60).toFixed(2),
        sun: +(asNumberLocal(minsByBucket.sun) / 60).toFixed(2),
        bh: +(asNumberLocal(minsByBucket.bh) / 60).toFixed(2),
      };
      return hours;
    }

    const scope = String(ts.sheet_scope || "").toUpperCase();
    if (scope === "WEEKLY") return zeroHours;

    const n = (v) => (v == null ? 0 : Number(v) || 0);
    return {
      day: n(ts.hours_day),
      night: n(ts.hours_night),
      sat: n(ts.hours_sat),
      sun: n(ts.hours_sun),
      bh: n(ts.hours_bh),
    };
  }

  // ✅ Updated: REST-free BH list (uses SQL policyOverride.bh_list)
 

  // ─────────────────────────────────────────────────────────────
  // DAILY helpers
  // ─────────────────────────────────────────────────────────────
  const boolish = (v) => {
    if (v === true) return true;
    if (v === false) return false;
    if (v == null) return false;
    const s = String(v).trim().toLowerCase();
    return (s === 'true' || s === '1' || s === 'yes' || s === 'y' || s === 'on');
  };

  const norm = (s) => String(s || "").trim();
  const normRole = (s) => norm(s).replace(/\s+/g, " ").trim().toUpperCase();
  const normBand = (v) => {
    const s = norm(v);
    if (!s) return null;
    let m = s.match(/^\s*band\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*b\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*([0-9]+)\s*$/);
    if (m && m[1]) return `Band ${parseInt(m[1], 10)}`;
    return s;
  };

  const parseCandidateRoleCodes = (rolesVal) => {
    try {
      let roles = rolesVal;
      if (typeof roles === "string") roles = JSON.parse(roles);
      if (!Array.isArray(roles)) return [];
      return roles
        .map((r) => (r && typeof r === "object" ? r.code : r))
        .map((c) => normRole(c))
        .filter(Boolean);
    } catch {
      return [];
    }
  };

  // Lightweight in-memory grade->role scoring using candidate roles only (no REST).
  const mapGradeToCandidateRoleLocal = (gradeRaw, candidateRoleCodes) => {
    const raw = String(gradeRaw || '').trim();
    if (!raw) return null;
    const squash = (s) => String(s || '').trim().toLowerCase().replace(/[^a-z0-9]+/g, ' ').trim();
    const g = squash(raw);
    if (!g) return null;

    const mentions = {
      rmn: g.includes('rmn') || g.includes('mental'),
      hca: g.includes('hca') || g.includes('health care'),
      rgn: g.includes('rgn') || g.includes('registered nurse'),
      lead: g.includes('lead')
    };

    const scoreRole = (roleStr) => {
      const rNorm = squash(roleStr || '');
      if (!rNorm) return 0;
      let score = 0;
      if (g.includes(rNorm)) score += 5;
      const gTok = g.split(/\s+/).filter(Boolean);
      const rTok = rNorm.split(/\s+/).filter(Boolean);
      score += rTok.filter(t => gTok.includes(t)).length;
      if (mentions.rmn && rNorm.includes('rmn')) score += 3;
      if (mentions.hca && rNorm.includes('hca')) score += 3;
      if (mentions.rgn && rNorm.includes('rgn')) score += 2;
      if (mentions.lead && rNorm.includes('lead')) score += 1;
      return score;
    };

    let best = { score: 0, role: null };
    for (const r of (candidateRoleCodes || [])) {
      const s = scoreRole(r);
      if (s > best.score) best = { score: s, role: r };
    }
    if (best.role && best.score >= 2) return { role: best.role };
    if ((candidateRoleCodes || []).length === 1) return { role: candidateRoleCodes[0] };
    return null;
  };

  const anyMissingRatesLocal = (usedBuckets, pay, charge) => {
    const u = usedBuckets || {};
    const p = pay || {};
    const c = charge || {};
    const used = (x) => (Number(x || 0) > 0);
    return (
      (used(u.day)   && (p.day   == null || c.day   == null)) ||
      (used(u.night) && (p.night == null || c.night == null)) ||
      (used(u.sat)   && (p.sat   == null || c.sat   == null)) ||
      (used(u.sun)   && (p.sun   == null || c.sun   == null)) ||
      (used(u.bh)    && (p.bh    == null || c.bh    == null))
    );
  };

  // ─────────────────────────────────────────────────────────────
  // Worker core (SQL-driven dequeue + context + rate batch + batch write)
  // ─────────────────────────────────────────────────────────────

  // 1) Lease outbox rows
  let lease = [];
  if (Array.isArray(onlyTimesheetIds) && onlyTimesheetIds.length) {
    const rows = await rpcTsfinDequeueSpecific(env, { timesheetIds: onlyTimesheetIds, limit });
    lease = (rows || []).map(r => ({
      outbox_id: r.id,
      timesheet_id: r.timesheet_id,
      reason: r.reason
    }));
  } else {
    lease = await rpcTsfinDequeueBatchIds(env, { limit });
  }

  if (!Array.isArray(lease) || !lease.length) return { picked: 0, ok: 0, fail: 0 };

  // 2) Map original timesheet_id -> effective/current timesheet_id
  //    ✅ FIX: if booking has no current row, fall back to highest version (still only 2 REST calls)
  const origIds = [...new Set(lease.map(x => String(x.timesheet_id)).filter(Boolean))];

  let origToCurrent = new Map();
  try {
    const inIds = origIds.map(enc).join(',');
    const { rows: tsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=in.(${inIds})` +
        `&select=timesheet_id,booking_id,is_current,version,updated_at,created_at`
    );

    const bookingIds = [...new Set((tsRows || []).map(r => r.booking_id).filter(Boolean))];
    const bookingToBest = new Map();

    if (bookingIds.length) {
      const inBookings = bookingIds.map(enc).join(',');
      const { rows: allRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?booking_id=in.(${inBookings})` +
          `&select=booking_id,timesheet_id,is_current,version,updated_at,created_at`
      );

      // choose best per booking: prefer current; else highest version; tie-break by updated/created
      const byBooking = new Map();
      for (const r of (allRows || [])) {
        const bid = r?.booking_id ? String(r.booking_id) : '';
        const tid = r?.timesheet_id ? String(r.timesheet_id) : '';
        if (!bid || !tid) continue;
        if (!byBooking.has(bid)) byBooking.set(bid, []);
        byBooking.get(bid).push(r);
      }

      for (const [bid, arr] of byBooking.entries()) {
        const rows = Array.isArray(arr) ? arr.slice() : [];
        // prefer current rows if any
        const currents = rows.filter(x => x && x.is_current === true);
        const pool = currents.length ? currents : rows;

        pool.sort((a, b) => {
          const va = Number(a?.version || 0) || 0;
          const vb = Number(b?.version || 0) || 0;
          if (vb !== va) return vb - va;

          const ua = a?.updated_at ? new Date(a.updated_at).getTime() : 0;
          const ub = b?.updated_at ? new Date(b.updated_at).getTime() : 0;
          if (ub !== ua) return ub - ua;

          const ca = a?.created_at ? new Date(a.created_at).getTime() : 0;
          const cb = b?.created_at ? new Date(b.created_at).getTime() : 0;
          return cb - ca;
        });

        const best = pool[0];
        if (best?.timesheet_id) bookingToBest.set(String(bid), String(best.timesheet_id));
      }
    }

    for (const r of (tsRows || [])) {
      const tid = String(r?.timesheet_id || '');
      if (!tid) continue;
      const bid = r?.booking_id ? String(r.booking_id) : '';
      const best = (bid && bookingToBest.get(bid)) ? bookingToBest.get(bid) : tid;
      origToCurrent.set(tid, best);
    }
  } catch {
    for (const id of origIds) origToCurrent.set(String(id), String(id));
  }

  // 3) Group outbox rows by effective timesheet_id (dedupe)
  const effToOutboxIds = new Map(); // effId -> [outbox_id...]
  const effToPrimary = new Map();   // effId -> outbox_id
  const effIds = [];

  for (const it of lease) {
    const orig = String(it.timesheet_id || '');
    const eff = origToCurrent.get(orig) || orig;
    if (!eff) continue;

    if (!effToOutboxIds.has(eff)) effToOutboxIds.set(eff, []);
    effToOutboxIds.get(eff).push(it.outbox_id);

    if (!effToPrimary.has(eff)) {
      effToPrimary.set(eff, it.outbox_id);
      effIds.push(eff);
    }
  }

  // 4) Load batch context for effective IDs (one RPC)
  const ctxRows2 = await rpcTsfinLoadContextBatch(env, { timesheetIds: effIds });
  const ctxByEff = new Map();
  for (const r of (ctxRows2 || [])) {
    const eid = String(r?.effective_timesheet_id || '');
    if (!eid) continue;
    ctxByEff.set(eid, r);
  }

  let ok = 0, fail = 0;

  // ✅ Track primaries that fail BEFORE the batch writer runs (so we don't clear their duplicate outbox rows)
  const preFailPrimaryOutboxSet = new Set();

  // weeklyWork items will be enriched via batch weekly context RPC later:
  // { ts, curFin, effFlags, policySql, cw, contract, ... }
  const weeklyWork = [];
  const dailyItemsForRates = [];
  const dailyWork = [];


  // 5) First pass: collect WEEKLY + DAILY work
  for (const effId of effIds) {
    const outboxIds = effToOutboxIds.get(effId) || [];
    const primaryOutboxId = effToPrimary.get(effId) || outboxIds[0] || null;

    const ctx = ctxByEff.get(effId) || null;
    if (!ctx) {
      for (const ob of outboxIds) {
        try {
          await sbRpc(env, "tsfin_mark_revoked", { p_timesheet_id: effId });
          await sbRpc(env, "tsfin_work_success", { p_id: ob });
          ok++;
        } catch (e) {
          await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: String(e?.message || e) });
          fail++;
        }
      }
      continue;
    }

    const ts = ctx.out_timesheet || null;
    const curFin = ctx.out_cur_fin || null;
    const effFlags = ctx.out_effective_flags || null;

    const isLocked = !!(curFin?.locked_by_invoice_id || curFin?.paid_at_utc);
    if (isLocked) {
      for (const ob of outboxIds) {
        try { await sbRpc(env, "tsfin_work_success", { p_id: ob }); ok++; } catch { fail++; }
      }
      continue;
    }

    const scope = String(ts?.sheet_scope || '').toUpperCase();

      if (scope === 'WEEKLY') {
      try {
        const basis = String(curFin?.basis || '').toUpperCase();
        const routeType = String(effFlags?.route_type || '').toUpperCase();

        // ✅ Primary routing = effective flags from v_timesheets_summary
        // (not existing TSFIN basis, which may be absent/wrong for new sheets)
        const isNhspRoute =
          (routeType === 'WEEKLY_NHSP' || routeType === 'WEEKLY_NHSP_ADJUSTMENT' || boolish(effFlags?.client_is_nhsp));

        const isHrRoute =
          (routeType === 'WEEKLY_HEALTHROSTER' || boolish(effFlags?.client_autoprocess_hr));

        // ✅ Secondary routing = current snapshot basis (kept for backwards compatibility)
        const isNhspBasis = isNhspRoute || (basis === 'NHSP' || basis === 'NHSP_ADJUSTMENT');
        const isHrBasis = isHrRoute || (
          basis === 'HEALTHROSTER_SELF_BILL' ||
          basis === 'HEALTHROSTER_SELF_BILL_ADJUSTMENT' ||
          basis === 'HEALTHROSTER_ADJUSTMENT'
        );

        // ✅ No REST here. We’ll batch-load {contract_week, contract} AFTER the first pass.
        weeklyWork.push({
          effId: String(effId),
          outbox_id: primaryOutboxId,
          extra_outbox_ids: outboxIds.filter(x => x !== primaryOutboxId),
          ts,
          curFin,
          effFlags,
          policySql: (ctx.out_policy || null),
          routeType,
          basis,
          isNhspRoute,
          isHrRoute,
          isNhspBasis,
          isHrBasis,
          cw: null,
          contract: null,
        });
      } catch (e) {
        for (const ob of outboxIds) {
          await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: String(e?.message || e) });
          fail++;
        }
      }
      continue;
    }


    // ── DAILY / ROTA batch path (SQL context + SQL rates + batch write)
    try {
      const candidate = ctx.out_candidate || null;
      const candidate_id = candidate?.id || null;
      const candidate_assignment = candidate_id ? 'ASSIGNED' : 'UNASSIGNED';

      const client_id = ctx.out_client_id || null;
      const workedDateYmd = ts?.worked_start_iso ? (toLocalParts(ts.worked_start_iso, null)?.ymd || null) : null;
      const policy = ctx.out_policy || {};

      const candidateRoleCodes = parseCandidateRoleCodes(candidate?.roles);
      const tsRoleRaw = norm(ts?.job_title_norm || '');
      const tsRole = tsRoleRaw ? normRole(tsRoleRaw) : null;
      const tsBand = normBand(ts?.band); // band no-guess (null stays null)

      // ✅ STRICT role match: only accept timesheet role if it exactly matches a candidate role code (normalised).
      // No local scoring / guessing.
      let roleForRates = null;
      if (candidate_id) {
        if (tsRole && candidateRoleCodes.includes(tsRole)) {
          roleForRates = tsRole;
        } else {
          roleForRates = null;
        }
      } else {
        roleForRates = tsRole; // candidate unresolved
      }

      const bandForRates = tsBand || null;

      let rate_type = 'UMBRELLA';
      const pm = String(candidate?.pay_method || '').toUpperCase();
      if (pm === 'PAYE' || pm === 'UMBRELLA') rate_type = pm;

      dailyItemsForRates.push({
        k: String(effId),
        candidate_id: candidate_id || null,
        client_id: client_id || null,
        role: roleForRates || null,
        band: bandForRates || null,
        date: workedDateYmd || null,
        rate_type
      });

      dailyWork.push({
        effId: String(effId),
        outbox_id: primaryOutboxId,
        extra_outbox_ids: outboxIds.filter(x => x !== primaryOutboxId),
        ts,
        ctx,
        policy,
        candidate,
        candidate_id,
        candidate_assignment,
        client_id,
        workedDateYmd,
        roleForRates,
        bandForRates,
        rate_type,
        isAuthorised: !!ts?.authorised_at_server
      });
    } catch (e) {
      for (const ob of outboxIds) {
        await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: String(e?.message || e) });
        fail++;
      }
    }
  }

  // ─────────────────────────────────────────────────────────────
  // ✅ WEEKLY: batch-load contract_week + contract in ONE RPC (no loadWeeklyContext REST)
  // Requires SQL RPC: tsfin_load_weekly_context_batch(p_timesheet_ids uuid[])
  // Returns rows: { timesheet_id, out_cw, out_contract }
  // ─────────────────────────────────────────────────────────────
  try {
    const wkIds = [...new Set(weeklyWork.map(w => String(w?.ts?.timesheet_id || '')).filter(Boolean))];

    if (wkIds.length) {
      const wkRows = await sbRpc(env, 'tsfin_load_weekly_context_batch', { p_timesheet_ids: wkIds });

      const wkByTsId = new Map();
      for (const r of (wkRows || [])) {
        const tid = r?.timesheet_id ? String(r.timesheet_id) : '';
        if (!tid) continue;
        wkByTsId.set(tid, r);
      }

      // Attach cw + contract onto weeklyWork items
      for (const w of weeklyWork) {
        const tid = String(w?.ts?.timesheet_id || '');
        const row = tid ? (wkByTsId.get(tid) || null) : null;
        w.cw = row?.out_cw || null;
        w.contract = row?.out_contract || null;
      }
    }
  } catch (e) {
    try { console.warn('[TSFIN][WEEKLY_CTX_BATCH] failed', { err: e?.message || String(e) }); } catch {}
  }

  // ─────────────────────────────────────────────────────────────
  // WEEKLY: batch-load nhsp_shifts ONCE for all weekly timesheets
  // ─────────────────────────────────────────────────────────────
  let shiftsByTsId = new Map();
  try {
    const weeklyTsIds = [...new Set(
      weeklyWork.map(w => w?.ts?.timesheet_id).filter(Boolean).map(x => String(x))
    )];

    if (weeklyTsIds.length) {
      const rows = await sbRpc(env, 'tsfin_load_nhsp_shifts_batch', { p_timesheet_ids: weeklyTsIds });
      for (const r of (rows || [])) {
        const tid = r?.timesheet_id ? String(r.timesheet_id) : null;
        if (!tid) continue;
        let arr = r?.shifts;
        if (typeof arr === 'string') {
          try { arr = JSON.parse(arr); } catch { arr = []; }
        }
        if (!Array.isArray(arr)) arr = [];
        shiftsByTsId.set(tid, arr);
      }
    }
  } catch {
    shiftsByTsId = new Map();
  }

  // ─────────────────────────────────────────────────────────────
  // 6) Resolve rates in one RPC for all DAILY items
  // ─────────────────────────────────────────────────────────────
  const ratesRows = await rpcTsfinResolveRatesBatch(env, { items: dailyItemsForRates });
  const ratesByK = new Map();
  for (const r of (ratesRows || [])) {
    const k = String(r?.k || '');
    if (!k) continue;
    ratesByK.set(k, r);
  }

  // ─────────────────────────────────────────────────────────────
  // 7) Build WEEKLY + DAILY snapshots, then batch-write ONCE
  // ─────────────────────────────────────────────────────────────
  const rowsToWriteAll = [];

  // --- WEEKLY snapshots (compute-only builders + enrich snapshot object, no TSFIN re-fetch) ---
  for (const w of weeklyWork) {
    const {
      outbox_id,
      extra_outbox_ids,
      ts,
      curFin,
      effFlags,
      cw,
      contract,
      routeType,
      basis,
      isNhspRoute,
      isHrRoute,
      isNhspBasis,
      isHrBasis,
      policySql
    } = w;

    if (!outbox_id) {
      for (const ob of [outbox_id, ...(extra_outbox_ids || [])].filter(Boolean)) {
        await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: "NO_OUTBOX_ID" });
        fail++;
      }
      continue;
    }

    if (!cw || !contract) {
      const reason = 'WEEKLY_CTX_MISSING_CW_OR_CONTRACT';
      for (const ob of [outbox_id, ...(extra_outbox_ids || [])].filter(Boolean)) {
        await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: reason });
        fail++;
      }
      continue;
    }

    try {
      const tsid = ts?.timesheet_id ? String(ts.timesheet_id) : null;
      const preloadedShifts = tsid ? (shiftsByTsId.get(tsid) || []) : [];
      const hasImportedShifts = Array.isArray(preloadedShifts) && preloadedShifts.length > 0;

      // ✅ pass SQL policy through; and pass imported shifts for HR enrichment (same table for NHSP + HR)
      const weeklyOptions = {
        policy_override: policySql || null,
        hr_eff_flags: effFlags || null,
        hr_preloaded_shifts: preloadedShifts,
        outbox_id,
        write_now: false
      };

      let buildRes = null;

      // ✅ FIX: if we have imported shifts, we must build from them based on ROUTE,
      // not based on existing snapshot basis (which may be missing/wrong).
      if (hasImportedShifts && (isNhspRoute || isHrRoute || isNhspBasis || isHrBasis)) {
        const routeU = String(routeType || '').toUpperCase();
        const basisU = String(basis || '').toUpperCase();

        const basisForBuild =
          (isHrRoute || isHrBasis)
            ? ((basisU && basisU.startsWith('HEALTHROSTER')) ? basisU : 'HEALTHROSTER_SELF_BILL')
            : ((routeU === 'WEEKLY_NHSP_ADJUSTMENT' || basisU === 'NHSP_ADJUSTMENT') ? 'NHSP_ADJUSTMENT' : 'NHSP');

        const getPolicyFn =
          (policySql && typeof policySql === 'object')
            ? (_clientId, _date) => policySql
            : (typeof getPolicyCached === 'function' ? getPolicyCached : async () => null);

        buildRes = await buildNhspWeeklySnapshotCached(
          env,
          ts,
          contract,
          preloadedShifts,
          curFin?.nhsp_import_id || null,
          basisForBuild,
          getPolicyFn,
          curFin,
          weeklyOptions
        );
      } else if (isNhspBasis) {
        buildRes = await rebuildFromExistingSegmentsEvidence(
          env,
          ts,
          cw,
          contract,
          curFin,
          weeklyOptions
        );
      } else if (isHrBasis) {
        buildRes = await rebuildFromExistingSegmentsEvidence(
          env,
          ts,
          cw,
          contract,
          curFin,
          weeklyOptions
        );
      } else {
        buildRes = await buildWeeklyScheduleSegmentsSnapshot(
          env,
          ts,
          cw,
          contract,
          curFin,
          weeklyOptions
        );
      }

      if (!buildRes || buildRes.ok !== true || !buildRes.snapshot) {
        const reason = buildRes?.reason ? String(buildRes.reason) : 'WEEKLY_BUILD_FAILED';
        for (const ob of [outbox_id, ...(extra_outbox_ids || [])].filter(Boolean)) {
          await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: reason });
          fail++;
        }
        continue;
      }

      const snapshot = buildRes.snapshot;

      if (snapshot && snapshot.occupant_key_norm == null && ts?.occupant_key_norm != null) {
        snapshot.occupant_key_norm = ts.occupant_key_norm;
      }

      // Enrich HR cross-check BEFORE write (mutates snapshot)
      try {
        await enrichTsfinWithHrCrosscheck(env, ts, snapshot, effFlags || null, preloadedShifts);
      } catch {}

      // ✅ SELF-HEAL: If current SEGMENTS snapshot is (locked segments) + (invalid elements),
      // merge-repair the current TSFIN segments in-place while preserving locked segment JSON exactly.
      try {
        const curIb0 = curFin?.invoice_breakdown_json || null;
        const curMode0 = String(curIb0?.mode || '').toUpperCase();
        const curSegs0 = Array.isArray(curIb0?.segments) ? curIb0.segments : null;

        let invalidSegCount0 = 0;
        let lockedSegCount0 = 0;

        if (curMode0 === 'SEGMENTS' && Array.isArray(curSegs0)) {
          for (const s0 of curSegs0) {
            const isObj0 = !!(s0 && typeof s0 === 'object' && !Array.isArray(s0));
            const segId0 = isObj0 ? String(s0.segment_id || '').trim() : '';
            if (!isObj0 || !segId0) {
              invalidSegCount0++;
              continue;
            }
            const lockId0 = String(s0.invoice_locked_invoice_id || '').trim();
            if (lockId0) lockedSegCount0++;
          }
        }

        const needsHeal0 = (invalidSegCount0 > 0 && lockedSegCount0 > 0);

        if (needsHeal0) {
          const newSegs0 = snapshot?.invoice_breakdown_json?.segments;
          const healRes0 = await rpcTsfinRepairMergeSegmentsLocked(env, {
            timesheetId: ts.timesheet_id,
            newSegments: Array.isArray(newSegs0) ? newSegs0 : [],
            actorUserId: null,
            correlationId: outbox_id ? `tsfin_selfheal:${String(outbox_id)}` : null
          });

          const okHeal0 =
            !!(healRes0 && typeof healRes0 === 'object' && healRes0.ok === true && Number(healRes0.new_invalid_count || 0) === 0);

          if (okHeal0) {
            // Clear the primary outbox row now; duplicate outbox rows will be bulk-cleared later
            await sbRpc(env, "tsfin_work_success", { p_id: outbox_id });
            ok++;
            continue;
          } else {
            const errMsg0 =
              (healRes0 && typeof healRes0 === 'object' && healRes0.error) ? String(healRes0.error) :
              'TSFIN_SELFHEAL_MERGE_FAILED';

            // Fail all leased outbox rows for this effective timesheet
            for (const ob0 of [outbox_id, ...(extra_outbox_ids || [])].filter(Boolean)) {
              await sbRpc(env, "tsfin_work_fail", { p_id: ob0, p_error: errMsg0 });
              fail++;
            }
            preFailPrimaryOutboxSet.add(String(outbox_id));
            continue;
          }
        }
      } catch (e0) {
        const errMsg0 = `TSFIN_SELFHEAL_ERROR:${String(e0?.message || e0)}`;
        for (const ob0 of [outbox_id, ...(extra_outbox_ids || [])].filter(Boolean)) {
          await sbRpc(env, "tsfin_work_fail", { p_id: ob0, p_error: errMsg0 });
          fail++;
        }
        preFailPrimaryOutboxSet.add(String(outbox_id));
        continue;
      }

      rowsToWriteAll.push({
        outbox_id,
        timesheet_id: ts.timesheet_id,
        snapshot
      });
    } catch (e) {
      for (const ob of [outbox_id, ...(extra_outbox_ids || [])].filter(Boolean)) {
        await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: String(e?.message || e) });
        fail++;
      }
    }
  }



  // --- DAILY snapshots ---
  for (const w of dailyWork) {
    const { effId, outbox_id, ts, policy, candidate, candidate_id, client_id, isAuthorised } = w;

    try {
      const r = ratesByK.get(String(effId)) || null;

      const pay = {
        day:   r?.pay_day   ?? null,
        night: r?.pay_night ?? null,
        sat:   r?.pay_sat   ?? null,
        sun:   r?.pay_sun   ?? null,
        bh:    r?.pay_bh    ?? null
      };
      const charge = {
        day:   r?.charge_day   ?? null,
        night: r?.charge_night ?? null,
        sat:   r?.charge_sat   ?? null,
        sun:   r?.charge_sun   ?? null,
        bh:    r?.charge_bh    ?? null
      };

      let segments = [];
      if (ts.worked_start_iso && ts.worked_end_iso) segments.push([ts.worked_start_iso, ts.worked_end_iso]);

      segments = subtractBreak(
        segments,
        ts.break_start_iso || null,
        ts.break_end_iso   || null,
        ts.break_minutes   || null
      );

      const hours = classifyMinutes(env, policy, segments);

      const missingRates = anyMissingRatesLocal(
        {
          day:   hours.hours_day,
          night: hours.hours_night,
          sat:   hours.hours_sat,
          sun:   hours.hours_sun,
          bh:    hours.hours_bh,
        },
        pay,
        charge
      );

      const effFlags = w.ctx?.out_effective_flags || null;
      const requiresHr =
        (effFlags && Object.prototype.hasOwnProperty.call(effFlags, 'client_requires_hr'))
          ? boolish(effFlags.client_requires_hr)
          : false;

      const pay_method =
        String(candidate?.pay_method || '').toUpperCase() === 'PAYE' ? 'PAYE'
        : String(candidate?.pay_method || '').toUpperCase() === 'UMBRELLA' ? 'UMBRELLA'
        : (ts.pay_method || null);

      let payChannelBad = false;
      try {
        if (candidate_id && client_id && typeof resolveEffectivePayChannel === 'function') {
          const umbrella = w.ctx?.out_umbrella || null;
          const channel = resolveEffectivePayChannel({
            pay_method: pay_method || candidate?.pay_method || null,
            candidate,
            umbrella,
          });
          payChannelBad = !channel || channel.ok === false;
        }
      } catch {
        payChannelBad = true;
      }

      let processing_status;
      let hasRateIssue = false;
      let hasPayChannelIssue = false;

      if (!candidate_id) {
        processing_status = "UNASSIGNED";
      } else if (!client_id) {
        processing_status = "CLIENT_UNRESOLVED";
      } else if (missingRates) {
        processing_status = "RATE_MISSING";
        hasRateIssue = true;
      } else if (payChannelBad) {
        processing_status = "PAY_CHANNEL_MISSING";
        hasPayChannelIssue = true;
      } else if (requiresHr) {
        processing_status = "READY_FOR_HR";
      } else {
        processing_status = "READY_FOR_INVOICE";
      }

      if (!isAuthorised && (processing_status === "READY_FOR_HR" || processing_status === "READY_FOR_INVOICE")) {
        processing_status = "PENDING_AUTH";
      }

      const total_pay_ex_vat = round2(
        hours.hours_day   * asNumberLocal(pay.day)   +
        hours.hours_night * asNumberLocal(pay.night) +
        hours.hours_sat   * asNumberLocal(pay.sat)   +
        hours.hours_sun   * asNumberLocal(pay.sun)   +
        hours.hours_bh    * asNumberLocal(pay.bh)
      );

      const total_charge_ex_vat = round2(
        hours.hours_day   * asNumberLocal(charge.day)   +
        hours.hours_night * asNumberLocal(charge.night) +
        hours.hours_sat   * asNumberLocal(charge.sat)   +
        hours.hours_sun   * asNumberLocal(charge.sun)   +
        hours.hours_bh    * asNumberLocal(charge.bh)
      );

     // ERNI applies based on SQL policy (finance windows) + pay_method
const applyTo = String(policy?.apply_erni_to || 'PAYE_ONLY').toUpperCase();
const erniPctRaw = Number(policy?.erni_pct ?? 0);
let erniMult = 1;
if (Number.isFinite(erniPctRaw) && erniPctRaw > 0) {
  const p = erniPctRaw > 1 ? (erniPctRaw / 100) : erniPctRaw; // supports 15 or 0.15
  erniMult = 1 + p;
}

const erniApplies =
  (applyTo === 'ALL') ||
  (applyTo === 'PAYE_ONLY' && String(pay_method || '').toUpperCase() === 'PAYE');

const payCostEx = round2(erniApplies ? (total_pay_ex_vat * erniMult) : total_pay_ex_vat);
const margin_ex_vat = round2(total_charge_ex_vat - payCostEx);

      const invoice_breakdown_json = {
        mode: "AGGREGATE",
        base_hours: {
          day:   hours.hours_day,
          night: hours.hours_night,
          sat:   hours.hours_sat,
          sun:   hours.hours_sun,
          bh:    hours.hours_bh,
          pay_rates: {
            day:   pay.day,
            night: pay.night,
            sat:   pay.sat,
            sun:   pay.sun,
            bh:    pay.bh,
          },
          charge_rates: {
            day:   charge.day,
            night: charge.night,
            sat:   charge.sat,
            sun:   charge.sun,
            bh:    charge.bh,
          },
          pay_ex_vat:    total_pay_ex_vat,
          charge_ex_vat: total_charge_ex_vat,
        },
        additional: { units: {}, pay_ex_vat: 0, charge_ex_vat: 0, margin_ex_vat: 0 },
        totals: { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat },
      };

      const rate_source_refs_json = {
        kind: r?.source_kind || 'NONE',
        override_id: r?.override_id || null,
        default_id: r?.default_id || null,
        rate_type: r?.rate_type || w.rate_type || null
      };

      const snapshot = {
        timesheet_id: ts.timesheet_id,
        timesheet_version: ts.version || 1,
        basis: "SELF_REPORTED",

        occupant_key_norm: ts.occupant_key_norm || null,
        worked_start_iso: ts.worked_start_iso || null,
        worked_end_iso:   ts.worked_end_iso   || null,
        break_start_iso:  ts.break_start_iso  || null,
        break_end_iso:    ts.break_end_iso    || null,
        break_minutes:    ts.break_minutes    || null,

        candidate_id,
        client_id: client_id || null,

        role: w.roleForRates || null,
        band: w.bandForRates || null,

        pay_method,

        policy_snapshot_json: policy || {},
        rate_source_refs_json,

        hours_day:   hours.hours_day,
        hours_night: hours.hours_night,
        hours_sat:   hours.hours_sat,
        hours_sun:   hours.hours_sun,
        hours_bh:    hours.hours_bh,

        pay_day:      pay.day,
        pay_night:    pay.night,
        pay_sat:      pay.sat,
        pay_sun:      pay.sun,
        pay_bh:       pay.bh,
        charge_day:   charge.day,
        charge_night: charge.night,
        charge_sat:   charge.sat,
        charge_sun:   charge.sun,
        charge_bh:    charge.bh,

        total_hours: round2(
          hours.hours_day +
          hours.hours_night +
          hours.hours_sat +
          hours.hours_sun +
          hours.hours_bh
        ),
        total_pay_ex_vat,
        total_charge_ex_vat,
        margin_ex_vat,

        additional_units_json: {},
        additional_pay_ex_vat: 0,
        additional_charge_ex_vat: 0,
        additional_margin_ex_vat: 0,

        pay_wtr_rate_pct_snapshot: null,
        candidate_assignment: w.candidate_assignment,
        processing_status,

        has_rate_issue:        !!hasRateIssue,
        has_pay_channel_issue: !!hasPayChannelIssue,

        invoice_breakdown_json,
      };

      rowsToWriteAll.push({
        outbox_id,
        timesheet_id: ts.timesheet_id,
        snapshot
      });
    } catch (e) {
      const allObs = [w.outbox_id, ...(w.extra_outbox_ids || [])].filter(Boolean);
      for (const ob of allObs) {
        await sbRpc(env, "tsfin_work_fail", { p_id: ob, p_error: String(e?.message || e) });
        fail++;
      }
    }
  }

  // ─────────────────────────────────────────────────────────────
  // 8) One batch write for WEEKLY + DAILY
  // ─────────────────────────────────────────────────────────────
  let wr = null;
  let failOutboxSet = new Set();

  if (rowsToWriteAll.length) {
    wr = await rpcTsfinWriteSnapshotsAndComplete(env, { rows: rowsToWriteAll });

    ok += Number(wr?.ok_count || 0) || 0;
    fail += Number(wr?.fail_count || 0) || 0;

    try {
      let errs = wr?.errors;
      if (typeof errs === 'string') {
        try { errs = JSON.parse(errs); } catch { errs = null; }
      }
      if (Array.isArray(errs)) {
        for (const e of errs) {
          const ob = e?.outbox_id ? String(e.outbox_id) : '';
          if (ob) failOutboxSet.add(ob);
        }
      }
    } catch {
      failOutboxSet = new Set();
    }
  }

  // ✅ Bulk-clear duplicate outbox rows ONLY if primary succeeded
  // Requires SQL RPC: tsfin_work_success_bulk(p_ids uuid[]) -> integer
  const extrasToClear = [];

  for (const w of weeklyWork) {
    const p = String(w?.outbox_id || '');
    if (!p) continue;
    if (failOutboxSet.has(p)) continue;
    if (preFailPrimaryOutboxSet.has(p)) continue;
    for (const ob of (w.extra_outbox_ids || [])) {
      if (ob) extrasToClear.push(ob);
    }
  }

  for (const w of dailyWork) {
    const p = String(w?.outbox_id || '');
    if (!p) continue;
    if (failOutboxSet.has(p)) continue;
    if (preFailPrimaryOutboxSet.has(p)) continue;
    for (const ob of (w.extra_outbox_ids || [])) {
      if (ob) extrasToClear.push(ob);
    }
  }

  if (extrasToClear.length) {
    for (const idsChunk of chunk(extrasToClear, 200)) {
      try {
        const cleared = await sbRpc(env, 'tsfin_work_success_bulk', { p_ids: idsChunk });
        ok += Number(cleared || 0) || 0;
      } catch {
        // best-effort only
      }
    }
  }

  return { picked: lease.length, ok, fail, write: wr };
}

async function buildWeeklyScheduleSegmentsSnapshot(env, ts, cw, contract, curFin, options = {}) {
  const pc = payChargeFromContract(contract);
  const pay = pc?.pay || null;
  const chg = pc?.charge || null;
  const method = pc?.method || contract?.pay_method_snapshot || null;

  const {
    outbox_id = null,
    write_now = false,
    hr_eff_flags = null,
    hr_preloaded_shifts = null,

    // ✅ NEW: allow caller to pass SQL policy (ctx.out_policy) to avoid any REST policy loads
    policy_override = null
  } = (options && typeof options === 'object') ? options : {};

  if (!pay || !chg) {
    throw new Error('CONTRACT_RATES_MISSING');
  }

  // ─────────────────────────────────────────────────────────────
  // ✅ Stable segment identity helpers
  // - Fixes delayed segment corruption by avoiding index-based segment_id.
  // - Uses a deterministic fingerprint derived from immutable segment attributes.
  // - Preserves per-segment controls (invoice_target_week_start, exclude_from_pay, invoice_locked_invoice_id)
  //   by mapping OLD → NEW using the same fingerprint.
  //
  // NOTE:
  // - We deliberately DO NOT rely on array index ordering.
  // - We prefer any stable upstream shift identifiers if present (e.g. shift_id/hr_shift_id/source_shift_id),
  //   otherwise we fall back to date/start/end/break minutes.
  // - `tsfin_prepare_write` (SQL) blocks writes if ANY segment is invoice-locked, so recompute should not occur
  //   for invoiced/locked segments. This change primarily protects delayed (uninvoiced) segment metadata.
  // ─────────────────────────────────────────────────────────────

  const _normStr = (v) => (v == null ? '' : String(v).trim());
  const _normNumInt = (v, d = 0) => {
    const n = Number(v);
    return Number.isFinite(n) ? n : d;
  };

  // FNV-1a 32-bit hash (deterministic, fast, no async crypto)
  const _hash32 = (s) => {
    let h = 0x811c9dc5;
    for (let i = 0; i < s.length; i++) {
      h ^= s.charCodeAt(i);
      h = Math.imul(h, 0x01000193);
    }
    // unsigned
    return (h >>> 0).toString(16).padStart(8, '0');
  };

  const _stableSegKey = (segObj) => {
    if (!segObj || typeof segObj !== 'object') return '';

    // Prefer stable upstream IDs if available
    const shiftId =
      _normStr(segObj.shift_id) ||
      _normStr(segObj.hr_shift_id) ||
      _normStr(segObj.source_shift_id) ||
      _normStr(segObj.rota_shift_id) ||
      _normStr(segObj.import_shift_id);

    if (shiftId) return `shift:${shiftId}`;

    const date = _normStr(segObj.date);

    const start =
      _normStr(segObj.start_utc) ||
      _normStr(segObj.start_iso) ||
      _normStr(segObj.start);

    const end =
      _normStr(segObj.end_utc) ||
      _normStr(segObj.end_iso) ||
      _normStr(segObj.end);

    const breakMins = _normNumInt(segObj.break_mins ?? segObj.break_minutes ?? 0, 0);

    // If we have no timestamps at all, we cannot build a meaningful stable key.
    // Fall back to old segment_id if present (still better than empty).
    const fallbackSid = _normStr(segObj.segment_id);
    if (!start && !end && !date) return fallbackSid;

    return `d:${date}|s:${start}|e:${end}|b:${breakMins}`;
  };

  const _stableSegId = (tsId, segKey) => {
    const k = _normStr(segKey);
    if (!k) return `ts:${tsId}:unknown`;
    return `ts:${tsId}:${_hash32(k)}`;
  };

  // ✅ POLICY B helper (HR-create/no-timesheet-required only)
  const basisU = String(curFin?.basis || 'CONTRACT_WEEKLY').toUpperCase();
  const isHrCreateNoTs =
    (basisU === 'HEALTHROSTER_SELF_BILL' || basisU === 'HEALTHROSTER_ADJUSTMENT');

  const isAuthorised = !!(ts && ts.authorised_at_server);
  // ✅ NEW GLOBAL RULE: never allow weekly to be READY_* unless authorised
  const processing_status = (!isAuthorised) ? 'PENDING_AUTH' : 'READY_FOR_INVOICE';

  // ✅ NEW (brief): preserve expenses/mileage (+ units) from current snapshot (curFin)
  const expPay   = round2(asNumberLocal(curFin?.expenses_pay_ex_vat ?? 0));
  const expChg   = round2(asNumberLocal(curFin?.expenses_charge_ex_vat ?? 0));
  const milUnits = round2(asNumberLocal(curFin?.mileage_units ?? 0));
  const milPay   = round2(asNumberLocal(curFin?.mileage_pay_ex_vat ?? 0));
  const milChg   = round2(asNumberLocal(curFin?.mileage_charge_ex_vat ?? 0));

  const actualRaw = Array.isArray(ts?.actual_schedule_json) ? ts.actual_schedule_json : [];
  const actual = normaliseScheduleBreakFields(actualRaw);

  if (!actual.length) {
    // ✅ Prefer SQL policy snapshot if provided (keeps weekly aligned with SQL-first design)
    let policy_snapshot_json = {};
    if (policy_override && typeof policy_override === 'object') {
      policy_snapshot_json = policy_override;
    }

    // ✅ NEW (brief): totals include preserved expenses/mileage even if there is no schedule
    const base_pay_ex_vat = 0;
    const base_charge_ex_vat = 0;
    const addl_pay_ex_vat = 0;
    const addl_charge_ex_vat = 0;

    const total_pay_ex_vat = round2(base_pay_ex_vat + addl_pay_ex_vat + expPay + milPay);
    const total_charge_ex_vat = round2(base_charge_ex_vat + addl_charge_ex_vat + expChg + milChg);

    // ERNI applies based on SQL policy_override (already finance-window anchored)
    const pol0 = (policy_override && typeof policy_override === 'object') ? policy_override : {};
    const applyTo0 = String(pol0.apply_erni_to || 'PAYE_ONLY').toUpperCase();
    const erniPctRaw0 = Number(pol0.erni_pct ?? 0);

    let erniMult0 = 1;
    if (Number.isFinite(erniPctRaw0) && erniPctRaw0 > 0) {
      const p = erniPctRaw0 > 1 ? (erniPctRaw0 / 100) : erniPctRaw0;
      erniMult0 = 1 + p;
    }

    const payMethodUpper0 = String(method || contract?.pay_method_snapshot || '').toUpperCase();
    const erniApplies0 =
      (applyTo0 === 'ALL') ||
      (applyTo0 === 'PAYE_ONLY' && payMethodUpper0 === 'PAYE');

    const payCostEx0 = round2(erniApplies0 ? (total_pay_ex_vat * erniMult0) : total_pay_ex_vat);
    const margin_ex_vat = round2(total_charge_ex_vat - payCostEx0);

    const snapshot = {
      timesheet_id: ts.timesheet_id,
      timesheet_version: ts.version || 1,
      basis: (curFin?.basis || 'CONTRACT_WEEKLY'),
      candidate_id: contract?.candidate_id || null,
      client_id: contract?.client_id || null,
      role: contract?.role || null,
      band: contract?.band || null,
      pay_method: method,
      policy_snapshot_json,
      rate_source_refs_json: { mode: 'CONTRACT_RATES_JSON', contract_id: contract?.id || null },

      hours_day: 0,
      hours_night: 0,
      hours_sat: 0,
      hours_sun: 0,
      hours_bh: 0,
      total_hours: 0,

      pay_day: pay.day, pay_night: pay.night, pay_sat: pay.sat, pay_sun: pay.sun, pay_bh: pay.bh,
      charge_day: chg.day, charge_night: chg.night, charge_sat: chg.sat, charge_sun: chg.sun, charge_bh: chg.bh,

      additional_units_json: {},
      additional_pay_ex_vat: 0,
      additional_charge_ex_vat: 0,
      additional_margin_ex_vat: 0,

      // ✅ totals include preserved expenses/mileage
      total_pay_ex_vat,
      total_charge_ex_vat,
      margin_ex_vat,

      // ✅ NEW (brief): preserve expense + mileage fields in snapshot
      expenses_pay_ex_vat: expPay,
      expenses_charge_ex_vat: expChg,
      expenses_description: curFin?.expenses_description ?? null,
      expenses_evidence_r2_key: curFin?.expenses_evidence_r2_key ?? null,
      expenses_evidence_manifest: curFin?.expenses_evidence_manifest ?? null,

      mileage_units: milUnits,
      mileage_pay_ex_vat: milPay,
      mileage_charge_ex_vat: milChg,
      mileage_evidence_r2_key: curFin?.mileage_evidence_r2_key ?? null,
      mileage_evidence_manifest: curFin?.mileage_evidence_manifest ?? null,
      mileage_pay_rate: curFin?.mileage_pay_rate ?? null,
      mileage_charge_rate: curFin?.mileage_charge_rate ?? null,

      candidate_assignment: (contract?.candidate_id ? 'ASSIGNED' : 'UNASSIGNED'),
      processing_status,

      invoice_breakdown_json: {
        mode: 'SEGMENTS',
        segments: [],
        totals: { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat }
      }
    };

    if (typeof enrichTsfinWithHrCrosscheck === 'function') {
      try { await enrichTsfinWithHrCrosscheck(env, ts, snapshot, hr_eff_flags || null, hr_preloaded_shifts || null); } catch {}
    }

    if (write_now) {
      if (!outbox_id) throw new Error('buildWeeklyScheduleSegmentsSnapshot: write_now requires options.outbox_id');
      const wr = await rpcTsfinWriteSnapshotsAndComplete(env, {
        rows: [{ outbox_id, timesheet_id: ts.timesheet_id, snapshot }]
      });
      return { ok: true, snapshot, write: wr };
    }

    return { ok: true, snapshot };
  }

  // Preserve per-segment controls if we have an existing SEGMENTS snapshot
  // ✅ IMPORTANT: map by stable fingerprint (NOT by segment_id)
  const preserved = new Map();
  try {
    const ib = curFin?.invoice_breakdown_json || null;
    const mode = String(ib?.mode || '').toUpperCase();
    const segs = Array.isArray(ib?.segments) ? ib.segments : null;
    if (mode === 'SEGMENTS' && segs) {
      for (const s of segs) {
        const key = _stableSegKey(s);
        if (!key) continue;
        preserved.set(key, {
          exclude_from_pay: (typeof s.exclude_from_pay === 'boolean') ? s.exclude_from_pay : undefined,
          invoice_target_week_start: (s.invoice_target_week_start != null) ? String(s.invoice_target_week_start) : undefined,
          invoice_locked_invoice_id: (s.invoice_locked_invoice_id != null) ? String(s.invoice_locked_invoice_id) : undefined
        });
      }
    }
  } catch {}

  const segments = [];
  let sumDay = 0, sumNight = 0, sumSat = 0, sumSun = 0, sumBh = 0;
  let sumPay = 0, sumChg = 0;

  for (let i = 0; i < actual.length; i++) {
    const seg = actual[i] || {};

    // ✅ IMPORTANT: pass policy_override through so resolveBucketsFromSchedule does NOT REST-load policy
    const mins = await resolveBucketsFromSchedule(env, contract, [seg], policy_override);

    const hDay   = +(asNumberLocal(mins.day)   / 60).toFixed(2);
    const hNight = +(asNumberLocal(mins.night) / 60).toFixed(2);
    const hSat   = +(asNumberLocal(mins.sat)   / 60).toFixed(2);
    const hSun   = +(asNumberLocal(mins.sun)   / 60).toFixed(2);
    const hBh    = +(asNumberLocal(mins.bh)    / 60).toFixed(2);

    sumDay += hDay; sumNight += hNight; sumSat += hSat; sumSun += hSun; sumBh += hBh;

    const payEx = round2(
      hDay   * asNumberLocal(pay.day) +
      hNight * asNumberLocal(pay.night) +
      hSat   * asNumberLocal(pay.sat) +
      hSun   * asNumberLocal(pay.sun) +
      hBh    * asNumberLocal(pay.bh)
    );

    const chgEx = round2(
      hDay   * asNumberLocal(chg.day) +
      hNight * asNumberLocal(chg.night) +
      hSat   * asNumberLocal(chg.sat) +
      hSun   * asNumberLocal(chg.sun) +
      hBh    * asNumberLocal(chg.bh)
    );

    sumPay += payEx;
    sumChg += chgEx;

    // ✅ Stable identity (no index-based ids)
    const key = _stableSegKey(seg);
    const sid = _stableSegId(ts.timesheet_id, key);

    const p = preserved.get(key) || null;

    const exclude_from_pay =
      (p && typeof p.exclude_from_pay === 'boolean') ? p.exclude_from_pay : false;

    const invoice_target_week_start =
      (p && p.invoice_target_week_start != null) ? p.invoice_target_week_start : undefined;

    const invoice_locked_invoice_id =
      (p && p.invoice_locked_invoice_id != null) ? p.invoice_locked_invoice_id : undefined;

    segments.push({
      segment_id: sid,
      date: seg.date || null,
      start_utc: seg.start_utc || seg.start_iso || null,
      end_utc: seg.end_utc || seg.end_iso || null,
      break_mins: Number(seg.break_mins ?? seg.break_minutes ?? 0) || 0,
      ref_num: (seg.ref_num != null && String(seg.ref_num).trim()) ? String(seg.ref_num).trim() : null,
      breaks: Array.isArray(seg.breaks) ? seg.breaks : [],

      hours_day: hDay,
      hours_night: hNight,
      hours_sat: hSat,
      hours_sun: hSun,
      hours_bh: hBh,

      pay_amount: payEx,
      charge_amount: chgEx,

      exclude_from_pay,
      ...(invoice_target_week_start != null ? { invoice_target_week_start } : {}),
      ...(invoice_locked_invoice_id != null ? { invoice_locked_invoice_id } : {})
    });
  }

  const hours = {
    day: round2(sumDay),
    night: round2(sumNight),
    sat: round2(sumSat),
    sun: round2(sumSun),
    bh: round2(sumBh)
  };

  const total_hours = round2(hours.day + hours.night + hours.sat + hours.sun + hours.bh);

  // ✅ Pass policy_override so this stays REST-free and BH logic is correct
  const addl = await computeWeeklyAdditionalFromTs(env, ts, cw, contract, policy_override);

  // ✅ Core totals (hours + additional) unchanged calculation
  const core_total_pay_ex_vat = round2(round2(sumPay) + round2(addl.additional_pay_ex_vat || 0));
  const core_total_charge_ex_vat = round2(round2(sumChg) + round2(addl.additional_charge_ex_vat || 0));

  // ✅ NEW (brief): totals include preserved expenses/mileage
  const total_pay_ex_vat = round2(core_total_pay_ex_vat + expPay + milPay);
  const total_charge_ex_vat = round2(core_total_charge_ex_vat + expChg + milChg);

  // ERNI applies based on SQL policy_override (already finance-window anchored)
  const pol = (policy_override && typeof policy_override === 'object') ? policy_override : {};
  const applyTo = String(pol.apply_erni_to || 'PAYE_ONLY').toUpperCase();
  const erniPctRaw = Number(pol.erni_pct ?? 0);

  let erniMult = 1;
  if (Number.isFinite(erniPctRaw) && erniPctRaw > 0) {
    const p = erniPctRaw > 1 ? (erniPctRaw / 100) : erniPctRaw;
    erniMult = 1 + p;
  }

  const payMethodUpper = String(method || contract?.pay_method_snapshot || '').toUpperCase();
  const erniApplies =
    (applyTo === 'ALL') ||
    (applyTo === 'PAYE_ONLY' && payMethodUpper === 'PAYE');

  const payCostEx = round2(erniApplies ? (total_pay_ex_vat * erniMult) : total_pay_ex_vat);
  const margin_ex_vat = round2(total_charge_ex_vat - payCostEx);

  // ✅ Policy snapshot: prefer SQL policy; fallback only if you *choose* to allow REST
  let policy_snapshot_json = {};
  if (policy_override && typeof policy_override === 'object') {
    policy_snapshot_json = policy_override;
  } else {
    // fallback (kept only for safety if caller forgets to pass policy_override)
    try {
      const we = String(ts?.week_ending_date || cw?.week_ending_date || '');
      if (we && contract?.client_id && typeof getPolicyCached === 'function') {
        policy_snapshot_json = await getPolicyCached(contract.client_id, we);
      }
      if (!policy_snapshot_json || typeof policy_snapshot_json !== 'object') policy_snapshot_json = {};
    } catch {
      policy_snapshot_json = {};
    }
  }

  const snapshot = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,

    basis: (curFin?.basis || 'CONTRACT_WEEKLY'),
    candidate_id: contract?.candidate_id || null,
    client_id: contract?.client_id || null,
    role: contract?.role || null,
    band: contract?.band || null,
    pay_method: method,

    policy_snapshot_json,
    rate_source_refs_json: { mode: 'CONTRACT_RATES_JSON', contract_id: contract?.id || null },

    hours_day: hours.day,
    hours_night: hours.night,
    hours_sat: hours.sat,
    hours_sun: hours.sun,
    hours_bh: hours.bh,
    total_hours,

    pay_day: pay.day, pay_night: pay.night, pay_sat: pay.sat, pay_sun: pay.sun, pay_bh: pay.bh,
    charge_day: chg.day, charge_night: chg.night, charge_sat: chg.sat, charge_sun: chg.sun, charge_bh: chg.bh,

    additional_units_json: addl.additional_units_json || {},
    additional_pay_ex_vat: round2(addl.additional_pay_ex_vat || 0),
    additional_charge_ex_vat: round2(addl.additional_charge_ex_vat || 0),
    additional_margin_ex_vat: round2(addl.additional_margin_ex_vat || 0),

    // ✅ totals include preserved expenses/mileage
    total_pay_ex_vat,
    total_charge_ex_vat,
    margin_ex_vat,

    // ✅ NEW (brief): preserve expense + mileage fields in snapshot
    expenses_pay_ex_vat: expPay,
    expenses_charge_ex_vat: expChg,
    expenses_description: curFin?.expenses_description ?? null,
    expenses_evidence_r2_key: curFin?.expenses_evidence_r2_key ?? null,
    expenses_evidence_manifest: curFin?.expenses_evidence_manifest ?? null,

    mileage_units: milUnits,
    mileage_pay_ex_vat: milPay,
    mileage_charge_ex_vat: milChg,
    mileage_evidence_r2_key: curFin?.mileage_evidence_r2_key ?? null,
    mileage_evidence_manifest: curFin?.mileage_evidence_manifest ?? null,
    mileage_pay_rate: curFin?.mileage_pay_rate ?? null,
    mileage_charge_rate: curFin?.mileage_charge_rate ?? null,

    candidate_assignment: (contract?.candidate_id ? 'ASSIGNED' : 'UNASSIGNED'),
    processing_status,

    invoice_breakdown_json: {
      mode: 'SEGMENTS',
      segments,
      additional: {
        units: addl.additional_units_json || {},
        pay_ex_vat: round2(addl.additional_pay_ex_vat || 0),
        charge_ex_vat: round2(addl.additional_charge_ex_vat || 0),
        margin_ex_vat: round2(addl.additional_margin_ex_vat || 0)
      },
      totals: {
        total_pay_ex_vat,
        total_charge_ex_vat,
        margin_ex_vat
      }
    }
  };

  if (typeof enrichTsfinWithHrCrosscheck === 'function') {
    try { await enrichTsfinWithHrCrosscheck(env, ts, snapshot, hr_eff_flags || null, hr_preloaded_shifts || null); } catch {}
  }

  if (write_now) {
    if (!outbox_id) throw new Error('buildWeeklyScheduleSegmentsSnapshot: write_now requires options.outbox_id');
    const wr = await rpcTsfinWriteSnapshotsAndComplete(env, {
      rows: [{ outbox_id, timesheet_id: ts.timesheet_id, snapshot }]
    });
    return { ok: true, snapshot, write: wr };
  }

  return { ok: true, snapshot };
}


async function rebuildFromExistingSegmentsEvidence(env, ts, cw, contract, curFin, options = {}) {
  const ib = curFin?.invoice_breakdown_json || null;
  const mode = String(ib?.mode || '').toUpperCase();
  const segs = Array.isArray(ib?.segments) ? ib.segments : null;
  if (mode !== 'SEGMENTS' || !segs || !segs.length) {
    throw new Error('NO_EXISTING_SEGMENTS_EVIDENCE');
  }

  const {
    outbox_id = null,
    write_now = false,
    hr_eff_flags = null,
    hr_preloaded_shifts = null,

    // ✅ NEW: allow caller to pass SQL policy (ctx.out_policy) to avoid REST
    policy_override = null
  } = (options && typeof options === 'object') ? options : {};

  const pc = payChargeFromContract(contract);
  const pay = pc?.pay || null;
  const chg = pc?.charge || null;
  const method = pc?.method || contract.pay_method_snapshot || null;
  if (!pay || !chg) throw new Error('CONTRACT_RATES_MISSING');

  // ✅ POLICY B helper (HR-create/no-timesheet-required only)
  const basisU = String(curFin?.basis || 'CONTRACT_WEEKLY').toUpperCase();
  const isHrCreateNoTs =
    (basisU === 'HEALTHROSTER_SELF_BILL' || basisU === 'HEALTHROSTER_ADJUSTMENT');

  const isAuthorised = !!(ts && ts.authorised_at_server);
  // ✅ NEW GLOBAL RULE: never allow weekly to be READY_* unless authorised
  const processing_status = (!isAuthorised) ? 'PENDING_AUTH' : 'READY_FOR_INVOICE';

  let sumDay = 0, sumNight = 0, sumSat = 0, sumSun = 0, sumBh = 0;
  let totalPayEx = 0, totalChgEx = 0;

  const nextSegments = segs.map(s => {
    const hDay   = asNumberLocal(s.hours_day);
    const hNight = asNumberLocal(s.hours_night);
    const hSat   = asNumberLocal(s.hours_sat);
    const hSun   = asNumberLocal(s.hours_sun);
    const hBh    = asNumberLocal(s.hours_bh);

    sumDay += hDay; sumNight += hNight; sumSat += hSat; sumSun += hSun; sumBh += hBh;

    const payEx = round2(
      hDay   * asNumberLocal(pay.day) +
      hNight * asNumberLocal(pay.night) +
      hSat   * asNumberLocal(pay.sat) +
      hSun   * asNumberLocal(pay.sun) +
      hBh    * asNumberLocal(pay.bh)
    );

    const chgEx = round2(
      hDay   * asNumberLocal(chg.day) +
      hNight * asNumberLocal(chg.night) +
      hSat   * asNumberLocal(chg.sat) +
      hSun   * asNumberLocal(chg.sun) +
      hBh    * asNumberLocal(chg.bh)
    );

    totalPayEx += payEx;
    totalChgEx += chgEx;

    return {
      ...s,
      pay_amount: payEx,
      charge_amount: chgEx
    };
  });

  totalPayEx = round2(totalPayEx);
totalChgEx = round2(totalChgEx);

// ✅ ERNI-aware margin (prefer SQL policy_override)
const _polForMargin = (policy_override && typeof policy_override === 'object') ? policy_override : policy_snapshot_json;
const _applyErniTo  = String(_polForMargin?.apply_erni_to || 'PAYE_ONLY').toUpperCase();
const _erniPctRaw   = Number(_polForMargin?.erni_pct ?? 0);

let _erniMult = 1;
if (Number.isFinite(_erniPctRaw) && _erniPctRaw > 0) {
  const p = _erniPctRaw > 1 ? (_erniPctRaw / 100) : _erniPctRaw;
  _erniMult = 1 + p;
}

const _payMethodU = String(method || '').toUpperCase();
const _erniApplies =
  (_applyErniTo === 'ALL') ||
  (_applyErniTo === 'PAYE_ONLY' && _payMethodU === 'PAYE');

const _payCostEx = round2(_erniApplies ? (totalPayEx * _erniMult) : totalPayEx);
const marginEx = round2(totalChgEx - _payCostEx);


  const hours_day   = round2(sumDay);
  const hours_night = round2(sumNight);
  const hours_sat   = round2(sumSat);
  const hours_sun   = round2(sumSun);
  const hours_bh    = round2(sumBh);
  const total_hours = round2(hours_day + hours_night + hours_sat + hours_sun + hours_bh);

  // ✅ Policy snapshot: prefer SQL policy_override; fallback to getPolicyCached only if missing
  let policy_snapshot_json = {};
  if (policy_override && typeof policy_override === 'object') {
    policy_snapshot_json = policy_override;
  } else {
    try {
      const we = String(ts.week_ending_date || cw.week_ending_date || '');
      policy_snapshot_json =
        (contract.client_id && we && typeof getPolicyCached === 'function')
          ? (await getPolicyCached(contract.client_id, we))
          : {};
      if (!policy_snapshot_json || typeof policy_snapshot_json !== 'object') policy_snapshot_json = {};
    } catch {
      policy_snapshot_json = {};
    }
  }

  const snapshot = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,

    basis: curFin?.basis || 'CONTRACT_WEEKLY',
    candidate_id: contract.candidate_id || null,
    client_id: contract.client_id || null,
    role: contract.role || null,
    band: contract.band || null,
    pay_method: method,

    policy_snapshot_json,
    rate_source_refs_json: { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null },

    hours_day,
    hours_night,
    hours_sat,
    hours_sun,
    hours_bh,
    total_hours,

    pay_day: pay.day, pay_night: pay.night, pay_sat: pay.sat, pay_sun: pay.sun, pay_bh: pay.bh,
    charge_day: chg.day, charge_night: chg.night, charge_sat: chg.sat, charge_sun: chg.sun, charge_bh: chg.bh,

    additional_units_json: {},
    additional_pay_ex_vat: 0,
    additional_charge_ex_vat: 0,
    additional_margin_ex_vat: 0,

    total_pay_ex_vat: totalPayEx,
    total_charge_ex_vat: totalChgEx,
    margin_ex_vat: marginEx,

    candidate_assignment: (contract.candidate_id ? 'ASSIGNED' : 'UNASSIGNED'),
    processing_status,

    invoice_breakdown_json: {
  mode: 'SEGMENTS',
  segments: nextSegments,
  totals: {
    total_pay_ex_vat: totalPayEx,
    total_charge_ex_vat: totalChgEx,
    margin_ex_vat: marginEx // now ERNI-aware for PAYE
  }
},


    external_source_rows_json: curFin?.external_source_rows_json || {}
  };

  if (typeof enrichTsfinWithHrCrosscheck === 'function') {
    try { await enrichTsfinWithHrCrosscheck(env, ts, snapshot, hr_eff_flags || null, hr_preloaded_shifts || null); } catch {}
  }

  if (write_now) {
    if (!outbox_id) throw new Error('rebuildFromExistingSegmentsEvidence: write_now requires options.outbox_id');
    const wr = await rpcTsfinWriteSnapshotsAndComplete(env, {
      rows: [{ outbox_id, timesheet_id: ts.timesheet_id, snapshot }]
    });
    return { ok: true, snapshot, write: wr };
  }

  return { ok: true, snapshot };
}


async function tsfinTargetedDrainNow(env, {
  timesheetIds = [],
  reason = 'CONTEXT_CHANGED',
  chunkSize = 50
} = {}) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L = (...a) => { if (LOG) console.log('[TSFIN][TARGET]', ...a); };

  // Load TSFIN knobs (adaptability layer)
  // Falls back safely if settings load fails
  let cfg = null;
  try { cfg = await loadSettingsDefaults(env); } catch {}
  const tsfinCfg = cfg?.importConfig?.tsfin || {};
  const maxInlineItems = Number(tsfinCfg.maxInlineItems || 0) > 0 ? Number(tsfinCfg.maxInlineItems) : 3;

  // Dedupe and normalize input ids
  const uniq = Array.from(new Set((timesheetIds || [])
    .map(x => String(x || '').trim())
    .filter(Boolean)));

  if (!uniq.length) {
    return {
      enqueued: 0,
      processed_now: 0,
      deferred: 0,
      ran: 0,
      picked: 0,
      ok: 0,
      fail: 0
    };
  }

  // Cap inline work to avoid blowing budgets even on paid tiers (adaptable via config).
  // We still enqueue ALL; we only drain a small number inline.
  const inlineIds = uniq.slice(0, maxInlineItems);
  const deferred = Math.max(0, uniq.length - inlineIds.length);

  L('START', { total: uniq.length, inline: inlineIds.length, deferred, reason, chunkSize, maxInlineItems });

  let enq = 0;
  let ran = 0;
  let picked = 0;
  let ok = 0;
  let fail = 0;

  // Enqueue all IDs (priority enqueue), chunked
  for (let i = 0; i < uniq.length; i += chunkSize) {
    const chunk = uniq.slice(i, i + chunkSize);
    try {
      const res = await sbRpc(env, 'enqueue_ts_financials_priority', {
        _timesheet_ids: chunk,
        _reason: reason
      });

      // enqueue_ts_financials_priority returns integer in your SQL (row_count).
      // PostgREST often returns it as a number or as [{...}] depending on configuration.
      // We treat success as "chunk.length enqueued" if we can't parse the return.
      let cnt = 0;
      if (typeof res === 'number') cnt = res;
      else if (typeof res === 'string') {
        const n = Number(res);
        cnt = Number.isFinite(n) ? n : 0;
      } else if (Array.isArray(res) && res[0] != null) {
        // Sometimes PostgREST returns a single-row table-like response
        const v = res[0]?.enqueue_ts_financials_priority ?? res[0]?.count ?? res[0]?.row_count ?? null;
        const n = Number(v);
        cnt = Number.isFinite(n) ? n : 0;
      }

      // If parsed count is zero but we had a chunk, treat as best-effort enqueue
      enq += (cnt > 0 ? cnt : chunk.length);

      L('ENQ_OK', { chunk: chunk.length, parsed_count: cnt });
    } catch (e) {
      console.warn('[TSFIN][TARGET] enqueue_ts_financials_priority failed', e?.message || e);
      L('ENQ_FAIL', { chunk: chunk.length, err: String(e?.message || e) });
      // If enqueue fails, no point draining for those ids
    }
  }

  // Drain ONLY inlineIds (deterministic targeted drain)
  // No "peek outbox" (removed) to keep subrequests minimal.
  // Circuit breaker: if we hit subrequest errors, we just return "queued" with deferred.
  if (inlineIds.length) {
    try {
      const res = await runTsfinWorkerOnce(env, {
        limit: inlineIds.length,
        onlyTimesheetIds: inlineIds
      });

      ran += 1;
      picked += Number(res?.picked || 0);
      ok += Number(res?.ok || 0);
      fail += Number(res?.fail || 0);

      L('DRAIN_OK', { ran, picked, ok, fail });
    } catch (e) {
      const msg = String(e?.message || e || '');
      console.warn('[TSFIN][TARGET] runTsfinWorkerOnce failed', msg);

      // Circuit breaker: do not retry in the same request.
      // Keep response deterministic: everything is enqueued; some may complete via cron.
      L('DRAIN_FAIL', { err: msg });
    }
  }

  // processed_now is how many we attempted to drain inline (not necessarily ok)
  const processed_now = inlineIds.length;

  return {
    enqueued: enq,
    processed_now,
    deferred,
    ran,
    picked,
    ok,
    fail
  };
}


// ---------------------------
// Pay channel resolution (pure)
// ---------------------------
function resolveEffectivePayChannel(input) {
  const pm = (input.pay_method || '').toUpperCase();
  const cand = input.candidate || {};
  const umb = input.umbrella || {};

  const trim = (v) => (v ?? '').toString().trim() || null;

  if (pm === 'PAYE') {
    const out = {
      pay_method: 'PAYE',
      source: 'CANDIDATE',
      account_holder: trim(cand.account_holder),
      bank_name: trim(cand.bank_name),
      sort_code: trim(cand.sort_code),
      account_number: trim(cand.account_number)
    };
    const missing = [];
    if (!out.sort_code) missing.push('sort_code');
    if (!out.account_number) missing.push('account_number');
    return { ...out, ok: missing.length === 0, missing };
  }

  if (pm === 'UMBRELLA') {
    const out = {
      pay_method: 'UMBRELLA',
      source: 'UMBRELLA',
      account_holder: trim(umb.name) || null,
      bank_name: trim(umb.bank_name),
      sort_code: trim(umb.sort_code),
      account_number: trim(umb.account_number)
    };
    const missing = [];
    if (!trim(cand.umbrella_id)) missing.push('umbrella_id');
    if (!out.sort_code) missing.push('sort_code');
    if (!out.account_number) missing.push('account_number');
    return { ...out, ok: missing.length === 0, missing };
  }

  return {
    pay_method: pm || null,
    source: 'MISSING',
    account_holder: null,
    bank_name: null,
    sort_code: null,
    account_number: null,
    ok: false,
    missing: ['pay_method']
  };
}

// ---------------------------
// Worker: dequeue → compute
// ---------------------------
// ---------------------------
// Worker: dequeue → compute
// ---------------------------
// helpers used above
function hasPayeBank(c) {
  if (!c) return false;
  return !!(c.account_number && c.sort_code); // minimal signal; holder/bank_name optional
}



// Run HR weekly cross-check in bulk for every (client, candidate, week)
// touched by a given HR_WEEKLY import.
//
// This helper is invoked from handleHrAutoprocessApply(env, req, importId).
async function applyWeeklyHealthRosterCrosscheck(env, { import_id }) {
  const enc = encodeURIComponent;
  if (!import_id) return { triples: 0, timesheets_checked: 0 };

  const chunk = (arr, n) => {
    const out = [];
    for (let i = 0; i < (arr?.length || 0); i += n) out.push(arr.slice(i, i + n));
    return out;
  };

  // ─────────────────────────────────────────────
  // Step 1: fetch hr_rows for this import
  // ─────────────────────────────────────────────
  let hrRows = [];
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/hr_rows` +
        `?import_id=eq.${enc(import_id)}` +
        `&select=client_id,candidate_id,week_ending_date,work_date,import_type`
    );
    hrRows = rows || [];
  } catch (e) {
    console.warn('[applyWeeklyHealthRosterCrosscheck] failed to load hr_rows', {
      import_id,
      err: e?.message || String(e)
    });
    return { triples: 0, timesheets_checked: 0 };
  }

  if (!hrRows.length) return { triples: 0, timesheets_checked: 0 };

  const filteredRows = hrRows.filter(r => {
    const t = (r.import_type || '').toString().toUpperCase();
    return !r.import_type || t === 'HEALTHROSTER_WEEKLY';
  });

  if (!filteredRows.length) return { triples: 0, timesheets_checked: 0 };

  // ─────────────────────────────────────────────
  // Step 2: compute distinct (client_id, candidate_id, week_ending_date)
  // ─────────────────────────────────────────────
  const triplesMap = new Map();

  const clientWeekdayCache = new Map();
  const clientsNeedingWeekEnd = new Set();

  for (const r of filteredRows) {
    if (!r.week_ending_date && r.client_id && r.work_date) clientsNeedingWeekEnd.add(r.client_id);
  }

  if (clientsNeedingWeekEnd.size) {
    try {
      const clientIds = Array.from(clientsNeedingWeekEnd).filter(Boolean);
      if (clientIds.length) {
        const { rows: csRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/client_settings` +
            `?client_id=in.(${clientIds.map(enc).join(',')})` +
            `&select=client_id,week_ending_weekday,effective_from,created_at` +
            `&order=client_id.asc,effective_from.desc.nullslast,created_at.desc`
        );

        for (const cs of (csRows || [])) {
          const cid = cs?.client_id || null;
          if (!cid) continue;
          if (clientWeekdayCache.has(cid)) continue;

          let weDow = 0;
          if (cs.week_ending_weekday != null) {
            const v = Number(cs.week_ending_weekday);
            if (Number.isInteger(v) && v >= 0 && v <= 6) weDow = v;
          }
          clientWeekdayCache.set(cid, weDow);
        }

        for (const cid of clientIds) {
          if (!clientWeekdayCache.has(cid)) clientWeekdayCache.set(cid, 0);
        }
      }
    } catch (e) {
      try {
        console.warn('[applyWeeklyHealthRosterCrosscheck] client_settings batch week_ending_weekday lookup failed', {
          import_id,
          err: e?.message || String(e)
        });
      } catch {}
      for (const cid of clientsNeedingWeekEnd) clientWeekdayCache.set(cid, 0);
    }
  }

  const parseYmd = (s) => {
    const str = String(s || '').trim();
    return /^\d{4}-\d{2}-\d{2}$/.test(str) ? str : null;
  };

  const weekEndingFromWorkDate = (workDateYmd, weDow) => {
    try {
      const d = new Date(`${workDateYmd}T00:00:00Z`);
      if (Number.isNaN(d.getTime())) return null;
      while (d.getUTCDay() !== weDow) d.setUTCDate(d.getUTCDate() + 1);
      const yyyy = d.getUTCFullYear();
      const mm = String(d.getUTCMonth() + 1).padStart(2, '0');
      const dd = String(d.getUTCDate()).padStart(2, '0');
      return `${yyyy}-${mm}-${dd}`;
    } catch {
      return null;
    }
  };

  const getWeekEndingForRow = (row) => {
    const clientId = row.client_id || null;
    const weekEnd = parseYmd(row.week_ending_date);
    const workDate = parseYmd(row.work_date);

    if (weekEnd) return weekEnd;
    if (!clientId || !workDate) return null;

    const weDow = (clientWeekdayCache.get(clientId) ?? 0);
    return weekEndingFromWorkDate(workDate, weDow);
  };

  for (const r of filteredRows) {
    const clientId = r.client_id || null;
    const candidateId = r.candidate_id || null;
    if (!clientId || !candidateId) continue;

    const weekEnd = getWeekEndingForRow(r);
    if (!weekEnd) continue;

    const key = `${clientId}__${candidateId}__${weekEnd}`;
    if (!triplesMap.has(key)) {
      triplesMap.set(key, { client_id: clientId, candidate_id: candidateId, week_ending_date: weekEnd });
    }
  }

  if (!triplesMap.size) return { triples: 0, timesheets_checked: 0 };

  // ─────────────────────────────────────────────
  // Step 3: for each triple, run enrichTsfinWithHrCrosscheck on all TSs
  // ✅ Now batches:
  //   - context via rpcTsfinLoadContextBatch
  //   - nhsp_shifts via SQL RPC tsfin_load_nhsp_shifts_batch
  // ─────────────────────────────────────────────
  let timesheetsChecked = 0;

  for (const triple of triplesMap.values()) {
    const { client_id, candidate_id, week_ending_date } = triple;

    // Find WEEKLY timesheet_ids via v_timesheets_funnel
    let tsIds = [];
    try {
      const { rows: fRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_funnel` +
          `?kind=eq.WEEK` +
          `&client_id=eq.${enc(client_id)}` +
          `&candidate_id=eq.${enc(candidate_id)}` +
          `&week_ending_date=eq.${enc(week_ending_date)}` +
          `&select=timesheet_id`
      );

      tsIds = Array.from(new Set((fRows || []).map(r => r?.timesheet_id).filter(Boolean)));
    } catch (e) {
      console.warn('[applyWeeklyHealthRosterCrosscheck] failed to load v_timesheets_funnel', {
        import_id,
        client_id,
        candidate_id,
        week_ending_date,
        err: e?.message || String(e)
      });
      continue;
    }

    if (!tsIds.length) continue;

    // ✅ Batch context load (timesheet + current TSFIN + effective flags)
    let ctxRowsAll = [];
    try {
      for (const idsChunk of chunk(tsIds, 50)) {
        const ctxRows = await rpcTsfinLoadContextBatch(env, { timesheetIds: idsChunk });
        if (Array.isArray(ctxRows) && ctxRows.length) ctxRowsAll.push(...ctxRows);
      }
    } catch (e) {
      console.warn('[applyWeeklyHealthRosterCrosscheck] rpcTsfinLoadContextBatch failed', {
        import_id,
        client_id,
        candidate_id,
        week_ending_date,
        err: e?.message || String(e)
      });
      continue;
    }

    if (!ctxRowsAll.length) continue;

    // ✅ Batch nhsp_shifts load via SQL RPC (one per chunk)
    const shiftsByTimesheetId = new Map();
    try {
      for (const idsChunk of chunk(tsIds, 50)) {
        const rows = await sbRpc(env, 'tsfin_load_nhsp_shifts_batch', {
          p_timesheet_ids: idsChunk
        });

        // rows: [{ timesheet_id, shifts: [...] }, ...]
        for (const r of (rows || [])) {
          const tid = r?.timesheet_id || null;
          if (!tid) continue;
          const shifts = Array.isArray(r?.shifts) ? r.shifts : [];
          shiftsByTimesheetId.set(tid, shifts);
        }
      }
    } catch (e) {
      console.warn('[applyWeeklyHealthRosterCrosscheck] tsfin_load_nhsp_shifts_batch failed', {
        import_id,
        client_id,
        candidate_id,
        week_ending_date,
        err: e?.message || String(e)
      });
      // If shifts batch fails, we still proceed; enrich will fallback to REST fetch.
    }

    // Enrich each ctx row (no per-timesheet context RPC; and shifts provided if we have them)
    for (const ctx of ctxRowsAll) {
      const ts = ctx?.out_timesheet || null;
      const fin = ctx?.out_cur_fin || null;
      const flags = ctx?.out_effective_flags || null;

      if (!ts || !fin) continue;

      const tid = fin?.timesheet_id || ctx?.effective_timesheet_id || null;
      const preloadedShifts = (tid && shiftsByTimesheetId.has(tid)) ? shiftsByTimesheetId.get(tid) : null;

      try {
        await enrichTsfinWithHrCrosscheck(env, ts, fin, flags, preloadedShifts);
        timesheetsChecked++;
      } catch (e) {
        console.warn('[applyWeeklyHealthRosterCrosscheck] enrich failed', {
          import_id,
          timesheet_id: tid,
          tsfin_id: fin?.id || null,
          err: e?.message || String(e)
        });
      }
    }
  }

  return { triples: triplesMap.size, timesheets_checked: timesheetsChecked };
}
async function handleTimesheetGetDailyAdjustments(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // Resolve the requested timesheet to CURRENT (rotation-safe)
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved || !resolved.current_timesheet_id) {
    return withCORS(env, req, notFound('Timesheet not found'));
  }

  const currentId = String(resolved.current_timesheet_id);

  // Load current row to see if this is already an adjustment with a parent_timesheet_id
  const cur = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentId)}` +
      `&is_current=eq.true` +
      `&select=timesheet_id,booking_id,sheet_scope,is_adjustment,parent_timesheet_id`
  );

  if (!cur) return withCORS(env, req, notFound('Timesheet not found'));

  const scope = String(cur.sheet_scope || '').toUpperCase();
  if (scope !== 'DAILY') {
    return withCORS(env, req, badRequest('This endpoint is only for DAILY timesheets'));
  }

  // If the current sheet is an adjustment, treat its parent as the root.
  // Otherwise, the current sheet is the root.
  const parentIdCandidate =
    (cur.parent_timesheet_id && String(cur.parent_timesheet_id).trim())
      ? String(cur.parent_timesheet_id)
      : currentId;

  // Resolve the parent candidate to CURRENT too (parent may have rotated)
  const resolvedParent = await resolveTimesheetToCurrent(env, parentIdCandidate);
  if (!resolvedParent || !resolvedParent.current_timesheet_id || !resolvedParent.booking_id) {
    // If parent resolution fails, fall back to the current sheet as root
    // (still better than hard failing).
    // But keep response honest.
  }

  const rootTimesheetId = String(resolvedParent?.current_timesheet_id || currentId);
  const rootBookingId   = String(resolvedParent?.booking_id || cur.booking_id || '');

  if (!rootBookingId) {
    return withCORS(env, req, serverError('Cannot resolve root booking_id for adjustment lookup'));
  }

  // Collect all root timesheet ids across rotations (same booking_id)
  const { rows: rootVersions } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?booking_id=eq.${enc(rootBookingId)}` +
      `&select=timesheet_id` +
      `&order=created_at.desc` +
      `&limit=100`
  );

  const rootIds = Array.from(new Set(
    (Array.isArray(rootVersions) ? rootVersions : [])
      .map(r => (r && r.timesheet_id) ? String(r.timesheet_id) : '')
      .filter(Boolean)
  ));

  // If for some reason we couldn't fetch versions, at least include the root id.
  if (!rootIds.length) rootIds.push(rootTimesheetId);

  // Query: all CURRENT adjustment timesheets whose parent_timesheet_id matches ANY root id
  // (covers adjustments created before parent rotated).
  const inClause = `in.(${rootIds.join(',')})`;

  const { rows: adjRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?parent_timesheet_id=${enc(inClause)}` +
      `&is_adjustment=eq.true` +
      `&is_current=eq.true` +
      `&select=timesheet_id,parent_timesheet_id,created_at` +
      `&order=created_at.desc` +
      `&limit=200`
  );

  const list = Array.isArray(adjRows) ? adjRows : [];
  const timesheet_ids = list
    .map(r => (r && r.timesheet_id) ? String(r.timesheet_id) : '')
    .filter(Boolean);

  return withCORS(env, req, ok({
    requested_timesheet_id: String(timesheetId),
    current_timesheet_id: currentId,

    root_timesheet_id: rootTimesheetId,
    root_booking_id: rootBookingId,

    count: timesheet_ids.length,
    timesheet_ids
  }));
}


// ======================= DAILY ONLY =======================
// Build TSFIN snapshot for DAILY timesheets (app/self-reported).
// Adds WRANGLER logging when: (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true)


async function buildDailySnapshot(env, ts) {
  const LOG = (typeof wranglerimportlog !== 'undefined' && wranglerimportlog === true);
  const L = (...a) => { if (LOG) console.log('[TSFIN][DAILY][buildDailySnapshot]', ...a); };

  const enc = encodeURIComponent;

  const occupantKey = ts.occupant_key_norm || null;
  const candidate   = await loadCandidate(env, occupantKey);
  const candidate_id = candidate?.id || null;
  const candidate_assignment = candidate ? "ASSIGNED" : "UNASSIGNED";

  L('START', {
    timesheet_id: ts?.timesheet_id,
    occupant_key_norm: occupantKey,
    job_title_norm: ts?.job_title_norm,
    band: ts?.band ?? null,
    hospital_norm: ts?.hospital_norm ?? null,
    candidate_id
  });

  // ✅ NEW (brief): Preserve existing TSFIN expense/mileage fields so recompute doesn't wipe them.
  // NOTE: This is safe even if no row exists yet (first compute) — preservedFin stays null.
  let preservedFin = null;
  try {
    if (ts?.timesheet_id) {
      preservedFin = await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
          `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
          `&is_current=eq.true` +
          `&select=` +
            [
              'expenses_pay_ex_vat',
              'expenses_charge_ex_vat',
              'expenses_description',
              'expenses_evidence_r2_key',
              'expenses_evidence_manifest',

              'mileage_units',
              'mileage_pay_ex_vat',
              'mileage_charge_ex_vat',
              'mileage_evidence_r2_key',
              'mileage_evidence_manifest',
              'mileage_pay_rate',
              'mileage_charge_rate'
            ].join(',')
      );
    }
  } catch {
    preservedFin = null;
  }

  // Client via alias-aware resolver
  const client_id = await resolveClientId(env, ts.hospital_norm || null);
  L('resolved client_id', { client_id });

  // Worked date in local timezone for policy & rates
  const workedDateYmd = ts.worked_start_iso
    ? toLocalParts(ts.worked_start_iso, null).ymd
    : null;

  L('workedDateYmd', { workedDateYmd, worked_start_iso: ts?.worked_start_iso, worked_end_iso: ts?.worked_end_iso });

  // TIME policy (day/night windows, BH list, holiday%, etc.)
  const policy = await loadPolicy(env, client_id, workedDateYmd);
  L('loaded policy', {
    client_id,
    workedDateYmd,
    timezone_id: policy?.timezone_id,
    day_start: policy?.day_start,
    day_end: policy?.day_end,
    night_start: policy?.night_start,
    night_end: policy?.night_end
  });

  // Build base segments from worked_start / worked_end and subtract breaks
  let segments = [];
  if (ts.worked_start_iso && ts.worked_end_iso) {
    segments.push([ts.worked_start_iso, ts.worked_end_iso]);
  }

  segments = subtractBreak(
    segments,
    ts.break_start_iso || null,
    ts.break_end_iso   || null,
    ts.break_minutes   || null
  );

  L('segments after subtractBreak', {
    segCount: Array.isArray(segments) ? segments.length : 0,
    break_minutes: ts?.break_minutes ?? null,
    break_start_iso: ts?.break_start_iso ?? null,
    break_end_iso: ts?.break_end_iso ?? null
  });

  // Classify into day/night/sat/sun/bh hours
  const hours = classifyMinutes(env, policy, segments);
  L('classified hours', hours);

  // ---------- Role + band canonicalisation (DAILY) ----------
  const norm = (s) => String(s || "").trim();
  const normRole = (s) =>
    norm(s)
      .replace(/\s+/g, " ")
      .trim()
      .toUpperCase();

  const normBand = (v) => {
    const s = norm(v);
    if (!s) return null;

    let m = s.match(/^\s*band\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*b\s*([0-9]+)\s*$/i);
    if (!m) m = s.match(/^\s*([0-9]+)\s*$/);

    if (m && m[1]) return `Band ${parseInt(m[1], 10)}`;

    return s;
  };

  const parseCandidateRoleCodes = (rolesVal) => {
    try {
      let roles = rolesVal;
      if (typeof roles === "string") {
        roles = JSON.parse(roles);
      }
      if (!Array.isArray(roles)) return [];
      return roles
        .map((r) => (r && typeof r === "object" ? r.code : r))
        .map((c) => normRole(c))
        .filter(Boolean);
    } catch {
      return [];
    }
  };

  const candidateRoleCodes = parseCandidateRoleCodes(candidate?.roles);
  L('candidate roles parsed', {
    candidate_id,
    roles_raw_type: typeof candidate?.roles,
    role_codes: candidateRoleCodes
  });

  // Timesheet-provided role/band
  const tsRoleRaw = norm(ts.job_title_norm || "");
  const tsRole    = tsRoleRaw ? normRole(tsRoleRaw) : null;
  const tsBand    = normBand(ts.band);

  L('timesheet role/band canonical', { tsRoleRaw, tsRole, tsBand });

  // Map the timesheet grade/title onto a candidate role (+ optional band hint)
  let roleForRates = null;
  let bandForRates = tsBand;

  if (candidate_id && client_id && workedDateYmd) {
    if (tsRole && candidateRoleCodes.includes(tsRole)) {
      roleForRates = tsRole;
      L('role direct match via candidate.roles', { roleForRates });
    } else {
      L('role not direct-matched; invoking mapRequestGradeToRole', {
        gradeRaw: tsRoleRaw || tsRole || null,
        candidate_roles: candidateRoleCodes,
        client_id,
        candidate_id,
        dateYmd: workedDateYmd
      });

      const mapped = await mapRequestGradeToRole(env, {
        client_id,
        candidate_id,
        gradeRaw: tsRoleRaw || tsRole || null,
        dateYmd: workedDateYmd,
        candidate_roles: candidateRoleCodes
      });

      L('mapRequestGradeToRole result', mapped || null);

      if (mapped?.role) {
        const mappedRole = normRole(mapped.role);
        const allowed = (!candidateRoleCodes.length || candidateRoleCodes.includes(mappedRole));
        L('mapped role candidate-membership check', { mappedRole, allowed });

        if (allowed) roleForRates = mappedRole;
      }

      // Only use mapped band if timesheet didn’t supply one
      if (!bandForRates && mapped?.band) {
        bandForRates = normBand(mapped.band);
        L('band inferred from grade (timesheet had no band)', { bandForRates });
      }
    }
  } else {
    roleForRates = tsRole;
    L('mapping skipped (missing candidate/client/date); using timesheet role', { roleForRates });
  }

  // Resolve rates using candidate, client, role, band, date
  L('calling resolveRates', {
    candidate_id,
    client_id,
    role: roleForRates || null,
    band: bandForRates || null,
    dateYmd: workedDateYmd
  });

  const rates = await resolveRates(env, {
    candidate_id: candidate_id,
    client_id,
    role: roleForRates || null,
    band: bandForRates || null,
    dateYmd: workedDateYmd,
  });

  L('resolveRates result', {
    source: rates?.source || null,
    hasPay: !!rates?.pay,
    hasCharge: !!rates?.charge,
    pay: rates?.pay || null,
    charge: rates?.charge || null
  });

  // Detect missing rates for any used bucket
  const missingRates = anyMissingRates(
    {
      day:   hours.hours_day,
      night: hours.hours_night,
      sat:   hours.hours_sat,
      sun:   hours.hours_sun,
      bh:    hours.hours_bh,
    },
    rates.pay,
    rates.charge
  );

  L('missingRates', { missingRates });

  // Determine pay_method for this snapshot
  const pay_method =
    candidate?.pay_method === "UMBRELLA"
      ? "UMBRELLA"
      : candidate?.pay_method === "PAYE"
      ? "PAYE"
      : ts.pay_method || null;

  L('pay_method resolved', { pay_method, cand_pay_method: candidate?.pay_method ?? null, ts_pay_method: ts?.pay_method ?? null });

  // Pay-channel state via resolveEffectivePayChannel
  let payChannelBad = false;
  try {
    if (candidate_id && client_id && typeof resolveEffectivePayChannel === 'function') {
      let umbrella = null;
      if (candidate?.umbrella_id) {
        umbrella = await sbGetOne(
          env,
          `${env.SUPABASE_URL}/rest/v1/umbrellas` +
            `?id=eq.${encodeURIComponent(candidate.umbrella_id)}` +
            `&select=id,name,bank_name,sort_code,account_number` +
            `&limit=1`
        );
      }

      const channel = resolveEffectivePayChannel({
        pay_method: pay_method || candidate?.pay_method || null,
        candidate,
        umbrella,
      });

      payChannelBad = !channel || channel.ok === false;
      L('resolveEffectivePayChannel', { ok: channel?.ok ?? null, missing: channel?.missing ?? null, payChannelBad });
    }
  } catch (e) {
    console.warn('[TSFIN][DAILY][buildDailySnapshot] resolveEffectivePayChannel failed', e);
    payChannelBad = true;
    L('resolveEffectivePayChannel error -> payChannelBad=true', { err: String(e?.message || e) });
  }

  // ✅ Contract/effective requires_hr (NOT policy.requires_hr)
  const boolish = (v) => {
    if (v === true) return true;
    if (v === false) return false;
    if (v == null) return false;
    const s = String(v).trim().toLowerCase();
    return (s === 'true' || s === '1' || s === 'yes' || s === 'y' || s === 'on');
  };

  let requiresHr = null;
  try {
    if (ts?.timesheet_id) {
      const { rows: eRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
          `?timesheet_id=eq.${encodeURIComponent(ts.timesheet_id)}` +
          `&select=client_requires_hr` +
          `&limit=1`
      );
      const eff = eRows?.[0] || null;
      if (eff && Object.prototype.hasOwnProperty.call(eff, 'client_requires_hr')) {
        requiresHr = boolish(eff.client_requires_hr);
      }
    }
  } catch {
    requiresHr = null;
  }
  if (requiresHr == null) requiresHr = !!policy?.requires_hr;

  L('requiresHr resolved', { requiresHr });

  // ── ID-first ladder + issue flags ──
  let processing_status;
  let hasRateIssue       = false;
  let hasPayChannelIssue = false;

  if (!candidate_id) {
    processing_status = "UNASSIGNED";
  } else if (!client_id) {
    processing_status = "CLIENT_UNRESOLVED";
  } else if (missingRates) {
    processing_status   = "RATE_MISSING";
    hasRateIssue        = true;
    hasPayChannelIssue  = !!payChannelBad;
  } else if (payChannelBad) {
    processing_status   = "PAY_CHANNEL_MISSING";
    hasRateIssue        = false;
    hasPayChannelIssue  = true;
  } else if (requiresHr) {
    processing_status   = "READY_FOR_HR";
    hasRateIssue        = false;
    hasPayChannelIssue  = false;
  } else {
    processing_status   = "READY_FOR_INVOICE";
    hasRateIssue        = false;
    hasPayChannelIssue  = false;
  }

  L('processing ladder result', { processing_status, hasRateIssue, hasPayChannelIssue });

  const pay = rates.pay || { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
  const charge = rates.charge || { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };

  // ✅ Base (hours-only) totals (unchanged computation)
  const base_pay_ex_vat = round2(
    hours.hours_day   * asNumberLocal(pay.day)   +
    hours.hours_night * asNumberLocal(pay.night) +
    hours.hours_sat   * asNumberLocal(pay.sat)   +
    hours.hours_sun   * asNumberLocal(pay.sun)   +
    hours.hours_bh    * asNumberLocal(pay.bh)
  );

  const base_charge_ex_vat = round2(
    hours.hours_day   * asNumberLocal(charge.day)   +
    hours.hours_night * asNumberLocal(charge.night) +
    hours.hours_sat   * asNumberLocal(charge.sat)   +
    hours.hours_sun   * asNumberLocal(charge.sun)   +
    hours.hours_bh    * asNumberLocal(charge.bh)
  );

  const base_margin_ex_vat = round2(base_charge_ex_vat - base_pay_ex_vat);

  // ✅ NEW (brief): preserved expenses/mileage are included in totals/margin
  const expPay   = round2(asNumberLocal(preservedFin?.expenses_pay_ex_vat ?? 0));
  const expChg   = round2(asNumberLocal(preservedFin?.expenses_charge_ex_vat ?? 0));
  const milPay   = round2(asNumberLocal(preservedFin?.mileage_pay_ex_vat ?? 0));
  const milChg   = round2(asNumberLocal(preservedFin?.mileage_charge_ex_vat ?? 0));
  const milUnits = round2(asNumberLocal(preservedFin?.mileage_units ?? 0));

  const total_pay_ex_vat = round2(base_pay_ex_vat + expPay + milPay);
  const total_charge_ex_vat = round2(base_charge_ex_vat + expChg + milChg);
  const margin_ex_vat = round2(total_charge_ex_vat - total_pay_ex_vat);

  L('money totals', { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat });

  const paymentReadyLite = !!(
    pay_method === "PAYE" &&
    !missingRates &&
    !payChannelBad
  );

  const pay_wtr_rate_pct_snapshot =
    paymentReadyLite
      ? (asNumberLocal(policy?.holiday_pay_pct) ?? null)
      : null;

  // ✅ Keep base_hours as hours-only, but totals reflect expenses/mileage too
  const invoice_breakdown_json = {
    mode: "AGGREGATE",
    base_hours: {
      day:   hours.hours_day,
      night: hours.hours_night,
      sat:   hours.hours_sat,
      sun:   hours.hours_sun,
      bh:    hours.hours_bh,
      pay_rates: {
        day:   rates.pay?.day   ?? null,
        night: rates.pay?.night ?? null,
        sat:   rates.pay?.sat   ?? null,
        sun:   rates.pay?.sun   ?? null,
        bh:    rates.pay?.bh    ?? null,
      },
      charge_rates: {
        day:   rates.charge?.day   ?? null,
        night: rates.charge?.night ?? null,
        sat:   rates.charge?.sat   ?? null,
        sun:   rates.charge?.sun   ?? null,
        bh:    rates.charge?.bh    ?? null,
      },
      pay_ex_vat:    base_pay_ex_vat,
      charge_ex_vat: base_charge_ex_vat,
    },
    additional: { units: {}, pay_ex_vat: 0, charge_ex_vat: 0, margin_ex_vat: 0 },
    totals: { total_pay_ex_vat, total_charge_ex_vat, margin_ex_vat },
  };

  const snapshot = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,
    basis: "SELF_REPORTED",

    occupant_key_norm: ts.occupant_key_norm || null,
    worked_start_iso: ts.worked_start_iso || null,
    worked_end_iso:   ts.worked_end_iso   || null,
    break_start_iso:  ts.break_start_iso  || null,
    break_end_iso:    ts.break_end_iso    || null,
    break_minutes:    ts.break_minutes    || null,

    candidate_id,
    client_id: client_id || null,

    // store canonical role+band used for resolution
    role: roleForRates || null,
    band: bandForRates || null,

    pay_method,

    policy_snapshot_json: policy,
    rate_source_refs_json: rates.source,

    hours_day:   hours.hours_day,
    hours_night: hours.hours_night,
    hours_sat:   hours.hours_sat,
    hours_sun:   hours.hours_sun,
    hours_bh:    hours.hours_bh,

    pay_day:      rates.pay?.day   ?? null,
    pay_night:    rates.pay?.night ?? null,
    pay_sat:      rates.pay?.sat   ?? null,
    pay_sun:      rates.pay?.sun   ?? null,
    pay_bh:       rates.pay?.bh    ?? null,
    charge_day:   rates.charge?.day   ?? null,
    charge_night: rates.charge?.night ?? null,
    charge_sat:   rates.charge?.sat   ?? null,
    charge_sun:   rates.charge?.sun   ?? null,
    charge_bh:    rates.charge?.bh    ?? null,

    total_hours: round2(
      hours.hours_day +
      hours.hours_night +
      hours.hours_sat +
      hours.hours_sun +
      hours.hours_bh
    ),

    // ✅ totals include preserved expenses/mileage
    total_pay_ex_vat,
    total_charge_ex_vat,
    margin_ex_vat,

    additional_units_json: {},
    additional_pay_ex_vat: 0,
    additional_charge_ex_vat: 0,
    additional_margin_ex_vat: 0,

    // ✅ NEW (brief): preserve expense + mileage fields in the snapshot
    expenses_pay_ex_vat: expPay,
    expenses_charge_ex_vat: expChg,
    expenses_description: preservedFin?.expenses_description ?? null,
    expenses_evidence_r2_key: preservedFin?.expenses_evidence_r2_key ?? null,
    expenses_evidence_manifest: preservedFin?.expenses_evidence_manifest ?? null,

    mileage_units: milUnits,
    mileage_pay_ex_vat: milPay,
    mileage_charge_ex_vat: milChg,
    mileage_evidence_r2_key: preservedFin?.mileage_evidence_r2_key ?? null,
    mileage_evidence_manifest: preservedFin?.mileage_evidence_manifest ?? null,
    mileage_pay_rate: preservedFin?.mileage_pay_rate ?? null,
    mileage_charge_rate: preservedFin?.mileage_charge_rate ?? null,

    pay_wtr_rate_pct_snapshot,
    candidate_assignment,
    processing_status,

    has_rate_issue:        hasRateIssue,
    has_pay_channel_issue: hasPayChannelIssue,

    invoice_breakdown_json,
  };

  L('WRITE SNAPSHOT', {
    timesheet_id: snapshot.timesheet_id,
    role: snapshot.role,
    band: snapshot.band,
    candidate_id: snapshot.candidate_id,
    client_id: snapshot.client_id,
    processing_status: snapshot.processing_status,
    source: snapshot.rate_source_refs_json
  });

  await writeSnapshot(env, snapshot);
}


// ---------------------------
// API: Manual drain
// ---------------------------
async function handleTsfinDrain(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();
  const body = await parseJSONBody(req).catch(() => null);
  const limit = Math.min(Math.max(parseInt(body?.limit || '50', 10) || 50, 1), 500);
  const res = await runTsfinWorkerOnce(env, { limit });
  return ok(res);
}

// ---------------------------
// API: Recompute (enqueue)
// ---------------------------
async function handleTsfinRecompute(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const body = await parseJSONBody(req).catch(() => null);
  const ids = Array.isArray(body?.timesheet_ids) ? body.timesheet_ids.slice(0, 200) : [];
  if (!ids.length) return badRequest('timesheet_ids array required');

  // ✅ Single RPC (batch) to avoid subrequest spikes
  await sbRpc(env, 'enqueue_ts_financials_priority', {
    _timesheet_ids: ids,
    _reason: 'MANUAL'
  });

  return ok({ enqueued: ids.length });
}

// ----------------------------------------
// GET TSFIN (include exp/mileage/PO fields)
// ----------------------------------------
// 6) GET /api/tsfin/financials (now includes mileage_units)
async function handleTsfinFinancials(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const sp = new URL(req.url).searchParams;
  const ids = splitCsv(sp.get('timesheet_ids'));

  let url = `${env.SUPABASE_URL}/rest/v1/timesheets_financials?is_current=eq.true`;
  const select = [
    '*',
    'expenses_pay_ex_vat','expenses_charge_ex_vat','expenses_description','expenses_evidence_r2_key',
    'mileage_units', // ✅ NEW
    'mileage_pay_ex_vat','mileage_charge_ex_vat','mileage_evidence_r2_key','mileage_pay_rate','mileage_charge_rate',
    'po_number',
    'candidate_id',
    'pay_method'
  ];
  url += `&select=${select.join(',')}`;
  if (ids.length) url += `&timesheet_id=in.(${ids.map(encodeURIComponent).join(',')})`;

  const { rows } = await sbFetch(env, url, false);

  const candIds = Array.from(new Set((rows || []).map((r) => r.candidate_id).filter(Boolean)));
  let candidatesById = new Map();
  let umbrellasById = new Map();

  if (candIds.length) {
    const candParam = candIds.map(encodeURIComponent).join(',');
    const { rows: candRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
      `?select=id,umbrella_id,account_holder,bank_name,sort_code,account_number` +
      `&id=in.(${candParam})`
    );
    candidatesById = new Map((candRows || []).map((c) => [c.id, c]));

    const umbIds = Array.from(new Set((candRows || [])
      .map((c) => c.umbrella_id)
      .filter(Boolean)));
    if (umbIds.length) {
      const umbParam = umbIds.map(encodeURIComponent).join(',');
      const { rows: umbRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/umbrellas` +
        `?select=id,name,bank_name,sort_code,account_number` +
        `&id=in.(${umbParam})`
      );
      umbrellasById = new Map((umbRows || []).map((u) => [u.id, u]));
    }
  }

  const items = (rows || []).map((r) => {
    const cand = candidatesById.get(r.candidate_id);
    const umb  = cand?.umbrella_id ? umbrellasById.get(cand.umbrella_id) : undefined;
    const effective_pay_channel = resolveEffectivePayChannel({
      pay_method: r.pay_method,
      candidate: cand,
      umbrella: umb
    });
    return { ...r, effective_pay_channel };
  });

  return ok({ items });
}

// ======================= DAILY ONLY =======================
// Pure compute: NO sbFetch / sbGetOne / sbRpc / fetch / writeSnapshot.
// Input:
//   - ctxRow: one row from tsfin_load_context_batch()
//   - ratesRow: one row from tsfin_resolve_rates_batch() (matching k/effective_timesheet_id)
// Output
//   - snapshot object suitable for tsfin_write_snapshots_and_complete({ snapshot: ... })

// ------------------------------------------------------
// MARK READY (validate evidence rules before promotion)
// ------------------------------------------------------
// ------------------------------------------------------
// MARK READY (validate rules before promotion; supports
// settings_defaults.hr_validation_required and
// settings_defaults.ts_reference_required)
// ------------------------------------------------------

async function handleTsfinMarkReady(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized('Unauthorized');

  const payload = await parseJSONBody(req);

  if (!payload || !Array.isArray(payload.items) || payload.items.length === 0) {
    return badRequest('items[] required (each item: { timesheet_id, expected_timesheet_id })');
  }

  // Normalise + de-dupe by expected_timesheet_id
  const seen = new Set();
  const items = [];
  for (const it of payload.items) {
    const requested = String(it?.timesheet_id || '').trim();
    const expected  = String(it?.expected_timesheet_id || '').trim();
    if (!requested || !expected) continue;
    if (seen.has(expected)) continue;
    seen.add(expected);
    items.push({ requested_timesheet_id: requested, expected_timesheet_id: expected });
  }
  if (!items.length) return badRequest('No valid items (timesheet_id + expected_timesheet_id required)');

  // Resolve requested → current and enforce expected == current
  const currentIds = [];
  for (const it of items) {
    let resolved = null;
    try { resolved = await resolveTimesheetToCurrent(env, it.requested_timesheet_id); } catch {}
    const current = resolved?.current_timesheet_id ? String(resolved.current_timesheet_id) : '';
    if (!current) return badRequest(`Timesheet not found: ${it.requested_timesheet_id}`);

    if (String(it.expected_timesheet_id) !== String(current)) {
      return new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: current }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      );
    }
    currentIds.push(current);
  }

  const ids = Array.from(new Set(currentIds)).filter(Boolean);
  if (!ids.length) return badRequest('No valid timesheet ids after resolution');

  const idsParam = ids.map(encodeURIComponent).join(',');

  // Global feature flag: ts_reference_required
  let tsRefRequired = false;
  try {
    const { rows: defRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=ts_reference_required`
    );
    if (defRows?.[0] && typeof defRows[0].ts_reference_required === 'boolean') {
      tsRefRequired = defRows[0].ts_reference_required;
    }
  } catch {}

  // Current/unlocked TSFIN snapshots we might promote
  const { rows: tsfinRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?select=timesheet_id,processing_status,candidate_id,client_id,pay_method,basis,` +
      `expenses_charge_ex_vat,expenses_evidence_r2_key,mileage_charge_ex_vat,mileage_evidence_r2_key,` +
      `hr_crosscheck_status,hr_crosscheck_issues` +
      `&timesheet_id=in.(${idsParam})` +
      `&is_current=eq.true` +
      `&locked_by_invoice_id=is.null`
  );
  const tsfinById = new Map((tsfinRows || []).map(r => [r.timesheet_id, r]));

  // Timesheet metadata (include contract_id because effective flags are contract-resolved)
  const tsMetaMap = new Map();
  {
    const { rows: tsRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?select=timesheet_id,contract_id,reference_number,authorised_at_server,submission_mode,` +
        `sheet_scope,day_references_json,actual_schedule_json,` +
        `r2_nurse_key,r2_auth_key,manual_pdf_r2_key` +
        `&timesheet_id=in.(${idsParam})`
    );
    for (const t of tsRows || []) tsMetaMap.set(t.timesheet_id, t);
  }

  // ✅ Effective flags (contract-resolved) per timesheet (single source of truth)
  const effByTsId = new Map();
  {
    const { rows: effRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary` +
        `?timesheet_id=in.(${idsParam})` +
        `&select=timesheet_id,client_requires_hr,client_autoprocess_hr,client_no_timesheet_required` +
        `&limit=10000`
    );
    for (const r of effRows || []) {
      if (r?.timesheet_id) effByTsId.set(r.timesheet_id, r);
    }
  }

  const boolish = (v) => {
    if (v === true) return true;
    if (v === false) return false;
    if (v == null) return false;
    const s = String(v).trim().toLowerCase();
    return (s === 'true' || s === '1' || s === 'yes' || s === 'y' || s === 'on');
  };

  // Determine which timesheets need HR validation
  const idsNeedingHr = ids.filter(id => {
    const eff = effByTsId.get(id);
    return eff ? boolish(eff.client_requires_hr) : false;
  });

  // Latest validation per TS (only those needing HR)
  const latestById = new Map();
  const OK = new Set(['VALIDATION_OK', 'OVERRIDDEN']);

  if (idsNeedingHr.length) {
    const valParam = idsNeedingHr.map(encodeURIComponent).join(',');
    const valUrl =
      `${env.SUPABASE_URL}/rest/v1/timesheet_validations` +
      `?select=timesheet_id,status,updated_at` +
      `&timesheet_id=in.(${valParam})` +
      `&order=timesheet_id.asc,updated_at.desc` +
      `&limit=10000`;

    const { rows: allVals } = await sbFetch(env, valUrl);
    for (const v of allVals || []) {
      if (!latestById.has(v.timesheet_id)) latestById.set(v.timesheet_id, v);
    }
  }

  // Evidence counts via timesheet_evidence
  const evidenceCountByTsId = new Map();
  try {
    const evParam = ids.map(encodeURIComponent).join(',');
    const { rows: evRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheet_evidence` +
        `?select=timesheet_id,count=id` +
        `&timesheet_id=in.(${evParam})` +
        `&group=timesheet_id`
    );
    for (const ev of evRows || []) evidenceCountByTsId.set(ev.timesheet_id, Number(ev.count) || 0);
  } catch (e) {
    console.warn('[handleTsfinMarkReady] evidence count lookup failed (non-fatal)', { err: e?.message || String(e) });
  }

  // Candidate → umbrella lookups for pay-channel gating
  const candIds = Array.from(new Set((tsfinRows || []).map(r => r.candidate_id).filter(Boolean)));
  let candidatesById = new Map();
  let umbrellasById  = new Map();

  if (candIds.length) {
    const candParam = candIds.map(encodeURIComponent).join(',');
    const { rows: candRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/candidates` +
        `?select=id,umbrella_id,account_holder,bank_name,sort_code,account_number` +
        `&id=in.(${candParam})`
    );
    candidatesById = new Map((candRows || []).map(c => [c.id, c]));

    const umbIds = Array.from(new Set((candRows || []).map(c => c.umbrella_id).filter(Boolean)));
    if (umbIds.length) {
      const umbParam = umbIds.map(encodeURIComponent).join(',');
      const { rows: umbRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/umbrellas` +
          `?select=id,name,bank_name,sort_code,account_number` +
          `&id=in.(${umbParam})`
      );
      umbrellasById = new Map((umbRows || []).map(u => [u.id, u]));
    }
  }

  const eligibleIds = [];
  const blocked = [];

  for (const id of ids) {
    const row = tsfinById.get(id);

    if (!row) { blocked.push({ id, reason: 'tsfin_missing_or_locked' }); continue; }
    if (row.processing_status !== 'READY_FOR_HR') { blocked.push({ id, reason: `bad_status_${row.processing_status}` }); continue; }

    // ✅ Effective contract-resolved flags for this timesheet
    const eff = effByTsId.get(id) || null;
    if (!eff) { blocked.push({ id, reason: 'effective_flags_missing' }); continue; }

    const requiresHr    = boolish(eff.client_requires_hr);
    const autoprocessHr = boolish(eff.client_autoprocess_hr);
    const noTsReq       = boolish(eff.client_no_timesheet_required);

    const tsMeta = tsMetaMap.get(id) || {};

    // 1) HR Validation gating
    if (requiresHr) {
      const v = latestById.get(id);
      if (!v || !OK.has(v.status)) { blocked.push({ id, reason: 'validation_not_ok' }); continue; }
    }

    // 1b) Authorisation gating when autoprocess_hr = false
    if (requiresHr && !autoprocessHr) {
      const authorised = !!tsMeta.authorised_at_server;
      if (!authorised) { blocked.push({ id, reason: 'awaiting_team_authorisation' }); continue; }
    }

    // 1c) HR cross-check gate
    if (requiresHr) {
      const hrStatus = (row.hr_crosscheck_status || '').toString().toUpperCase() || null;
      const hrIssues = Array.isArray(row.hr_crosscheck_issues) ? row.hr_crosscheck_issues : [];
      if (hrStatus && hrStatus !== 'OK') { blocked.push({ id, reason: 'hr_crosscheck_failed' }); continue; }
      if (hrIssues.includes('DUPLICATE_CONTRACTS')) { blocked.push({ id, reason: 'hr_crosscheck_failed' }); continue; }
    }

    // 1d) Timesheet required gate (no_timesheet_required=false) + evidence
    if (requiresHr && !noTsReq) {
      const subMode  = String(tsMeta.submission_mode || '').toUpperCase();

      const hasElectronic =
        subMode === 'ELECTRONIC' &&
        !!(tsMeta.r2_nurse_key && tsMeta.r2_auth_key);

      const hasManual = !!tsMeta.manual_pdf_r2_key;

      const evCount = evidenceCountByTsId.get(id) || 0;
      const hasAnyEvidence = (evCount > 0) || hasManual || hasElectronic;

      if (!hasAnyEvidence) { blocked.push({ id, reason: 'timesheet_missing' }); continue; }
    }

    // 2) Evidence rules: if charge>0 → expenses/mileage evidence required
    const expChg = Number(row.expenses_charge_ex_vat || 0);
    const milChg = Number(row.mileage_charge_ex_vat || 0);
    if (expChg > 0 && !row.expenses_evidence_r2_key) { blocked.push({ id, reason: 'expenses_evidence_missing' }); continue; }
    if (milChg > 0 && !row.mileage_evidence_r2_key) { blocked.push({ id, reason: 'mileage_evidence_missing' }); continue; }

    // 3) Pay-channel gating
    const cand = candidatesById.get(row.candidate_id);
    const umb  = cand?.umbrella_id ? umbrellasById.get(cand.umbrella_id) : undefined;
    const channel = resolveEffectivePayChannel({ pay_method: row.pay_method, candidate: cand, umbrella: umb });
    if (!channel.ok) { blocked.push({ id, reason: 'pay_channel_missing' }); continue; }

    // 4) Timesheet reference gating (if required) — schedule-aware
    if (tsRefRequired) {
      if (!timesheetHasInvoiceReference(tsMeta)) { blocked.push({ id, reason: 'reference_missing' }); continue; }
    }

    eligibleIds.push(id);
  }

  if (!eligibleIds.length) {
    return badRequest(
      'No timesheets are eligible to mark READY_FOR_INVOICE (validation/evidence/pay-channel/reference/timesheet/authorisation/HR rules failed).'
    );
  }

  const updUrl =
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?timesheet_id=in.(${eligibleIds.map(encodeURIComponent).join(',')})` +
    `&is_current=eq.true` +
    `&locked_by_invoice_id=is.null` +
    `&processing_status=eq.READY_FOR_HR`;

  const res = await fetch(updUrl, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      processing_status: 'READY_FOR_INVOICE',
      updated_at: new Date().toISOString()
    })
  });

  if (!res.ok) {
    const t = await res.text().catch(() => '');
    return serverError(`Failed to mark READY_FOR_INVOICE: ${t}`);
  }

  const promoted = await res.json().catch(() => []);
  return ok({
    promoted_count: promoted.length,
    promoted_ids: promoted.map(r => r.timesheet_id),
    blocked_ids: blocked
  });
}


// ---------------------------
// Finance Preview (replacement that uses snapshots)
// ---------------------------

// ---------------------------------------
// FINANCE PREVIEW (now adds exp/mileage)
// ---------------------------------------
// ---------------------------------------
// FINANCE PREVIEW (now adds exp/mileage)
// ---------------------------------------

async function handleFinancePreviewTsfin(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  const body = await parseJSONBody(req).catch(() => null);
  const ids = Array.isArray(body?.timesheet_ids) ? [...new Set(body.timesheet_ids)].slice(0, 200) : [];
  if (!ids.length) return badRequest('timesheet_ids array required');

  const { rows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?is_current=eq.true&timesheet_id=in.(${ids.map(encodeURIComponent).join(',')})` +
      `&select=timesheet_id,client_id,pay_method,policy_snapshot_json,pay_wtr_rate_pct_snapshot,` +
      [
        'hours_day','hours_night','hours_sat','hours_sun','hours_bh',
        'pay_day','pay_night','pay_sat','pay_sun','pay_bh',
        'charge_day','charge_night','charge_sat','charge_sun','charge_bh',
        'total_pay_ex_vat','total_charge_ex_vat','total_hours',
        'expenses_pay_ex_vat','expenses_charge_ex_vat',
        'mileage_pay_ex_vat','mileage_charge_ex_vat'
      ].join(',')
  );
  if (!rows?.length) return notFound('No current snapshots');

  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  // Anchor date for finance defaults: "rate in force when we create/amend the invoice" -> today (Europe/London)
  const todayIso = (() => {
    try {
      const s = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).format(new Date());
      const [dd, mm, yyyy] = s.split('/');
      return `${yyyy}-${mm}-${dd}`;
    } catch {
      const d = new Date();
      const y = d.getFullYear();
      const m = String(d.getMonth() + 1).padStart(2, '0');
      const day = String(d.getDate()).padStart(2, '0');
      return `${y}-${m}-${day}`;
    }
  })();

  // VAT context per client
  const clientIds = [...new Set(rows.map((r) => r.client_id).filter(Boolean))];
  const mapClientVat = {};

  // Defaults from FINANCE WINDOWS (NOT settings_defaults)
  let defaultVat = 20;
  let defaultWtr = 0;
  let defaultApplyHolidayTo = 'PAYE_ONLY';

  // Pull finance window once (VAT + WTR defaults)
  {
    try {
      const res = await fetch(
        `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
        {
          method: 'POST',
          headers: { ...sbHeaders(env), 'content-type': 'application/json' },
          body: JSON.stringify({ p_date: todayIso })
        }
      );

      const txt = await res.text().catch(() => '');
      if (res.ok) {
        const j = txt ? JSON.parse(txt) : null;
        const row = Array.isArray(j) ? j[0] : j;

        const vVat = Number(row?.vat_rate_pct);
        if (Number.isFinite(vVat)) defaultVat = vVat;

        const vWtr = Number(row?.holiday_pay_pct);
        if (Number.isFinite(vWtr)) defaultWtr = vWtr;

        const apply = String(row?.apply_holiday_to || 'PAYE_ONLY').toUpperCase();
        defaultApplyHolidayTo = apply || 'PAYE_ONLY';

        // If global window says NONE, default WTR must be 0 for fallback logic.
        if (defaultApplyHolidayTo === 'NONE') defaultWtr = 0;
      }
    } catch {
      // keep safe fallbacks
      defaultVat = 20;
      defaultWtr = 0;
      defaultApplyHolidayTo = 'PAYE_ONLY';
    }
  }

  if (clientIds.length) {
    const { rows: cRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/clients?select=id,vat_chargeable&id=in.(${clientIds.map(encodeURIComponent).join(',')})`
    );
    const vatChargeableById = Object.fromEntries((cRows || []).map((c) => [c.id, !!c.vat_chargeable]));

    // IMPORTANT: pick the client_settings VAT row IN SCOPE (as-of today) to avoid future-dated rows being applied early.
    const csUrl =
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
      `?select=client_id,vat_rate_pct,effective_from` +
      `&client_id=in.(${clientIds.map(encodeURIComponent).join(',')})` +
      `&or=(effective_from.lte.${encodeURIComponent(todayIso)},effective_from.is.null)` +
      `&order=client_id.asc,effective_from.desc.nullslast`;

    const { rows: cs } = await sbFetch(env, csUrl);

    const latestInScopeVatByClient = new Map();
    for (const r of cs || []) {
      const cid = r?.client_id;
      if (!cid) continue;
      if (latestInScopeVatByClient.has(cid)) continue; // first row per client after ordering is the in-scope "latest"
      const v = Number(r.vat_rate_pct);
      latestInScopeVatByClient.set(cid, Number.isFinite(v) ? v : defaultVat);
    }

    for (const cid of clientIds) {
      const chargeable = vatChargeableById[cid] ?? true;
      const rate = chargeable ? (latestInScopeVatByClient.get(cid) ?? defaultVat) : 0;
      mapClientVat[cid] = { vat_chargeable: chargeable, vat_rate_pct: rate };
    }
  }

  const agg = {
    total_timesheets: rows.length,
    hours: { day: 0, night: 0, sat: 0, sun: 0, bh: 0, total: 0 },
    totals: {
      pay_ex_vat: 0,
      charge_ex_vat: 0,
      expenses_charge_ex_vat: 0,
      mileage_charge_ex_vat: 0,
      subtotal_ex_vat: 0,
      vat_amount: 0,
      total_inc_vat: 0
    },
    // PAYE WTR informational split across the selection
    paye_wtr: {
      timesheets: 0,
      hours_total: 0,
      pay_inclusive_ex_vat: 0,
      basic_ex_wtr_ex_vat: 0,
      wtr_element_ex_vat: 0,
      effective_rate_pct_weighted: 0
    }
  };

  // Trackers for weighted WTR%
  let wtrWeightedNum = 0;
  let wtrWeightedDen = 0;

  for (const r of rows) {
    const h = {
      day: +r.hours_day || 0,
      night: +r.hours_night || 0,
      sat: +r.hours_sat || 0,
      sun: +r.hours_sun || 0,
      bh: +r.hours_bh || 0
    };

    // Use the TSFIN monetary totals (do not re-multiply hours×rates)
    const payTotal = Number(r.total_pay_ex_vat || 0);
    const chgTotal = Number(r.total_charge_ex_vat || 0);

    const expChg = Number(r.expenses_charge_ex_vat || 0);
    const milChg = Number(r.mileage_charge_ex_vat || 0);

    const vatCtx = mapClientVat[r.client_id] || { vat_chargeable: true, vat_rate_pct: defaultVat };
    const lineEx  = round2(chgTotal + expChg + milChg);
    const lineVat = round2(lineEx * (vatCtx.vat_rate_pct / 100));
    const lineInc = round2(lineEx + lineVat);

    agg.hours.day   += h.day;
    agg.hours.night += h.night;
    agg.hours.sat   += h.sat;
    agg.hours.sun   += h.sun;
    agg.hours.bh    += h.bh;
    agg.hours.total += (+r.total_hours || (h.day + h.night + h.sat + h.sun + h.bh));

    agg.totals.pay_ex_vat             += payTotal;
    agg.totals.charge_ex_vat          += chgTotal;
    agg.totals.expenses_charge_ex_vat += expChg;
    agg.totals.mileage_charge_ex_vat  += milChg;
    agg.totals.subtotal_ex_vat        += lineEx;
    agg.totals.vat_amount             += lineVat;
    agg.totals.total_inc_vat          += lineInc;

    // ---- PAYE WTR informational split (does not affect margin) ----
    if ((r.pay_method || '').toUpperCase() === 'PAYE') {
      // Prefer the snapshot if present; else derive from policy; else fall back to finance-window default
      let wtrPct = (r.pay_wtr_rate_pct_snapshot == null) ? null : Number(r.pay_wtr_rate_pct_snapshot);

      if (wtrPct == null || !Number.isFinite(wtrPct)) {
        const pol = r.policy_snapshot_json || {};

        let polPct = Number(pol.holiday_pay_pct ?? NaN);
        let applyTo = String(pol.apply_holiday_to || '').toUpperCase();

        if (applyTo === 'NONE') {
          wtrPct = 0;
        } else {
          // If applyTo missing/unknown, we don't block; just use pct if it exists.
          if (!Number.isFinite(polPct)) {
            // finance-window fallback (respects NONE by defaultWtr already being 0 in that case)
            wtrPct = defaultWtr;
          } else {
            wtrPct = polPct;
          }
        }
      }

      const baseExWtr = payTotal > 0 ? (payTotal / (1 + (wtrPct / 100))) : 0;
      const wtr = payTotal - baseExWtr;

      agg.paye_wtr.timesheets += 1;
      agg.paye_wtr.hours_total += (+r.total_hours || (h.day + h.night + h.sat + h.sun + h.bh));
      agg.paye_wtr.pay_inclusive_ex_vat += payTotal;
      agg.paye_wtr.basic_ex_wtr_ex_vat  += baseExWtr;
      agg.paye_wtr.wtr_element_ex_vat   += wtr;

      if (payTotal > 0 && Number.isFinite(wtrPct)) {
        wtrWeightedNum += (wtrPct * payTotal);
        wtrWeightedDen += payTotal;
      }
    }
  }

  // Final rounding
  agg.hours.day   = round2(agg.hours.day);
  agg.hours.night = round2(agg.hours.night);
  agg.hours.sat   = round2(agg.hours.sat);
  agg.hours.sun   = round2(agg.hours.sun);
  agg.hours.bh    = round2(agg.hours.bh);
  agg.hours.total = round2(agg.hours.total);

  Object.keys(agg.totals).forEach((k) => { agg.totals[k] = round2(agg.totals[k]); });

  // Round WTR aggregates and compute weighted effective WTR%
  agg.paye_wtr.pay_inclusive_ex_vat        = round2(agg.paye_wtr.pay_inclusive_ex_vat);
  agg.paye_wtr.basic_ex_wtr_ex_vat         = round2(agg.paye_wtr.basic_ex_wtr_ex_vat);
  agg.paye_wtr.wtr_element_ex_vat          = round2(agg.paye_wtr.wtr_element_ex_vat);
  agg.paye_wtr.hours_total                 = round2(agg.paye_wtr.hours_total);
  agg.paye_wtr.effective_rate_pct_weighted = round2(
    wtrWeightedDen > 0 ? (wtrWeightedNum / wtrWeightedDen) : 0
  );

  return ok(agg);
}

async function handleCreateInvoiceExpenses(env, req) {
  // EXPENSES-ONLY (and/or mileage) invoice creation, separate from HOURS.
  // Requires snapshots to be READY_FOR_INVOICE & unlocked; sums expenses/mileage parts only.
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized('Unauthorized');

  const enc = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  const body = await parseJSONBody(req).catch(() => null);
  if (!body || !Array.isArray(body.timesheet_ids) || body.timesheet_ids.length === 0) {
    return badRequest("timesheet_ids[] required");
  }

  const timesheetIds = [...new Set(body.timesheet_ids)].filter(Boolean);
  if (!timesheetIds.length) return badRequest("No valid timesheet_ids");

  const inIds = timesheetIds.map(enc).join(',');

  // Eligible snapshots (READY, unlocked) — we will only invoice expense/mileage components.
  const snapUrl =
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?select=*` +
    `&timesheet_id=in.(${inIds})` +
    `&is_current=eq.true` +
    `&locked_by_invoice_id=is.null` +
    `&processing_status=eq.READY_FOR_INVOICE`;

  const { rows: snaps } = await sbFetch(env, snapUrl);
  if (!snaps?.length) return badRequest("No eligible timesheets (need READY_FOR_INVOICE & unlocked).");

  // Filter to rows that actually have expenses or mileage to bill
  const billable = snaps.filter(s =>
    Number(s.expenses_charge_ex_vat || 0) > 0 || Number(s.mileage_charge_ex_vat || 0) > 0
  );
  if (!billable.length) return badRequest("No expenses/mileage to invoice for the given timesheets.");

  // Must be single client
  const clientIds = [...new Set(billable.map(s => s.client_id).filter(Boolean))];
  if (clientIds.length !== 1) {
    return badRequest(`Expected exactly one client across snapshots, found ${clientIds.length}.`);
  }
  const client_id = clientIds[0];

  // Client snapshot
  const { rows: cliRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/clients?select=id,name,invoice_address,primary_invoice_email,vat_chargeable,payment_terms_days&id=eq.${enc(client_id)}`
  );
  const client = cliRows?.[0] || null;
  if (!client) return badRequest("Client not found for snapshots.");

  // settings_defaults (NON-FINANCE ONLY — bank details only for invoice header)
  const { rows: defRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/settings_defaults?id=eq.1&select=bank_name,bank_sort_code,bank_account_number,vat_registration_number`
  );

  // Create header (DRAFT)
  const issuedAt = new Date().toISOString();
  const termsDays = Number(client.payment_terms_days ?? 30);
  const dueAt = new Date(Date.now() + termsDays * 86_400_000).toISOString();

  // VAT default from FINANCE WINDOWS (settings_finance_pick), anchored to invoice issue date (Europe/London)
  const issuedYmdLondon = (() => {
    try {
      const s = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).format(new Date(issuedAt));
      const [dd, mm, yyyy] = s.split('/');
      return `${yyyy}-${mm}-${dd}`;
    } catch {
      return String(issuedAt).slice(0, 10);
    }
  })();

  let defaultVat = 20;
  try {
    const res = await fetch(
      `${env.SUPABASE_URL}/rest/v1/rpc/settings_finance_pick`,
      {
        method: 'POST',
        headers: { ...sbHeaders(env), 'content-type': 'application/json' },
        body: JSON.stringify({ p_date: issuedYmdLondon || null })
      }
    );
    const txt = await res.text().catch(() => '');
    if (res.ok) {
      const j = txt ? JSON.parse(txt) : null;
      const row = Array.isArray(j) ? j[0] : j;
      const v = Number(row?.vat_rate_pct);
      if (Number.isFinite(v)) defaultVat = v;
    }
  } catch {
    defaultVat = 20;
  }

  // Client VAT override (client_settings) — must be IN SCOPE for issued date (prevents future-dated VAT applying early)
  let clientVatOverride = null;
  try {
    const csUrl =
      `${env.SUPABASE_URL}/rest/v1/client_settings` +
      `?select=client_id,vat_rate_pct,effective_from` +
      `&client_id=eq.${enc(client_id)}` +
      `&or=(effective_from.lte.${enc(issuedYmdLondon)},effective_from.is.null)` +
      `&order=effective_from.desc.nullslast&limit=1`;

    const { rows: csRows } = await sbFetch(env, csUrl);
    const cs = csRows?.[0] || null;
    if (cs && cs.vat_rate_pct != null && cs.vat_rate_pct !== '') {
      const n = Number(cs.vat_rate_pct);
      clientVatOverride = Number.isFinite(n) ? n : null;
    }
  } catch {
    clientVatOverride = null;
  }

  const vatRatePct = client.vat_chargeable === false ? 0 : Number(clientVatOverride ?? defaultVat);

  // Base TS meta
  const { rows: tsRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?select=timesheet_id,booking_id,week_ending_date,reference_number` +
      `&timesheet_id=in.(${inIds})`
  );
  const tsMetaMap = Object.fromEntries((tsRows || []).map(t => [t.timesheet_id, t]));

  // NEW: map timesheet_id -> contract_id -> labels (kept for consistency, may be used in future expense renderers)
  const { rows: wkRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?timesheet_id=in.(${inIds})&select=timesheet_id,contract_id`
  );
  const tsToContract = Object.fromEntries((wkRows || []).map(w => [w.timesheet_id, w.contract_id]).filter(([a,b]) => a && b));
  const contractIds = [...new Set(Object.values(tsToContract).filter(Boolean))];
  let mapContractLabels = {};
  if (contractIds.length) {
    const { rows: conRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts?id=in.(${contractIds.map(enc).join(',')})&select=id,bucket_labels_json`
    );
    mapContractLabels = Object.fromEntries((conRows || []).map(c => [c.id, c.bucket_labels_json || null]));
  }

  let DEFAULT_STATIONERY_KEY =
    env.INVOICE_STATIONERY_KEY || 'Assets/Stationery/Letterhead/A4/Letterhead_v1@300dpi.png';
  if (/\.pdf$/i.test(DEFAULT_STATIONERY_KEY)) {
    DEFAULT_STATIONERY_KEY = DEFAULT_STATIONERY_KEY.replace(/\.pdf$/i, '@300dpi.png');
  }
  const DEFAULT_STATIONERY_MARGINS_MM = { top: 32, right: 12, bottom: 20, left: 12 };
  const DEFAULT_HIDE_BANK_FOOTER = true;

  const header_snapshot_json = {
    client_id,
    client_name: client.name,
    client_invoice_address: client.invoice_address ?? null,
    client_primary_invoice_email: client.primary_invoice_email ?? null,
    vat_chargeable: !!client.vat_chargeable,
    applied_vat_rate_pct: vatRatePct,
    payment_terms_days: termsDays,
    issued_at_utc: issuedAt,
    due_at_utc: dueAt,
    stationery_key: DEFAULT_STATIONERY_KEY,
    stationery_margins_mm: DEFAULT_STATIONERY_MARGINS_MM,
    hide_bank_footer: DEFAULT_HIDE_BANK_FOOTER,
    bank: {
      name: defRows?.[0]?.bank_name ?? null,
      sort_code: defRows?.[0]?.bank_sort_code ?? null,
      account_number: defRows?.[0]?.bank_account_number ?? null,
    },
    vat_registration_number: defRows?.[0]?.vat_registration_number ?? null,
    meta: { source: 'TSFIN_EXPENSES', timesheet_count: billable.length }
  };

  const invIns = await fetch(`${env.SUPABASE_URL}/rest/v1/invoices`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      client_id,
      status: 'DRAFT',
      issued_at_utc: issuedAt,
      due_at_utc: dueAt,
      subtotal_ex_vat: 0,
      vat_amount: 0,
      total_inc_vat: 0,
      header_snapshot_json
    })
  });
  if (!invIns.ok) {
    const t = await invIns.text();
    return serverError(`Failed to create invoice: ${t}`);
  }
  const invoice = (await invIns.json())[0];

  // Build EXPENSES/MILEAGE lines only
  let sumEx = 0, sumVat = 0, sumInc = 0;
  const lines = [];

  for (const s of billable) {
    const tsMeta = tsMetaMap[s.timesheet_id] || {};

    // Expenses
    const expCharge = Number(s.expenses_charge_ex_vat || 0);
    if (expCharge > 0) {
      const expPay = Number(s.expenses_pay_ex_vat || 0);
      const expMargin = round2(expCharge - expPay);
      const expVat = round2(expCharge * vatRatePct / 100);
      const expInc = round2(expCharge + expVat);

      sumEx += expCharge; sumVat += expVat; sumInc += expInc;

      const expMeta = {
        line_type: 'EXPENSES',
        timesheet_id: s.timesheet_id,
        timesheet_version: s.timesheet_version,
        booking_id: tsMeta.booking_id ?? null,
        week_ending_date_local: tsMeta.week_ending_date ?? null,
        po_number: s.po_number ?? null,
        description: s.expenses_description ?? null,
        evidence_r2_key: s.expenses_evidence_r2_key ?? null,
        totals: {
          pay_ex_vat: expPay,
          charge_ex_vat: expCharge,
          margin_ex_vat: expMargin,
          vat_rate_pct: vatRatePct,
          vat_amount: expVat,
          total_inc_vat: expInc
        }
      };

      lines.push({
        invoice_id: invoice.id,
        timesheet_id: s.timesheet_id,
        booking_id: tsMeta.booking_id ?? null,
        description: `Expenses – ${s.expenses_description || 'Receipted'}`,
        hours_day: 0, hours_night: 0, hours_sat: 0, hours_sun: 0, hours_bh: 0,
        pay_day: null, pay_night: null, pay_sat: null, pay_sun: null, pay_bh: null,
        charge_day: null, charge_night: null, charge_sat: null, charge_sun: null, charge_bh: null,
        total_pay_ex_vat: expPay,
        total_charge_ex_vat: expCharge,
        margin_ex_vat: expMargin,
        vat_rate_pct: vatRatePct,
        vat_amount: expVat,
        total_inc_vat: expInc,
        meta_json: expMeta
      });
    }

    // Mileage
    const milCharge = Number(s.mileage_charge_ex_vat || 0);
    if (milCharge > 0) {
      const milPay = Number(s.mileage_pay_ex_vat || 0);
      const milMargin = round2(milCharge - milPay);
      const milVat = round2(milCharge * vatRatePct / 100);
      const milInc = round2(milCharge + milVat);

      sumEx += milCharge; sumVat += milVat; sumInc += milInc;

      const milMeta = {
        line_type: 'MILEAGE',
        timesheet_id: s.timesheet_id,
        timesheet_version: s.timesheet_version,
        booking_id: tsMeta.booking_id ?? null,
        week_ending_date_local: tsMeta.week_ending_date ?? null,
        po_number: s.po_number ?? null,
        evidence_r2_key: s.mileage_evidence_r2_key ?? null,
        pay_rate: s.mileage_pay_rate ?? null,
        charge_rate: s.mileage_charge_rate ?? null,
        totals: {
          pay_ex_vat: milPay,
          charge_ex_vat: milCharge,
          margin_ex_vat: milMargin,
          vat_rate_pct: vatRatePct,
          vat_amount: milVat,
          total_inc_vat: milInc
        }
      };

      lines.push({
        invoice_id: invoice.id,
        timesheet_id: s.timesheet_id,
        booking_id: tsMeta.booking_id ?? null,
        description: `Mileage – Receipted`,
        hours_day: 0, hours_night: 0, hours_sat: 0, hours_sun: 0, hours_bh: 0,
        pay_day: null, pay_night: null, pay_sat: null, pay_sun: null, pay_bh: null,
        charge_day: null, charge_night: null, charge_sat: null, charge_sun: null, charge_bh: null,
        total_pay_ex_vat: milPay,
        total_charge_ex_vat: milCharge,
        margin_ex_vat: milMargin,
        vat_rate_pct: vatRatePct,
        vat_amount: milVat,
        total_inc_vat: milInc,
        meta_json: milMeta
      });
    }
  }

  // Persist lines
  if (lines.length) {
    const resLines = await fetch(`${env.SUPABASE_URL}/rest/v1/invoice_lines`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify(lines)
    });
    if (!resLines.ok) {
      const t = await resLines.text();
      return serverError(`Failed to insert invoice_lines: ${t}`);
    }
  }

  // Update totals
  const updInv = await fetch(`${env.SUPABASE_URL}/rest/v1/invoices?id=eq.${enc(invoice.id)}`, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      subtotal_ex_vat: round2(sumEx),
      vat_amount: round2(sumVat),
      total_inc_vat: round2(sumInc),
      updated_at: new Date().toISOString()
    })
  });
  if (!updInv.ok) {
    const t = await updInv.text();
    return serverError(`Failed to update invoice totals: ${t}`);
  }

  // Lock the snapshots we used (billable only)
  const billableIds = [...new Set(billable.map(s => s.timesheet_id).filter(Boolean).map(String))];
  const billableParam = billableIds.map(enc).join(',');

  const lockUrl =
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
    `?timesheet_id=in.(${billableParam})` +
    `&is_current=eq.true` +
    `&locked_by_invoice_id=is.null` +
    `&processing_status=eq.READY_FOR_INVOICE`;

  const lockRes = await fetch(lockUrl, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
    body: JSON.stringify({ locked_by_invoice_id: invoice.id, locked_at_utc: new Date().toISOString() })
  });
  if (!lockRes.ok) {
    const t = await lockRes.text();
    return serverError(`Failed to lock snapshots: ${t}`);
  }

  // Mark linked weeks as INVOICED
  const usedTsIds = [...new Set(lines.map(l => l.timesheet_id).filter(Boolean))];
  await setWeeksInvoicedForTimesheets(env, usedTsIds);

  // Ensure TS PDFs & write keys back to lines (consistent with HOURS flow)
  const concurrency = Math.max(1, Number(env.TIMESHEET_RENDER_CONCURRENCY || 4));
  async function mapWithLimit(arr, limit, iterator) {
    let idx = 0;
    const results = new Array(arr.length);
    const workers = Array.from({ length: Math.min(limit, arr.length) }, async () => {
      while (true) {
        const current = idx++;
        if (current >= arr.length) break;
        results[current] = await iterator(arr[current], current);
      }
    });
    await Promise.all(workers);
    return results;
  }
  await mapWithLimit(usedTsIds, concurrency, async (tsId) => {
    const key = await ensureTimesheetPdf(env, tsId);
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/invoice_lines?invoice_id=eq.${enc(invoice.id)}&timesheet_id=eq.${enc(tsId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
        body: JSON.stringify({ paper_ts_r2_key: key })
      }
    );
    return key;
  });

  return ok({
    invoice_id: invoice.id,
    client_id,
    lines: lines.length,
    totals: { ex_vat: round2(sumEx), vat: round2(sumVat), inc_vat: round2(sumInc) }
  });
}

// 10) POST /api/contract-weeks/:id/additional
// Creates an ADDITIONAL contract_week row (is_adjustment=true, submission_mode_snapshot='MANUAL')
// AND immediately creates a real MANUAL WEEKLY timesheet (line_type='HOURS') with an empty schedule,
// plus an initial TSFIN snapshot (zero hours; ready for expenses patching).
async function handleContractWeekCreateAdditionalWeeklyAdjustment(env, req, weekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  // Load base week
  const base = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=*`
  );
  if (!base) return withCORS(env, req, notFound('Week not found'));

  // Load contract (needed for timesheet creation)
  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(base.contract_id)}&select=*`
  );
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  // Determine next additional_seq for this contract+week_ending_date
  const { rows: siblings } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(base.contract_id)}` +
      `&week_ending_date=eq.${enc(base.week_ending_date)}` +
      `&select=additional_seq` +
      `&order=additional_seq.desc&limit=1`
  );
  const nextSeq = ((siblings && siblings[0] && Number(siblings[0].additional_seq)) || 0) + 1;

  const now = nowIso();

  // 1) Create the additional contract_week row (MANUAL + adjustment)
  const cwIns = await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify({
      contract_id: base.contract_id,
      week_ending_date: base.week_ending_date,
      additional_seq: nextSeq,

      is_adjustment: true,
      submission_mode_snapshot: 'MANUAL',

      status: 'SUBMITTED',

      created_at: now,
      updated_at: now,
    })
  });

  if (!cwIns.ok) return withCORS(env, req, serverError(await cwIns.text()));
  const newWeek = (await cwIns.json().catch(() => []))[0] || null;
  if (!newWeek?.id) return withCORS(env, req, serverError('Failed to create additional week'));

  // 2) Create the real WEEKLY MANUAL HOURS timesheet immediately (empty schedule allowed)
  const candidate = contract.candidate_id
    ? await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(contract.candidate_id)}&select=id,display_name,mileage_pay_rate`
      )
    : null;

  const client = contract.client_id
    ? await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${enc(contract.client_id)}&select=id,name,mileage_charge_rate`
      )
    : null;

  const booking_id = await makeWeeklyBookingId(contract?.candidate_id || null, contract, newWeek);

  const occupant_norm = (candidate?.display_name || String(candidate?.id || 'worker')).toLowerCase();
  const hospital_norm = (contract.display_site || client?.name || String(contract.client_id)).toLowerCase();
  const ward_norm     = (contract.ward_hint || 'contract').toLowerCase();
  const job_title_norm= (contract.role || 'weekly').toLowerCase();

  const tsPayload = [{
    booking_id,
    version: 1,
    is_current: true,
    status: 'RECEIVED',

    occupant_key_norm: occupant_norm,
    hospital_norm,
    ward_norm,
    job_title_norm,

    shift_label_norm: `weekly-additional-${nextSeq}`,

    week_ending_date: newWeek.week_ending_date,
    contract_id: contract.id,

    // ✅ REMOVED: contract_week_id (column does not exist in timesheets)
    // Link is via contract_weeks.timesheet_id patch below.

    submission_mode: 'MANUAL',
    sheet_scope: 'WEEKLY',

    manual_pdf_r2_key: null,
    line_type: 'HOURS',
    actual_schedule_json: [],

    additional_units_week: {},
    additional_units_per_day: {},

    day_references_json: null,

    is_adjustment: true,

    created_at: now,
    updated_at: now
  }];

  const tsIns = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(tsPayload)
  });
  if (!tsIns.ok) return withCORS(env, req, serverError(await tsIns.text()));
  const ts = (await tsIns.json().catch(() => []))[0] || null;
  if (!ts?.timesheet_id) return withCORS(env, req, serverError('Failed to create additional timesheet'));

  // 3) Link contract_week -> timesheet
  await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(newWeek.id)}`, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), 'Prefer': 'return=minimal' },
    body: JSON.stringify({
      timesheet_id: ts.timesheet_id,
      status: 'SUBMITTED',
      updated_at: nowIso()
    })
  }).catch(() => {});

  // 4) Create initial TSFIN snapshot (zero hours; ready for expenses/mileage patching)
  const toNumPos = (v) => {
    if (v === '' || v === null || v === undefined) return null;
    const n = Number(v);
    return (Number.isFinite(n) && n > 0) ? n : null;
  };

  let fin = null;
  try {
    const fwRows = await sbRpc(env, 'settings_finance_pick', { p_date: newWeek?.week_ending_date || null });
    const fw = Array.isArray(fwRows) ? fwRows[0] : fwRows;
    fin = (fw && typeof fw === 'object') ? fw : null;
  } catch {
    fin = null;
  }

  const contractMileagePay    = toNumPos(contract?.mileage_pay_rate);
  const contractMileageCharge = toNumPos(contract?.mileage_charge_rate);

  const finMileagePay    = toNumPos(fin?.mileage_pay_defaults);
  const finMileageCharge = toNumPos(fin?.mileage_charge_defaults);

  const candMileagePay   = toNumPos(candidate?.mileage_pay_rate);
  const clientMileageChg = toNumPos(client?.mileage_charge_rate);

  const mileage_pay_rate =
    contractMileagePay ?? finMileagePay ?? candMileagePay ?? null;

  const mileage_charge_rate =
    contractMileageCharge ?? finMileageCharge ?? clientMileageChg ?? null;

  const mileage_rate_source =
    (contractMileagePay != null || contractMileageCharge != null) ? 'CONTRACT'
      : (finMileagePay != null || finMileageCharge != null) ? 'FINANCE_WINDOW_DEFAULT'
      : (candMileagePay != null || clientMileageChg != null) ? 'CANDIDATE_CLIENT'
      : null;

  const snap = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,
    basis: 'CONTRACT_WEEKLY',

    candidate_id: contract.candidate_id || null,
    client_id: contract.client_id || null,
    role: contract.role || null,
    band: contract.band || null,

    candidate_assignment: (contract.candidate_id ? 'ASSIGNED' : 'UNASSIGNED'),
    processing_status: 'PENDING_AUTH',

    pay_method: contract.pay_method_snapshot || null,

    policy_snapshot_json: {},
    rate_source_refs_json: {
      mode: 'CONTRACT_RATES_JSON',
      contract_id: contract.id || null,
      mileage_rate_source
    },

    hours_day: 0, hours_night: 0, hours_sat: 0, hours_sun: 0, hours_bh: 0,
    total_hours: 0,

    pay_day: null, pay_night: null, pay_sat: null, pay_sun: null, pay_bh: null,
    charge_day: null, charge_night: null, charge_sat: null, charge_sun: null, charge_bh: null,

    additional_units_json: {},
    additional_pay_ex_vat: 0,
    additional_charge_ex_vat: 0,
    additional_margin_ex_vat: 0,

    expenses_pay_ex_vat: 0,
    expenses_charge_ex_vat: 0,
    expenses_description: null,
    expenses_evidence_r2_key: null,
    expenses_evidence_manifest: null,

    mileage_units: 0,
    mileage_pay_ex_vat: 0,
    mileage_charge_ex_vat: 0,

    mileage_pay_rate,
    mileage_charge_rate,

    mileage_evidence_r2_key: null,
    mileage_evidence_manifest: null,

    total_pay_ex_vat: 0,
    total_charge_ex_vat: 0,
    margin_ex_vat: 0,

    invoice_breakdown_json: {
      mode: 'SEGMENTS',
      segments: [],
      additional: { units: {}, pay_ex_vat: 0, charge_ex_vat: 0, margin_ex_vat: 0 },
      totals: { total_pay_ex_vat: 0, total_charge_ex_vat: 0, margin_ex_vat: 0 }
    },

    created_at: nowIso(),
  };

  await writeSnapshot(env, snap);

  return withCORS(env, req, ok({
    contract_week: { ...newWeek, timesheet_id: ts.timesheet_id },
    contract_week_id: newWeek.id,
    timesheet_id: ts.timesheet_id
  }));
}
async function handleContractsCount(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const url = new URL(req.url);
  const q = (k) => url.searchParams.get(k);

  // Build filters object matching contract_list_count RPC keys
  const filters = {};

  // ids support (Focus presets): accept ids=uuid,uuid OR id=in.(...)
  const idExpr = q('id');
  const idsRaw = q('ids');

  const ids = [];
  if (idExpr && /^in\.\(.+\)$/.test(idExpr.trim())) {
    const inner = idExpr.trim().slice(4, -1); // drop "in.(" and ")"
    inner.split(',').map(s => s.trim()).filter(Boolean).forEach(x => ids.push(x));
  } else if (idsRaw) {
    idsRaw.split(',').map(s => s.trim()).filter(Boolean).forEach(x => ids.push(x));
  }
  if (ids.length) filters.ids = ids;

  const pass = (k) => {
    const v = q(k);
    if (v != null && String(v).trim() !== '') filters[k] = v;
  };

  pass('candidate_id');
  pass('client_id');
  pass('pay_method_snapshot');
  pass('role');
  pass('band');
  pass('candidate_name');
  pass('client_name');
  pass('active_on');
  pass('auto_invoice');
  pass('q');
  pass('default_submission_mode');
  pass('submission_mode');
  pass('week_ending_weekday_snapshot');
  pass('require_reference_to_pay');
  pass('require_reference_to_invoice');
  pass('has_custom_labels');
  pass('created_from');
  pass('created_to');
  pass('updated_from');
  pass('updated_to');
  pass('start_date_from');
  pass('start_date_to');
  pass('end_date_from');
  pass('end_date_to');
  pass('mileage_pay_rate');
  pass('mileage_charge_rate');
  pass('status');

  try {
    const res = await sbRpc(env, 'contract_list_count', { p_filters: filters });
    const rows = Array.isArray(res) ? res : (res?.data || []);
    const row0 = (rows && rows.length) ? rows[0] : null;
    const count = Number(row0?.count_all || 0);
    return withCORS(env, req, ok({ count }));
  } catch (e) {
    return withCORS(env, req, serverError(String(e?.message || e)));
  }
}


async function handleTimesheetCreateAdditionalDailyManual(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const enc = encodeURIComponent;

  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // Load the ORIGINAL timesheet (must be DAILY). Use the CURRENT version for context.
  const orig = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(timesheetId)}` +
      `&is_current=eq.true` +
      `&select=*`
  );
  if (!orig) return withCORS(env, req, notFound('Timesheet not found'));

  const scope = String(orig.sheet_scope || '').toUpperCase();
  if (scope !== 'DAILY') {
    return withCORS(env, req, badRequest('Timesheet is not DAILY; additional daily manual only applies to DAILY sheets'));
  }

  // ✅ NEW: parent linkage for adjustments (stable relationship to the original timesheet id)
  const parent_timesheet_id = String(orig.timesheet_id || timesheetId || '').trim() || null;

  // Load original TSFIN snapshot (best-effort) to preserve policy/rates context
  let origFin = null;
  try {
    origFin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(orig.timesheet_id)}` +
        `&is_current=eq.true` +
        `&select=*`
    );
  } catch {
    origFin = null;
  }

  // Determine date_of_shift (YYYY-MM-DD) for booking hash
  const toYmdFromIso = (iso) => {
    if (!iso) return null;
    try {
      if (typeof toLocalParts === 'function') {
        const p = toLocalParts(iso, null);
        return p?.ymd || null;
      }
    } catch {}
    // Fallback: take first 10 chars if already "YYYY-MM-DD..."
    const s = String(iso || '');
    const ymd = s.slice(0, 10);
    return /^\d{4}-\d{2}-\d{2}$/.test(ymd) ? ymd : null;
  };

  const dateOfShiftYmd =
    toYmdFromIso(orig.scheduled_start_iso) ||
    toYmdFromIso(orig.worked_start_iso) ||
    null;

  if (!dateOfShiftYmd) {
    return withCORS(env, req, badRequest('Cannot infer shift date for additional daily adjustment timesheet'));
  }

  // Unique shift label (UUID-based, per your decision)
  const uuid = (() => {
    try {
      if (typeof crypto !== 'undefined' && typeof crypto.randomUUID === 'function') return crypto.randomUUID();
    } catch {}
    // fallback (should not be needed in Workers, but avoids hard failure)
    return `${Date.now()}-${Math.random().toString(16).slice(2)}`;
  })();

  const shiftLabel = `daily-adjustment-${uuid}`;

  // booking_id must be unique per adjustment (shift_label participates in the hash)
  const booking_id = await makeBookingId(
    orig.occupant_key_norm || null,   // candidate_id input (stable key; may be CID... string)
    dateOfShiftYmd,
    orig.hospital_norm || null,
    orig.ward_norm || null,
    orig.job_title_norm || null,
    shiftLabel
  );

  const now = nowIso();

  // Create the new DAILY MANUAL adjustment timesheet
  // - preserve context fields (occupant/client hints/scheduled) but keep worked/break blank
  // - make it clearly distinguishable via shift_label_norm + is_adjustment
  const tsInsert = [{
    booking_id,
    version: 1,
    is_current: true,

    // Status for a newly created admin/manual sheet
    status: 'RECEIVED',

    occupant_key_norm: orig.occupant_key_norm || null,
    hospital_norm: orig.hospital_norm || null,
    ward_norm: orig.ward_norm || null,
    job_title_norm: orig.job_title_norm || null,

    // label shown in UI; keep it distinct
    shift_label_norm: String(shiftLabel).toLowerCase(),

    // Keep scheduled context (helps display the correct shift date/period)
    scheduled_start_iso: orig.scheduled_start_iso || null,
    scheduled_end_iso: orig.scheduled_end_iso || null,

    // ✅ REQUIRED BY BRIEF: blank worked/break fields (no hours)
    worked_start_iso: null,
    worked_end_iso: null,
    break_start_iso: null,
    break_end_iso: null,
    break_minutes: null,
    worked_minutes: null,

    // Keep week context
    week_ending_date: orig.week_ending_date || null,

    // Copy optional descriptive fields (safe; helps UI + troubleshooting)
    band: orig.band ?? null,
    candidate_hint_text: orig.candidate_hint_text ?? null,

    // Daily timesheets are not contract-driven (copy if present)
    contract_id: orig.contract_id || null,

    // ✅ REQUIRED BY BRIEF
    submission_mode: 'MANUAL',
    sheet_scope: 'DAILY',
    line_type: 'HOURS',
    is_adjustment: true,

    // ✅ NEW: parent linkage
    parent_timesheet_id,

    // No signatures/evidence on creation
    authorised_at_server: null,
    r2_nurse_key: null,
    r2_auth_key: null,
    img_sha256_nurse: null,
    img_sha256_auth: null,

    // No manual PDF yet
    manual_pdf_r2_key: null,
    manual_pdf_rotation_degrees: 0,

    // No QR state on manual adjustment by default
    qr_token: null,
    qr_status: null,
    qr_payload_json: {},
    qr_generated_at: null,
    qr_scanned_at: null,
    qr_scan_info_json: null,
    qr_r2_key: null,
    qr_last_sent_hash: null,
    qr_last_sent_at_utc: null,
    qr_signed_hash: null,
    qr_signed_at_utc: null,

    // No day references (daily has schedule_json/ISO fields)
    day_references_json: null,
    actual_schedule_json: null,

    // additional units not used on DAILY; keep empty for safety
    additional_units_week: {},
    additional_units_per_day: {},

    // Give a fresh idempotency key
    idempotency_key: uuid,

    created_at: now,
    updated_at: now
  }];

  const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
    method: 'POST',
    headers: { ...sbHeaders(env), 'Prefer': 'return=representation' },
    body: JSON.stringify(tsInsert)
  });

  if (!ins.ok) return withCORS(env, req, serverError(await ins.text()));
  const createdTs = (await ins.json().catch(() => []))[0] || null;
  if (!createdTs?.timesheet_id) return withCORS(env, req, serverError('Failed to create additional daily timesheet'));

  // ─────────────────────────────────────────────────────────────
  // Create initial TSFIN snapshot (0 hours, preserve policy/rates context)
  // ✅ UPDATED: initialise mileage rates with contract-first then (origFin if present) then finance-window defaults then candidate/client fallback
  // ─────────────────────────────────────────────────────────────
  const parseMaybeJson = (v) => {
    if (v == null) return null;
    if (typeof v === 'object') return v;
    if (typeof v === 'string') {
      try { return JSON.parse(v); } catch { return null; }
    }
    return null;
  };

  const toNumPos = (v) => {
    if (v === '' || v === null || v === undefined) return null;
    const n = Number(v);
    return (Number.isFinite(n) && n > 0) ? n : null;
  };

  const policySnap = parseMaybeJson(origFin?.policy_snapshot_json) || {};
  const rateRefs   = parseMaybeJson(origFin?.rate_source_refs_json) || {};

  const payMethod = (origFin?.pay_method != null)
    ? origFin.pay_method
    : (orig?.pay_method || null);

  const roleForSnap =
    (origFin?.role != null) ? origFin.role :
    (orig?.job_title_norm != null ? String(orig.job_title_norm) : null);

  const bandForSnap =
    (origFin?.band != null) ? origFin.band :
    (orig?.band ?? null);

  const candidateIdForSnap =
    (origFin?.candidate_id != null) ? origFin.candidate_id :
    (orig?.candidate_id ?? null);

  const clientIdForSnap =
    (origFin?.client_id != null) ? origFin.client_id :
    (orig?.client_id ?? null);

  const candidateAssignment =
    candidateIdForSnap ? 'ASSIGNED' : 'UNASSIGNED';

  // Best-effort: load contract for contract-first mileage rates (if contract_id exists)
  let contract = null;
  try {
    const cid = createdTs?.contract_id || orig?.contract_id || null;
    if (cid) {
      contract = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(cid)}&select=id,mileage_pay_rate,mileage_charge_rate`);
    }
  } catch {
    contract = null;
  }

  // Finance window defaults for the shift date (date-linked)
  let fin = null;
  try {
    const fwRows = await sbRpc(env, 'settings_finance_pick', { p_date: dateOfShiftYmd || null });
    const fw = Array.isArray(fwRows) ? fwRows[0] : fwRows;
    fin = (fw && typeof fw === 'object') ? fw : null;
  } catch {
    fin = null;
  }

  // Candidate/client fallback (pay from candidate, charge from client)
  let candRow = null;
  let clientRow = null;
  try {
    if (candidateIdForSnap) {
      candRow = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(candidateIdForSnap)}&select=id,mileage_pay_rate`);
    }
  } catch { candRow = null; }

  try {
    if (clientIdForSnap) {
      clientRow = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${enc(clientIdForSnap)}&select=id,mileage_charge_rate`);
    }
  } catch { clientRow = null; }

  const contractMileagePay    = toNumPos(contract?.mileage_pay_rate);
  const contractMileageCharge = toNumPos(contract?.mileage_charge_rate);

  const origMileagePay    = toNumPos(origFin?.mileage_pay_rate);
  const origMileageCharge = toNumPos(origFin?.mileage_charge_rate);

  const finMileagePay    = toNumPos(fin?.mileage_pay_defaults);
  const finMileageCharge = toNumPos(fin?.mileage_charge_defaults);

  const candMileagePay   = toNumPos(candRow?.mileage_pay_rate);
  const clientMileageChg = toNumPos(clientRow?.mileage_charge_rate);

  const mileage_pay_rate =
    contractMileagePay ?? origMileagePay ?? finMileagePay ?? candMileagePay ?? null;

  const mileage_charge_rate =
    contractMileageCharge ?? origMileageCharge ?? finMileageCharge ?? clientMileageChg ?? null;

  const mileage_rate_source =
    (contractMileagePay != null || contractMileageCharge != null) ? 'CONTRACT'
      : (origMileagePay != null || origMileageCharge != null) ? 'ORIG_TSFIN'
      : (finMileagePay != null || finMileageCharge != null) ? 'FINANCE_WINDOW_DEFAULT'
      : (candMileagePay != null || clientMileageChg != null) ? 'CANDIDATE_CLIENT'
      : null;

  const snap = {
    timesheet_id: createdTs.timesheet_id,
    timesheet_version: createdTs.version || 1,
    basis: (origFin?.basis || 'SELF_REPORTED'),

    occupant_key_norm: createdTs.occupant_key_norm || null,
    worked_start_iso: null,
    worked_end_iso: null,
    break_start_iso: null,
    break_end_iso: null,
    break_minutes: null,

    candidate_id: candidateIdForSnap,
    client_id: clientIdForSnap,

    role: roleForSnap || null,
    band: bandForSnap || null,

    pay_method: payMethod,

    // ✅ preserve policy + rates context (never null)
    policy_snapshot_json: policySnap,
    rate_source_refs_json: {
      ...(rateRefs && typeof rateRefs === 'object' ? rateRefs : {}),
      mileage_rate_source
    },

    // zero hours
    hours_day: 0,
    hours_night: 0,
    hours_sat: 0,
    hours_sun: 0,
    hours_bh: 0,

    pay_day:   origFin?.pay_day   ?? null,
    pay_night: origFin?.pay_night ?? null,
    pay_sat:   origFin?.pay_sat   ?? null,
    pay_sun:   origFin?.pay_sun   ?? null,
    pay_bh:    origFin?.pay_bh    ?? null,

    charge_day:   origFin?.charge_day   ?? null,
    charge_night: origFin?.charge_night ?? null,
    charge_sat:   origFin?.charge_sat   ?? null,
    charge_sun:   origFin?.charge_sun   ?? null,
    charge_bh:    origFin?.charge_bh    ?? null,

    total_hours: 0,
    total_pay_ex_vat: 0,
    total_charge_ex_vat: 0,
    margin_ex_vat: 0,

    additional_units_json: {},
    additional_pay_ex_vat: 0,
    additional_charge_ex_vat: 0,
    additional_margin_ex_vat: 0,

    // start empty; FE patches these via /tsfin/expenses and /tsfin/mileage
    expenses_pay_ex_vat: 0,
    expenses_charge_ex_vat: 0,
    expenses_description: null,
    expenses_evidence_r2_key: null,
    expenses_evidence_manifest: null,

    mileage_units: 0,
    mileage_pay_ex_vat: 0,
    mileage_charge_ex_vat: 0,

    // ✅ UPDATED: initialise rates
    mileage_pay_rate,
    mileage_charge_rate,

    mileage_evidence_r2_key: null,
    mileage_evidence_manifest: null,

    candidate_assignment: candidateAssignment,

    // New adjustment sheet starts unauthorised
    processing_status: 'PENDING_AUTH',

    has_rate_issue: false,
    has_pay_channel_issue: false,

    invoice_breakdown_json: {
      mode: 'AGGREGATE',
      base_hours: {
        day: 0, night: 0, sat: 0, sun: 0, bh: 0,
        pay_rates: {
          day:   origFin?.pay_day   ?? null,
          night: origFin?.pay_night ?? null,
          sat:   origFin?.pay_sat   ?? null,
          sun:   origFin?.pay_sun   ?? null,
          bh:    origFin?.pay_bh    ?? null
        },
        charge_rates: {
          day:   origFin?.charge_day   ?? null,
          night: origFin?.charge_night ?? null,
          sat:   origFin?.charge_sat   ?? null,
          sun:   origFin?.charge_sun   ?? null,
          bh:    origFin?.charge_bh    ?? null
        },
        pay_ex_vat: 0,
        charge_ex_vat: 0
      },
      additional: { units: {}, pay_ex_vat: 0, charge_ex_vat: 0, margin_ex_vat: 0 },
      totals: { total_pay_ex_vat: 0, total_charge_ex_vat: 0, margin_ex_vat: 0 }
    }
  };

  await writeSnapshot(env, snap);

  return withCORS(env, req, ok({
    timesheet_id: createdTs.timesheet_id,
    parent_timesheet_id
  }));
}



// ---------------------------
// Invoices (TSFIN) – create from READY_FOR_INVOICE snapshots, lock them, build invoice_lines
// ---------------------------

// REPLACE your handleCreateInvoiceTsfin with this
// -----------------------------
// CREATE INVOICE (TSFIN → INV)
// -----------------------------
// -----------------------------
// CREATE INVOICE (TSFIN → INV)
// -----------------------------
// === AMENDMENT inside broker/src/index.js ===
// Keep your existing handleCreateInvoiceTsfin; replace it fully with this version
// -----------------------------
// CREATE INVOICE (TSFIN → INV)
// Adds ts reference number into meta for hours lines
// -----------------------------

// Helper: mark linked weeks as INVOICED (used by both HOURS + EXPENSES creators)




async function handleContractsPlanRanges(env, req, contractId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const ranges = Array.isArray(body?.ranges) ? body.ranges : [];
  const extendWindow = body?.extend_contract_window === true;
  if (!ranges.length) return withCORS(env, req, badRequest('ranges[] is required'));

  const c = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=id,candidate_id,client_id,start_date,end_date,default_submission_mode,week_ending_weekday_snapshot,std_schedule_json`
  );
  if (!c) return withCORS(env, req, badRequest('Contract not found'));

  if (extendWindow) {
    const unionStart = ranges.reduce((m,r)=> Math.min(m, Date.parse(toYmd(r.from||r.From||r.start))), Infinity);
    const unionEnd   = ranges.reduce((m,r)=> Math.max(m, Date.parse(toYmd(r.to||r.To||r.end))),   -Infinity);
    if (isFinite(unionStart) && isFinite(unionEnd)) {
      const reqStart = toYmd(new Date(unionStart));
      const reqEnd   = toYmd(new Date(unionEnd));

      let minWE = null, maxWE = null;
      try {
        const { rows: minRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?contract_id=eq.${enc(c.id)}&timesheet_id=not.is.null&select=week_ending_date` +
          `&order=week_ending_date.asc&limit=1`
        );
        minWE = (minRows && minRows[0] && minRows[0].week_ending_date) || null;

        const { rows: maxRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?contract_id=eq.${enc(c.id)}&timesheet_id=not.is.null&select=week_ending_date` +
          `&order=week_ending_date.desc&limit=1`
        );
        maxWE = (maxRows && maxRows[0] && maxRows[0].week_ending_date) || null;
      } catch {}

      let newStart = c.start_date;
      let newEnd   = c.end_date;
      if (reqStart < c.start_date) newStart = reqStart;
      if (reqEnd   > c.end_date)   newEnd   = reqEnd;

      if (minWE) {
        const minWeekStart = addDays(minWE, -6);
        if (newStart > minWeekStart) newStart = minWeekStart;
      }
      if (maxWE) {
        if (newEnd < maxWE) newEnd = maxWE;
      }

      if (newStart !== c.start_date || newEnd !== c.end_date) {
        const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(c.id)}`, {
          method: 'PATCH',
          headers: { ...sbHeaders(env), 'Prefer':'return=representation' },
          body: JSON.stringify({ start_date: newStart, end_date: newEnd, updated_at: nowIso() })
        });
        if (!res.ok) return withCORS(env, req, serverError(await res.text()));
        const upd = (await res.json().catch(()=>[]))[0] || c;
        c.start_date = upd.start_date; c.end_date = upd.end_date;

        const delRes = await fetch(
          `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(c.id)}&timesheet_id=is.null&or=(week_ending_date.lt.${enc(c.start_date)},week_ending_date.gt.${enc(c.end_date)})`,
          { method:'DELETE', headers: { ...sbHeaders(env), 'Prefer':'return=minimal' } }
        );
        try { await delRes.arrayBuffer(); } catch {}
      }
    }
  }

  const weekdayToJs = { mon:1, tue:2, wed:3, thu:4, fri:5, sat:6, sun:0 };
  const toWeekdayMask = (arr)=> new Set((arr||[]).map(x=> String(x||'').toLowerCase()).filter(k=> k in weekdayToJs));

  function buildPlanEntryForDate(ymd, contract, explicitDayObj) {
    if (explicitDayObj && explicitDayObj.start && explicitDayObj.end) {
      const s = parseHHMM(explicitDayObj.start), e = parseHHMM(explicitDayObj.end);
      if (s==null || e==null) throw new Error(`Invalid HH:MM for ${ymd}`);
      const br = Math.max(0, Number(explicitDayObj.break_minutes||0));
      const overnight = explicitDayObj.overnight===true || e<=s;
      const mins = Math.max(0, minutesDiff(s, e, overnight) - br);
      const breaks = Array.isArray(explicitDayObj.breaks) ? explicitDayObj.breaks : [];
      return { date: ymd, start: explicitDayObj.start, end: explicitDayObj.end, breaks, break_minutes: br, overnight, expected_minutes: mins };
    }
    const jsDow = dow(ymd);
    const key = ({sun:0,mon:1,tue:2,wed:3,thu:4,fri:5,sat:6});
    let wkKey = null;
    for (const [k,v] of Object.entries(key)) if (v===jsDow) { wkKey = k; break; }
    const tpl = contract.std_schedule_json?.[wkKey];
    if (tpl && tpl.start && tpl.end) {
      const s = parseHHMM(tpl.start), e = parseHHMM(tpl.end);
      if (s==null || e==null) throw new Error(`Invalid std_schedule_json time for weekday ${wkKey}`);
      const br = Math.max(0, Number(tpl.break_minutes||0));
      const overnight = tpl.overnight===true || e<=s;
      const mins = Math.max(0, minutesDiff(s, e, overnight) - br);
      const breaks = Array.isArray(tpl.breaks) ? tpl.breaks : [];
      return { date: ymd, start: tpl.start, end: tpl.end, breaks, break_minutes: br, overnight, expected_minutes: mins };
    }
    return { date: ymd, start: null, end: null, breaks: [], break_minutes: 0, overnight: false, expected_minutes: 0 };
  }

  function splitDatesByWeek(r, wew) {
    const out = new Map();
    const d0 = new Date(toYmd(r.from||r.From||r.start)+'T00:00:00Z');
    const d1 = new Date(toYmd(r.to||r.To||r.end)+'T00:00:00Z');

    const mask = Array.isArray(r.days) && r.days.length && typeof r.days[0] === 'string'
      ? toWeekdayMask(r.days) : null;
    const explicit = Array.isArray(r.days) && r.days.length && typeof r.days[0] === 'object'
      ? new Map(r.days.map(o => [toYmd(o.date), o])) : null;

    for (let dt = new Date(d0); dt <= d1; dt.setUTCDate(dt.getUTCDate()+1)) {
      const ymd = toYmd(dt);
      if (ymd < c.start_date || ymd > c.end_date) continue;
      let include = false;
      let explicitObj = null;

      if (explicit) {
        if (explicit.has(ymd)) { include = true; explicitObj = explicit.get(ymd); }
      } else if (mask) {
        const js = dt.getUTCDay();
        const wd = Object.entries(weekdayToJs).find(([,v]) => v===js)?.[0];
        include = wd ? mask.has(wd) : false;
      } else {
        include = true;
      }

      if (!include) continue;
      const we = computeWeekEnding(ymd, c.week_ending_weekday_snapshot || 0);
      const arr = out.get(we) || [];
      arr.push({ date: ymd, explicit: explicitObj || null });
      out.set(we, arr);
    }
    return out;
  }

  async function ensureWeek(contractId, weYmd) {
    const { rows: weeks } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(contractId)}&week_ending_date=eq.${enc(weYmd)}`+
      `&select=id,additional_seq,timesheet_id,planned_schedule_json,status,submission_mode_snapshot&order=additional_seq.asc`
    );
    return weeks || [];
  }

  async function createWeek(contractId, weYmd, additionalSeq=0) {
    const today = toYmd(new Date());
    const payload = [{
      contract_id: contractId,
      week_ending_date: weYmd,
      additional_seq: Number(additionalSeq||0),
      status: (weYmd <= today ? 'OPEN' : 'PLANNED'),
      submission_mode_snapshot: c.default_submission_mode,
      timesheet_id: null,
      planned_schedule_json: [],
      created_at: nowIso(),
      updated_at: nowIso()
    }];
    const ins = await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?on_conflict=contract_id,week_ending_date,additional_seq`, {
      method: 'POST', headers: { ...sbHeaders(env), 'Prefer':'resolution=merge-duplicates,return=representation' },
      body: JSON.stringify(payload)
    });
    if (!ins.ok) throw new Error(await ins.text());
    const row = (await ins.json().catch(()=>[]))[0];
    return row;
  }

  const results = [];
  let contractWindowChanged = false;

  for (const r of ranges) {
    const mergeMode = (String(r.merge||'append').toLowerCase()==='replace') ? 'replace' : 'append';
    const tsExistsPolicy = (String(r.when_timesheet_exists||'create_additional').toLowerCase()==='reject') ? 'reject' : 'create_additional';

    let createdWeeks = 0, patchedWeeks = 0, createdAdditionalWeeks = 0, daysPlanned = 0, skippedOutside = 0, skippedDueTS = 0;

    const byWe = splitDatesByWeek(r, c.week_ending_weekday_snapshot || 0);
    contractWindowChanged = contractWindowChanged || extendWindow;

    for (const [we, dayList] of byWe.entries()) {
      let siblings = await ensureWeek(c.id, we);
      let base = siblings.find(x => x.additional_seq === 0);

      if (!base) {
        base = await createWeek(c.id, we, 0);
        createdWeeks += 1;
        siblings = [base];
      }

      let targetWeek = base;
      if (base.timesheet_id) {
        if (tsExistsPolicy === 'reject') { skippedDueTS += dayList.length; continue; }
        const maxSeq = siblings.reduce((m,w)=> Math.max(m, Number(w.additional_seq||0)), 0);
        targetWeek = await createWeek(c.id, we, maxSeq+1);
        createdAdditionalWeeks += 1;
      }

      const planArr = Array.isArray(targetWeek.planned_schedule_json) ? targetWeek.planned_schedule_json.slice() : [];
      let changed = false;

      for (const d of dayList) {
        const ymd = d.date;
        if (ymd < c.start_date || ymd > c.end_date) { skippedOutside += 1; continue; }
        const idx = planArr.findIndex(p => p?.date === ymd);
        const entry = buildPlanEntryForDate(ymd, c, d.explicit);

        if (idx >= 0) {
          if (mergeMode === 'replace') { planArr[idx] = entry; changed = true; daysPlanned += 1; }
        } else {
          planArr.push(entry); changed = true; daysPlanned += 1;
        }
      }

      if (changed) {
        const today = toYmd(new Date());
        const statusIfReviving = (we <= today ? 'OPEN' : 'PLANNED');

        const patch = {
          planned_schedule_json: planArr,
          updated_at: nowIso()
        };

        // If this week was previously CANCELLED, revive it when adding plan entries.
        if (String(targetWeek.status || '').toUpperCase() === 'CANCELLED') {
          patch.status = statusIfReviving;
        }

        const res = await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(targetWeek.id)}`, {
          method:'PATCH', headers:{ ...sbHeaders(env), 'Prefer':'return=representation' },
          body: JSON.stringify(patch)
        });
        if (!res.ok) return withCORS(env, req, serverError(await res.text()));
        patchedWeeks += 1;
      }
    }

    results.push({
      from: toYmd(r.from||r.From||r.start),
      to:   toYmd(r.to||r.To||r.end),
      created_weeks: createdWeeks,
      patched_weeks: patchedWeeks,
      created_additional_weeks: createdAdditionalWeeks,
      days_planned: daysPlanned,
      skipped_outside_window: skippedOutside,
      skipped_due_to_timesheet: skippedDueTS
    });
  }

  return withCORS(env, req, ok({
    contract_window_changed: contractWindowChanged,
    ranges: results
  }));
}
async function handleContractsUnplanRanges(env, req, contractId) {
  console.log('[UNPLAN][HIT]', 'handleContractsUnplanRanges called', { contractId });

  // ===== Correlation + entry log =====
  const corr = req.headers.get('X-Save-Corr') || `unplan:${contractId}:${Date.now()}`;
  const log = (...a) => console.log('[UNPLAN]', corr, ...a);
  const warn = (...a) => console.warn('[UNPLAN]', corr, ...a);
  const errl = (...a) => console.error('[UNPLAN]', corr, ...a);

  log('ENTRY', { contractId });

  // ===== Auth =====
  const user = await requireUser(env, req, ['admin']);
  if (!user) {
    warn('UNAUTHORISED');
    return withCORS(env, req, unauthorized());
  }
  log('AUTH OK', { user: user?.id || '(anon)' });

  // ===== Parse body =====
  let body;
  try {
    body = await parseJSONBody(req);
  } catch (e) {
    errl('Invalid JSON body', { error: String(e) });
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const ranges = Array.isArray(body?.ranges) ? body.ranges : [];
  const tsExistsPolicy =
    (String(body?.when_timesheet_exists || 'skip').toLowerCase() === 'error') ? 'error' : 'skip';

  // NOTE: We still accept empty_week_action for backward compatibility,
  // but we now ALWAYS DELETE the contract_weeks row if it becomes empty (timesheet_id IS NULL).
  const emptyWeekActionRaw = (['cancel', 'delete', 'keep'].includes(String(body?.empty_week_action || 'cancel').toLowerCase()))
    ? String(body.empty_week_action).toLowerCase()
    : 'cancel';

  log('REQUEST', {
    rangesCount: ranges.length,
    tsExistsPolicy,
    emptyWeekAction: emptyWeekActionRaw,
    emptyWeekAction_effective: 'delete_if_empty',
    sampleRange: ranges[0] || null
  });

  if (!ranges.length) {
    warn('ranges[] is empty');
    return withCORS(env, req, badRequest('ranges[] is required'));
  }

  // ===== Load contract window + WE policy =====
  const c = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(contractId)}&select=id,start_date,end_date,week_ending_weekday_snapshot`
  );
  if (!c) {
    warn('Contract not found');
    return withCORS(env, req, badRequest('Contract not found'));
  }
  log('CONTRACT LOADED', {
    id: c.id,
    start_date: c.start_date,
    end_date: c.end_date,
    wew: c.week_ending_weekday_snapshot
  });

  // ✅ NEW: helper to list weeks that are BLOCKED by existing timesheets, with basic state flags
  async function loadBlockedWeeksSummary(contractId, weFrom, weTo) {
    let rows = [];
    try {
      const { rows: wkRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
          `?contract_id=eq.${enc(contractId)}` +
          `&timesheet_id=not.is.null` +
          `&week_ending_date=gte.${enc(weFrom)}` +
          `&week_ending_date=lte.${enc(weTo)}` +
          `&select=id,week_ending_date,additional_seq,status,timesheet_id`
      );
      rows = wkRows || [];
    } catch {
      rows = [];
    }

    // Best-effort enrich with TSFIN flags (authorised/invoiced/paid)
    const tsIds = [...new Set((rows || []).map(r => r?.timesheet_id).filter(Boolean).map(String))];
    const tsfinMap = new Map();

    if (tsIds.length) {
      try {
        const inTs = tsIds.map(enc).join(',');
        const { rows: tfRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
            `?timesheet_id=in.(${inTs})` +
            `&is_current=eq.true` +
            `&select=timesheet_id,authorised_at_utc,locked_by_invoice_id,paid_at_utc,processing_status`
        );
        for (const r of (tfRows || [])) {
          if (!r?.timesheet_id) continue;
          tsfinMap.set(String(r.timesheet_id), r);
        }
      } catch {
        // non-fatal
      }
    }

    const out = (rows || []).map(w => {
      const tsId = w?.timesheet_id ? String(w.timesheet_id) : null;
      const tf = tsId ? (tsfinMap.get(tsId) || null) : null;

      return {
        week_ending_date: w?.week_ending_date || null,
        additional_seq: w?.additional_seq ?? null,
        contract_week_status: w?.status || null,
        timesheet_id: tsId,
        tsfin_processing_status: tf?.processing_status || null,
        authorised: !!tf?.authorised_at_utc,
        invoiced: !!tf?.locked_by_invoice_id,
        paid: !!tf?.paid_at_utc
      };
    });

    // Stable order for UI: by WE asc, then seq
    out.sort((a, b) => {
      const wa = String(a.week_ending_date || '');
      const wb = String(b.week_ending_date || '');
      if (wa !== wb) return wa.localeCompare(wb);
      return Number(a.additional_seq || 0) - Number(b.additional_seq || 0);
    });

    return out;
  }

  const weekdayToJs = { mon:1, tue:2, wed:3, thu:4, fri:5, sat:6, sun:0 };
  const toWeekdayMask = (arr)=> new Set((arr||[]).map(x=> String(x||'').toLowerCase()).filter(k=> k in weekdayToJs));

  function splitDatesByWE(r) {
    const out = new Map();
    const d0 = new Date(toYmd(r.from||r.From||r.start)+'T00:00:00Z');
    const d1 = new Date(toYmd(r.to||r.To||r.end)+'T00:00:00Z');

    const explicit = Array.isArray(r.days) && r.days.length && typeof r.days[0] === 'string' && /^\d{4}-\d{2}-\d{2}$/.test(r.days[0])
      ? new Set(r.days.map(d => toYmd(d)))
      : null;

    const mask = (!explicit && Array.isArray(r.days) && r.days.length && typeof r.days[0] === 'string')
      ? toWeekdayMask(r.days)
      : null;

    const hasMask = !!(mask && mask.size);

    for (let dt = new Date(d0); dt <= d1; dt.setUTCDate(dt.getUTCDate()+1)) {
      const ymd = toYmd(dt);
      if (ymd < c.start_date || ymd > c.end_date) continue;

      let include = false;
      if (explicit) {
        include = explicit.has(ymd);
      } else if (hasMask) {
        const js = dt.getUTCDay();
        const wd = Object.entries(weekdayToJs).find(([,v]) => v===js)?.[0];
        include = wd ? mask.has(wd) : false;
      } else {
        include = true;
      }

      if (!include) continue;

      // ✅ week_ending_date is computed using the contract/client week-ending weekday policy
      const we = computeWeekEnding(ymd, c.week_ending_weekday_snapshot || 0);
      const arr = out.get(we) || [];
      arr.push(ymd);
      out.set(we, arr);
    }
    return out;
  }

  async function loadWeeks(contractId, weSet) {
    if (!weSet.size) return [];
    const weList = [...weSet].map(enc).join(',');
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?contract_id=eq.${enc(contractId)}&week_ending_date=in.(${weList})` +
      `&select=id,week_ending_date,additional_seq,timesheet_id,planned_schedule_json,status`
    );
    return rows || [];
  }

  const results = [];
  let totalPatchedWeeks = 0;
  let totalDaysRemoved = 0;
  let totalEmptiedWeeks = 0;
  let totalSkippedDueTS = 0;

  // ✅ NEW: track blocked weeks across the whole call (so the UI can show a single neat list)
  const blockedWeeksAll = [];

  // ===== Apply unplanning to the targeted ranges =====
  for (const r of ranges) {
    const fromY = toYmd(r.from||r.From||r.start);
    const toY   = toYmd(r.to||r.To||r.end);

    // Existing convention: if days is [] (empty array), treat as "remove everything in range"
    const isRemoveAllFastPath = Array.isArray(r.days) && r.days.length === 0;

    log('RANGE_START', { from: fromY, to: toY, removeAllFastPath: isRemoveAllFastPath });

    if (isRemoveAllFastPath) {
      const weFrom = computeWeekEnding(fromY, c.week_ending_weekday_snapshot || 0);
      const weTo   = computeWeekEnding(toY,   c.week_ending_weekday_snapshot || 0);

      log('FASTPATH_REMOVE_ALL', {
        weFrom, weTo,
        note: 'Deleting contract_weeks rows (timesheet_id IS NULL) rather than cancelling.'
      });

      // ✅ NEW: collect blocked weeks FIRST (timesheet exists => cannot remove)
      const blocked = await loadBlockedWeeksSummary(c.id, weFrom, weTo);
      if (blocked.length) blockedWeeksAll.push(...blocked);

      // NEW BEHAVIOUR: always DELETE week rows without timesheets in the WE range
      const del = await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(c.id)}` +
        `&timesheet_id=is.null` +
        `&week_ending_date=gte.${enc(weFrom)}` +
        `&week_ending_date=lte.${enc(weTo)}`,
        { method:'DELETE', headers: { ...sbHeaders(env), 'Prefer':'return=representation' } }
      );

      if (!del.ok) {
        const txt = await del.text();
        errl('DELETE weeks failed', { status: del.status, txt });
        return withCORS(env, req, serverError(txt));
      }

      const deletedRows = await del.json().catch(()=>[]);
      const deletedCount = Array.isArray(deletedRows) ? deletedRows.length : 0;

      log('FASTPATH_DELETE_RESULT', { deletedCount, blockedCount: blocked.length });

      results.push({
        from: fromY,
        to:   toY,
        patched_weeks: deletedCount,
        days_removed: 0,
        emptied_weeks: deletedCount,
        emptied_weeks_action: 'delete',
        skipped_due_to_timesheet: 0,              // legacy field (days skipped); unknown in fastpath
        blocked_weeks: blocked,                   // ✅ NEW
        blocked_weeks_count: blocked.length        // ✅ NEW
      });

      totalPatchedWeeks += deletedCount;
      totalEmptiedWeeks += deletedCount;
      continue;
    }

    // Group dates by WE for targeted unplan
    const byWE = splitDatesByWE(r);
    const weSet = new Set(byWE.keys());

    log('SPLIT_BY_WE', { weCount: weSet.size, weeks: [...weSet].slice(0, 6) });

    const weeks = await loadWeeks(c.id, weSet);
    log('WEEKS_LOADED', { count: weeks.length });

    let patchedWeeks = 0, daysRemoved = 0, emptiedWeeks = 0, skippedDueTS = 0;

    const weeksByWE = new Map();
    for (const w of weeks) {
      const arr = weeksByWE.get(w.week_ending_date) || [];
      arr.push(w);
      weeksByWE.set(w.week_ending_date, arr);
    }

    // ✅ NEW: collect blocked weeks for this range (only weeks where overlap would have been removed)
    const blockedThisRange = [];

    for (const [we, dates] of byWE.entries()) {
      const siblings = weeksByWE.get(we) || [];
      if (!siblings.length) {
        log('NO_WEEKS_FOR_WE', { we });
        continue;
      }

      const dateSet = new Set(dates);

      for (const w of siblings) {
        // If there is a real timesheet, we do NOT mutate/delete week rows here.
        if (w.timesheet_id) {
          const planArr = Array.isArray(w.planned_schedule_json) ? w.planned_schedule_json : [];
          const overlapCount = planArr.filter(p => dateSet.has(p?.date)).length;

          if (overlapCount) {
            if (tsExistsPolicy === 'error') {
              warn('TS_EXISTS_ERROR_POLICY', { we, weekId: w.id, overlapCount });
              return withCORS(env, req, badRequest(`Timesheet exists for WE ${we}; cannot remove planned dates`));
            }
            skippedDueTS += overlapCount;
            log('SKIP_DUE_TS', { we, weekId: w.id, overlapCount });

            // ✅ NEW: record this blocked week once (UI list)
            blockedThisRange.push({
              week_ending_date: w.week_ending_date || we,
              additional_seq: w.additional_seq ?? null,
              contract_week_status: w.status || null,
              timesheet_id: String(w.timesheet_id),
              overlap_days_blocked: overlapCount
            });
          }
          continue;
        }

        const raw = w.planned_schedule_json;
        const plan = Array.isArray(raw) ? raw : (typeof raw === 'string' ? JSON.parse(raw) : []);
        const newPlan = plan.filter(p => !dateSet.has(p?.date));
        const removedHere = plan.length - newPlan.length;

        if (!removedHere) continue;

        daysRemoved += removedHere;

        // NEW BEHAVIOUR: if the week becomes empty and has no timesheet, DELETE the row.
        if (!newPlan.length) {
          const del = await fetch(
            `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(w.id)}`,
            { method:'DELETE', headers:{ ...sbHeaders(env), 'Prefer':'return=minimal' } }
          );
          try { await del.arrayBuffer(); } catch {}

          emptiedWeeks += 1;
          patchedWeeks += 1;

          log('DELETE_EMPTY_WEEK', { we, weekId: w.id });
          continue;
        }

        // Otherwise patch the reduced plan
        const res = await fetch(
          `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(w.id)}`,
          {
            method:'PATCH',
            headers:{ ...sbHeaders(env), 'Prefer':'return=minimal' },
            body: JSON.stringify({ planned_schedule_json: newPlan, updated_at: nowIso() })
          }
        );
        try { await res.arrayBuffer(); } catch {}

        patchedWeeks += 1;
        log('PATCH_PARTIAL_WEEK', { we, weekId: w.id, removedHere });
      }
    }

    // ✅ NEW: best-effort enrich blockedThisRange with TSFIN flags (authorised/invoiced/paid)
    let blockedEnriched = blockedThisRange;
    try {
      const tsIds = [...new Set(blockedThisRange.map(x => x.timesheet_id).filter(Boolean).map(String))];
      if (tsIds.length) {
        const inTs = tsIds.map(enc).join(',');
        const { rows: tfRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
            `?timesheet_id=in.(${inTs})&is_current=eq.true` +
            `&select=timesheet_id,authorised_at_utc,locked_by_invoice_id,paid_at_utc,processing_status`
        );
        const m = new Map((tfRows || []).map(r => [String(r.timesheet_id), r]));
        blockedEnriched = blockedThisRange.map(b => {
          const tf = m.get(String(b.timesheet_id)) || null;
          return {
            ...b,
            tsfin_processing_status: tf?.processing_status || null,
            authorised: !!tf?.authorised_at_utc,
            invoiced: !!tf?.locked_by_invoice_id,
            paid: !!tf?.paid_at_utc
          };
        });
      }
    } catch {
      // non-fatal
    }

    if (blockedEnriched.length) blockedWeeksAll.push(...blockedEnriched);

    results.push({
      from: fromY,
      to:   toY,
      patched_weeks: patchedWeeks,
      days_removed: daysRemoved,
      emptied_weeks: emptiedWeeks,
      emptied_weeks_action: 'delete_if_empty',
      skipped_due_to_timesheet: skippedDueTS,
      blocked_weeks: blockedEnriched,                  // ✅ NEW
      blocked_weeks_count: blockedEnriched.length       // ✅ NEW
    });

    totalPatchedWeeks += patchedWeeks;
    totalDaysRemoved  += daysRemoved;
    totalEmptiedWeeks += emptiedWeeks;
    totalSkippedDueTS += skippedDueTS;

    log('RANGE_DONE', {
      from: fromY,
      to: toY,
      patchedWeeks,
      daysRemoved,
      emptiedWeeks,
      skippedDueTS,
      blockedWeeks: blockedEnriched.length
    });
  }

  // ===== Normalize contract window AFTER unplanning =====
  let minWE = null, maxWE = null;
  try {
    const { rows: minRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(c.id)}&timesheet_id=not.is.null&select=week_ending_date` +
      `&order=week_ending_date.asc&limit=1`
    );
    minWE = (minRows && minRows[0] && minRows[0].week_ending_date) || null;

    const { rows: maxRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(c.id)}&timesheet_id=not.is.null&select=week_ending_date` +
      `&order=week_ending_date.desc&limit=1`
    );
    maxWE = (maxRows && maxRows[0] && maxRows[0].week_ending_date) || null;
  } catch (e) {
    warn('FETCH_TS_ENVELOPE_FAILED', { error: String(e) });
  }

  // Scan remaining planned dates (best-effort)
  let minPlanned = null, maxPlanned = null;
  try {
    const { rows: allWeeks } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?contract_id=eq.${enc(c.id)}&select=planned_schedule_json,week_ending_date,timesheet_id`
    );
    for (const w of (allWeeks || [])) {
      const arr = Array.isArray(w?.planned_schedule_json)
        ? w.planned_schedule_json
        : (typeof w?.planned_schedule_json === 'string'
            ? JSON.parse(w.planned_schedule_json || '[]')
            : []);
      for (const p of arr) {
        const y = toYmd(p?.date);
        if (!y) continue;
        if (!minPlanned || y < minPlanned) minPlanned = y;
        if (!maxPlanned || y > maxPlanned) maxPlanned = y;
      }
    }
  } catch (e) {
    warn('SCAN_PLANNED_FAILED', { error: String(e) });
  }

  let newStart = c.start_date;
  let newEnd   = c.end_date;

  if (minPlanned && maxPlanned) {
    newStart = minPlanned;
    newEnd   = maxPlanned;
  } else {
    if (minWE || maxWE) {
      newStart = minWE ? addDays(minWE, -6) : c.start_date;
      newEnd   = maxWE ? maxWE : c.end_date;
    } else {
      newStart = c.start_date;
      newEnd   = c.start_date;
    }
  }

  const beforeClamp = { newStart, newEnd, minWE, maxWE };

  if (minWE) {
    const minWeekStart = addDays(minWE, -6);
    if (newStart > minWeekStart) newStart = minWeekStart;
  }
  if (maxWE) {
    if (newEnd < maxWE) newEnd = maxWE;
  }

  log('NORMALIZE_WINDOW', {
    proposed: beforeClamp,
    clamped: { newStart, newEnd }
  });

  let contractWindowChanged = false;
  if (newStart !== c.start_date || newEnd !== c.end_date) {
    log('PATCH_CONTRACT_WINDOW', {
      oldStart: c.start_date, oldEnd: c.end_date, newStart, newEnd
    });

    const pr = await fetch(`${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(c.id)}`, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), 'Prefer':'return=representation' },
      body: JSON.stringify({ start_date: newStart, end_date: newEnd, updated_at: nowIso() })
    });

    if (!pr.ok) {
      const txt = await pr.text();
      errl('PATCH_CONTRACT_WINDOW_FAILED', { status: pr.status, txt });
      return withCORS(env, req, serverError(txt));
    }

    const upd = (await pr.json().catch(()=>[]))[0] || c;
    c.start_date = upd.start_date;
    c.end_date   = upd.end_date;
    contractWindowChanged = true;

    try {
      log('PRUNE_OUTSIDE_WEEKS', { keepFrom: c.start_date, keepTo: c.end_date });
      const delRes = await fetch(
        `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?contract_id=eq.${enc(c.id)}` +
        `&timesheet_id=is.null` +
        `&or=(week_ending_date.lt.${enc(c.start_date)},week_ending_date.gt.${enc(c.end_date)})`,
        { method:'DELETE', headers: { ...sbHeaders(env), 'Prefer':'return=minimal' } }
      );
      try { await delRes.arrayBuffer(); } catch {}
    } catch (e) {
      warn('PRUNE_OUTSIDE_WEEKS_FAILED', { error: String(e) });
    }
  } else {
    log('WINDOW_UNCHANGED', { start_date: c.start_date, end_date: c.end_date });
  }

  // ✅ NEW: de-dup blocked weeks list (by week_ending_date + additional_seq + timesheet_id)
  const blockedDedup = [];
  try {
    const seen = new Set();
    for (const b of (blockedWeeksAll || [])) {
      const k = `${b.week_ending_date || ''}::${b.additional_seq ?? ''}::${b.timesheet_id || ''}`;
      if (seen.has(k)) continue;
      seen.add(k);
      blockedDedup.push(b);
    }
  } catch {}

  const response = {
    contract_window_changed: contractWindowChanged,
    ranges: results,
    totals: {
      patched_weeks: totalPatchedWeeks,
      days_removed: totalDaysRemoved,
      emptied_weeks: totalEmptiedWeeks,
      skipped_due_to_timesheet: totalSkippedDueTS
    },
    final_window: { start_date: c.start_date, end_date: c.end_date },

    // ✅ NEW: top-level blocked list for UI summaries
    blocked_weeks: blockedDedup,
    blocked_weeks_count: blockedDedup.length
  };

  log('EXIT OK', response);
  return withCORS(env, req, ok(response));
}

async function handleContractWeekGeneratePrintable(env, req, weekId) {
  const enc = encodeURIComponent;
  const cleanKey = (k) => String(k || '').replace(/^\/+/, '').trim();

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!weekId) return withCORS(env, req, badRequest('contract_week_id is required'));

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  try {
    console.log('[QR_WEEKLY][GENERATE] incoming', { weekId, body });
  } catch {}

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?id=eq.${enc(weekId)}&select=*`
  );
  if (!cw) return withCORS(env, req, notFound('Weekly slot not found'));

  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?id=eq.${enc(cw.contract_id)}&select=*`
  );
  if (!contract) return withCORS(env, req, notFound('Contract not found'));

  // 1a) QR route allowed?
  let defaultSubmissionMode = 'ELECTRONIC';
  try {
    if (contract.client_id) {
      const { rows: csRows } = await sbFetch(
        env,
        `${env.SUPABASE_URL}/rest/v1/client_settings` +
          `?client_id=eq.${enc(contract.client_id)}` +
          `&select=default_submission_mode,updated_at,created_at` +
          `&order=updated_at.desc.nullslast,created_at.desc.nullslast` +
          `&limit=1`
      );
      const cs = csRows?.[0] || null;
      if (cs && cs.default_submission_mode) {
        defaultSubmissionMode = String(cs.default_submission_mode || 'ELECTRONIC').toUpperCase();
      }
    }
  } catch {
    defaultSubmissionMode = 'ELECTRONIC';
  }

  if (defaultSubmissionMode !== 'ELECTRONIC' && defaultSubmissionMode !== 'MANUAL') {
    return withCORS(
      env,
      req,
      badRequest(`client_settings.default_submission_mode=${defaultSubmissionMode} is not supported`)
    );
  }

  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;
  const asNumberLocal = (v) => (v == null ? 0 : Number(v) || 0);

  // 2) Hours from schedule or totals
  let hours = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
  let actual_schedule_json = null;

  if (Array.isArray(body?.actual_schedule_json) && body.actual_schedule_json.length) {
    actual_schedule_json = body.actual_schedule_json;

    try {
      validateScheduleStructure(actual_schedule_json);
    } catch (e) {
      return withCORS(
        env,
        req,
        badRequest(e?.message || 'Invalid schedule: overlapping shifts or invalid break windows.')
      );
    }

    try {
      const mins = await resolveBucketsFromSchedule(env, contract, actual_schedule_json);
      hours = {
        day:   +(mins.day   / 60).toFixed(2),
        night: +(mins.night / 60).toFixed(2),
        sat:   +(mins.sat   / 60).toFixed(2),
        sun:   +(mins.sun   / 60).toFixed(2),
        bh:    +(mins.bh    / 60).toFixed(2)
      };
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid actual_schedule_json'));
    }
  } else if (body?.hours) {
    const n = (v) => (v == null ? 0 : Number(v) || 0);
    hours = {
      day:   n(body.hours.day),
      night: n(body.hours.night),
      sat:   n(body.hours.sat),
      sun:   n(body.hours.sun),
      bh:    n(body.hours.bh)
    };
  } else {
    return withCORS(env, req, badRequest('Provide either actual_schedule_json or hours totals'));
  }

  // 2b) Rate guard
  const { pay, charge, method } = payChargeFromContract(contract);
  const anyMissing = (h, P, C) =>
    (h.day   > 0 && ((P.day   == null && P.day   !== 0) || (C.day   == null && C.day   !== 0))) ||
    (h.night > 0 && ((P.night == null && P.night !== 0) || (C.night == null && C.night !== 0))) ||
    (h.sat   > 0 && ((P.sat   == null && P.sat   !== 0) || (C.sat   == null && C.sat   !== 0))) ||
    (h.sun   > 0 && ((P.sun   == null && P.sun   !== 0) || (C.sun   == null && C.sun   !== 0))) ||
    (h.bh    > 0 && ((P.bh    == null && P.bh    !== 0) || (C.bh    == null && C.bh    !== 0)));

  if (anyMissing(hours, pay, charge)) {
    return withCORS(env, req, badRequest('Missing rate(s) in contract for one or more entered hour buckets'));
  }

  // additional units
  const unitsWeek  = (body.additional_units_week && typeof body.additional_units_week === 'object')
    ? body.additional_units_week
    : {};
  const unitsPerDay = (body.additional_units_per_day && typeof body.additional_units_per_day === 'object')
    ? body.additional_units_per_day
    : {};

  const addlConfig = Array.isArray(contract.additional_rates_json)
    ? contract.additional_rates_json
    : [];

  const weekDates = [];
  try {
    const base = new Date(String(cw.week_ending_date) + 'T00:00:00Z');
    for (let offset = 6; offset >= 0; offset--) {
      const d = new Date(base);
      d.setUTCDate(base.getUTCDate() - offset);
      const yyyy = d.getUTCFullYear();
      const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
      const dd   = String(d.getUTCDate()).padStart(2, '0');
      const ymd  = `${yyyy}-${mm}-${dd}`;
      const dow  = d.getUTCDay();
      weekDates.push({ ymd, dow });
    }
  } catch {}

 let bhSet = new Set();
try {
  const pol = await loadPolicy(env, contract.client_id || null, cw.week_ending_date);
  const bhList = Array.isArray(pol?.bh_list) ? pol.bh_list : [];
  bhSet = new Set(bhList.map(String));
} catch {
  bhSet = new Set();
}


  const isBH = (ymd) => bhSet.has(ymd);

  const normaliseFreq = (raw) => {
    const s = String(raw || '').toUpperCase();
    if (s === 'ONE_PER_WEEK')          return 'ONE_PER_WEEK';
    if (s === 'ONE_PER_DAY')           return 'ONE_PER_DAY';
    if (s === 'WEEKENDS_AND_BH_ONLY')  return 'WEEKENDS_AND_BH_ONLY';
    if (s === 'WEEKDAYS_EXCL_BH_ONLY') return 'WEEKDAYS_EXCL_BH_ONLY';
    return 'ONE_PER_WEEK';
  };

  const shouldIncludeDay = (freq, meta) => {
    const { ymd, dow } = meta;
    const bh = isBH(ymd);
    if (freq === 'ONE_PER_DAY') return true;
    if (freq === 'WEEKENDS_AND_BH_ONLY') return bh || dow === 0 || dow === 6;
    if (freq === 'WEEKDAYS_EXCL_BH_ONLY') return !bh && dow >= 1 && dow <= 5;
    return false;
  };

  let additional_units_json    = {};
  let additional_pay_ex_vat    = 0;
  let additional_charge_ex_vat = 0;
  const badBuckets = [];

  for (const cfgRaw of addlConfig) {
    if (!cfgRaw || typeof cfgRaw !== 'object') continue;
    const code = String(cfgRaw.code || '').toUpperCase() || 'EX1';
    const freq = normaliseFreq(cfgRaw.frequency);
    let unitCount = 0;
    const daysUsed = {};

    if (freq === 'ONE_PER_WEEK') {
      const u = Number(unitsWeek[code] || 0);
      if (u && Number.isFinite(u)) unitCount = u;
    } else {
      const perRaw = (unitsPerDay[code] && typeof unitsPerDay[code] === 'object') ? unitsPerDay[code] : {};
      for (const meta of weekDates) {
        const raw = perRaw[meta.ymd];
        if (raw == null || raw === '') continue;
        const v = Number(raw);
        if (!Number.isFinite(v) || !v) continue;
        if (!shouldIncludeDay(freq, meta)) continue;
        unitCount += v;
        daysUsed[meta.ymd] = v;
      }
    }

    if (!unitCount || !Number.isFinite(unitCount)) continue;

    const payRate    = (cfgRaw.pay_rate    != null) ? Number(cfgRaw.pay_rate)    : NaN;
    const chargeRate = (cfgRaw.charge_rate != null) ? Number(cfgRaw.charge_rate) : NaN;
    if (!Number.isFinite(payRate) || !Number.isFinite(chargeRate)) {
      badBuckets.push(cfgRaw.bucket_name || code);
      continue;
    }

    const payEx = +Number(unitCount * payRate).toFixed(2);
    const chgEx = +Number(unitCount * chargeRate).toFixed(2);

    additional_units_json[code] = {
      bucket_name: cfgRaw.bucket_name || null,
      unit_name:   cfgRaw.unit_name   || null,
      frequency:   freq,
      unit_count:  unitCount,
      pay_rate:    payRate,
      charge_rate: chargeRate,
      pay_ex_vat:  payEx,
      charge_ex_vat: chgEx,
      days: Object.keys(daysUsed).length ? daysUsed : undefined
    };

    additional_pay_ex_vat    += payEx;
    additional_charge_ex_vat += chgEx;
  }

  if (badBuckets.length) {
    const msg = `Missing additional rate(s) in contract for bucket(s): ${badBuckets.join(', ')}`;
    return withCORS(env, req, badRequest(msg));
  }

  additional_pay_ex_vat    = +Number(additional_pay_ex_vat).toFixed(2);
  additional_charge_ex_vat = +Number(additional_charge_ex_vat).toFixed(2);
  const additional_margin_ex_vat = +Number(additional_charge_ex_vat - additional_pay_ex_vat).toFixed(2);

  // Create/reuse timesheet
  const candidate = contract.candidate_id
    ? await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/candidates?id=eq.${enc(contract.candidate_id)}&select=id,display_name,email`)
    : null;
  const client = contract.client_id
    ? await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/clients?id=eq.${enc(contract.client_id)}&select=id,name`)
    : null;

  const now = nowIso();

  const occupant_norm  = (candidate?.display_name || String(candidate?.id || 'worker')).toLowerCase();
  const hospital_norm  = (contract.display_site || client?.name || String(contract.client_id)).toLowerCase();
  const ward_norm      = (contract.ward_hint || 'contract').toLowerCase();
  const job_title_norm = (contract.role || 'weekly').toLowerCase();
  const booking_id     = await makeWeeklyBookingId(contract?.candidate_id || null, contract, cw);

  let ts = null;

  if (cw.timesheet_id) {
    const existing = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(cw.timesheet_id)}&is_current=eq.true&select=*`
    );
    if (!existing) return withCORS(env, req, serverError('Linked timesheet not found for contract_week (current version)'));

    const scope = String(existing.sheet_scope || '').toUpperCase();
    if (scope && scope !== 'WEEKLY') return withCORS(env, req, badRequest('Existing timesheet linked to this week is not WEEKLY; cannot use QR printable route'));

    const curFin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?timesheet_id=eq.${enc(existing.timesheet_id)}&is_current=eq.true&select=locked_by_invoice_id,paid_at_utc`
    );
    if (curFin?.locked_by_invoice_id || curFin?.paid_at_utc) {
      return withCORS(env, req, badRequest('Cannot generate QR printable: timesheet already invoiced or paid'));
    }

    const tsPatch = { sheet_scope: 'WEEKLY', submission_mode: 'MANUAL', line_type: 'HOURS', updated_at: now };
    if (Array.isArray(actual_schedule_json)) tsPatch.actual_schedule_json = actual_schedule_json;

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(existing.timesheet_id)}&is_current=eq.true`,
      { method: 'PATCH', headers: { ...sbHeaders(env), Prefer: 'return=minimal' }, body: JSON.stringify(tsPatch) }
    ).catch(() => {});

    ts = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(existing.timesheet_id)}&is_current=eq.true&select=*`);
  } else {
    const tsPayload = [{
      booking_id,
      version: 1,
      is_current: true,
      status: 'RECEIVED',
      occupant_key_norm: occupant_norm,
      hospital_norm,
      ward_norm,
      job_title_norm,
      shift_label_norm: 'weekly',
      week_ending_date: cw.week_ending_date,
      r2_nurse_key: null,
      r2_auth_key: null,
      contract_id: contract.id,
      submission_mode: 'MANUAL',
      manual_pdf_r2_key: null,
      line_type: 'HOURS',
      actual_schedule_json,
      authorised_at_server: null,
      sheet_scope: 'WEEKLY',
      qr_payload_json: {},
      created_at: now,
      updated_at: now
    }];

    const tsIns = await fetch(`${env.SUPABASE_URL}/rest/v1/timesheets`, {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify(tsPayload)
    });
    if (!tsIns.ok) return withCORS(env, req, serverError(await tsIns.text()));
    ts = (await tsIns.json().catch(() => []))[0];

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(cw.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          timesheet_id: ts.timesheet_id,
          submission_mode_snapshot: 'MANUAL',
          status: 'OPEN',
          updated_at: now
        })
      }
    ).catch(() => {});
  }

  if (!ts?.timesheet_id) return withCORS(env, req, serverError('Failed to create or load timesheet for QR weekly'));

  const oldQrKey = ts.qr_r2_key ? cleanKey(ts.qr_r2_key) : null;

  // Policy snapshot
  let policySnapshot = {};
  try {
    policySnapshot = await loadPolicy(env, contract.client_id || null, cw.week_ending_date);
    if (!policySnapshot || typeof policySnapshot !== 'object') policySnapshot = {};
  } catch {
    policySnapshot = {};
  }

  const pay_wtr_rate_pct_snapshot =
    (String(method || '').toUpperCase() === 'PAYE' && policySnapshot && policySnapshot.holiday_pay_pct != null)
      ? Number(policySnapshot.holiday_pay_pct)
      : null;

  // Snapshot build (unchanged)
  const n2 = (x) => Number(x) || 0;

  const basePay = +(hours.day * n2(pay.day) + hours.night * n2(pay.night) + hours.sat * n2(pay.sat) + hours.sun * n2(pay.sun) + hours.bh * n2(pay.bh)).toFixed(2);
  const baseCharge = +(hours.day * n2(charge.day) + hours.night * n2(charge.night) + hours.sat * n2(charge.sat) + hours.sun * n2(charge.sun) + hours.bh * n2(charge.bh)).toFixed(2);

  const totalPay = +Number(basePay + additional_pay_ex_vat).toFixed(2);
  const totalCharge = +Number(baseCharge + additional_charge_ex_vat).toFixed(2);
  const margin = +Number(totalCharge - totalPay).toFixed(2);

  const invoice_breakdown_json = {
    mode: 'AGGREGATE',
    base_hours: {
      day: hours.day, night: hours.night, sat: hours.sat, sun: hours.sun, bh: hours.bh,
      pay_rates: { day: pay.day, night: pay.night, sat: pay.sat, sun: pay.sun, bh: pay.bh },
      charge_rates: { day: charge.day, night: charge.night, sat: charge.sat, sun: charge.sun, bh: charge.bh },
      pay_ex_vat: basePay,
      charge_ex_vat: baseCharge
    },
    additional: {
      units: additional_units_json,
      pay_ex_vat: additional_pay_ex_vat,
      charge_ex_vat: additional_charge_ex_vat,
      margin_ex_vat: additional_margin_ex_vat
    },
    totals: { total_pay_ex_vat: totalPay, total_charge_ex_vat: totalCharge, margin_ex_vat: margin }
  };

  const snapshot = {
    timesheet_id: ts.timesheet_id,
    timesheet_version: ts.version || 1,
    basis: 'CONTRACT_WEEKLY',
    candidate_id: contract.candidate_id || null,
    client_id: contract.client_id || null,
    role: contract.role || null,
    band: contract.band || null,
    pay_method: method,
    candidate_assignment: contract.candidate_id ? 'ASSIGNED' : 'UNASSIGNED',
    processing_status: 'AWAITING_MANUAL_SIGNATURE',
    hours_day: Number(hours.day || 0),
    hours_night: Number(hours.night || 0),
    hours_sat: Number(hours.sat || 0),
    hours_sun: Number(hours.sun || 0),
    hours_bh: Number(hours.bh || 0),
    total_hours: round2(Number(hours.day || 0) + Number(hours.night || 0) + Number(hours.sat || 0) + Number(hours.sun || 0) + Number(hours.bh || 0)),
    pay_day: pay.day, pay_night: pay.night, pay_sat: pay.sat, pay_sun: pay.sun, pay_bh: pay.bh,
    charge_day: charge.day, charge_night: charge.night, charge_sat: charge.sat, charge_sun: charge.sun, charge_bh: charge.bh,
    total_pay_ex_vat: totalPay,
    total_charge_ex_vat: totalCharge,
    margin_ex_vat: margin,
    additional_units_json,
    additional_pay_ex_vat,
    additional_charge_ex_vat,
    additional_margin_ex_vat,
    expenses_pay_ex_vat: 0,
    expenses_charge_ex_vat: 0,
    expenses_description: null,
    expenses_evidence_r2_key: null,
    mileage_pay_ex_vat: 0,
    mileage_charge_ex_vat: 0,
    mileage_evidence_r2_key: null,
    mileage_pay_rate: null,
    mileage_charge_rate: null,
    pay_on_hold: false,
    pay_on_hold_reason: null,
    pay_on_hold_since_utc: null,
    paid_at_utc: null,
    paid_by_user_id: null,
    payment_reference: null,
    policy_snapshot_json: policySnapshot,
    rate_source_refs_json: { mode: 'CONTRACT_RATES_JSON', contract_id: contract.id || null },
    pay_wtr_rate_pct_snapshot,
    created_at: now,
    invoice_breakdown_json
  };

  await writeSnapshot(env, snapshot).catch((e) => {
    console.warn('[QR_WEEKLY][GENERATE] writeSnapshot failed', { timesheet_id: ts.timesheet_id, err: e?.message || String(e) });
  });

  // Generate token FIRST
  const qrToken = (typeof crypto !== 'undefined' && crypto.randomUUID)
    ? crypto.randomUUID()
    : `${ts.timesheet_id}:${Date.now()}`;

  // Generate QR + store
  let qrText = null;
  let qr_r2_key = null;
  try {
    const res = await generateAndStoreTimesheetQr(env, {
      timesheet_id: ts.timesheet_id,
      contract_week_id: cw.id,
      contract_id: contract.id,
      candidate_id: contract.candidate_id || null,
      client_id: contract.client_id || null,
      week_ending_ymd: cw.week_ending_date,
      qr_token: qrToken
    });
    qrText = res?.qrText || null;
    qr_r2_key = res?.qr_r2_key || null;
  } catch (e) {
    console.warn('[QR_WEEKLY][GENERATE] generateAndStoreTimesheetQr failed', { timesheet_id: ts.timesheet_id, err: e?.message || String(e) });
  }

  // Store QR metadata on current timesheet (capture success for safe delete)
  let qrPatchOk = false;
  try {
    const resp = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          sheet_scope: 'WEEKLY',
          qr_token: qrToken,
          qr_status: 'PENDING',
          qr_generated_at: now,
          qr_scanned_at: null,
          qr_scan_info_json: null,
          qr_r2_key: qr_r2_key || null,
          updated_at: now
        })
      }
    );
    qrPatchOk = !!resp.ok;
  } catch {
    qrPatchOk = false;
  }

  // ✅ NEW: delete old QR image key now that we replaced it (best-effort, only if DB patch succeeded)
  if (qrPatchOk) {
    try {
      const bucket = env.R2_BUCKET || env.R2;
      const newQrKeyClean = qr_r2_key ? cleanKey(qr_r2_key) : null;
      if (bucket && typeof bucket.delete === 'function' && oldQrKey && newQrKeyClean && oldQrKey !== newQrKeyClean) {
        await bucket.delete(oldQrKey).catch(() => {});
      }
    } catch {
      // non-fatal
    }
  }

  // Render PDF (generated)
  const pdfKey = await renderTimesheetPDFAndSave(env, ts.timesheet_id).catch((e) => {
    console.error('[QR_WEEKLY][GENERATE] renderTimesheetPDFAndSave failed', { timesheet_id: ts.timesheet_id, err: e?.message || String(e) });
    return null;
  });

  if (pdfKey) {
    const patchUrl =
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
      `&is_current=eq.true` +
      `&or=(manual_pdf_r2_key.is.null,manual_pdf_r2_key.eq.)`;

    await fetch(
      patchUrl,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({ manual_pdf_r2_key: pdfKey, updated_at: now })
      }
    ).catch(() => {});
  }

  // Email to candidate with PDF via mail_outbox
  let emailQueued = false;
  try {
    const email = (candidate && candidate.email && String(candidate.email).trim()) || null;
    if (email && pdfKey) {
      const subject = `Weekly timesheet for signature – week ending ${cw.week_ending_date}`;

      const lines = [
        `Your weekly timesheet is ready.`,
        ``,
        `Please print, sign with the ward manager and upload the signed copy via the app.`,
        ``,
        `Week ending: ${cw.week_ending_date}`,
        `Timesheet ID: ${ts.timesheet_id}`
      ];
      const bodyText = lines.join('\n');
      const bodyHtml = `<p>${lines.map(l => (l === '' ? '<br/>' : enc(l))).join('<br/>')}</p>`;

      const outboxRow = {
        type: 'TIMESHEET_QR',
        to: email,
        cc: null,
        subject,
        body_text: bodyText,
        body_html: bodyHtml,
        attachments: [
          { r2_key: pdfKey, filename: `Timesheet_${cw.week_ending_date}.pdf`, content_type: 'application/pdf' }
        ],
        status: 'QUEUED',
        reference: `timesheet_qr:weekly:${ts.timesheet_id}:${cw.week_ending_date}`,
        created_by: user?.id || null,
        created_at_utc: now
      };

      const insOut = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
        body: JSON.stringify(outboxRow)
      });

      if (insOut.ok) emailQueued = true;
      else {
        const errTxt = await insOut.text().catch(() => '');
        console.warn('[QR_WEEKLY][GENERATE] mail_outbox insert failed', errTxt);
      }
    }
  } catch (e) {
    console.warn('[QR_WEEKLY][GENERATE] mail queue failed (non-fatal)', e?.message || e);
  }

  // Audit
  try {
    await writeAudit(
      env,
      user,
      'WEEKLY_QR_PRINTABLE_GENERATED',
      {
        contract_week_id: cw.id,
        contract_id: contract.id,
        timesheet_id: ts.timesheet_id,
        pdf_r2_key: pdfKey,
        qr_token: qrToken,
        qr_status: 'PENDING',
        qr_r2_key,
        email_queued: emailQueued
      },
      { entity: 'contract_weeks', subject_id: cw.id, req }
    );
  } catch (e) {
    console.warn('[QR_WEEKLY][GENERATE] audit failed', e?.message || e);
  }

  return withCORS(env, req, ok({
    contract_week_id: cw.id,
    timesheet_id: ts.timesheet_id,
    pdf_r2_key: pdfKey,
    qr_token: qrToken,
    qr_status: 'PENDING',
    qr_r2_key,
    email_queued: emailQueued
  }));
}

async function handleTimesheetBucketPreview(env, req) {
  const enc    = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  // ✅ YYYY-MM-DD in Europe/London (stable, no locale ordering assumptions)
  const toLondonYmd = (dt) => {
    try {
      const d = (dt instanceof Date) ? dt : new Date(dt);
      if (!d || Number.isNaN(d.getTime())) return null;

      const parts = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).formatToParts(d);

      const y  = parts.find(p => p.type === 'year')?.value || '';
      const m  = parts.find(p => p.type === 'month')?.value || '';
      const dd = parts.find(p => p.type === 'day')?.value || '';
      if (!y || !m || !dd) return null;

      return `${y}-${m}-${dd}`;
    } catch {
      return null;
    }
  };

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const timesheetId    = body?.timesheet_id     || null;
  const contractWeekId = body?.contract_week_id || null;

  if (!timesheetId && !contractWeekId) {
    return withCORS(env, req, badRequest('timesheet_id or contract_week_id is required'));
  }

  let ts       = null;
  let cw       = null;
  let contract = null;

  // ─────────────────────
  // 0) Load context
  // ─────────────────────
  if (timesheetId) {
    // Existing timesheet: use CURRENT weekly context
    ts = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(timesheetId)}` +
        `&is_current=eq.true` +
        `&select=*`
    );
    if (!ts) {
      return withCORS(env, req, notFound('Timesheet not found'));
    }

    const ctx = await loadWeeklyContext(env, ts); // { cw, contract } for weekly TS
    if (!ctx) {
      return withCORS(env, req, badRequest('Not a weekly contract-driven timesheet'));
    }
    cw       = ctx.cw;
    contract = ctx.contract;
  } else {
    // Planned week: no TS yet
    cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(contractWeekId)}&select=*`
    );
    if (!cw) {
      return withCORS(env, req, notFound('Contract week not found'));
    }

    contract = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(cw.contract_id)}&select=*`
    );
    if (!contract) {
      return withCORS(env, req, notFound('Contract not found'));
    }
  }

  // ─────────────────────
  // 0.5) Finance globals (anchor aligned to TSFIN rules)
  //   - authorised TS  -> authorised_at_server (London date)
  //   - otherwise      -> today (London date)
  // ─────────────────────
  let financeAnchorYmd  = null;
  let financeAnchorKind = 'TODAY';

  try {
    const authIso = ts?.authorised_at_server || null;
    const authYmd = authIso ? toLondonYmd(authIso) : null;
    if (authYmd) {
      financeAnchorYmd  = authYmd;
      financeAnchorKind = 'AUTHORISED_AT_SERVER';
    } else {
      financeAnchorYmd  = toLondonYmd(new Date()) || null;
      financeAnchorKind = 'TODAY';
    }
  } catch {
    financeAnchorYmd  = toLondonYmd(new Date()) || null;
    financeAnchorKind = 'TODAY';
  }

  const finance = await loadFinanceGlobals(env, financeAnchorYmd || null).catch(() => ({}));

  // Robust pct normaliser: accepts 15 or 0.15
  const pctToMultiplier = (pctMaybe) => {
    let p = Number(pctMaybe);
    if (!Number.isFinite(p) || p <= 0) return 1;
    if (p > 1) p = p / 100; // treat as percent
    const m = 1 + p;
    return (Number.isFinite(m) && m > 0) ? m : 1;
  };

  const applyErniTo = String(finance?.apply_erni_to || 'PAYE_ONLY').toUpperCase();
  const erniPctRaw  = finance?.erni_pct ?? 0;
  const erniMult    = pctToMultiplier(erniPctRaw);

  // Determine the contract pay method (PAYE vs UMBRELLA)
  const contractPayMethod = String(
    contract?.pay_method_snapshot || contract?.pay_method || ''
  ).toUpperCase();

  const erniApplies =
    (applyErniTo === 'ALL') ||
    (applyErniTo === 'PAYE_ONLY' && contractPayMethod === 'PAYE');

  // ─────────────────────
  // 1) Derive hours by buckets
  // ─────────────────────
  let hours = { day: 0, night: 0, sat: 0, sun: 0, bh: 0 };
  let actual_schedule_json = null;

  // 1a) FE schedule override from Lines
   if (Array.isArray(body.actual_schedule_json) && body.actual_schedule_json.length) {
    actual_schedule_json = normaliseScheduleBreakFields(body.actual_schedule_json);

    try {
      validateScheduleStructure(actual_schedule_json);
    } catch (e) {
      return withCORS(
        env,
        req,
        badRequest(e.message || 'Invalid schedule (overlap/breaks).')
      );
    }

    try {
      const mins = await resolveBucketsFromSchedule(env, contract, actual_schedule_json);
      hours = {
        day:   +(mins.day   / 60).toFixed(2),
        night: +(mins.night / 60).toFixed(2),
        sat:   +(mins.sat   / 60).toFixed(2),
        sun:   +(mins.sun   / 60).toFixed(2),
        bh:    +(mins.bh    / 60).toFixed(2)
      };
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Invalid actual_schedule_json'));
    }

  // 1b) Direct hours override
  } else if (body?.hours) {
    const n = (v) => (v == null ? 0 : Number(v) || 0);
    hours = {
      day:   n(body.hours.day),
      night: n(body.hours.night),
      sat:   n(body.hours.sat),
      sun:   n(body.hours.sun),
      bh:    n(body.hours.bh)
    };

  // 1c) Existing TS: fallback to computeWeeklyHours
  } else if (ts) {
    const h = await computeWeeklyHours(env, ts, contract);
    hours = h;

  // 1d) Planned week: use planned or std schedule
  } else {
    let sched = cw.planned_schedule_json || cw.std_schedule_json || contract.std_schedule_json || null;

    if (typeof sched === 'string') {
      try {
        sched = JSON.parse(sched);
      } catch {
        sched = null;
      }
    }

    if (!Array.isArray(sched) || !sched.length) {
      return withCORS(
        env,
        req,
        badRequest('No schedule or hours available to preview for this planned week.')
      );
    }

     actual_schedule_json = normaliseScheduleBreakFields(sched);

    try {
      validateScheduleStructure(actual_schedule_json);
    } catch (e) {
      return withCORS(
        env,
        req,
        badRequest(e.message || 'Invalid planned schedule (overlap/breaks).')
      );
    }


    try {
      const mins = await resolveBucketsFromSchedule(env, contract, actual_schedule_json);
      hours = {
        day:   +(mins.day   / 60).toFixed(2),
        night: +(mins.night / 60).toFixed(2),
        sat:   +(mins.sat   / 60).toFixed(2),
        sun:   +(mins.sun   / 60).toFixed(2),
        bh:    +(mins.bh    / 60).toFixed(2)
      };
    } catch (e) {
      return withCORS(env, req, badRequest(e.message || 'Failed to classify planned schedule'));
    }
  }

  // ─────────────────────
  // 2) Rates and missing-rate guard (core buckets)
  // ─────────────────────
  const { pay, charge } = payChargeFromContract(contract);

  const anyMissing = (h, P, C) =>
    (h.day   > 0 && (P.day   == null || C.day   == null)) ||
    (h.night > 0 && (P.night == null || C.night == null)) ||
    (h.sat   > 0 && (P.sat   == null || C.sat   == null)) ||
    (h.sun   > 0 && (P.sun   == null || C.sun   == null)) ||
    (h.bh    > 0 && (P.bh    == null || C.bh    == null));

  if (anyMissing(hours, pay, charge)) {
    return withCORS(
      env,
      req,
      badRequest('Missing rate(s) in contract for one or more entered hour buckets')
    );
  }

  // ─────────────────────
  // 3) Additional units + totals (inline, no computeWeeklyAdditionalFromTs)
  // ─────────────────────
  // Staged week units from FE (e.g. { "CALL": 2, "TRAIN": 1 })
  let unitsWeek = body?.additional_units_week || {};
  if (!unitsWeek || typeof unitsWeek !== 'object') unitsWeek = {};

  // Contract additional rates config
  let cfgArr = contract.additional_rates_json || [];
  if (typeof cfgArr === 'string') {
    try { cfgArr = JSON.parse(cfgArr); } catch { cfgArr = []; }
  }
  if (!Array.isArray(cfgArr)) cfgArr = [];

  const additional_units_json = {};
  let additional_pay_ex_vat    = 0;
  let additional_charge_ex_vat = 0;

  for (const [rawCode, rawUnits] of Object.entries(unitsWeek)) {
    const units = Number(rawUnits || 0);
    if (!Number.isFinite(units) || units <= 0) continue;

    const code = String(rawCode || '').toUpperCase();
    const cfg  = cfgArr.find(
      c => c && String(c.code || '').toUpperCase() === code
    ) || {};

    const bucketName = (cfg.bucket_name || code || '').trim();
    const unitName   = (cfg.unit_name   || 'units').trim();

    const payRate    = Number(cfg.pay_rate    || 0);
    const chargeRate = Number(cfg.charge_rate || 0);

    const payEx = round2(units * payRate);
    const chgEx = round2(units * chargeRate);

    // ✅ PAYE margin must include ERNI (finance window by anchor), when applicable
    const payCostEx = erniApplies ? round2(payEx * erniMult) : payEx;
    const marEx     = round2(chgEx - payCostEx);

    additional_units_json[code] = {
      code,
      bucket_name: bucketName,
      unit_name:   unitName,
      unit_count:  units,
      pay_rate:    payRate || null,
      charge_rate: chargeRate || null,
      pay_ex_vat:  payEx,
      charge_ex_vat: chgEx,
      margin_ex_vat: marEx,

      // helpful for UI/debugging
      ...(erniApplies ? { pay_cost_ex_vat_including_erni: payCostEx } : {})
    };

    additional_pay_ex_vat    += payEx;
    additional_charge_ex_vat += chgEx;
  }

  additional_pay_ex_vat    = round2(additional_pay_ex_vat);
  additional_charge_ex_vat = round2(additional_charge_ex_vat);

  // ✅ additional margin uses ERNI-adjusted pay cost when PAYE
  const additional_pay_cost_ex_vat = erniApplies ? round2(additional_pay_ex_vat * erniMult) : additional_pay_ex_vat;
  const additional_margin_ex_vat   = round2(additional_charge_ex_vat - additional_pay_cost_ex_vat);

  // ─────────────────────
  // 4) Core hours totals + overall totals
  // ─────────────────────
  const hoursPayEx = round2(
    hours.day   * (pay.day   || 0) +
    hours.night * (pay.night || 0) +
    hours.sat   * (pay.sat   || 0) +
    hours.sun   * (pay.sun   || 0) +
    hours.bh    * (pay.bh    || 0)
  );

  const hoursChargeEx = round2(
    hours.day   * (charge.day   || 0) +
    hours.night * (charge.night || 0) +
    hours.sat   * (charge.sat   || 0) +
    hours.sun   * (charge.sun   || 0) +
    hours.bh    * (charge.bh    || 0)
  );

  // Totals (pay totals remain "worker pay"; margin uses employer-cost if PAYE+ERNI applies)
  const total_pay_ex_vat    = round2(hoursPayEx + additional_pay_ex_vat);
  const total_charge_ex_vat = round2(hoursChargeEx + additional_charge_ex_vat);

  const total_pay_cost_ex_vat = erniApplies ? round2(total_pay_ex_vat * erniMult) : total_pay_ex_vat;
  const margin_ex_vat         = round2(total_charge_ex_vat - total_pay_cost_ex_vat);

  if (margin_ex_vat < 0) {
    return withCORS(
      env,
      req,
      badRequest(
        erniApplies
          ? 'Negative margin (PAYE + ERNI applied): total charge is less than total pay cost including ERNI.'
          : 'Negative margin: total charge is less than total pay for the staged hours/rates.'
      )
    );
  }

  return withCORS(env, req, ok({
    hours,
    pay,
    charge,

    // finance context (anchored to match TSFIN rules)
    finance: {
      apply_erni_to: applyErniTo,
      erni_pct: Number(erniPctRaw ?? 0),
      erni_multiplier: erniMult,
      erni_applies: !!erniApplies,
      anchor: financeAnchorKind,
      anchor_ymd: financeAnchorYmd
    },

    additional_units_json,
    additional_pay_ex_vat,
    additional_charge_ex_vat,
    additional_margin_ex_vat,

    total_pay_ex_vat,
    total_charge_ex_vat,
    margin_ex_vat,

    // helpful for UI/debugging (PAYE employer-cost view)
    ...(erniApplies ? { total_pay_cost_ex_vat_including_erni: total_pay_cost_ex_vat } : {})
  }));
}

function normaliseScheduleBreakFields(schedule = []) {
  if (!Array.isArray(schedule)) return [];

  return schedule.map(seg => {
    const s = { ...(seg || {}) };

    const hasBreakWindows =
      (Array.isArray(s.breaks) && s.breaks.length > 0) ||
      (s.break_start != null && String(s.break_start).trim()) ||
      (s.break_end   != null && String(s.break_end).trim());

    if (hasBreakWindows) {
      // If we have explicit windows, drop summary break minutes
      delete s.break_minutes;
      delete s.break_mins;
    }

    return s;
  });
}

// ─────────────────────────────────────────────────────────────
// QR helpers (TSQ1 payload + HMAC + PNG generation + store)
// ─────────────────────────────────────────────────────────────

function base64UrlEncode(input) {
  const bytes =
    input instanceof Uint8Array
      ? input
      : textEncoder.encode(String(input));

  let binary = '';
  for (let i = 0; i < bytes.length; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  let b64 = btoa(binary);
  // URL-safe
  b64 = b64.replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/g, '');
  return b64;
}

function base64UrlDecode(str) {
  let b64 = str.replace(/-/g, '+').replace(/_/g, '/');
  const pad = b64.length % 4;
  if (pad) b64 += '='.repeat(4 - pad);

  const binary = atob(b64);
  const bytes = new Uint8Array(binary.length);
  for (let i = 0; i < binary.length; i++) {
    bytes[i] = binary.charCodeAt(i);
  }
  return bytes;
}

function randomNonceHex(lenBytes = 16) {
  const arr = new Uint8Array(lenBytes);
  crypto.getRandomValues(arr);
  let out = '';
  for (let i = 0; i < arr.length; i++) {
    out += arr[i].toString(16).padStart(2, '0');
  }
  return out;
}

function nowIso() {
  return new Date().toISOString();
}

/**
 * Build the TSQ1 payload JSON object with keys in fixed order.
 *
 * @param {Object} args
 * @param {string} args.timesheet_id
 * @param {string} args.contract_week_id
 * @param {string} args.contract_id
 * @param {string} args.candidate_id
 * @param {string} args.client_id
 * @param {string} args.week_ending_ymd  // 'YYYY-MM-DD'
 */
function buildTsq1Payload({ qr_token }) {
  const tok = String(qr_token || '').trim();
  if (!tok) throw new Error('buildTsq1Payload requires qr_token');

  return { v: 1, tok };
}


/**
 * Compute base64url(HMAC-SHA256("TSQ1.<payload_b64url>", secret)).
 *
 * Uses Workers crypto.subtle with env.QR_SIGNING_SECRET as raw key bytes.
 *
 * @param {string} payloadB64url
 * @param {Object} env
 * @returns {Promise<string>} sig_b64url
 */
async function signTsq1(payloadB64url, env) {
  const secret = env.QR_SIGNING_SECRET || '';
  if (!secret) throw new Error('QR_SIGNING_SECRET is not configured');

  const keyData = textEncoder.encode(secret);
  const key = await crypto.subtle.importKey(
    'raw',
    keyData,
    { name: 'HMAC', hash: 'SHA-256' },
    false,
    ['sign']
  );

  const data = textEncoder.encode(`TSQ1.${payloadB64url}`);
  const sigBuf = await crypto.subtle.sign('HMAC', key, data);
  return base64UrlEncode(new Uint8Array(sigBuf));
}

/**
 * Build the final QR text string:
 *   TSQ1.<payload_b64url>.<sig_b64url>
 *
 * @param {Object} payloadObj - result of buildTsq1Payload()
 * @param {Object} env
 * @returns {Promise<string>} qrText
 */
async function buildTsq1String(payloadObj, env) {
  if (!payloadObj || typeof payloadObj !== 'object') {
    throw new Error('TSQ1 payload missing');
  }

  // Critical: all issued QR codes must include tok so reissue can invalidate old prints.
  if (!payloadObj.tok || typeof payloadObj.tok !== 'string' || !payloadObj.tok.trim()) {
    throw new Error('TSQ1 payload missing tok (qr_token). Generate token first, then build TSQ1.');
  }

  // JSON.stringify preserves insertion order of non-integer keys
  const json = JSON.stringify(payloadObj); // compact, no spaces
  const payloadB64url = base64UrlEncode(json);
  const sigB64url = await signTsq1(payloadB64url, env);
  return `TSQ1.${payloadB64url}.${sigB64url}`;
}
/**
 * (Option A) PNG generation is disabled.
 * QR codes must be drawn directly into the PDF from the TSQ1 string/modules.
 *
 * This function is left intentionally to fail-fast if any legacy call site
 * still tries to generate a PNG in a Worker (which requires canvas).
 */
async function generateQrPng(qrText) {
  void qrText;
  throw new Error('generateQrPng is disabled under Option A. Draw QR modules into the PDF instead.');
}

/**
 * Create a signed TSQ1 QR string and store ONLY the TSQ1 payload on the
 * current timesheet version row (no PNG, no R2).
 *
 * @param {Object} env
 * @param {Object} args
 * @param {string} args.timesheet_id     - timesheets.timesheet_id
 * @param {string} args.contract_week_id - contract_weeks.id (or null for daily)
 * @param {string} args.contract_id      - contracts.id
 * @param {string} args.candidate_id     - contracts.candidate_id
 * @param {string} args.client_id        - contracts.client_id
 * @param {string} args.week_ending_ymd  - 'YYYY-MM-DD' (or worked date ymd for daily)
 * @param {string} args.qr_token         - REQUIRED (generate token first)
 * @returns {Promise<{ qrText: string, qr_r2_key: null }>}
 */
async function generateAndStoreTimesheetQr(env, {
  timesheet_id,
  contract_week_id,
  contract_id,
  candidate_id,
  client_id,
  week_ending_ymd,
  qr_token // NEW (required)
}) {
  if (!qr_token || typeof qr_token !== 'string' || !qr_token.trim()) {
    throw new Error('generateAndStoreTimesheetQr requires qr_token (generate token first)');
  }

  // 1) Build payload (includes tok)
  const payload = buildTsq1Payload({
    timesheet_id,
    contract_week_id,
    contract_id,
    candidate_id,
    client_id,
    week_ending_ymd,
    qr_token
  });

  // 2) Build TSQ1.<payload_b64url>.<sig_b64url>
  const qrText = await buildTsq1String(payload, env);

  // 3) Patch ONLY the current timesheet version row
  // IMPORTANT: timesheet_id is versioned; never PATCH by timesheet_id alone.
  const url =
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
    `?timesheet_id=eq.${encodeURIComponent(timesheet_id)}` +
    `&is_current=eq.true`;

  const patchBody = {
    // Option A: no stored PNG key
    qr_r2_key: null,

    // Store the exact payload used to generate the QR (schema has qr_payload_json NOT NULL)
    qr_payload_json: payload
  };

  const r = await fetch(url, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
    body: JSON.stringify(patchBody)
  });

  if (!r.ok) {
    const t = await r.text().catch(() => '');
    throw new Error(`Failed to patch timesheets current row for QR: ${r.status} ${t}`);
  }

  return { qrText, qr_r2_key: null };
}
async function handleTimesheetQrResendEmail(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  // ✅ Guarded write: require expected_timesheet_id
  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // ✅ stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = resolved.current_timesheet_id;

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  const cleanKey = (k) => String(k || '').replace(/^\/+/, '').trim();

  const patchTimesheetCurrentOrThrow = async (patchBody, label) => {
    const url =
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true`;

    const r = await fetch(url, {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
      body: JSON.stringify(patchBody)
    });

    if (!r.ok) {
      const t = await r.text().catch(() => '');
      throw new Error(`[QR_RESEND] timesheet patch failed (${label}): ${r.status} ${t}`);
    }
  };

  // Load current timesheet
  let ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );
  if (!ts) return withCORS(env, req, notFound('Timesheet not found'));

  const scope = String(ts.sheet_scope || '').toUpperCase();

  let qrStatus = String(ts.qr_status || '').toUpperCase();
  let hasToken = !!(ts.qr_token && String(ts.qr_token).trim());
  let hasGeneratedAt = !!ts.qr_generated_at;
  let scannedAt = ts.qr_scanned_at || null;

  // ✅ NEW: never allow resend/reissue if signed markers exist
  const hasSignedMarkers =
    !!ts.qr_scanned_at ||
    !!(ts.qr_signed_hash && String(ts.qr_signed_hash).trim());
  if (hasSignedMarkers) {
    return withCORS(env, req, badRequest('Cannot resend/reissue: timesheet already has signed markers'));
  }

  if (qrStatus === 'EXPIRED') {
    return withCORS(env, req, badRequest('QR is expired; reissue required'));
  }
  if (qrStatus !== 'PENDING') {
    return withCORS(env, req, badRequest(`QR send not allowed (qr_status=${qrStatus || 'NULL'})`));
  }

  // Internal state classification (NOT user-facing)
  const awaitingSignatureUpload = (hasToken && hasGeneratedAt && !scannedAt); // issued, not scanned
  const notYetIssued = (!scannedAt && (!hasToken || !hasGeneratedAt));       // no token/gen

  if (!notYetIssued && !awaitingSignatureUpload) {
    return withCORS(env, req, badRequest('QR send not allowed in current state'));
  }

  // ✅ Must have hours before sending
  const hasHoursForSend = (() => {
    if (scope === 'WEEKLY') {
      const arr = Array.isArray(ts.actual_schedule_json) ? ts.actual_schedule_json : [];
      return arr.some(seg => {
        if (!seg || typeof seg !== 'object') return false;
        const s = String(seg.start || '').trim();
        const e = String(seg.end || '').trim();
        return !!(s && e);
      });
    }
    const ws = ts.worked_start_iso ? String(ts.worked_start_iso).trim() : '';
    const we = ts.worked_end_iso   ? String(ts.worked_end_iso).trim()   : '';
    return !!(ws && we);
  })();

  if (!hasHoursForSend) {
    return withCORS(env, req, badRequest('Cannot send: no hours recorded yet'));
  }

  // Resolve contract + candidate email first
  if (!ts.contract_id) {
    return withCORS(env, req, badRequest('Cannot send: timesheet.contract_id is missing'));
  }

  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?id=eq.${enc(ts.contract_id)}` +
      `&select=id,candidate_id,client_id` +
      `&limit=1`
  );
  if (!contract) return withCORS(env, req, badRequest('Cannot send: contract not found'));

  const cand = contract.candidate_id
    ? await sbGetOne(
        env,
        `${env.SUPABASE_URL}/rest/v1/candidates` +
          `?id=eq.${enc(contract.candidate_id)}` +
          `&select=id,display_name,email` +
          `&limit=1`
      )
    : null;

  const toEmail = cand?.email ? String(cand.email).trim() : null;
  if (!toEmail) return withCORS(env, req, badRequest('Candidate email not found'));

  // TSFIN defence-in-depth
  try {
    const fin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=id,processing_status,locked_by_invoice_id,paid_at_utc` +
        `&limit=1`
    );

    if (fin && (fin.locked_by_invoice_id || fin.paid_at_utc)) {
      return withCORS(env, req, badRequest('Cannot send: timesheet is invoiced/locked or paid'));
    }

    if (fin && String(fin.processing_status || '').toUpperCase() !== 'AWAITING_MANUAL_SIGNATURE') {
      const nowFix = nowIso();
      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify({
            processing_status: 'AWAITING_MANUAL_SIGNATURE',
            updated_at: nowFix
          })
        }
      ).catch(() => {});
    }
  } catch {}

  const dateLabel =
    (scope === 'WEEKLY')
      ? (ts.week_ending_date || '')
      : (ts.worked_start_iso ? String(ts.worked_start_iso).slice(0, 10) : '');

  // ------------------------------------------------------------
  // Hash: compute current printable-content hash
  // ------------------------------------------------------------
  const stableClone = (v) => {
    if (Array.isArray(v)) return v.map(stableClone);
    if (v && typeof v === 'object') {
      const out = {};
      for (const k of Object.keys(v).sort()) out[k] = stableClone(v[k]);
      return out;
    }
    return v;
  };

  const hashObj = {
    sheet_scope: scope || null,
    week_ending_date: ts.week_ending_date || null,
    worked_start_iso: ts.worked_start_iso || null,
    worked_end_iso: ts.worked_end_iso || null,
    break_start_iso: ts.break_start_iso || null,
    break_end_iso: ts.break_end_iso || null,
    break_minutes: (ts.break_minutes != null ? ts.break_minutes : null),
    reference_number: ts.reference_number || null,
    day_references_json: ts.day_references_json || null,
    actual_schedule_json: ts.actual_schedule_json || null,
    additional_units_week: ts.additional_units_week || null,
    additional_units_per_day: ts.additional_units_per_day || null
  };

  let current_hash = null;
  try {
    current_hash = await sha256Hex(JSON.stringify(stableClone(hashObj)));
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to compute QR content hash: ${e?.message || e}`));
  }

  const prev_last_sent_hash = (ts.qr_last_sent_hash != null) ? String(ts.qr_last_sent_hash) : '';
  const hasPrevHash = !!String(prev_last_sent_hash || '').trim();
  const canResendSameHours = hasPrevHash && (String(prev_last_sent_hash) === String(current_hash));

  const mustReissueBecauseHoursChanged =
    awaitingSignatureUpload && hasPrevHash && !canResendSameHours;

  const mustReissueBecauseNoBaselineHash =
    awaitingSignatureUpload && !hasPrevHash;

  let result = null; // 'NEW_ISSUED' | 'RESENT' | 'REISSUED'

  // ------------------------------------------------------------
  // If we need a new token: create it + persist token/gen properly
  // ------------------------------------------------------------
  let qrTokenToUse = (ts.qr_token && String(ts.qr_token).trim()) ? String(ts.qr_token).trim() : null;
  let qr_r2_key = ts.qr_r2_key || null;

  // ✅ NEW: remember old QR key so we can delete it if we reissue and successfully repoint
  const oldQrKey = ts.qr_r2_key ? cleanKey(ts.qr_r2_key) : null;

  if (notYetIssued || mustReissueBecauseHoursChanged || mustReissueBecauseNoBaselineHash) {
    const now2 = nowIso();

    let qrToken;
    try {
      qrToken = (typeof crypto !== 'undefined' && typeof crypto.randomUUID === 'function')
        ? crypto.randomUUID()
        : `${currentTimesheetId}:${Date.now()}`;
    } catch {
      qrToken = `${currentTimesheetId}:${Date.now()}`;
    }

    // Store TSQ1 payload on current row
    let qrRes = null;
    try {
      qrRes = await generateAndStoreTimesheetQr(env, {
        timesheet_id: currentTimesheetId,
        contract_week_id: null,
        contract_id: contract.id,
        candidate_id: contract.candidate_id || null,
        client_id: contract.client_id || null,
        week_ending_ymd: (scope === 'WEEKLY') ? (ts.week_ending_date || null) : (dateLabel || null),
        qr_token: qrToken
      });
    } catch (e) {
      return withCORS(env, req, serverError(`Failed to generate QR: ${e?.message || e}`));
    }

    qrTokenToUse = qrToken;
    qr_r2_key = qrRes?.qr_r2_key || null;

    try {
      await patchTimesheetCurrentOrThrow({
        qr_token: qrToken,
        qr_status: 'PENDING',
        qr_generated_at: now2,
        qr_scanned_at: null,
        qr_scan_info_json: null,
        qr_r2_key: qr_r2_key || null,
        updated_at: now2
      }, 'issue_token');
    } catch (e) {
      return withCORS(env, req, serverError(e?.message || 'Failed to persist QR token'));
    }

    // ✅ NEW: delete old QR image key now that we replaced it (best-effort)
    try {
      const bucket = env.R2_BUCKET || env.R2;
      const newQrKey = qr_r2_key ? cleanKey(qr_r2_key) : null;
      if (bucket && typeof bucket.delete === 'function' && oldQrKey && newQrKey && oldQrKey !== newQrKey) {
        await bucket.delete(oldQrKey).catch(() => {});
      }
    } catch {
      // non-fatal
    }

    result = notYetIssued ? 'NEW_ISSUED' : 'REISSUED';

    // Reload so any subsequent logic sees the issued state
    ts = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true` +
        `&select=*` +
        `&limit=1`
    );
  } else {
    result = 'RESENT';
  }

  // ✅ Ensure we have a GENERATED printable PDF to attach
  let pdfKey = null;
  try {
    pdfKey = await renderTimesheetPDFAndSave(env, currentTimesheetId);
  } catch (e) {
    return withCORS(env, req, serverError('Failed to prepare timesheet PDF for send'));
  }
  if (!pdfKey) return withCORS(env, req, serverError('No PDF available to send'));

  // ✅ OPTIONAL: ensure manual_pdf_r2_key points to the generated PDF if blank (materialises evidence)
  try {
    const patchUrl =
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&or=(manual_pdf_r2_key.is.null,manual_pdf_r2_key.eq.)`;

    await fetch(
      patchUrl,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          manual_pdf_r2_key: pdfKey,
          updated_at: nowIso()
        })
      }
    ).catch(() => {});
  } catch {
    // non-fatal
  }

  const subject =
    (scope === 'WEEKLY')
      ? `Weekly QR timesheet – week ending ${dateLabel || '(unknown)'}`
      : `Daily QR timesheet – ${dateLabel || '(unknown date)'}`;

  const lines = [
    `Please print the attached timesheet, ask the ward manager to sign it,`,
    `and then upload the signed copy via the app.`,
    ``,
    ...(dateLabel ? [`Date: ${dateLabel}`] : []),
    `Timesheet ID: ${currentTimesheetId}`
  ];
  const body_text = lines.join('\n');
  const body_html = `<p>${lines.map(l => (l === '' ? '<br/>' : l)).join('<br/>')}</p>`;

  const insert = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      type: 'TIMESHEET_QR',
      to: toEmail,
      cc: null,
      subject,
      body_html,
      body_text,
      attachments: [{ r2_key: pdfKey, filename: `Timesheet_${dateLabel || currentTimesheetId}.pdf` }],
      status: 'QUEUED',
      reference: `timesheet_qr:${String(result || 'send').toLowerCase()}:${currentTimesheetId}`,
      created_by: user?.id || null
    })
  });

  if (!insert.ok) {
    const t = await insert.text().catch(() => '');
    return withCORS(env, req, serverError(`Failed to queue QR email: ${t}`));
  }

  // Persist last-sent hash + timestamp (non-fatal if migration not present)
  const nowSent = nowIso();
  try {
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          qr_last_sent_hash: current_hash,
          qr_last_sent_at_utc: nowSent,
          updated_at: nowSent
        })
      }
    ).catch(() => {});
  } catch {}

  // Audit
  try {
    await writeAudit(
      env,
      user,
      'QR_RESENT',
      {
        timesheet_id: currentTimesheetId,
        pdf_r2_key: pdfKey,
        to: toEmail,
        result,
        current_hash,
        prev_last_sent_hash: prev_last_sent_hash || null,
        qr_token_written: !!(qrTokenToUse && String(qrTokenToUse).trim())
      },
      { entity: 'timesheets', subject_id: currentTimesheetId, req }
    );
  } catch {}

  return withCORS(env, req, ok({
    queued: true,
    result, // 'NEW_ISSUED' | 'RESENT' | 'REISSUED'
    timesheet_id: currentTimesheetId,
    current_timesheet_id: currentTimesheetId,
    requested_timesheet_id: resolved.requested_timesheet_id || timesheetId,
    was_stale: !!resolved.was_stale,

    pdf_key: pdfKey,

    // Action hints for UI
    qr_can_resend_same_hours: true,
    current_hash,
    qr_last_sent_hash: current_hash
  }));
}

async function handleTimesheetQrRestore(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  // ✅ Guarded write
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // ✅ stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved?.current_timesheet_id) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = String(resolved.current_timesheet_id);

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  // required: kind = 'PENDING' | 'SIGNED' (matches SQL)
  const kindRaw = String(body?.kind || body?.restore_kind || body?.p_restore_kind || '').toUpperCase();
  if (kindRaw !== 'PENDING' && kindRaw !== 'SIGNED') {
    return withCORS(env, req, badRequest('kind must be PENDING or SIGNED'));
  }

  // Helper: map SQL-raised JSON to 409
  const tryParseMovedFromRpcError = (text) => {
    const t = String(text || '');
    const start = t.indexOf('{');
    const end = t.lastIndexOf('}');
    if (start >= 0 && end > start) {
      const chunk = t.slice(start, end + 1);
      try {
        const j = JSON.parse(chunk);
        if (j && j.error === 'TIMESHEET_MOVED' && j.current_timesheet_id) return j;
      } catch {}
    }
    return null;
  };

  const rpcRes = await fetch(`${env.SUPABASE_URL}/rest/v1/rpc/timesheet_qr_restore_version`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      p_timesheet_id: currentTimesheetId,
      p_expected_timesheet_id: expected,        // ✅ REQUIRED by SQL
      p_restore_kind: kindRaw,                  // ✅ REQUIRED by SQL
      p_actor_user_id: user?.id || null
    })
  });

  if (!rpcRes.ok) {
    const t = await rpcRes.text().catch(() => '');
    const moved = tryParseMovedFromRpcError(t);
    if (moved) {
      return withCORS(
        env,
        req,
        new Response(JSON.stringify(moved), { status: 409, headers: { 'Content-Type': 'application/json' } })
      );
    }
    return withCORS(env, req, badRequest(`Restore failed: ${t}`));
  }

  const rpcRows = await rpcRes.json().catch(() => []);
  const rpcRow = Array.isArray(rpcRows) ? rpcRows[0] : rpcRows;

  // ✅ Re-resolve after RPC (defensive if RPC rotates)
  let afterId = currentTimesheetId;
  try {
    const resolvedAfter = await resolveTimesheetToCurrent(env, currentTimesheetId);
    if (resolvedAfter?.current_timesheet_id) afterId = String(resolvedAfter.current_timesheet_id);
  } catch {}

  // Fetch new current state
  let tsCur = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(afterId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );

  let finCur = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(afterId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );

  // ─────────────────────────────────────────────────────────────
  // ✅ NEW: reset / recompute QR hash fields for truth rules
  // ─────────────────────────────────────────────────────────────
  try {
    const now = nowIso();

    const stableClone = (v) => {
      if (Array.isArray(v)) return v.map(stableClone);
      if (v && typeof v === 'object') {
        const out = {};
        for (const k of Object.keys(v).sort()) out[k] = stableClone(v[k]);
        return out;
      }
      return v;
    };

    const computeCurrentHash = async (tsRow) => {
      const scope = String(tsRow?.sheet_scope || '').toUpperCase();
      if (scope === 'WEEKLY') {
        const obj = {
          sheet_scope: 'WEEKLY',
          week_ending_date: tsRow?.week_ending_date || null,
          actual_schedule_json: tsRow?.actual_schedule_json || null,
          reference_number: tsRow?.reference_number || null,
          day_references_json: tsRow?.day_references_json || null,
          additional_units_week: tsRow?.additional_units_week || {},
          additional_units_per_day: tsRow?.additional_units_per_day || {}
        };
        return await sha256Hex(JSON.stringify(stableClone(obj)));
      }

      // DAILY
      const obj = {
        sheet_scope: 'DAILY',
        worked_start_iso: tsRow?.worked_start_iso || null,
        worked_end_iso: tsRow?.worked_end_iso || null,
        break_start_iso: tsRow?.break_start_iso || null,
        break_end_iso: tsRow?.break_end_iso || null,
        break_minutes: (tsRow?.break_minutes != null ? tsRow.break_minutes : null),
        reference_number: tsRow?.reference_number || null,
        day_references_json: tsRow?.day_references_json || null
      };
      return await sha256Hex(JSON.stringify(stableClone(obj)));
    };

    if (kindRaw === 'PENDING') {
      // Ensure signed markers are cleared for a pending restore
      const patch = {
        qr_signed_hash: null,
        qr_signed_at_utc: null,
        updated_at: now
      };

      await fetch(
        `${env.SUPABASE_URL}/rest/v1/timesheets` +
          `?timesheet_id=eq.${enc(afterId)}&is_current=eq.true`,
        {
          method: 'PATCH',
          headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
          body: JSON.stringify(patch)
        }
      ).catch(() => {});
    }

    if (kindRaw === 'SIGNED') {
      const hasScan = !!(tsCur?.qr_scanned_at);
      const hasSignedPdf = !!(tsCur?.manual_pdf_r2_key && String(tsCur.manual_pdf_r2_key).trim());
      const existingSignedHash = (tsCur?.qr_signed_hash != null) ? String(tsCur.qr_signed_hash).trim() : '';

      // If this restored version has a signed scan + signed pdf but hash is missing, recompute.
      if (hasScan && hasSignedPdf && !existingSignedHash) {
        const h = await computeCurrentHash(tsCur);
        const patch = {
          qr_signed_hash: h,
          qr_signed_at_utc: tsCur.qr_scanned_at || now,
          updated_at: now
        };

        await fetch(
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?timesheet_id=eq.${enc(afterId)}&is_current=eq.true`,
          {
            method: 'PATCH',
            headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
            body: JSON.stringify(patch)
          }
        ).catch(() => {});
      }
    }

    // Re-fetch so caller gets the post-patch view
    tsCur = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(afterId)}` +
        `&is_current=eq.true` +
        `&select=*` +
        `&limit=1`
    );
  } catch (e) {
    // Best-effort: do not fail restore if hash patching fails
    try {
      console.warn('[QR_RESTORE] hash reset/recompute failed (non-fatal)', {
        timesheet_id: afterId,
        kind: kindRaw,
        err: e?.message || String(e)
      });
    } catch {}
  }

  // Re-fetch TSFIN after potential patches (optional; harmless)
  finCur = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(afterId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );

  // ✅ NEW: Purge superseded versions immediately (best-effort; never blocks restore)
  try {
    const bookingId = tsCur?.booking_id ? String(tsCur.booking_id) : '';
    if (bookingId) {
      await purgeSupersededTimesheetArtifactsForBooking(env, bookingId);
    }
  } catch (e) {
    try {
      console.warn('[QR_RESTORE] purge failed (non-fatal)', {
        timesheet_id: afterId,
        err: e?.message || String(e)
      });
    } catch {}
  }

  return withCORS(env, req, ok({
    ok: true,
    timesheet_id: afterId,
    current_timesheet_id: afterId,
    requested_timesheet_id: resolved?.requested_timesheet_id || timesheetId,
    was_stale: !!resolved?.was_stale,

    restored: rpcRow || null,
    timesheet: tsCur || null,
    tsfin: finCur || null
  }));
}


async function handleTimesheetQrRefuseAndReset(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  let body = null;
  try { body = await parseJSONBody(req); } catch { body = null; }

  // ✅ Guarded write
  const expected = body?.expected_timesheet_id ? String(body.expected_timesheet_id) : '';
  if (!expected) return withCORS(env, req, badRequest('expected_timesheet_id is required'));

  // ✅ stale-safe resolve
  const resolved = await resolveTimesheetToCurrent(env, timesheetId);
  if (!resolved?.current_timesheet_id) return withCORS(env, req, notFound('Timesheet not found'));
  const currentTimesheetId = String(resolved.current_timesheet_id);

  // ✅ Guard mismatch → 409 TIMESHEET_MOVED
  if (String(expected) !== String(currentTimesheetId)) {
    return withCORS(
      env,
      req,
      new Response(
        JSON.stringify({ error: 'TIMESHEET_MOVED', current_timesheet_id: currentTimesheetId }),
        { status: 409, headers: { 'Content-Type': 'application/json' } }
      )
    );
  }

  const reason =
    (body && typeof body.reason === 'string')
      ? body.reason
      : (body && typeof body.rejected_reason === 'string' ? body.rejected_reason : '');

  const reasonTrim = String(reason || '').trim();

  // Helper: map SQL-raised JSON to 409
  const tryParseMovedFromRpcError = (text) => {
    const t = String(text || '');
    const start = t.indexOf('{');
    const end = t.lastIndexOf('}');
    if (start >= 0 && end > start) {
      const chunk = t.slice(start, end + 1);
      try {
        const j = JSON.parse(chunk);
        if (j && j.error === 'TIMESHEET_MOVED' && j.current_timesheet_id) return j;
      } catch {}
    }
    return null;
  };

  // Call SQL RPC — operate on CURRENT id
  const rpcRes = await fetch(`${env.SUPABASE_URL}/rest/v1/rpc/timesheet_qr_refuse_and_reset`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      p_timesheet_id: currentTimesheetId,
      p_expected_timesheet_id: expected,                 // ✅ REQUIRED by SQL
      p_reason: reasonTrim || null,
      p_actor_user_id: user?.id || null
    })
  });

  if (!rpcRes.ok) {
    const t = await rpcRes.text().catch(() => '');
    const moved = tryParseMovedFromRpcError(t);
    if (moved) {
      return withCORS(
        env,
        req,
        new Response(JSON.stringify(moved), { status: 409, headers: { 'Content-Type': 'application/json' } })
      );
    }
    return withCORS(env, req, badRequest(`Refuse failed: ${t}`));
  }

  const rpcRows = await rpcRes.json().catch(() => []);
  const rpcRow = Array.isArray(rpcRows) ? rpcRows[0] : rpcRows;

  // ✅ Re-resolve after RPC (defensive if RPC rotates)
  let afterId = currentTimesheetId;
  try {
    const resolvedAfter = await resolveTimesheetToCurrent(env, currentTimesheetId);
    if (resolvedAfter?.current_timesheet_id) afterId = String(resolvedAfter.current_timesheet_id);
  } catch {}

  // ✅ NEW: refusal/reset creates a fresh "awaiting hours" QR-enabled state.
  // Clear both issued+signed hash fields so evidence/stage truth rules don't treat it as sent/signed.
  try {
    const now = nowIso();
    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets` +
        `?timesheet_id=eq.${enc(afterId)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({
          qr_last_sent_hash: null,
          qr_last_sent_at_utc: null,
          qr_signed_hash: null,
          qr_signed_at_utc: null,
          updated_at: now
        })
      }
    ).catch(() => {});
  } catch (e) {
    // Best-effort: do not fail refuse if hash clearing fails
    try {
      console.warn('[QR_REFUSE] failed to clear qr hash fields (non-fatal)', {
        timesheet_id: afterId,
        err: e?.message || String(e)
      });
    } catch {}
  }

  // Resolve candidate email via contract on the CURRENT row after RPC
  const tsCur = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(afterId)}` +
      `&is_current=eq.true` +
      `&select=contract_id,sheet_scope,week_ending_date,worked_start_iso` +
      `&limit=1`
  );

  let queuedEmail = false;

  if (tsCur?.contract_id) {
    const contract = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contracts` +
        `?id=eq.${enc(tsCur.contract_id)}` +
        `&select=id,candidate_id,client_id` +
        `&limit=1`
    );

    const cand = contract?.candidate_id
      ? await sbGetOne(
          env,
          `${env.SUPABASE_URL}/rest/v1/candidates` +
            `?id=eq.${enc(contract.candidate_id)}` +
            `&select=id,display_name,email` +
            `&limit=1`
        )
      : null;

    const toEmail = cand?.email ? String(cand.email).trim() : null;

    if (toEmail) {
      const scope = String(tsCur.sheet_scope || '').toUpperCase();
      const dateLabel =
        (scope === 'WEEKLY')
          ? (tsCur.week_ending_date || '')
          : (tsCur.worked_start_iso ? String(tsCur.worked_start_iso).slice(0, 10) : '');

      const subject =
        (scope === 'WEEKLY')
          ? `Weekly timesheet refused – week ending ${dateLabel || '(unknown)'}`
          : `Daily timesheet refused – ${dateLabel || '(unknown date)'}`;

      const lines = [
        `Your submitted timesheet has been refused.`,
        ``,
        ...(reasonTrim ? [`Reason: ${reasonTrim}`, ``] : []),
        `Please open the app and resubmit as requested.`,
        ``,
        `Timesheet ID: ${afterId}`
      ];
      const body_text = lines.join('\n');
      const body_html = `<p>${lines.map(l => (l === '' ? '<br/>' : l)).join('<br/>')}</p>`;

      const out = await fetch(`${env.SUPABASE_URL}/rest/v1/mail_outbox`, {
        method: 'POST',
        headers: { ...sbHeaders(env), Prefer: 'return=representation' },
        body: JSON.stringify({
          type: 'TIMESHEET_REFUSAL',
          to: toEmail,
          cc: null,
          subject,
          body_html,
          body_text,
          attachments: null,
          status: 'QUEUED',
          reference: `timesheet_qr:refused:${afterId}`,
          created_by: user?.id || null
        })
      });

      queuedEmail = out.ok;
    }
  }

  const tsFull = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(afterId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );

  const fin = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(afterId)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );

  // ✅ NEW: Purge superseded versions immediately (best-effort; never blocks refusal)
  try {
    const bookingId = tsFull?.booking_id ? String(tsFull.booking_id) : '';
    if (bookingId) {
      await purgeSupersededTimesheetArtifactsForBooking(env, bookingId);
    }
  } catch (e) {
    try {
      console.warn('[QR_REFUSE] purge failed (non-fatal)', {
        timesheet_id: afterId,
        err: e?.message || String(e)
      });
    } catch {}
  }

  return withCORS(env, req, ok({
    ok: true,
    timesheet_id: afterId,
    current_timesheet_id: afterId,
    requested_timesheet_id: resolved?.requested_timesheet_id || timesheetId,
    was_stale: !!resolved?.was_stale,

    rpc: rpcRow || null,
    email_queued: queuedEmail,
    timesheet: tsFull || null,
    tsfin: fin || null
  }));
}


async function handleContractWeekDeletePlanned(env, req, contractWeekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!contractWeekId) return withCORS(env, req, badRequest('contract_week_id is required'));

  const rpcRes = await fetch(`${env.SUPABASE_URL}/rest/v1/rpc/contract_week_delete_planned`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      p_contract_week_id: contractWeekId,
      p_actor_user_id: user?.id || null
    })
  });

  if (!rpcRes.ok) {
    const t = await rpcRes.text().catch(() => '');
    return withCORS(env, req, badRequest(`Planned delete failed: ${t}`));
  }

  const rows = await rpcRes.json().catch(() => []);
  const row = Array.isArray(rows) ? rows[0] : rows;

  // RPC inserts audit event CONTRACT_WEEK_DELETED_PLANNED. :contentReference[oaicite:9]{index=9}
  return withCORS(env, req, ok({ ok: true, result: row || null }));
}

async function handleTimesheetAuditFeed(env, req, timesheetId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!timesheetId) return withCORS(env, req, badRequest('timesheet_id is required'));

  const rpcRes = await fetch(`${env.SUPABASE_URL}/rest/v1/rpc/timesheet_audit_feed`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({ p_timesheet_id: timesheetId })
  });

  if (!rpcRes.ok) {
    const t = await rpcRes.text().catch(() => '');
    return withCORS(env, req, serverError(`Audit feed failed: ${t}`));
  }

  const rows = await rpcRes.json().catch(() => []);
  return withCORS(env, req, ok({ items: rows || [] }));
}

async function handleTimesheetAuthoriseGeneric(env, req, timesheetId) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const expectedTimesheetId = body?.expected_timesheet_id || null;
  const guard = await guardCurrentTimesheetWrite(env, req, timesheetId, expectedTimesheetId);
  if (!guard.ok) return guard.res;

  const currentTimesheetId = guard.resolved.current_timesheet_id;
  const now = nowIso();

  const boolish = (v) => {
    if (v === true) return true;
    if (v === false) return false;
    if (v == null) return false;
    const s = String(v).trim().toLowerCase();
    return (s === 'true' || s === '1' || s === 'yes' || s === 'y' || s === 'on');
  };

  const hasAnySegmentInvoiceLock = (tf) => {
    try {
      const ib = tf?.invoice_breakdown_json;
      if (!ib || typeof ib !== 'object') return false;
      const mode = String(ib?.mode || '').toUpperCase();
      if (mode !== 'SEGMENTS') return false;
      const segs = Array.isArray(ib?.segments) ? ib.segments : [];
      return segs.some(s => {
        const v = s?.invoice_locked_invoice_id;
        return v != null && String(v).trim() !== '';
      });
    } catch {
      return false;
    }
  };

  // Load current TS + TSFIN
  const tsBefore = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=` +
        [
          'timesheet_id',
          'contract_id',
          'authorised_at_server',
          'submission_mode',
          'sheet_scope',
          'week_ending_date',
          'worked_start_iso',
          'worked_end_iso',
          'break_start_iso',
          'break_end_iso',
          'break_minutes',
          'reference_number',
          'day_references_json',
          'actual_schedule_json',
          'additional_units_week',
          'additional_units_per_day',
          'qr_status',
          'qr_signed_hash',
          'qr_signed_at_utc',
          'qr_scanned_at',
          'version',
          'status'
        ].join(','),
  ).catch(() => null);

  const { rows: finRows } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
      `?timesheet_id=eq.${enc(currentTimesheetId)}` +
      `&is_current=eq.true` +
      `&select=id,client_id,basis,processing_status,locked_by_invoice_id,paid_at_utc,invoice_breakdown_json` +
      `&limit=1`
  );
  const fin = finRows?.[0] || null;

  const finBeforeStatus = String(fin?.processing_status || '').toUpperCase();
  let finAfterStatus = fin?.processing_status || null;

  if (!fin) {
    return withCORS(env, req, badRequest('Cannot authorise: no financial snapshot exists for this timesheet'));
  }

  if (fin.locked_by_invoice_id || fin.paid_at_utc || hasAnySegmentInvoiceLock(fin)) {
    return withCORS(env, req, badRequest('Cannot authorise: timesheet is locked or paid'));
  }

  if (finBeforeStatus === 'AWAITING_MANUAL_SIGNATURE') {
    return withCORS(env, req, badRequest('Cannot authorise: QR timesheet is awaiting signature'));
  }

  // Signed QR stale check (unchanged)
  try {
    const signedHash = (tsBefore?.qr_signed_hash != null) ? String(tsBefore.qr_signed_hash).trim() : '';
    const hasSignedHash = !!signedHash;

    if (hasSignedHash) {
      const scope = String(tsBefore?.sheet_scope || '').toUpperCase();

      const stableClone = (v) => {
        if (Array.isArray(v)) return v.map(stableClone);
        if (v && typeof v === 'object') {
          const out = {};
          for (const k of Object.keys(v).sort()) out[k] = stableClone(v[k]);
          return out;
        }
        return v;
      };

      const currentObj = (scope === 'WEEKLY')
        ? {
            sheet_scope: 'WEEKLY',
            week_ending_date: tsBefore?.week_ending_date || null,
            actual_schedule_json: tsBefore?.actual_schedule_json || null,
            reference_number: tsBefore?.reference_number || null,
            day_references_json: tsBefore?.day_references_json || null,
            additional_units_week: tsBefore?.additional_units_week || {},
            additional_units_per_day: tsBefore?.additional_units_per_day || {}
          }
        : {
            sheet_scope: 'DAILY',
            worked_start_iso: tsBefore?.worked_start_iso || null,
            worked_end_iso: tsBefore?.worked_end_iso || null,
            break_start_iso: tsBefore?.break_start_iso || null,
            break_end_iso: tsBefore?.break_end_iso || null,
            break_minutes: (tsBefore?.break_minutes != null ? tsBefore.break_minutes : null),
            reference_number: tsBefore?.reference_number || null,
            day_references_json: tsBefore?.day_references_json || null
          };

      const currentHash = await sha256Hex(JSON.stringify(stableClone(currentObj)));

      if (String(currentHash) !== String(signedHash)) {
        return withCORS(env, req, badRequest('Cannot authorise: signed QR timesheet no longer matches current hours (revoke and request resubmission)'));
      }
    }
  } catch (e) {
    return withCORS(env, req, serverError(`Failed to validate QR signed hash: ${e?.message || e}`));
  }

  // Stamp timesheet authorised (best effort)
  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(currentTimesheetId)}&is_current=eq.true`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({ authorised_at_server: now, updated_at: now })
    }
  ).catch(() => {});

  const basisU = String(fin?.basis || '').toUpperCase();
  const forceReadyForInvoice =
    (basisU === 'NHSP' ||
     basisU === 'NHSP_ADJUSTMENT' ||
     basisU === 'HEALTHROSTER_SELF_BILL' ||
     basisU === 'HEALTHROSTER_ADJUSTMENT');

  // Fetch policy switch + validation status from v_timesheets_summary_base
  let eff = null;
  try {
    const { rows: eRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/v_timesheets_summary_base` +
        `?timesheet_id=eq.${enc(currentTimesheetId)}` +
        `&select=client_requires_hr,hr_validation_required_for_invoice,validation_status` +
        `&limit=1`
    );
    eff = eRows?.[0] || null;
  } catch {
    eff = null;
  }

  const requiresHr = eff ? boolish(eff.client_requires_hr) : false;

  const hrValidationRequiredForInvoice = eff ? boolish(eff.hr_validation_required_for_invoice) : false;
  const validationStatus = (eff?.validation_status != null) ? String(eff.validation_status).toUpperCase() : '';
  const validationOk = (validationStatus === 'VALIDATION_OK' || validationStatus === 'OVERRIDDEN');

  // ✅ NEW gating: HR validation requirement blocks READY_FOR_INVOICE until OK/OVERRIDDEN
  const mustHoldForHrValidation = (hrValidationRequiredForInvoice && !validationOk);

  let newStatus = fin.processing_status;
  const ps = finBeforeStatus;
  if (ps === 'PENDING_AUTH' || ps === 'READY_FOR_HR') {
    if (mustHoldForHrValidation) {
      newStatus = 'READY_FOR_HR';
    } else {
      newStatus = forceReadyForInvoice
        ? 'READY_FOR_INVOICE'
        : (requiresHr ? 'READY_FOR_HR' : 'READY_FOR_INVOICE');
    }
  }
  finAfterStatus = newStatus;

  await fetch(
    `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
      body: JSON.stringify({
        processing_status: newStatus,
        authorised_by_user_id: user.id,
        authorised_at_utc: now,
        updated_at: now
      })
    }
  ).catch(() => {});

  // Audit (kept)
  try {
    const wasAlreadyAuthorised = !!(tsBefore && tsBefore.authorised_at_server);
    const didPromoteStatus = String(finBeforeStatus || '') !== String(finAfterStatus || '').toUpperCase();

    if (!wasAlreadyAuthorised || didPromoteStatus) {
      await writeAudit(
        env,
        user,
        'TIMESHEET_AUTHORISED',
        {
          timesheet_id: currentTimesheetId,
          authorised_at_utc: now,
          tsfin_processing_status_before: finBeforeStatus || null,
          tsfin_processing_status_after: finAfterStatus ? String(finAfterStatus).toUpperCase() : null,
          hr_validation_required_for_invoice: hrValidationRequiredForInvoice,
          validation_status: validationStatus || null
        },
        {
          entity: 'timesheets',
          subject_id: currentTimesheetId,
          req,
          before: {
            authorised_at_server: tsBefore?.authorised_at_server || null,
            tsfin_processing_status: finBeforeStatus || null
          },
          reason: didPromoteStatus ? 'PROMOTED_TSFIN_STATUS' : 'STAMPED_AUTHORISE'
        }
      );
    }
  } catch {}

  return withCORS(env, req, ok({
    authorised: true,
    tsfin_updated: true,
    processing_status: newStatus,
    booking_id: guard.resolved.booking_id || null,
    requested_timesheet_id: guard.resolved.requested_timesheet_id || timesheetId,
    current_timesheet_id: currentTimesheetId,
    current_version: guard.resolved.current_version ?? null,
    was_stale: !!guard.resolved.was_stale
  }));
}


async function loadWeeklyContext(env, ts) {
  const enc = encodeURIComponent; // ✅ define here so global move is safe

  if (!ts || !ts.timesheet_id || !ts.contract_id || !ts.week_ending_date) {
    return null;
  }

  const cw = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
      `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
      `&select=*` +
      `&limit=1`
  );
  if (!cw) return null;

  const contract = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts` +
      `?id=eq.${enc(cw.contract_id)}` +
      `&select=*`
  );
  if (!contract) return null;

  return { cw, contract };
}


async function handleTimesheetQrScan(env, req) {
  const enc = encodeURIComponent;

  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try {
    body = await parseJSONBody(req);
  } catch {
    return withCORS(env, req, badRequest('Invalid JSON'));
  }

  const qrText = String(body?.qr_text || '').trim();
  const image_r2_key_raw = body?.image_r2_key ? String(body.image_r2_key) : '';

  if (!qrText) {
    return withCORS(env, req, badRequest('qr_text is required'));
  }

  // ✅ For signed acceptance, we require the uploaded scan key.
  // This endpoint is the “signed upload/scan acceptance” endpoint.
  const cleanKey = (k) => String(k || '').replace(/^\/+/, '').trim();
  const image_r2_key = cleanKey(image_r2_key_raw);
  if (!image_r2_key) {
    return withCORS(env, req, badRequest('image_r2_key is required'));
  }

  try {
    console.log('[QR][SCAN] incoming', {
      preview: qrText.slice(0, 64) + (qrText.length > 64 ? '…' : '')
    });
  } catch {}

  // 1) Verify signature + parse payload
  const verification = await verifyTsq1(qrText, env);
  if (!verification?.ok) {
    return withCORS(env, req, badRequest(`Invalid QR: ${verification?.reason || 'UNKNOWN'}`));
  }

  const p = verification.payload || {};
  const payloadToken = (p && typeof p.tok === 'string') ? p.tok.trim() : '';

  // ✅ New minimal TSQ1 payload is { v, tok } only
  if (!payloadToken) {
    return withCORS(env, req, badRequest('Invalid QR: missing tok'));
  }

  // 2) Resolve timesheet by token (NOT by timesheet_id in payload anymore)
  const ts = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/timesheets` +
      `?qr_token=eq.${enc(payloadToken)}` +
      `&is_current=eq.true` +
      `&select=*` +
      `&limit=1`
  );

  if (!ts) {
    return withCORS(env, req, notFound('Timesheet not found for QR token'));
  }

  const sheetScope = String(ts.sheet_scope || '').toUpperCase();

  const qrStatusNow = String(ts.qr_status || '').toUpperCase();
  if (qrStatusNow !== 'PENDING') {
    if (qrStatusNow === 'USED')      return withCORS(env, req, badRequest('QR already used'));
    if (qrStatusNow === 'CANCELLED') return withCORS(env, req, badRequest('QR cancelled; a new QR must be issued'));
    if (qrStatusNow === 'EXPIRED')   return withCORS(env, req, badRequest('QR expired; a new QR must be issued'));
    return withCORS(env, req, badRequest(`QR invalid state (qr_status=${qrStatusNow || 'NULL'})`));
  }

  // 3) Token enforcement (reissue invalidation)
  const tsToken = ts.qr_token ? String(ts.qr_token) : '';
  if (!tsToken) {
    return withCORS(env, req, badRequest('Timesheet has no active QR token; cannot accept scan'));
  }
  if (String(payloadToken) !== String(tsToken)) {
    return withCORS(env, req, badRequest('QR token is no longer valid for this timesheet'));
  }

  const now = nowIso();

  // Helpers for stable hashing (shared basis across send/resend/evidence)
  const stableClone = (v) => {
    if (Array.isArray(v)) return v.map(stableClone);
    if (v && typeof v === 'object') {
      const out = {};
      for (const k of Object.keys(v).sort()) out[k] = stableClone(v[k]);
      return out;
    }
    return v;
  };

  const computeCurrentHash = async (sheetScopeU, tsRow, finRow) => {
    if (sheetScopeU === 'WEEKLY') {
      const obj = {
        sheet_scope: 'WEEKLY',
        week_ending_date: tsRow.week_ending_date || null,
        actual_schedule_json: tsRow.actual_schedule_json || null,
        reference_number: tsRow.reference_number || null,
        day_references_json: tsRow.day_references_json || null,
        additional_units_week: tsRow.additional_units_week || {},
        additional_units_per_day: tsRow.additional_units_per_day || {}
      };
      return await sha256Hex(JSON.stringify(stableClone(obj)));
    }

    // DAILY
    const obj = {
      sheet_scope: 'DAILY',
      worked_start_iso: tsRow.worked_start_iso || null,
      worked_end_iso: tsRow.worked_end_iso || null,
      break_start_iso: tsRow.break_start_iso || null,
      break_end_iso: tsRow.break_end_iso || null,
      break_minutes: (tsRow.break_minutes != null ? tsRow.break_minutes : null),
      reference_number: tsRow.reference_number || null,
      day_references_json: tsRow.day_references_json || null
    };
    return await sha256Hex(JSON.stringify(stableClone(obj)));
  };

  // ✅ Canonical deterministic PDF key (the “one PDF only” rule)
  const canonicalPdfKey = cleanKey(`docs-pdf/timesheets/ts_${ts.timesheet_id}.pdf`);

  // ✅ Step A: Copy the uploaded signed scan OVER the canonical key (overwrite).
  // Do NOT patch DB if this fails.
  try {
    await r2CopyOverwrite(env, image_r2_key, canonicalPdfKey);
  } catch (e) {
    console.warn('[QR][SCAN] failed to copy signed scan to canonical key', {
      timesheet_id: ts.timesheet_id,
      from: image_r2_key,
      to: canonicalPdfKey,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError(`Failed to store signed scan: ${e?.message || e}`));
  }

  // ─────────────────────────────────────────────────────────────
  // WEEKLY
  // ─────────────────────────────────────────────────────────────
  if (sheetScope === 'WEEKLY') {
    const cw = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
        `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
        `&select=*` +
        `&limit=1`
    ).catch(() => null);

    const contract = ts.contract_id
      ? await sbGetOne(
          env,
          `${env.SUPABASE_URL}/rest/v1/contracts` +
            `?id=eq.${enc(ts.contract_id)}` +
            `&select=*` +
            `&limit=1`
        )
      : null;

    if (!contract) return withCORS(env, req, notFound('Contract not found for QR'));

    const fin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
        `&is_current=eq.true` +
        `&select=*`
    );
    if (!fin) return withCORS(env, req, serverError('No financial snapshot for timesheet'));

    if (fin.locked_by_invoice_id || fin.paid_at_utc) {
      return withCORS(env, req, badRequest('Timesheet already invoiced or paid; cannot process QR scan'));
    }

    const finStatus = String(fin.processing_status || '').toUpperCase();
    if (finStatus !== 'AWAITING_MANUAL_SIGNATURE') {
      return withCORS(
        env,
        req,
        badRequest(`Unexpected processing_status=${fin.processing_status}; expected AWAITING_MANUAL_SIGNATURE`)
      );
    }

    // ✅ Compute signed hash at acceptance time
    let signedHash = null;
    try {
      signedHash = await computeCurrentHash('WEEKLY', ts, fin);
    } catch (e) {
      return withCORS(env, req, serverError(`Failed to compute signed hash: ${e?.message || e}`));
    }

    // ✅ Patch timesheet: point manual_pdf_r2_key to the CANONICAL key (not image_r2_key)
    const tsPatch = {
      qr_status: 'USED',
      qr_scanned_at: now,
      qr_signed_hash: signedHash,
      qr_signed_at_utc: now,
      manual_pdf_r2_key: canonicalPdfKey,
      qr_scan_info_json: {
        kind: 'WEEKLY_QR_TIMESHEET',
        payload: p,
        original_image_r2_key: image_r2_key,
        canonical_pdf_r2_key: canonicalPdfKey
      },
      updated_at: now
    };

    const tsRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(tsPatch)
      }
    );

    if (!tsRes.ok) {
      const t = await tsRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to patch timesheet after QR scan: ${t}`));
    }

    const finRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({ processing_status: 'PENDING_AUTH', updated_at: now })
      }
    );

    if (!finRes.ok) {
      const t = await finRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to update TSFIN after QR scan: ${t}`));
    }

    // ✅ Best-effort delete original uploaded key (only if it differs from canonical)
    try {
      const bucket = env.R2_BUCKET || env.R2;
      if (bucket && typeof bucket.delete === 'function' && image_r2_key !== canonicalPdfKey) {
        await bucket.delete(image_r2_key);
      }
    } catch (e) {
      console.warn('[QR_WEEKLY][SCAN] delete original image key failed (non-fatal)', {
        timesheet_id: ts.timesheet_id,
        original_image_r2_key: image_r2_key,
        err: e?.message || String(e)
      });
    }

    try {
      await writeAudit(
        env,
        user,
        'WEEKLY_QR_SCANNED',
        {
          timesheet_id: ts.timesheet_id,
          contract_week_id: cw?.id || null,
          contract_id: contract.id,
          qr_text: qrText,
          qr_payload: p,

          // record both keys explicitly
          original_image_r2_key: image_r2_key,
          canonical_pdf_r2_key: canonicalPdfKey,

          processing_status_from: fin.processing_status,
          processing_status_to: 'PENDING_AUTH',
          qr_signed_hash: signedHash
        },
        { entity: 'timesheets', subject_id: ts.timesheet_id, req }
      );
    } catch (e) {
      console.warn('[QR_WEEKLY][SCAN] audit failed', e?.message || e);
    }

    return withCORS(env, req, ok({
      timesheet_id: ts.timesheet_id,
      contract_week_id: cw?.id || null,
      contract_id: contract.id,
      candidate_id: contract.candidate_id || null,
      client_id: contract.client_id || null,
      week_ending_date: cw?.week_ending_date || ts.week_ending_date || null,
      sheet_scope: 'WEEKLY',
      processing_status: 'PENDING_AUTH',
      qr_status: 'USED',

      // keep old field for caller compatibility
      image_r2_key,

      // new: explicit canonical key
      canonical_pdf_r2_key: canonicalPdfKey
    }));
  }

  // ─────────────────────────────────────────────────────────────
  // DAILY
  // ─────────────────────────────────────────────────────────────
  if (sheetScope === 'DAILY') {
    const fin = await sbGetOne(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?timesheet_id=eq.${enc(ts.timesheet_id)}` +
        `&is_current=eq.true` +
        `&select=*`
    );
    if (!fin) return withCORS(env, req, serverError('No financial snapshot for timesheet'));

    if (fin.locked_by_invoice_id || fin.paid_at_utc) {
      return withCORS(env, req, badRequest('Timesheet already invoiced or paid; cannot process QR scan'));
    }

    const finStatus = String(fin.processing_status || '').toUpperCase();
    if (finStatus !== 'AWAITING_MANUAL_SIGNATURE') {
      return withCORS(
        env,
        req,
        badRequest(`Unexpected processing_status=${fin.processing_status}; expected AWAITING_MANUAL_SIGNATURE`)
      );
    }

    // ✅ Compute signed hash at acceptance time
    let signedHash = null;
    try {
      signedHash = await computeCurrentHash('DAILY', ts, fin);
    } catch (e) {
      return withCORS(env, req, serverError(`Failed to compute signed hash: ${e?.message || e}`));
    }

    // ✅ Patch timesheet: point manual_pdf_r2_key to the CANONICAL key (not image_r2_key)
    const tsPatch = {
      qr_status: 'USED',
      qr_scanned_at: now,
      updated_at: now,
      qr_signed_hash: signedHash,
      qr_signed_at_utc: now,
      manual_pdf_r2_key: canonicalPdfKey,
      qr_scan_info_json: {
        kind: 'DAILY_QR_TIMESHEET',
        payload: p,
        original_image_r2_key: image_r2_key,
        canonical_pdf_r2_key: canonicalPdfKey
      }
    };

    const tsRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets?timesheet_id=eq.${enc(ts.timesheet_id)}&is_current=eq.true`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(tsPatch)
      }
    );

    if (!tsRes.ok) {
      const t = await tsRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to patch timesheet after QR scan: ${t}`));
    }

    const finRes = await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(fin.id)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify({ processing_status: 'PENDING_AUTH', updated_at: now })
      }
    );

    if (!finRes.ok) {
      const t = await finRes.text().catch(() => '');
      return withCORS(env, req, serverError(`Failed to update TSFIN after QR scan: ${t}`));
    }

    // ✅ Best-effort delete original uploaded key (only if it differs from canonical)
    try {
      const bucket = env.R2_BUCKET || env.R2;
      if (bucket && typeof bucket.delete === 'function' && image_r2_key !== canonicalPdfKey) {
        await bucket.delete(image_r2_key);
      }
    } catch (e) {
      console.warn('[QR_DAILY][SCAN] delete original image key failed (non-fatal)', {
        timesheet_id: ts.timesheet_id,
        original_image_r2_key: image_r2_key,
        err: e?.message || String(e)
      });
    }

    let contract = null;
    if (ts.contract_id) {
      try {
        contract = await sbGetOne(env, `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(ts.contract_id)}&select=*`);
      } catch {
        contract = null;
      }
    }

    try {
      await writeAudit(
        env,
        user,
        'DAILY_QR_SCANNED',
        {
          timesheet_id: ts.timesheet_id,
          contract_id: contract?.id || ts.contract_id || null,
          qr_text: qrText,
          qr_payload: p,

          // record both keys explicitly
          original_image_r2_key: image_r2_key,
          canonical_pdf_r2_key: canonicalPdfKey,

          processing_status_from: fin.processing_status,
          processing_status_to: 'PENDING_AUTH',
          qr_signed_hash: signedHash
        },
        { entity: 'timesheets', subject_id: ts.timesheet_id, req }
      );
    } catch (e) {
      console.warn('[QR_DAILY][SCAN] audit failed', e?.message || e);
    }

    return withCORS(env, req, ok({
      timesheet_id: ts.timesheet_id,
      contract_id: contract?.id || ts.contract_id || null,
      candidate_id: contract?.candidate_id || null,
      client_id: contract?.client_id || null,
      sheet_scope: 'DAILY',
      processing_status: 'PENDING_AUTH',
      qr_status: 'USED',

      // keep old field for caller compatibility
      image_r2_key,

      // new: explicit canonical key
      canonical_pdf_r2_key: canonicalPdfKey
    }));
  }

  return withCORS(env, req, badRequest('QR mismatch: unsupported sheet_scope for QR'));
}




// NEW helper: copy an existing R2 object to another key (overwrite destination).
// - Uses the same bucket selection style already present in your codebase: env.R2_BUCKET || env.R2
// - Preserves httpMetadata/customMetadata when present.
// - Throws on failure so caller can avoid patching DB on copy failure.
async function r2CopyOverwrite(env, fromKey, toKey) {
  const bucket = env.R2_BUCKET || env.R2;
  if (!bucket || typeof bucket.get !== 'function' || typeof bucket.put !== 'function') {
    throw new Error('Storage not configured (expected env.R2 or env.R2_BUCKET with get/put)');
  }

  const clean = (k) => String(k || '').replace(/^\/+/, '').trim();
  const src = clean(fromKey);
  const dst = clean(toKey);

  if (!src) throw new Error('r2CopyOverwrite: fromKey is empty');
  if (!dst) throw new Error('r2CopyOverwrite: toKey is empty');

  const obj = await bucket.get(src).catch((e) => {
    throw new Error(`r2CopyOverwrite: failed to get source key="${src}": ${e?.message || String(e)}`);
  });

  if (!obj) {
    throw new Error(`r2CopyOverwrite: source not found key="${src}"`);
  }

  // Preserve metadata when available
  const putOpts = {};
  if (obj.httpMetadata) putOpts.httpMetadata = obj.httpMetadata;
  if (obj.customMetadata) putOpts.customMetadata = obj.customMetadata;

  // Overwrite destination with source body stream
  await bucket.put(dst, obj.body, putOpts).catch((e) => {
    throw new Error(`r2CopyOverwrite: failed to put dest key="${dst}": ${e?.message || String(e)}`);
  });

  return { ok: true, from: src, to: dst };
}

async function verifyTsq1(qrText, env) {
  try {
    const raw = String(qrText || '').trim();
    if (!raw) return { ok: false, reason: 'EMPTY' };

    const parts = raw.split('.');
    if (parts.length !== 3) return { ok: false, reason: 'MALFORMED' };

    const [prefix, payloadB64url, sigB64url] = parts;
    if (prefix !== 'TSQ1') return { ok: false, reason: 'BAD_PREFIX' };
    if (!payloadB64url || !sigB64url) return { ok: false, reason: 'MALFORMED' };

    const secret = env.QR_SIGNING_SECRET || '';
    if (!secret) return { ok: false, reason: 'NO_SECRET' };

    // Verify signature over "TSQ1.<payload_b64url>"
    const keyData = textEncoder.encode(secret);
    const key = await crypto.subtle.importKey(
      'raw',
      keyData,
      { name: 'HMAC', hash: 'SHA-256' },
      false,
      ['verify']
    );

    const signedData = textEncoder.encode(`TSQ1.${payloadB64url}`);
    const sigBytes = base64UrlToUint8(sigB64url);
    const sigOk = await crypto.subtle.verify('HMAC', key, sigBytes, signedData);
    if (!sigOk) return { ok: false, reason: 'BAD_SIG' };

    // Decode payload
    let jsonStr = '';
    try {
      jsonStr = new TextDecoder().decode(base64UrlToUint8(payloadB64url));
    } catch {
      return { ok: false, reason: 'BAD_PAYLOAD_B64' };
    }

    let payload = null;
    try {
      payload = JSON.parse(jsonStr);
    } catch {
      return { ok: false, reason: 'BAD_PAYLOAD_JSON' };
    }

    if (!payload || typeof payload !== 'object') return { ok: false, reason: 'BAD_PAYLOAD' };

    // Minimal required fields
    if (!payload.tsid) return { ok: false, reason: 'MISSING_TSID' };

    // REQUIRE token for all TSQ1 (no backward compat)
    if (!payload.tok || typeof payload.tok !== 'string' || !payload.tok.trim()) {
      return { ok: false, reason: 'MISSING_TOK' };
    }

    return { ok: true, payload };
  } catch (e) {
    return { ok: false, reason: e?.message || 'ERROR' };
  }
}


async function handleContractWeekPlanPatch(env, req, weekId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); }
  catch { return withCORS(env, req, badRequest('Invalid JSON')); }

  const adds = Array.isArray(body?.add) ? body.add : [];
  const removes = Array.isArray(body?.remove) ? body.remove : [];
  const mergeMode = (String(body?.merge||'append').toLowerCase()==='replace') ? 'replace' : 'append';

  // NOTE: we keep empty_week_action for backward compatibility,
  // but effective behaviour is:
  // - if plan becomes empty (and no timesheet), DELETE the contract_weeks row.
  const emptyActionRaw = (['cancel','delete','keep'].includes(String(body?.empty_week_action||'cancel').toLowerCase()))
    ? String(body.empty_week_action).toLowerCase()
    : 'cancel';

  if (!adds.length && !removes.length) {
    return withCORS(env, req, badRequest('Nothing to change (add[]/remove[] empty)'));
  }

  // Load week + its contract (for std_schedule_json)
  const w = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(weekId)}&select=id,contract_id,week_ending_date,additional_seq,timesheet_id,planned_schedule_json,status`
  );
  if (!w) return withCORS(env, req, badRequest('Week not found'));

  const c = await sbGetOne(
    env,
    `${env.SUPABASE_URL}/rest/v1/contracts?id=eq.${enc(w.contract_id)}&select=id,start_date,end_date,std_schedule_json,week_ending_weekday_snapshot`
  );
  if (!c) return withCORS(env, req, badRequest('Contract not found'));

  // No removing/adding on weeks with TS (base rule)
  if (w.timesheet_id) {
    return withCORS(env, req, badRequest('Cannot edit plan for a week that already has a timesheet. Create an additional week instead.'));
  }

  const plan = Array.isArray(w.planned_schedule_json) ? w.planned_schedule_json.slice() : [];
  let changed = false;

  // Helper to build entry (infer overnight from times only; recompute expected_minutes)
  function buildEntry(d) {
    if (!d?.date) throw new Error('add[].date is required');
    const ymd = toYmd(d.date);
    if (ymd < c.start_date || ymd > c.end_date) throw new Error(`Date ${ymd} is outside contract window`);

    if (d.start && d.end) {
      const s = parseHHMM(d.start), e = parseHHMM(d.end);
      if (s==null || e==null) throw new Error(`Invalid HH:MM for ${ymd}`);
      const br = Math.max(0, Number(d.break_minutes||0));
      const overnight = (e <= s); // infer only from times
      const mins = Math.max(0, minutesDiff(s, e, overnight) - br);
      const breaks = Array.isArray(d.breaks) ? d.breaks : [];
      return { date: ymd, start:d.start, end:d.end, breaks, break_minutes:br, overnight, expected_minutes:mins };
    }

    // fallback to template (also infer only from times)
    const jsDow = (new Date(ymd+'T00:00:00Z')).getUTCDay();
    const names = ['sun','mon','tue','wed','thu','fri','sat'];
    const tpl = c.std_schedule_json?.[names[jsDow]];

    if (tpl?.start && tpl?.end) {
      const s = parseHHMM(tpl.start), e = parseHHMM(tpl.end);
      if (s==null || e==null) throw new Error(`Invalid std_schedule_json time for ${names[jsDow]}`);
      const br = Math.max(0, Number(tpl.break_minutes||0));
      const overnight = (e <= s); // infer only from times
      const mins = Math.max(0, minutesDiff(s, e, overnight) - br);
      const breaks = Array.isArray(tpl.breaks) ? tpl.breaks : [];
      return { date: ymd, start:tpl.start, end:tpl.end, breaks, break_minutes:br, overnight, expected_minutes:mins };
    }

    return { date: ymd, start:null, end:null, breaks:[], break_minutes:0, overnight:false, expected_minutes:0 };
  }

  // Apply adds
  for (const d of adds) {
    try {
      const e = buildEntry(d);
      const idx = plan.findIndex(p => p?.date === e.date);
      if (idx >= 0) {
        if (mergeMode === 'replace') { plan[idx] = e; changed = true; }
      } else {
        plan.push(e); changed = true;
      }
    } catch (ex) {
      return withCORS(env, req, badRequest(ex.message || 'Invalid add[] payload'));
    }
  }

  // Apply removes
  for (const y of removes) {
    const ymd = toYmd(y);
    const idx = plan.findIndex(p => p?.date === ymd);
    if (idx >= 0) { plan.splice(idx,1); changed = true; }
  }

  if (!changed) {
    return withCORS(env, req, ok({ updated:false, week_id: w.id, empty_week_action: emptyActionRaw }));
  }

  // NEW BEHAVIOUR: if emptied, DELETE the contract_weeks row (since there is no TS)
  if (!plan.length) {
    const del = await fetch(
      `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(w.id)}`,
      { method:'DELETE', headers:{ ...sbHeaders(env), 'Prefer':'return=minimal' } }
    );
    try { await del.arrayBuffer(); } catch {}

    return withCORS(env, req, ok({
      updated: true,
      week_deleted: true,
      week_id: w.id,
      empty_week_action: emptyActionRaw,
      empty_week_action_effective: 'delete'
    }));
  }

  // If we are (re)adding days to a previously cancelled week, restore status automatically.
  const todayYmd = toYmd(new Date());
  const desiredStatus = (String(w.week_ending_date) <= todayYmd) ? 'OPEN' : 'PLANNED';

  const patch = {
    planned_schedule_json: plan,
    updated_at: nowIso()
  };

  if (String(w.status || '').toUpperCase() === 'CANCELLED') {
    patch.status = desiredStatus;
  }

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/contract_weeks?id=eq.${enc(w.id)}`,
    {
      method:'PATCH',
      headers:{ ...sbHeaders(env), 'Prefer':'return=representation' },
      body: JSON.stringify(patch)
    }
  );
  if (!res.ok) return withCORS(env, req, serverError(await res.text()));

  const row = (await res.json().catch(()=>[]))[0] || null;
  return withCORS(env, req, ok({
    updated: true,
    week: row,
    empty_week_action: emptyActionRaw,
    empty_week_action_effective: 'delete_if_empty'
  }));
}



async function setWeeksInvoicedForTimesheets(env, timesheetIds) {
  const ids = Array.from(new Set((timesheetIds || []).filter(Boolean)));
  if (!ids.length) return;
  const inList = ids.map(encodeURIComponent).join(',');
  await fetch(`${env.SUPABASE_URL}/rest/v1/contract_weeks?timesheet_id=in.(${inList})`, {
    method: 'PATCH',
    headers: { ...sbHeaders(env), Prefer: 'return=minimal' },
    body: JSON.stringify({ status: 'INVOICED', updated_at: new Date().toISOString() })
  });
}

async function handleCreateInvoiceTsfin(env, req) {
  // SQL-first: enqueue HOURS job + run generator immediately (so FE gets invoice_id),
  // but DO NOT issue here (issue happens when emailing; self-bill issuance handled in SQL generator).
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized('Unauthorized');

  const body = await parseJSONBody(req).catch(() => null);
  if (!body || !Array.isArray(body.timesheet_ids) || body.timesheet_ids.length === 0) {
    return badRequest("timesheet_ids[] required");
  }

  const timesheetIds = [...new Set(body.timesheet_ids)].filter(Boolean);
  if (!timesheetIds.length) return badRequest("No valid timesheet_ids");

  // Actor for SQL audit: prefer the logged-in user id if present
  const actorUserId = (user && (user.id || user.user_id)) ? (user.id || user.user_id) : null;

  // Optional audit/request metadata (stored in outbox payload; SQL picks these up for audit)
  const meta = {
    ip: req.headers.get('cf-connecting-ip') || req.headers.get('x-forwarded-for') || null,
    user_agent: req.headers.get('user-agent') || null,
    correlation_id: req.headers.get('x-correlation-id') || null
  };

  // Optional passthrough (only if caller supplied it)
  if (body && body.stationery_key) meta.stationery_key = body.stationery_key;

  // 1) Enqueue HOURS job (single DB call)
  const enq = await sbRpc(env, 'invoice_outbox_enqueue_hours', {
    p_timesheet_ids: timesheetIds,
    p_actor_user_id: actorUserId,
    p_meta: meta
  });

  // sbRpc can return string, array, or {data}
  const outboxId =
    (typeof enq === 'string' && enq) ? enq :
    (Array.isArray(enq) && enq[0]) ? enq[0] :
    (enq && typeof enq === 'object' && typeof enq.data === 'string') ? enq.data :
    (enq && typeof enq === 'object' && Array.isArray(enq.data) && enq.data[0]) ? enq.data[0] :
    null;

  if (!outboxId) {
    return serverError('Failed to enqueue invoice job (no outbox id returned).');
  }

  // 2) Generate immediately (single DB call)
  const gen = await sbRpc(env, 'invoice_generate_from_outbox_batch', {
    p_outbox_ids: [outboxId],
    p_actor_user_id: actorUserId
  });

  const results = Array.isArray(gen) ? gen : (Array.isArray(gen?.data) ? gen.data : []);
  const r0 = results.find(r => String(r?.outbox_id || '') === String(outboxId)) || results[0] || null;

  if (!r0 || r0.ok !== true) {
    const err =
      (r0 && r0.warnings && typeof r0.warnings === 'object' && r0.warnings.error)
        ? String(r0.warnings.error)
        : 'Invoice generation failed';
    return serverError(err);
  }

  const invoiceId = (Array.isArray(r0.invoice_ids) && r0.invoice_ids.length) ? r0.invoice_ids[0] : null;
  if (!invoiceId) {
    return serverError('Invoice generated but no invoice_id returned.');
  }

  // IMPORTANT: do NOT issue here. Issuing happens when emailing (except self-bill, handled in SQL generator).
  return ok({
    invoice_id: invoiceId,
    outbox_id: outboxId
  });
}


function extractBillableSegmentsForWeek(snaps, weekStart) {
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  const computeWeekStartFromWeekEnding = (weYmd) => {
    if (!weYmd) return null;
    const d = new Date(`${weYmd}T00:00:00Z`);
    if (Number.isNaN(d.getTime())) return weYmd;
    d.setUTCDate(d.getUTCDate() - 6);
    const yyyy = d.getUTCFullYear();
    const mm   = String(d.getUTCMonth() + 1).padStart(2, '0');
    const dd   = String(d.getUTCDate()).padStart(2, '0');
    return `${yyyy}-${mm}-${dd}`;
  };

  const entries = [];
  const tsIdsUsed = new Set();
  const tsfinIdsUsed = new Set();

  for (const s of snaps || []) {
    if (!s) continue;
    const basis = String(s.basis || '').toUpperCase();
    const ib = s.invoice_breakdown_json || {};
    const tsMeta = s.timesheet || {};
    const naturalWeekStart = tsMeta.week_ending_date
      ? computeWeekStartFromWeekEnding(tsMeta.week_ending_date)
      : null;

    if (ib && ib.mode === 'SEGMENTS' && Array.isArray(ib.segments)) {
      const segs = ib.segments || [];
      for (let idx = 0; idx < segs.length; idx++) {
        const seg = segs[idx];
        if (!seg || typeof seg !== 'object') continue;
        if (seg.invoice_locked_invoice_id) continue;

        const targetWeek = seg.invoice_target_week_start || naturalWeekStart;
        if (!targetWeek || targetWeek !== weekStart) continue;

        entries.push({
          tsfin_id: s.id,
          timesheet_id: s.timesheet_id,
          candidate_id: s.candidate_id,
          client_id: s.client_id,
          basis,
          segment: seg,
          segment_index: idx,
          pseudo: false
        });
        tsIdsUsed.add(s.timesheet_id);
        tsfinIdsUsed.add(s.id);
      }
    } else {
      // WEEKLY_BUCKETS / AGGREGATE: treat as atomic for this week
      if (!naturalWeekStart || naturalWeekStart !== weekStart) continue;
      if (s.locked_by_invoice_id) continue;

      const pay = Number(s.total_pay_ex_vat || 0);
      const chg = Number(s.total_charge_ex_vat || 0);
      const margin = round2(chg - pay);

      const pseudoSeg = {
        segment_id: `ts:${s.timesheet_id}`,
        date: tsMeta.week_ending_date || weekStart,
        pay_amount: pay,
        charge_amount: chg,
        margin_amount: margin,
        invoice_target_week_start: weekStart,
        invoice_locked_invoice_id: s.locked_by_invoice_id || null
      };

      entries.push({
        tsfin_id: s.id,
        timesheet_id: s.timesheet_id,
        candidate_id: s.candidate_id,
        client_id: s.client_id,
        basis,
        segment: pseudoSeg,
        segment_index: -1,
        pseudo: true
      });
      tsIdsUsed.add(s.timesheet_id);
      tsfinIdsUsed.add(s.id);
    }
  }

  return {
    entries,
    timesheet_ids: [...tsIdsUsed],
    tsfin_ids: [...tsfinIdsUsed]
  };
}

async function lockSegmentsForInvoice(env, invoiceId, segmentRefs) {
  const enc = encodeURIComponent;
  const nowIso = new Date().toISOString();

  if (!Array.isArray(segmentRefs) || !segmentRefs.length) return;

  const byTsfin = new Map();
  for (const ref of segmentRefs) {
    if (!ref || !ref.tsfin_id) continue;
    const id = ref.tsfin_id;
    let entry = byTsfin.get(id);
    if (!entry) {
      entry = {
        tsfin_id: id,
        segmentIds: new Set(),
        lockWhole: false
      };
      byTsfin.set(id, entry);
    }
    if (!ref.segment_id) {
      entry.lockWhole = true;
    } else {
      entry.segmentIds.add(String(ref.segment_id));
    }
  }

  if (!byTsfin.size) return;

  for (const [tsfinId, ref] of byTsfin.entries()) {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials` +
        `?id=eq.${enc(tsfinId)}` +
        `&select=id,basis,locked_by_invoice_id,invoice_breakdown_json`
    );
    const snap = rows?.[0] || null;
    if (!snap) continue;

    let ib = snap.invoice_breakdown_json || null;
    const basis = String(snap.basis || '').toUpperCase();
    const isSelfBillOrNhsp = (
      basis === 'NHSP' ||
      basis === 'NHSP_ADJUSTMENT' ||
      basis === 'HEALTHROSTER_SELF_BILL' ||
      basis === 'HEALTHROSTER_ADJUSTMENT'
    );

    let allLocked = true;

    if (ib && typeof ib === 'object' && ib.mode === 'SEGMENTS' && Array.isArray(ib.segments)) {
      ib = {
        ...ib,
        segments: ib.segments.map((seg) => {
          if (!seg || typeof seg !== 'object') return seg;
          const sid = String(seg.segment_id || '');
          let locked = seg.invoice_locked_invoice_id;

          if (ref.lockWhole || ref.segmentIds.has(sid)) {
            if (!locked) locked = invoiceId;
          }

          if (!locked) allLocked = false;

          return {
            ...seg,
            invoice_locked_invoice_id: locked
          };
        })
      };
    } else {
      // No segments; treat as "no segment-level lock", and allLocked is just existing lock
      allLocked = !!snap.locked_by_invoice_id || ref.lockWhole;
    }

    const patch = {
      updated_at: nowIso
    };

    if (ib) {
      patch.invoice_breakdown_json = ib;
    }

    // For non-NHSP/HR basis: if all segments are locked (or lockWhole), set locked_by_invoice_id
    if (!isSelfBillOrNhsp && allLocked) {
      patch.locked_by_invoice_id = invoiceId;
      patch.locked_at_utc = nowIso;
    }

    await fetch(
      `${env.SUPABASE_URL}/rest/v1/timesheets_financials?id=eq.${enc(tsfinId)}`,
      {
        method: 'PATCH',
        headers: { ...sbHeaders(env), Prefer: 'return-minimal' },
        body: JSON.stringify(patch)
      }
    ).catch((e) => {
      console.warn('[lockSegmentsForInvoice] patch failed', {
        tsfin_id: tsfinId,
        err: e?.message || String(e)
      });
    });
  }
}

async function handleCreateInvoiceTsfinByWeek(env, req) {
  // SQL-first: enqueue BY_WEEK job + run generator immediately (so FE gets invoice_id),
  // but DO NOT issue here (issue happens when emailing; self-bill issuance handled in SQL generator).
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized('Unauthorized');

  const body = await parseJSONBody(req).catch(() => null);
  const clientId = body?.client_id || null;
  const invoiceWeekStart = body?.invoice_week_start || null; // YYYY-MM-DD

  if (!clientId) return badRequest('client_id is required');
  if (!invoiceWeekStart) return badRequest('invoice_week_start is required');

  // Validate basic YYYY-MM-DD shape + Date parse
  const wsDate = new Date(`${invoiceWeekStart}T00:00:00Z`);
  if (Number.isNaN(wsDate.getTime())) {
    return badRequest('invoice_week_start must be a valid YYYY-MM-DD date');
  }

  // Actor for SQL audit
  const actorUserId = (user && (user.id || user.user_id)) ? (user.id || user.user_id) : null;

  // Optional audit/request metadata (stored in outbox payload; SQL picks these up for audit)
  const meta = {
    ip: req.headers.get('cf-connecting-ip') || req.headers.get('x-forwarded-for') || null,
    user_agent: req.headers.get('user-agent') || null,
    correlation_id: req.headers.get('x-correlation-id') || null
  };

  // Optional passthrough (only if caller supplied it)
  if (body && body.stationery_key) meta.stationery_key = body.stationery_key;

  // 1) Enqueue BY_WEEK job (single DB call)
  const enq = await sbRpc(env, 'invoice_outbox_enqueue_by_week', {
    p_client_id: clientId,
    p_invoice_week_start: invoiceWeekStart,
    p_actor_user_id: actorUserId,
    p_meta: meta
  });

  const outboxId =
    (typeof enq === 'string' && enq) ? enq :
    (Array.isArray(enq) && enq[0]) ? enq[0] :
    (enq && typeof enq === 'object' && typeof enq.data === 'string') ? enq.data :
    (enq && typeof enq === 'object' && Array.isArray(enq.data) && enq.data[0]) ? enq.data[0] :
    null;

  if (!outboxId) {
    return serverError('Failed to enqueue invoice BY_WEEK job (no outbox id returned).');
  }

  // 2) Generate immediately (single DB call)
  const gen = await sbRpc(env, 'invoice_generate_from_outbox_batch', {
    p_outbox_ids: [outboxId],
    p_actor_user_id: actorUserId
  });

  const results = Array.isArray(gen) ? gen : (Array.isArray(gen?.data) ? gen.data : []);
  const r0 = results.find(r => String(r?.outbox_id || '') === String(outboxId)) || results[0] || null;

  if (!r0 || r0.ok !== true) {
    const err =
      (r0 && r0.warnings && typeof r0.warnings === 'object' && r0.warnings.error)
        ? String(r0.warnings.error)
        : 'Invoice generation failed';
    return serverError(err);
  }

  const invoiceId = (Array.isArray(r0.invoice_ids) && r0.invoice_ids.length) ? r0.invoice_ids[0] : null;
  if (!invoiceId) {
    return serverError('Invoice generated but no invoice_id returned.');
  }

  // IMPORTANT: do NOT issue here. Issuing happens when emailing (except self-bill, handled in SQL generator).
  return ok({
    invoice_id: invoiceId,
    outbox_id: outboxId,
    client_id: clientId,
    invoice_week_start: invoiceWeekStart
  });
}



// Self-bill helper: reuse existing invoice for (client, week) if possible,
// otherwise create a new self-bill invoice header.
async function findOrCreateSelfBillInvoice(
  env,
  client_id,
  weekStart,
  client,
  defRows,
  vatRatePct,
  timesheet_ids,
  entries
) {
  const enc = encodeURIComponent;
  const round2 = (n) => Math.round((Number(n) || 0) * 100) / 100;

  // 1) Reuse ONLY editable/open self-bill bucket invoices (DRAFT/ON_HOLD).
  const { rows: existingOpen } = await sbFetch(
    env,
    `${env.SUPABASE_URL}/rest/v1/invoices` +
      `?client_id=eq.${enc(client_id)}` +
      `&status=in.(DRAFT,ON_HOLD)` +
      `&header_snapshot_json->meta->>source=eq.TSFIN_SEGMENTS` +
      `&header_snapshot_json->meta->>invoice_week_start=eq.${enc(weekStart)}` +
      `&select=*` +
      `&order=created_at.desc` +
      `&limit=1`
  );

  if (existingOpen && existingOpen[0]) return existingOpen[0];

  // 2) If there is an ISSUED bucket already, we MUST NOT reuse it.
  //    We create a NEW DRAFT bucket and mark meta so the correction result can surface a warning.
  let issuedBucket = null;
  try {
    const { rows: issuedRows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/invoices` +
        `?client_id=eq.${enc(client_id)}` +
        `&status=eq.ISSUED` +
        `&header_snapshot_json->meta->>source=eq.TSFIN_SEGMENTS` +
        `&header_snapshot_json->meta->>invoice_week_start=eq.${enc(weekStart)}` +
        `&select=id,invoice_no,status,created_at,issued_at_utc` +
        `&order=created_at.desc` +
        `&limit=1`
    );
    issuedBucket = (issuedRows && issuedRows[0]) ? issuedRows[0] : null;
  } catch {
    issuedBucket = null;
  }

  // 3) Create a NEW DRAFT self-bill invoice bucket.
  const def = defRows && defRows[0] ? defRows[0] : {};
  const nowIso = new Date().toISOString();

  // Attach-policy derivation (kept as-is; best-effort, contract-driven).
  let requiresHr = false;
  let hrAttach   = true;
  let tsAttach   = true;

  try {
    const tsIds = Array.isArray(timesheet_ids)
      ? [...new Set(timesheet_ids.map(String).filter(Boolean))]
      : [];

    if (tsIds.length) {
      const inIds = tsIds.map(enc).join(',');

      let contractIds = [];
      try {
        const { rows: tsRows } = await sbFetch(
          env,
          `${env.SUPABASE_URL}/rest/v1/timesheets` +
            `?timesheet_id=in.(${inIds})` +
            `&select=timesheet_id,contract_id`
        );
        contractIds = (tsRows || [])
          .map(r => r?.contract_id)
          .filter(Boolean)
          .map(String);
      } catch {
        contractIds = [];
      }

      if (!contractIds.length) {
        try {
          const { rows: wkRows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/contract_weeks` +
              `?timesheet_id=in.(${inIds})` +
              `&select=timesheet_id,contract_id`
          );
          contractIds = (wkRows || [])
            .map(r => r?.contract_id)
            .filter(Boolean)
            .map(String);
        } catch {
          contractIds = [];
        }
      }

      contractIds = [...new Set(contractIds)];

      if (contractIds.length) {
        let conRows = [];
        let sawHrAttachField = false;
        let sawTsAttachField = false;

        try {
          const { rows } = await sbFetch(
            env,
            `${env.SUPABASE_URL}/rest/v1/contracts` +
              `?id=in.(${contractIds.map(enc).join(',')})` +
              `&select=id,requires_hr,hr_attach_to_invoice,ts_attach_to_invoice`
          );
          conRows = Array.isArray(rows) ? rows : [];
        } catch {
          conRows = [];
        }

        for (const c of conRows) {
          if (!c || !c.id) continue;
          if (Object.prototype.hasOwnProperty.call(c, 'requires_hr') && c.requires_hr === true) {
            requiresHr = true;
          }
          if (Object.prototype.hasOwnProperty.call(c, 'hr_attach_to_invoice')) sawHrAttachField = true;
          if (Object.prototype.hasOwnProperty.call(c, 'ts_attach_to_invoice')) sawTsAttachField = true;
        }

        if (sawHrAttachField) {
          hrAttach = conRows.some(c =>
            c && Object.prototype.hasOwnProperty.call(c, 'hr_attach_to_invoice') && c.hr_attach_to_invoice !== false
          );
        }

        if (sawTsAttachField) {
          tsAttach = conRows.some(c =>
            c && Object.prototype.hasOwnProperty.call(c, 'ts_attach_to_invoice') && c.ts_attach_to_invoice !== false
          );
        }
      }
    }
  } catch {
    requiresHr = false;
    hrAttach = true;
    tsAttach = true;
  }

  const termsDays = Number(client.payment_terms_days ?? 30);

  const meta = {
    source: 'TSFIN_SEGMENTS',
    self_bill: true,
    invoice_week_start: weekStart,
    timesheet_count: Array.isArray(timesheet_ids) ? timesheet_ids.length : 0,
    segment_count: Array.isArray(entries) ? entries.length : 0
  };

  // ✅ If prior bucket exists and is ISSUED, flag so UI can warn.
  if (issuedBucket && issuedBucket.id) {
    meta.adjustment_bucket_created_due_to_issued = true;
    meta.adjustment_prior_invoice_id = issuedBucket.id;
    meta.adjustment_prior_invoice_no = issuedBucket.invoice_no || null;
    meta.adjustment_note = 'Adjustment invoice created because prior invoice bucket was already issued.';
  }

  const header_snapshot_json = {
    client_id,
    client_name: client.name,
    client_invoice_address: client.invoice_address ?? null,
    client_primary_invoice_email: client.primary_invoice_email ?? null,
    vat_chargeable: !!client.vat_chargeable,
    applied_vat_rate_pct: vatRatePct,
    payment_terms_days: termsDays,

    // ✅ Do NOT set issued/due at creation. Issuing computes these.
    issued_at_utc: null,
    due_at_utc: null,

    stationery_key: env.INVOICE_STATIONERY_KEY || null,
    stationery_margins_mm: null,
    hide_bank_footer: null,
    bank: {
      name: def.bank_name ?? null,
      sort_code: def.bank_sort_code ?? null,
      account_number: def.bank_account_number ?? null,
    },
    vat_registration_number: def.vat_registration_number ?? null,
    meta,
    attach_policy: {
      requires_hr: requiresHr,
      hr_attach_to_invoice: hrAttach,
      ts_attach_to_invoice: tsAttach,
    },
  };

  const invIns = await fetch(`${env.SUPABASE_URL}/rest/v1/invoices`, {
    method: 'POST',
    headers: { ...sbHeaders(env), Prefer: 'return=representation' },
    body: JSON.stringify({
      client_id,
      status: 'DRAFT',
      status_date_utc: nowIso,
      issued_at_utc: null,
      due_at_utc: null,
      subtotal_ex_vat: round2(0),
      vat_amount:      round2(0),
      total_inc_vat:   round2(0),
      on_hold_reason: null,
      header_snapshot_json
    })
  });

  if (!invIns.ok) {
    const t = await invIns.text().catch(() => '');
    throw new Error(`Failed to create self-bill invoice: ${t}`);
  }

  const createdArr = await invIns.json().catch(() => []);
  const invoice = Array.isArray(createdArr) ? createdArr[0] : createdArr;
  if (!invoice || !invoice.id) {
    throw new Error('Failed to create self-bill invoice: no invoice returned');
  }

  return invoice;
}


async function handleTimesheetSourcePrint(env, req, timesheetId) {
  const enc = encodeURIComponent;
  const url = new URL(req.url);
  const q = (k) => url.searchParams.get(k);

  // Admin auth
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!timesheetId) {
    return withCORS(env, req, badRequest('timesheet_id is required'));
  }

  const scopeRaw = (q('scope') || 'all').toLowerCase();
  const scope = (scopeRaw === 'shift') ? 'shift' : 'all';
  const shiftId = scope === 'shift' ? (q('shift_id') || '') : '';
  const includeExcluded = (q('include_excluded') || '').toLowerCase() === 'true';

  // ✅ Optional filter: only return rows for this import batch id
  const importIdRaw = q('import_id');
  const importId = (importIdRaw != null && String(importIdRaw).trim() !== '') ? String(importIdRaw).trim() : null;

  try {
    const data = await collectSourceRowsForTimesheet(env, timesheetId, {
      scope,
      shift_id: shiftId || null,
      include_excluded: includeExcluded,
      import_id: importId
    });

    return withCORS(env, req, ok({
      timesheet_id: timesheetId,
      scope,
      includes_excluded: includeExcluded,
      imports: data.imports || []
    }));
  } catch (e) {
    console.error('[TIMESHEET_SOURCE_PRINT] error', {
      timesheet_id: timesheetId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to collect source rows for timesheet'));
  }
}
async function collectSourceRowsForTimesheet(env, timesheetId, opts = {}) {
  const enc = encodeURIComponent;

  const scope = (opts.scope || 'all').toLowerCase();
  const filterShiftIdRaw = (scope === 'shift' && opts.shift_id) ? String(opts.shift_id).trim() : null;
  const includeExcluded = !!opts.include_excluded;

  // Optional filter: only include rows for this import batch id
  const filterImportIdRaw =
    (opts.import_id != null && String(opts.import_id).trim() !== '')
      ? String(opts.import_id).trim()
      : null;

  // RPC expects UUIDs for import_id and shift_id (nhsp_shifts.id)
  const uuidRe =
    /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;

  const p_shift_id  = (filterShiftIdRaw && uuidRe.test(filterShiftIdRaw)) ? filterShiftIdRaw : null;
  const p_import_id = (filterImportIdRaw && uuidRe.test(filterImportIdRaw)) ? filterImportIdRaw : null;

  // Single-call: Postgres RPC resolves requested timesheet_id -> current timesheet_id (rotation-safe)
  const rpcRes = await fetch(
    `${env.SUPABASE_URL}/rest/v1/rpc/timesheet_import_rows_for_timesheet_current`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation' },
      body: JSON.stringify({
        p_timesheet_id: timesheetId,
        p_include_excluded: !!includeExcluded,
        p_import_id: p_import_id,
        p_shift_id: p_shift_id
      })
    }
  );

  const txt = await rpcRes.text().catch(() => '');
  if (!rpcRes.ok) {
    throw new Error(txt || `RPC timesheet_import_rows_for_timesheet_current failed (${rpcRes.status})`);
  }

  let rpcRows = [];
  try {
    const json = txt ? JSON.parse(txt) : [];
    rpcRows = Array.isArray(json) ? json : [];
  } catch {
    rpcRows = [];
  }

  // Map RPC rows into the same imports[] shape your FE expects from /source-print
  const imports = rpcRows.map(r => {
    const header_columns = Array.isArray(r?.header_columns)
      ? r.header_columns
      : (r?.header_columns && typeof r.header_columns === 'object')
        ? r.header_columns
        : [];

    // SQL returns rows as jsonb array of { raw_columns, payload }
    const rowsJson = Array.isArray(r?.rows) ? r.rows : [];

    const rows = rowsJson.map(x => {
      const raw = Array.isArray(x?.raw_columns) ? x.raw_columns : null;
      const payload = (x && typeof x === 'object' && x.payload != null) ? x.payload : (x || {});
      return { raw_columns: raw, payload };
    });

    return {
      source_system: String(r?.source_system || '').toUpperCase() || 'UNKNOWN',
      import_id: r?.import_id || null,

      // Optional metadata (handy for future download buttons, not required for preview)
      filename: r?.filename || null,
      uploaded_at_utc: r?.uploaded_at_utc || null,
      file_r2_key: r?.file_r2_key || null,

      header_columns,
      rows
    };
  });

  return { imports };
}
async function collectSourceRowsForInvoice(env, invoiceId) {
  const r = await sbRpc(env, 'invoice_source_rows_collect', {
    p_invoice_id: invoiceId,
    p_force_refresh: true   // ✅ correctness-first; still 1 DB call
  });

  // sbRpc can return array or {data}
  const rows = Array.isArray(r) ? r : (r?.data || []);

  const imports = (rows || []).map(row => ({
    source_system: String(row?.source_system || '').toUpperCase(),
    import_id: row?.import_id || null,
    header_columns: Array.isArray(row?.header_columns) ? row.header_columns : [],
    rows: Array.isArray(row?.rows_json)
      ? row.rows_json.map(payload => ({
          raw_columns: (payload && Array.isArray(payload.raw_columns)) ? payload.raw_columns : null,
          payload: payload || {}
        }))
      : []
  }));

  return { imports };
}
async function handleInvoiceSourcePrint(env, req, invoiceId) {
  // Admin auth
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  if (!invoiceId) {
    return withCORS(env, req, badRequest('invoice_id is required'));
  }

  try {
    const data = await collectSourceRowsForInvoice(env, invoiceId);

    return withCORS(env, req, ok({
      invoice_id: invoiceId,
      imports: data.imports || []
    }));
  } catch (e) {
    console.error('[INVOICE_SOURCE_PRINT] error', {
      invoice_id: invoiceId,
      err: e?.message || String(e)
    });
    return withCORS(env, req, serverError('Failed to collect source rows for invoice'));
  }
}
 
// ---------------------------
// Credit note: create credit for an invoice and unlock associated snapshots
// ---------------------------
// ---------------------------
// Credit note: create credit for an invoice and unlock associated snapshots
// ---------------------------
async function handleCreateCreditNoteTsfin(env, req, invoiceId) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return unauthorized();

  try {
    const actorUserId = (user && user.id) ? user.id : null;

    const r = await sbRpc(env, 'invoice_create_credit_note_and_unlock', {
      p_invoice_id: invoiceId,
      p_actor_user_id: actorUserId
    });

    const rows = Array.isArray(r) ? r : (r?.data || []);
    const x = rows?.[0] || null;
    if (!x || !x.credit_note_id) {
      return serverError('Credit note RPC returned no credit_note_id');
    }

    return ok({
      credit_note_id: x.credit_note_id,
      unlocked_snapshots: Number(x.unlocked_snapshots || 0)
    });
  } catch (e) {
    return serverError(`Credit note create failed: ${e?.message || e}`);
  }
}


// ─────────────────────────────────────────────────────────────
// Global finance windows helper (SQL-first, low subrequests)
// - Reads effective VAT/ERNI/HolidayPay for a given date via RPC: settings_finance_pick(p_date)
// - Caches per-day in memory (Worker instance) with a short TTL to avoid repeated RPCs
// - If ymdOrNull is null/invalid, uses today (Europe/London) on the DB side
// ─────────────────────────────────────────────────────────────

const __financeGlobalsCache = {
  map: new Map(), // key -> { expMs, value }
  ttlMs: 60_000
};

function __isYmd(s) {
  return typeof s === 'string' && /^\d{4}-\d{2}-\d{2}$/.test(s);
}

async function loadFinanceGlobals(env, ymdOrNull = null) {
  // ✅ SETTINGS FIX:
  // - Never rely on p_date=null (DB "today") because timezone/clock skew can select the wrong window.
  // - Always anchor to an explicit YYYY-MM-DD in Europe/London when caller doesn't provide one.
  // - Keep safe numeric defaults if RPC returns nothing / fails.

  const pickTodayYmdLondon = () => {
    // Prefer your existing helper if available
    try {
      if (typeof toLocalParts === 'function') {
        const p = toLocalParts(new Date().toISOString(), null);
        if (p?.ymd && __isYmd(p.ymd)) return String(p.ymd);
      }
    } catch {}

    // Fallback: Intl in Europe/London
    try {
      const s = new Intl.DateTimeFormat('en-GB', {
        timeZone: 'Europe/London',
        year: 'numeric',
        month: '2-digit',
        day: '2-digit'
      }).format(new Date());
      const [dd, mm, yyyy] = String(s).split('/');
      const ymd = `${yyyy}-${mm}-${dd}`;
      if (__isYmd(ymd)) return ymd;
    } catch {}

    // Last resort: UTC date slice
    const ymd = new Date().toISOString().slice(0, 10);
    return __isYmd(ymd) ? ymd : null;
  };

  const anchorYmd = __isYmd(ymdOrNull) ? String(ymdOrNull) : (pickTodayYmdLondon() || null);
  const cacheKey = anchorYmd || 'TODAY';
  const nowMs = Date.now();

  // Cache hit
  try {
    const hit = __financeGlobalsCache.map.get(cacheKey);
    if (hit && hit.expMs > nowMs && hit.value && typeof hit.value === 'object') {
      return hit.value;
    }
  } catch {}

  // Safe defaults if RPC fails or returns empty
  const DEFAULTS = {
    id: null,
    date_from: null,
    date_to: null,
    vat_rate_pct: 20,
    erni_pct: 13.8,
    holiday_pay_pct: 12.07,
    apply_holiday_to: 'PAYE_ONLY',
    apply_erni_to: 'PAYE_ONLY',
    margin_includes: null,
    source: 'FALLBACK'
  };

  const numOr = (v, dflt) => {
    const n = Number(v);
    return Number.isFinite(n) ? n : dflt;
  };

  const parseObjMaybe = (v) => {
    if (v && typeof v === 'object') return v;
    if (typeof v === 'string') {
      try {
        const p = JSON.parse(v);
        return (p && typeof p === 'object') ? p : null;
      } catch {
        return null;
      }
    }
    return null;
  };

  let r0 = null;

  try {
    // Single RPC call: effective finance window (or settings_defaults fallback inside the RPC)
    const rows = await sbRpc(env, 'settings_finance_pick', {
      // ✅ always pass an explicit date when we can
      p_date: anchorYmd
    });

    r0 = Array.isArray(rows) && rows.length ? rows[0] : (rows || null);
  } catch {
    r0 = null;
  }

  const out = {
    id: r0?.id ?? DEFAULTS.id,
    date_from: r0?.date_from ?? DEFAULTS.date_from,
    date_to: r0?.date_to ?? DEFAULTS.date_to,

    vat_rate_pct: numOr(r0?.vat_rate_pct, DEFAULTS.vat_rate_pct),
    erni_pct: numOr(r0?.erni_pct, DEFAULTS.erni_pct),
    holiday_pay_pct: numOr(r0?.holiday_pay_pct, DEFAULTS.holiday_pay_pct),

    apply_holiday_to: (r0?.apply_holiday_to != null) ? String(r0.apply_holiday_to) : DEFAULTS.apply_holiday_to,
    apply_erni_to: (r0?.apply_erni_to != null) ? String(r0.apply_erni_to) : DEFAULTS.apply_erni_to,
    margin_includes: parseObjMaybe(r0?.margin_includes) ?? DEFAULTS.margin_includes,

    source: (r0?.source != null) ? String(r0.source) : DEFAULTS.source
  };

  // Cache set + prune
  try {
    __financeGlobalsCache.map.set(cacheKey, {
      expMs: nowMs + (__financeGlobalsCache.ttlMs || 60_000),
      value: out
    });

    // best-effort prune to avoid unbounded growth
    if (__financeGlobalsCache.map.size > 32) {
      for (const [k, v] of __financeGlobalsCache.map.entries()) {
        if (!v || v.expMs <= nowMs) __financeGlobalsCache.map.delete(k);
      }
      while (__financeGlobalsCache.map.size > 32) {
        const firstKey = __financeGlobalsCache.map.keys().next().value;
        if (!firstKey) break;
        __financeGlobalsCache.map.delete(firstKey);
      }
    }
  } catch {}

  return out;
}


// ─────────────────────────────────────────────────────────────
// Import Column Aliases cache (module-level, short TTL)
// ─────────────────────────────────────────────────────────────
const __IMPORT_COL_ALIAS_CACHE = new Map(); 
// key -> { expMs:number, aliases:string[] }

function __nowMs(){ return Date.now(); }

function __normEnum(s){ return String(s || '').trim().toUpperCase(); }

function __normAlias(s){
  return String(s || '').trim().toLowerCase();
}

// Back-compat wrappers for older router naming
async function handleTsfinExpensesPatch(env, req, timesheetId) {
  return handleTsfinPatchExpenses(env, req, timesheetId);
}

async function handleTsfinMileagePatch(env, req, timesheetId) {
  return handleTsfinPatchMileage(env, req, timesheetId);
}


async function getImportColumnAliasesCached(env, systemType, fieldKey) {
  const sys = __normEnum(systemType);
  const key = __normEnum(fieldKey);
  const cacheKey = `${sys}|${key}`;

  const hit = __IMPORT_COL_ALIAS_CACHE.get(cacheKey);
  const now = __nowMs();
  if (hit && hit.expMs && hit.expMs > now && Array.isArray(hit.aliases)) {
    return hit.aliases;
  }

  // If table not yet created, fail soft: return []
  // (callers still have fallback matchers)
  try {
    const { rows } = await sbFetch(
      env,
      `${env.SUPABASE_URL}/rest/v1/import_column_aliases` +
      `?system_type=eq.${encodeURIComponent(sys)}` +
      `&field_key=eq.${encodeURIComponent(key)}` +
      `&active=eq.true` +
      `&select=alias_name` +
      `&order=alias_name.asc`
    );

    const aliases = (rows || [])
      .map(r => __normAlias(r?.alias_name))
      .filter(Boolean);

    // TTL: 5 minutes
    __IMPORT_COL_ALIAS_CACHE.set(cacheKey, {
      expMs: now + 5 * 60 * 1000,
      aliases
    });

    return aliases;
  } catch (e) {
    console.warn('[IMPORT_COL_ALIASES] load failed (soft)', {
      systemType: sys,
      fieldKey: key,
      err: e?.message || String(e)
    });
    __IMPORT_COL_ALIAS_CACHE.set(cacheKey, {
      expMs: now + 60 * 1000,
      aliases: []
    });
    return [];
  }
}

function findColByAliases(headerRow, aliases, fallbackIdx, fallbackMatcher) {
  const hdr = Array.isArray(headerRow) ? headerRow : [];
  const normAliases = (aliases || [])
    .map(a => String(a || '').trim().toLowerCase())
    .filter(Boolean);

  // 1) Try alias list (exact or substring)
  if (normAliases.length) {
    const idx = hdr.findIndex(cell => {
      const h = String(cell || '').trim().toLowerCase();
      if (!h) return false;
      // exact match OR substring match
      return normAliases.some(a => h === a || h.includes(a));
    });
    if (idx >= 0) return idx;
  }

  // 2) Try fallback matcher
  if (typeof fallbackMatcher === 'function') {
    const idx2 = hdr.findIndex(cell => fallbackMatcher(String(cell || '').toLowerCase()));
    if (idx2 >= 0) return idx2;
  }

  // 3) Fallback index
  return fallbackIdx;
}
function __isUuid(s){
  const v = String(s || '').trim();
  return /^[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i.test(v);
}
function __upper(s){ return String(s||'').trim().toUpperCase(); }
function __trim(s){ return String(s||'').trim(); }

function __validateBandMappingPayload(p, { allowPartial=false } = {}) {
  const out = {};

  const system_type = p?.system_type != null ? __upper(p.system_type) : null;
  const incoming_code = p?.incoming_code != null ? __trim(p.incoming_code) : null;
  const band_match_pattern = p?.band_match_pattern != null ? __trim(p.band_match_pattern) : null;

  const candidate_id = p?.candidate_id ? String(p.candidate_id) : null;
  const client_id = p?.client_id ? String(p.client_id) : null;

  if (!allowPartial || p?.system_type != null) {
    if (!['NHSP','HR_WEEKLY'].includes(system_type)) return { error: 'system_type must be NHSP or HR_WEEKLY' };
    out.system_type = system_type;
  }

  if (!allowPartial || p?.incoming_code != null) {
    if (!incoming_code) return { error: 'incoming_code is required' };
    out.incoming_code = incoming_code;
  }

  if (!allowPartial || p?.band_match_pattern != null) {
    if (!band_match_pattern) return { error: 'band_match_pattern is required' };
    out.band_match_pattern = band_match_pattern;
  }

  if (p?.candidate_id !== undefined) {
    if (candidate_id && !__isUuid(candidate_id)) return { error: 'candidate_id must be a uuid' };
    out.candidate_id = candidate_id || null;
  }

  if (p?.client_id !== undefined) {
    if (client_id && !__isUuid(client_id)) return { error: 'client_id must be a uuid' };
    out.client_id = client_id || null;
  }

  // scope rule: cannot set both
  const cand = (out.candidate_id !== undefined ? out.candidate_id : candidate_id) || null;
  const cli  = (out.client_id !== undefined ? out.client_id : client_id) || null;
  if (cand && cli) return { error: 'scope invalid: candidate_id and client_id cannot both be set' };

  if (p?.active !== undefined) out.active = !!p.active;
  if (p?.notes !== undefined) out.notes = (p.notes == null ? null : String(p.notes));

  // always bump updated_at when writing
  out.updated_at = new Date().toISOString();

  return { ok: true, value: out };
}

export async function handleListAssignmentBandMappings(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const url = new URL(req.url);
  const q = url.searchParams;

  const system_type   = q.get('system_type') ? __upper(q.get('system_type')) : null;
  const candidate_id  = q.get('candidate_id');
  const client_id     = q.get('client_id');
  const incoming_like = q.get('incoming_like'); // optional substring filter
  const include_inactive = (q.get('include_inactive') === 'true');

  // optional "scope" helper
  const scope = q.get('scope') ? __upper(q.get('scope')) : null; // GLOBAL|CLIENT|CANDIDATE

  let qs =
    `${env.SUPABASE_URL}/rest/v1/assignment_band_mappings` +
    `?select=*` +
    `&order=system_type.asc,incoming_code.asc,band_match_pattern.asc`;

  if (system_type) qs += `&system_type=eq.${encodeURIComponent(system_type)}`;
  if (!include_inactive) qs += `&active=eq.true`;

  if (scope === 'GLOBAL') {
    qs += `&candidate_id=is.null&client_id=is.null`;
  } else if (scope === 'CANDIDATE') {
    if (!candidate_id || !__isUuid(candidate_id)) return withCORS(env, req, badRequest('candidate_id is required for scope=CANDIDATE'));
    qs += `&candidate_id=eq.${encodeURIComponent(candidate_id)}`;
  } else if (scope === 'CLIENT') {
    if (!client_id || !__isUuid(client_id)) return withCORS(env, req, badRequest('client_id is required for scope=CLIENT'));
    qs += `&candidate_id=is.null&client_id=eq.${encodeURIComponent(client_id)}`;
  } else {
    // direct filters (optional)
    if (candidate_id) {
      if (!__isUuid(candidate_id)) return withCORS(env, req, badRequest('candidate_id must be uuid'));
      qs += `&candidate_id=eq.${encodeURIComponent(candidate_id)}`;
    }
    if (client_id) {
      if (!__isUuid(client_id)) return withCORS(env, req, badRequest('client_id must be uuid'));
      qs += `&client_id=eq.${encodeURIComponent(client_id)}`;
    }
  }

  if (incoming_like) {
    const pat = String(incoming_like).replace(/[%]/g,'').trim();
    if (pat) qs += `&incoming_code=ilike.${encodeURIComponent(`*${pat}*`)}`;
  }

  const { rows } = await sbFetch(env, qs);
  return withCORS(env, req, ok({ rows: rows || [] }));
}

export async function handleCreateAssignmentBandMapping(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const v = __validateBandMappingPayload(body || {}, { allowPartial: false });
  if (!v.ok) return withCORS(env, req, badRequest(v.error));

  const nowIso = new Date().toISOString();
  const payload = {
    ...v.value,
    created_at: nowIso,
    updated_at: nowIso,
    active: (body?.active === undefined ? true : !!body.active)
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/assignment_band_mappings`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation', 'content-type': 'application/json' },
      body: JSON.stringify([payload])
    }
  );
  const txt = await res.text().catch(() => '');
  if (!res.ok) return withCORS(env, req, serverError(`Insert failed: ${txt}`));

  const json = txt ? JSON.parse(txt) : [];
  const row = Array.isArray(json) ? json[0] : json;
  return withCORS(env, req, ok({ row }));
}

export async function handleUpdateAssignmentBandMapping(env, req, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!id || !__isUuid(id)) return withCORS(env, req, badRequest('id must be uuid'));

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }

  const v = __validateBandMappingPayload(body || {}, { allowPartial: true });
  if (!v.ok) return withCORS(env, req, badRequest(v.error));

  const patch = v.value;

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/assignment_band_mappings?id=eq.${encodeURIComponent(id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation', 'content-type': 'application/json' },
      body: JSON.stringify(patch)
    }
  );
  const txt = await res.text().catch(() => '');
  if (!res.ok) return withCORS(env, req, serverError(`Update failed: ${txt}`));

  const json = txt ? JSON.parse(txt) : [];
  const row = Array.isArray(json) ? json[0] : json;
  return withCORS(env, req, ok({ row }));
}

export async function handleDeleteAssignmentBandMapping(env, req, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!id || !__isUuid(id)) return withCORS(env, req, badRequest('id must be uuid'));

  // soft delete
  const patch = {
    active: false,
    updated_at: new Date().toISOString()
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/assignment_band_mappings?id=eq.${encodeURIComponent(id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation', 'content-type': 'application/json' },
      body: JSON.stringify(patch)
    }
  );
  const txt = await res.text().catch(() => '');
  if (!res.ok) return withCORS(env, req, serverError(`Delete (deactivate) failed: ${txt}`));

  const json = txt ? JSON.parse(txt) : [];
  const row = Array.isArray(json) ? json[0] : json;
  return withCORS(env, req, ok({ row }));
}
function __validateColumnAliasPayload(p, { allowPartial=false } = {}) {
  const out = {};

  const system_type = p?.system_type != null ? __upper(p.system_type) : null;
  const field_key   = p?.field_key   != null ? __upper(p.field_key)   : null;
  const alias_name  = p?.alias_name  != null ? __trim(p.alias_name)   : null;

  if (!allowPartial || p?.system_type != null) {
    if (!['NHSP','HR_WEEKLY','HR_DAILY'].includes(system_type)) {
      return { error: 'system_type must be NHSP, HR_WEEKLY, or HR_DAILY' };
    }
    out.system_type = system_type;
  }
  if (!allowPartial || p?.field_key != null) {
    if (!['ASSIGNMENT','GRADE'].includes(field_key)) {
      return { error: 'field_key must be ASSIGNMENT or GRADE' };
    }
    out.field_key = field_key;
  }
  if (!allowPartial || p?.alias_name != null) {
    if (!alias_name) return { error: 'alias_name is required' };
    out.alias_name = alias_name;
  }

  if (p?.active !== undefined) out.active = !!p.active;
  if (p?.notes !== undefined) out.notes = (p.notes == null ? null : String(p.notes));

  out.updated_at = new Date().toISOString();
  return { ok: true, value: out };
}

export async function handleListImportColumnAliases(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  const url = new URL(req.url);
  const q = url.searchParams;

  const system_type = q.get('system_type') ? __upper(q.get('system_type')) : null;
  const field_key   = q.get('field_key')   ? __upper(q.get('field_key'))   : null;
  const include_inactive = (q.get('include_inactive') === 'true');

  let qs =
    `${env.SUPABASE_URL}/rest/v1/import_column_aliases` +
    `?select=*` +
    `&order=system_type.asc,field_key.asc,alias_name.asc`;

  if (system_type) qs += `&system_type=eq.${encodeURIComponent(system_type)}`;
  if (field_key)   qs += `&field_key=eq.${encodeURIComponent(field_key)}`;
  if (!include_inactive) qs += `&active=eq.true`;

  const { rows } = await sbFetch(env, qs);
  return withCORS(env, req, ok({ rows: rows || [] }));
}

export async function handleCreateImportColumnAlias(env, req) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const v = __validateColumnAliasPayload(body || {}, { allowPartial: false });
  if (!v.ok) return withCORS(env, req, badRequest(v.error));

  const nowIso = new Date().toISOString();
  const payload = {
    ...v.value,
    created_at: nowIso,
    updated_at: nowIso,
    active: (body?.active === undefined ? true : !!body.active)
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/import_column_aliases`,
    {
      method: 'POST',
      headers: { ...sbHeaders(env), Prefer: 'return=representation', 'content-type': 'application/json' },
      body: JSON.stringify([payload])
    }
  );
  const txt = await res.text().catch(() => '');
  if (!res.ok) return withCORS(env, req, serverError(`Insert failed: ${txt}`));

  const json = txt ? JSON.parse(txt) : [];
  const row = Array.isArray(json) ? json[0] : json;
  return withCORS(env, req, ok({ row }));
}

export async function handleUpdateImportColumnAlias(env, req, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!id || !__isUuid(id)) return withCORS(env, req, badRequest('id must be uuid'));

  let body;
  try { body = await parseJSONBody(req); } catch { body = null; }
  const v = __validateColumnAliasPayload(body || {}, { allowPartial: true });
  if (!v.ok) return withCORS(env, req, badRequest(v.error));

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/import_column_aliases?id=eq.${encodeURIComponent(id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation', 'content-type': 'application/json' },
      body: JSON.stringify(v.value)
    }
  );
  const txt = await res.text().catch(() => '');
  if (!res.ok) return withCORS(env, req, serverError(`Update failed: ${txt}`));

  const json = txt ? JSON.parse(txt) : [];
  const row = Array.isArray(json) ? json[0] : json;
  return withCORS(env, req, ok({ row }));
}

export async function handleDeleteImportColumnAlias(env, req, id) {
  const user = await requireUser(env, req, ['admin']);
  if (!user) return withCORS(env, req, unauthorized());
  if (!id || !__isUuid(id)) return withCORS(env, req, badRequest('id must be uuid'));

  const patch = {
    active: false,
    updated_at: new Date().toISOString()
  };

  const res = await fetch(
    `${env.SUPABASE_URL}/rest/v1/import_column_aliases?id=eq.${encodeURIComponent(id)}`,
    {
      method: 'PATCH',
      headers: { ...sbHeaders(env), Prefer: 'return=representation', 'content-type': 'application/json' },
      body: JSON.stringify(patch)
    }
  );
  const txt = await res.text().catch(() => '');
  if (!res.ok) return withCORS(env, req, serverError(`Delete (deactivate) failed: ${txt}`));

  const json = txt ? JSON.parse(txt) : [];
  const row = Array.isArray(json) ? json[0] : json;
  return withCORS(env, req, ok({ row }));
}


// ---------------------------
// Auth, CORS, JSON helpers stubs – remove these if you already have them globally
// ---------------------------

// ---------------------- Router ----------------------
function matchPath(pathname, pattern) {
  const pa = pathname.split("/").filter(Boolean);
  const pb = pattern.split("/").filter(Boolean);
  if (pa.length !== pb.length) return null;
  const params = {};
  for (let i = 0; i < pb.length; i++) {
    if (pb[i].startsWith(":")) params[pb[i].slice(1)] = decodeURIComponent(pa[i]);
    else if (pb[i] !== pa[i]) return null;
  }
  return params;
}
// BACKEND — FULL ROUTER ( default) — unchanged routes map but now benefits from updated CORS/sbFetch
export default {
  async fetch(req, env) {
    const pre = preflightIfNeeded(env, req);
    if (pre) return pre;

    const url = new URL(req.url);
    const p = url.pathname;

    try {
      // ====================== AUTH ======================
      if (req.method === 'POST' && p === '/auth/login')   return withCORS(env, req, await handleAuthLogin(env, req));
      if (req.method === 'POST' && p === '/auth/refresh') return withCORS(env, req, await handleAuthRefresh(env, req));
      if (req.method === 'POST' && p === '/auth/logout')  return withCORS(env, req, await handleAuthLogout(env, req));
      if (req.method === 'POST' && p === '/auth/forgot')  return withCORS(env, req, await handleAuthForgot(env, req));
      if (req.method === 'POST' && p === '/auth/reset')   return withCORS(env, req, await handleAuthReset(env, req));

      // ====================== HEALTH ======================
      if (req.method === "GET" && p === "/healthz") return handleHealth(env);
      if (req.method === "GET" && p === "/readyz")  return handleReady(env);
      if (req.method === "GET" && p === "/version") return handleVersion();

      // Me
      if (req.method === 'GET' && p === '/api/me') {
        return handleMe(env, req);
      }

      // User grid preferences (per-user summary column layout)
      if (req.method === 'GET' && p === '/api/users/me/grid-prefs') {
        return withCORS(env, req, await handleUserGridPrefsGet(env, req));
      }
      if (req.method === 'PATCH' && p === '/api/users/me/grid-prefs') {
        return withCORS(env, req, await handleUserGridPrefsPatch(env, req));
      }


      // ====================== PUBLIC (mobile) WRITE FLOW ======================
      if (req.method === "POST" && p === "/timesheets/presign")            return handlePresign(env, req);
      if (req.method === "PUT"  && p === "/upload")                         return handleUpload(env, req, url);
      if (req.method === "POST" && p === "/timesheets/submit")              return handleSubmit(env, req);

      // Time / TZ checks
      if (req.method === "POST" && p === "/time/uk-check")                  return handleUKTimeCheck(env, req);

      // Revoke flows
      if (req.method === "POST" && p === "/timesheets/revoke")              return handleRevoke(env, req);
      if (req.method === "POST" && p === "/timesheets/revoke-and-presign")  return handleRevokeAndPresign(env, req);

      // Reads
      const one = matchPath(p, "/timesheets/:booking_id");
      if (req.method === "GET" && one)                                      return handleGetOne(env, req, one.booking_id, url);
      if (req.method === "GET" && p === "/timesheets")                      return handleList(env, req, url);
      if (req.method === "POST" && p === "/timesheets/query")               return handleQuery(env, req);
      if (req.method === "POST" && p === "/timesheets/authorised-status")   return handleAuthorisedStatus(env, req);

      // Signatures
      if (req.method === "POST" && p === "/signatures/presign-get")         return handleSignPresignGet(env, req);
      if (req.method === "POST" && p === "/signatures/presign-get/batch")   return handleSignPresignGetBatch(env, req);
      if (req.method === "GET"  && p === "/signatures/get")                 return handleSignGet(env, req, url);



      // ====================== ADMIN/BACKOFFICE API ROUTES ======================

// Settings (singleton)
if (req.method === 'GET' && p === '/api/settings/defaults')           return handleGetSettings(env, req);
if (req.method === 'PUT' && p === '/api/settings/defaults')           return handleUpdateSettings(env, req);
if (req.method === 'GET'   && p === '/api/settings/finance-windows') return handleSettingsFinanceWindows(env, req);
if (req.method === 'POST'  && p === '/api/settings/finance-windows') return handleSettingsFinanceWindows(env, req);

if (req.method === 'PATCH' && p.startsWith('/api/settings/finance-windows/')) {
  const id = p.split('/').pop();
  return handleSettingsFinanceWindows(env, req, id);
}

if (req.method === 'DELETE' && p.startsWith('/api/settings/finance-windows/')) {
  const id = p.split('/').pop();
  return handleSettingsFinanceWindows(env, req, id);
}

// NEW: Weekly band mappings (NHSP + HR weekly)
if (req.method === 'GET'  && p === '/api/assignment-band-mappings')   return handleListAssignmentBandMappings(env, req);
if (req.method === 'POST' && p === '/api/assignment-band-mappings')   return handleCreateAssignmentBandMapping(env, req);
{
  const m = matchPath(p, '/api/assignment-band-mappings/:id');
  if (m && req.method === 'PATCH')                                    return handleUpdateAssignmentBandMapping(env, req, m.id);
  if (m && req.method === 'DELETE')                                   return handleDeleteAssignmentBandMapping(env, req, m.id);
}

// NEW: Import column aliases (Grade/Assignment header name config)
if (req.method === 'GET'  && p === '/api/import-column-aliases')      return handleListImportColumnAliases(env, req);
if (req.method === 'POST' && p === '/api/import-column-aliases')      return handleCreateImportColumnAlias(env, req);
{
  const m = matchPath(p, '/api/import-column-aliases/:id');
  if (m && req.method === 'PATCH')                                    return handleUpdateImportColumnAlias(env, req, m.id);
  if (m && req.method === 'DELETE')                                   return handleDeleteImportColumnAlias(env, req, m.id);
}

// Job Titles (families / subfamilies / roles)
if (req.method === 'GET'  && p === '/api/job-titles')                 return handleListJobTitles(env, req);
if (req.method === 'POST' && p === '/api/job-titles')                 return handleCreateJobTitle(env, req);
{
  const jt = matchPath(p, '/api/job-titles/:id');
  if (jt && req.method === 'PATCH')                                   return handleUpdateJobTitle(env, req, jt.id);
  if (jt && req.method === 'DELETE')                                  return handleDeleteJobTitle(env, req, jt.id);
}

      // Tools
      if (req.method === 'GET'  && p === '/api/tools/postcode-lookup')      return handlePostcodeLookup(env, req);


      // Clients
      if (req.method === 'GET' && p === '/api/clients')                     return handleListClients(env, req);
      if (req.method === 'POST' && p === '/api/clients')                    return handleCreateClient(env, req);
      // Enriched details route (legacy/expanded shape)
      {
        const clientDetails = matchPath(p, '/api/clients/:id/details');
        if (clientDetails && req.method === 'GET')                          return handleGetClient(env, req, clientDetails.id);
      }

{
  const clientAlias = matchPath(p, '/api/clients/:id/aliases');
  if (clientAlias && req.method === 'DELETE') {
    return handleClientAliasesDelete(env, req, clientAlias.id);
  }
}

      {
        const client = matchPath(p, '/api/clients/:id');
        if (client && req.method === 'GET')                                 return handleClientsGet(env, req, client.id);   // base row for pickers
        if (client && req.method === 'PUT')                                 return handleUpdateClient(env, req, client.id);
      }

      // Client Hospitals
      {
        const chList = matchPath(p, '/api/clients/:client_id/hospitals');
        if (chList && req.method === 'GET')    return handleListHospitals(env, req, chList.client_id);
        if (chList && req.method === 'POST')   return handleCreateHospital(env, req, chList.client_id);

        const chOne = matchPath(p, '/api/clients/:client_id/hospitals/:hospital_id');
        if (chOne && req.method === 'GET')     return handleGetHospital(env, req, chOne.client_id, chOne.hospital_id);
        if (chOne && (req.method === 'PATCH' || req.method === 'PUT'))
                                               return handleUpdateHospital(env, req, chOne.client_id, chOne.hospital_id);
        if (chOne && req.method === 'DELETE')  return handleDeleteHospital(env, req, chOne.client_id, chOne.hospital_id);
      }

      // Umbrellas
      if (req.method === 'GET' && p === '/api/umbrellas')                   return handleListUmbrellas(env, req);
      if (req.method === 'POST' && p === '/api/umbrellas')                  return handleCreateUmbrella(env, req);
      {
        const umb = matchPath(p, '/api/umbrellas/:umbrella_id');
        if (umb && req.method === 'GET')                                    return handleGetUmbrella(env, req, umb.umbrella_id);
        if (umb && req.method === 'PUT')                                    return handleUpdateUmbrella(env, req, umb.umbrella_id);
      }

      // Overlap check (must be before broader overrides matchers)
      if (req.method === 'GET' && p === '/api/rates/candidate-overrides/overlap-exists') {
        return handleCandidateOverrideOverlapExists(env, req);
      }
      // Candidates
      if (req.method === 'GET' && p === '/api/candidates')                  return handleListCandidates(env, req);
      if (req.method === 'POST' && p === '/api/candidates')                 return handleCreateCandidate(env, req);
      // Enriched legacy/details route
      {
        const candDet = matchPath(p, '/api/candidates/:candidate_id/details');
        if (candDet && req.method === 'GET')                                return handleGetCandidate(env, req, candDet.candidate_id);
      }

{
  const candAlias = matchPath(p, '/api/candidates/:id/aliases');
  if (candAlias && req.method === 'DELETE') {
    return handleCandidateAliasesDelete(env, req, candAlias.id);
  }
}


      // Candidate calendar
      {
        const cc = matchPath(p, '/api/candidates/:id/calendar');
        if (cc && req.method === 'GET')                                     return handleCandidateCalendar(env, req, cc.id);
      }

      // NEW: candidate pay-method change preview
      {
        const m = matchPath(p, '/api/candidates/:id/pay-method-change-preview');
        if (m && req.method === 'GET')                                      return handleCandidatePayMethodChangePreview(env, req, m.id);
      }

      // NEW: candidate pay-method change apply
      {
        const m = matchPath(p, '/api/candidates/:id/pay-method-change');
        if (m && req.method === 'POST')                                     return handleCandidatePayMethodChange(env, req, m.id);
      }

      {
        const cand = matchPath(p, '/api/candidates/:candidate_id');
        if (cand && req.method === 'GET')
          return handleGetCandidate(env, req, cand.candidate_id); // full row + job_titles
        if (cand && req.method === 'PUT')
          return handleUpdateCandidate(env, req, cand.candidate_id);
      }

      // ====================== PAY ADVANCES ======================
      {
        const m = matchPath(p, '/api/candidates/:id/advances');
        if (m && req.method === 'GET')   return handlePayAdvancesList(env, req);
      }
      {
        const m = matchPath(p, '/api/candidates/:id/advances/summary');
        if (m && req.method === 'GET')   return handlePayAdvancesSummary(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/candidates/:id/advances/missing-shift');
        if (m && req.method === 'POST')  return handlePayAdvancesCreateMissingShift(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/candidates/:id/advances/manual');
        if (m && req.method === 'POST')  return handlePayAdvancesCreateManual(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/advances/:id');
        if (m && req.method === 'PATCH') return handlePayAdvancesUpdate(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/advances/:id/pause');
        if (m && req.method === 'POST')  return handlePayAdvancesPause(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/advances/:id/resume');
        if (m && req.method === 'POST')  return handlePayAdvancesResume(env, req, m.id);
      }

      // Rates — client defaults
      if (req.method === 'GET'  && p === '/api/rates/client-defaults')      return handleListClientRates(env, req);
      if (req.method === 'POST' && p === '/api/rates/client-defaults')      return handleUpsertClientRate(env, req);
      {
        const r = matchPath(p, '/api/rates/client-defaults/:id');
        if (r && req.method === 'PUT')      return handleUpdateClientDefault(env, req, r.id);   // NEW: full-field update
        if (r && req.method === 'PATCH')    return handlePatchClientDefault(env, req, r.id);    // existing: enable/disable etc.
        if (r && req.method === 'DELETE')   return handleDeleteClientDefault(env, req, r.id);   // existing delete
      }

      // Candidate overrides
      if (req.method === 'GET' && p === '/api/rates/candidate-overrides')   return handleListOverridesByCandidate(env, req);
      if (req.method === 'GET' && p === '/api/rates/client-overrides')      return handleListOverridesByClient(env, req);
      if (req.method === 'POST' && p === '/api/rates/candidate-overrides')  return handleCreateOverride(env, req);

      // Resolve preview
      if (req.method === 'GET'  && p === '/api/rates/resolve-preview')      return handleResolveRate(env, req);
      if (req.method === 'POST' && p === '/api/rates/resolve-preview')      return handleResolveRate(env, req);

      {
        const cov = matchPath(p, '/api/rates/candidate-overrides/:candidate_id');
        if (cov && req.method === 'PATCH')                                  return handleUpdateOverride(env, req, cov.candidate_id);
        if (cov && req.method === 'DELETE')                                 return handleDeleteOverride(env, req, cov.candidate_id);
      }

      if (req.method === 'GET' && p === '/api/rates/candidate-overrides/by-client') {
        return handleListOverridesByClient(env, req);
      }

      // HealthRoster
      if (req.method === 'POST' && p === '/api/healthroster/import')        return handleHRImport(env, req);
      {
        const hrRows = matchPath(p, '/api/healthroster/:import_id/rows');
        if (hrRows && req.method === 'GET')                                  return handleHRRows(env, req, hrRows.import_id);
      }
      {
        const hrMap = matchPath(p, '/api/healthroster/:import_id/mapping');
        if (hrMap && (req.method === 'GET' || req.method === 'POST'))        return handleHRMapping(env, req, hrMap.import_id);
      }
      {
        const hrVal = matchPath(p, '/api/healthroster/:import_id/validate');
        if (hrVal && req.method === 'POST')                                  return handleHRValidate(env, req, hrVal.import_id);
      }

      // inside your main fetch router, with the other HealthRoster routes
if (req.method === 'GET' && p === '/api/healthroster/autoprocess/clients') {
  return withCORS(env, req, await handleHrAutoprocessClients(env, req));
}

      // NEW: HealthRoster weekly autoprocess (separate from rota validation)
      if (req.method === 'POST' && p === '/api/healthroster/autoprocess/import') {
        return handleHrAutoprocessImport(env, req);
      }
      {
        // NEW: HealthRoster weekly autoprocess PREVIEW
        const hrAutoPrev = matchPath(p, '/api/healthroster/autoprocess/:import_id/preview');
        if (hrAutoPrev && req.method === 'GET') {
          return handleHrAutoprocessPreview(env, req, hrAutoPrev.import_id);
        }

        const hrAuto = matchPath(p, '/api/healthroster/:import_id/autoprocess-apply');
        if (hrAuto && req.method === 'POST') {
          return handleHrAutoprocessApply(env, req, hrAuto.import_id);
        }
      }

      if (req.method === 'POST' && p === '/api/hr/tso-failure-email')        return handleQueueTsoFailureEmail(env, req);

          // NEW: HR rota daily import/preview/apply
      if (req.method === 'POST' && p === '/api/imports/hr-rota/parse') {
        return handleImportHrRotaParse(env, req);
      }
      {
        const rotaPrev = matchPath(p, '/api/imports/hr-rota/:import_id/preview');
        if (rotaPrev && req.method === 'GET') {
          return handleHrRotaValidationPreview(env, req, rotaPrev.import_id);
        }
      }
      {
        const rotaApply = matchPath(p, '/api/imports/hr-rota/:import_id/apply');
        if (rotaApply && req.method === 'POST') {
          return handleHrRotaValidationApply(env, req, rotaApply.import_id);
        }
      }
      {
        // NEW: HR rota daily resolve-conflicts (name/client aliases only)
        const rotaResolve = matchPath(p, '/api/imports/hr-rota/:import_id/resolve-conflicts');
        if (rotaResolve && req.method === 'POST') {
          return handleHrRotaResolveMappings(env, req, rotaResolve.import_id);
        }
      }

      // NEW: HR daily rota TSO email
      if (req.method === 'POST' && p === '/api/hr/rota/tso-email') {
        return handleHrRotaQueueTsoEmail(env, req);
      }

          // NHSP imports + apply + diagnostics
      if (req.method === 'POST' && p === '/api/nhsp/import')                 return handleNhspImport(env, req);
      {
        const nRows = matchPath(p, '/api/nhsp/:import_id/rows');
        if (nRows && req.method === 'GET')                                   return handleNhspRows(env, req, nRows.import_id);
      }
      {
        const nPrev = matchPath(p, '/api/nhsp/:import_id/preview');
        if (nPrev && req.method === 'GET')                                   return handleNhspImportPreview(env, req, nPrev.import_id);
      }
      {
        const nConf = matchPath(p, '/api/nhsp/:import_id/confirm');
        if (nConf && req.method === 'POST')                                  return handleNhspImportConfirm(env, req, nConf.import_id);
      }
      {
        const nApply = matchPath(p, '/api/nhsp/:import_id/apply');
        if (nApply && req.method === 'POST')                                 return handleNhspApply(env, req, nApply.import_id);
      }
      {
        // NEW: NHSP weekly resolve-conflicts (aliases + contract check)
        const nResolve = matchPath(p, '/api/nhsp/:import_id/resolve-conflicts');
        if (nResolve && req.method === 'POST') {
          return withCORS(env, req, await handleNhspResolveMappings(env, req, nResolve.import_id));
        }
      }
      if (req.method === 'GET' && p === '/api/nhsp/imports')                 return handleNhspImportsList(env, req);

      {
        const nSum = matchPath(p, '/api/nhsp/:import_id/summary');
        if (nSum && req.method === 'GET')                                    return handleNhspImportSummary(env, req, nSum.import_id);
      }

      if (req.method === 'POST' && p === '/api/timesheets/finance-preview')  return handleFinancePreviewTsfin(env, req);

      if (req.method === 'POST' && p === '/api/timesheets/bucket-preview') {
        return handleTimesheetBucketPreview(env, req);
      }

      // TSFIN worker & utilities
      if (req.method === 'POST' && p === '/api/tsfin/queue/drain')           return handleTsfinDrain(env, req);
      if (req.method === 'POST' && p === '/api/tsfin/recompute')             return handleTsfinRecompute(env, req);
      if (req.method === 'GET'  && p === '/api/tsfin/financials')            return handleTsfinFinancials(env, req);
      if (req.method === 'POST' && p === '/api/tsfin/mark-ready')            return handleTsfinMarkReady(env, req);

      {
        const tsfinOne = matchPath(p, '/api/tsfin/:timesheet_id');
        if (tsfinOne && req.method === 'PATCH')                              return handleTsfinPatch(env, req, tsfinOne.timesheet_id);

        const tsfinExp = matchPath(p, '/api/tsfin/:timesheet_id/expenses');
        if (tsfinExp && req.method === 'PATCH')                              return handleTsfinPatchExpenses(env, req, tsfinExp.timesheet_id);

        const tsfinMil = matchPath(p, '/api/tsfin/:timesheet_id/mileage');
        if (tsfinMil && req.method === 'PATCH')                              return handleTsfinPatchMileage(env, req, tsfinMil.timesheet_id);

        const tsfinPO = matchPath(p, '/api/tsfin/:timesheet_id/po');
        if (tsfinPO && req.method === 'PATCH')                               return handleTsfinPatchPO(env, req, tsfinPO.timesheet_id);

        const tsfinSeg = matchPath(p, '/api/tsfin/:timesheet_id/segments');
        if (tsfinSeg && req.method === 'PATCH')                              return handleTsfinUpdateSegments(env, req, tsfinSeg.timesheet_id);
      }


      {
        const payHold = matchPath(p, '/api/timesheets/:id/pay-hold');
        if (payHold && req.method === 'PATCH')                               return handleTimesheetPayHold(env, req, payHold.id);

        const markPaid = matchPath(p, '/api/timesheets/:id/mark-paid');
        if (markPaid && req.method === 'PATCH')                              return handleTimesheetMarkPaid(env, req, markPaid.id);
      }
{
  const m = matchPath(p, '/api/timesheets/:id/adjustments');
  if (m && req.method === 'GET') return handleTimesheetGetDailyAdjustments(env, req, m.id);
}

      {
        const m = matchPath(p, '/api/timesheets/:id/revert-to-electronic');
        if (m && req.method === 'POST') {
          return handleTimesheetRevertToElectronic(env, req, m.id);
        }
      }

// Evidence (timesheet_evidence)

// GET /api/timesheets/:id/evidence
// POST /api/timesheets/:id/evidence
{
  const m = matchPath(p, '/api/timesheets/:id/evidence');
  if (m && req.method === 'GET') {
    return withCORS(env, req, await handleTimesheetEvidenceList(env, req, m.id));
  }
  if (m && req.method === 'POST') {
    return withCORS(env, req, await handleTimesheetEvidenceAdd(env, req, m.id));
  }
}

// PATCH /api/timesheets/:id/evidence/:evidence_id   (reclassify kind)
// DELETE /api/timesheets/:id/evidence/:evidence_id
{
  const m = matchPath(p, '/api/timesheets/:id/evidence/:evidence_id');

  if (m && req.method === 'PATCH') {
    return withCORS(env, req, await handleTimesheetEvidenceUpdateKind(env, req, m.id, m.evidence_id));
  }

  if (m && req.method === 'DELETE') {
    return withCORS(env, req, await handleTimesheetEvidenceDelete(env, req, m.id, m.evidence_id));
  }
}






      // ─────────────────────────────────────────────────────────────────────────────
      // Pickers: snapshots, deltas, id-list
      // ─────────────────────────────────────────────────────────────────────────────
      if (req.method === 'GET' && p === '/api/pickers/candidates/snapshot')  return withCORS(env, req, await handlePickerCandidatesSnapshot(env, req));
      if (req.method === 'GET' && p === '/api/pickers/candidates/delta')     return withCORS(env, req, await handlePickerCandidatesDelta(env, req));
      if (req.method === 'GET' && p === '/api/pickers/candidates/id-list')   return withCORS(env, req, await handlePickerCandidatesIdList(env, req));

      if (req.method === 'GET' && p === '/api/pickers/clients/snapshot')     return withCORS(env, req, await handlePickerClientsSnapshot(env, req));
      if (req.method === 'GET' && p === '/api/pickers/clients/delta')        return withCORS(env, req, await handlePickerClientsDelta(env, req));
      if (req.method === 'GET' && p === '/api/pickers/clients/id-list')      return withCORS(env, req, await handlePickerClientsIdList(env, req));


      // Invoices
      if (req.method === 'GET'  && p === '/api/invoices')                    return handleListInvoices(env, req);
      if (req.method === 'POST' && p === '/api/invoices')                    return handleCreateInvoiceTsfin(env, req);
      if (req.method === 'POST' && p === '/api/invoices/create-expenses')    return handleCreateInvoiceExpenses(env, req);
      // NEW: per-week, segment-based TSFIN invoicer
      if (req.method === 'POST' && p === '/api/invoices/tsfin/by-week')      return handleCreateInvoiceTsfinByWeek(env, req);

      {
        const inv = matchPath(p, '/api/invoices/:invoice_id');
        if (inv && req.method === 'GET')                                     return handleGetInvoice(env, req, inv.invoice_id);
      }


{
  const m = matchPath(p, '/api/invoices/:invoice_id');
  if (m && req.method === 'DELETE') return handleInvoiceDeleteOne(env, req, m.invoice_id);
}


      {
        const invSource = matchPath(p, '/api/invoices/:invoice_id/source-print');
        if (invSource && req.method === 'GET')                               return handleInvoiceSourcePrint(env, req, invSource.invoice_id);
      }

      {
        const invRender = matchPath(p, '/api/invoices/:invoice_id/render');
        if (invRender && req.method === 'POST')                              return handleInvoiceRender(env, req, invRender.invoice_id);
      }

      {
        const m = matchPath(p, '/api/invoices/:invoice_id/hold');
        if (m && req.method === 'POST')                                      return handleInvoiceHold(env, req, m.invoice_id);
      }
      {
        const m = matchPath(p, '/api/invoices/:invoice_id/unhold');
        if (m && req.method === 'POST')                                      return handleInvoiceUnhold(env, req, m.invoice_id);
      }

      // =============================================================================
// NEW ROUTES — Invoice batch modals
// =============================================================================
if (req.method === 'GET'  && p === '/api/invoices/batch-generate/candidates') return handleInvoiceBatchGenerateCandidates(env, req);
if (req.method === 'POST' && p === '/api/invoices/batch-generate/confirm')    return handleInvoiceBatchGenerateConfirm(env, req);

if (req.method === 'GET'  && p === '/api/invoices/batch-issue/candidates')    return handleInvoiceBatchIssueCandidates(env, req);
if (req.method === 'POST' && p === '/api/invoices/batch-issue/confirm')       return handleInvoiceBatchIssueConfirm(env, req);

      {
        const m = matchPath(p, '/api/invoices/:invoice_id/unissue');
        if (m && req.method === 'POST') return handleInvoiceUnissue(env, req, m.invoice_id);
      }

      {
        const invEmail = matchPath(p, '/api/invoices/:invoice_id/email');
        if (invEmail && req.method === 'POST')                               return handleInvoiceEmail(env, req, invEmail.invoice_id);
      }

      {
        const invCredit = matchPath(p, '/api/invoices/:invoice_id/credit-note');
        if (invCredit && req.method === 'POST')                              return handleCreateCreditNoteTsfin(env, req, invCredit.invoice_id);
      }

      {
        const invPaid = matchPath(p, '/api/invoices/:invoice_id/mark-paid');
        if (invPaid && req.method === 'POST')                                return handleInvoiceMarkPaid(env, req, invPaid.invoice_id);
      }
         {
        const inv = matchPath(p, '/api/invoices/:invoice_id/save-edits');
        if (inv && req.method === 'POST')                                    return handleInvoiceSaveEdits(env, req, inv.invoice_id);
      }
      {
        const inv = matchPath(p, '/api/invoices/:invoice_id/eligible-timesheets');
        if (inv && req.method === 'GET')                                     return handleInvoiceEligibleTimesheets(env, req, inv.invoice_id);
      }
      {
        const invUnpaid = matchPath(p, '/api/invoices/:invoice_id/mark-unpaid');
        if (invUnpaid && req.method === 'POST')                              return handleInvoiceMarkUnpaid(env, req, invUnpaid.invoice_id);
      }
      {
        const m = matchPath(p, '/api/invoices/:invoice_id/issue');
        if (m && req.method === 'POST') return handleInvoiceIssue(env, req, m.invoice_id);
      }
      {
        const m = matchPath(p, '/api/invoices/:invoice_id/remove-timesheet');
        if (m && req.method === 'POST')                                      return handleInvoiceRemoveTimesheet(env, req, m.invoice_id);
      }

      // NHSP invoice helpers
      if (req.method === 'GET'  && p === '/api/nhsp/invoices/candidates')    return handleNhspInvoiceCandidates(env, req);
      if (req.method === 'POST' && p === '/api/nhsp/invoices/run')           return handleNhspInvoiceRun(env, req);
      {
        const m = matchPath(p, '/api/nhsp/shifts/:id/defer');
        if (m && req.method === 'POST')                                      return handleNhspShiftDefer(env, req, m.id);
      }

if (req.method === 'POST' && p === '/api/tspdf/queue/drain') {
  return withCORS(env, req, await handleTsPdfDrain(env, req));
}


      // Remittances
      if (req.method === 'POST' && p === '/api/remittances/email-for-candidate') {
        return handleRemittanceEmailForCandidate(env, req);
      }
      if (req.method === 'POST' && p === '/api/remittances/send')            return handleRemittancesSend(env, req);

      // ====================== SEARCH (able) ======================
      if (req.method === 'GET' && p === '/api/search/timesheets')            return handleSearchTimesheets(env, req);
      if (req.method === 'GET' && p === '/api/search/invoices')              return handleSearchInvoices(env, req);
      if (req.method === 'GET' && p === '/api/search/candidates')            return handleSearchCandidates(env, req);
      if (req.method === 'GET' && p === '/api/search/clients')               return handleSearchClients(env, req);
      if (req.method === 'GET' && p === '/api/search/umbrellas')             return handleSearchUmbrellas(env, req);

      // ====================== REPORT PRESETS ======================
      if (req.method === 'GET'  && p === '/api/report-presets')              return handleReportPresetsList(env, req);
      if (req.method === 'POST' && p === '/api/report-presets')              return handleReportPresetsCreate(env, req);
      {
        const rp = matchPath(p, '/api/report-presets/:id');
        if (rp && (req.method === 'PATCH' || req.method === 'PUT'))          return handleReportPresetsUpdate(env, req, rp.id);
        if (rp && req.method === 'DELETE')                                   return handleReportPresetsDelete(env, req, rp.id);
      }

      // ====================== REPORTS (json/csv/print) ======================
      if (req.method === 'GET'  && p === '/api/reports/timesheets')          return handleReportTimesheets(env, req);
      if (req.method === 'GET'  && p === '/api/reports/invoices')            return handleReportInvoices(env, req);
      if (req.method === 'GET'  && p === '/api/reports/candidates')          return handleReportCandidates(env, req);
      if (req.method === 'GET'  && p === '/api/reports/clients')             return handleReportClients(env, req);
      if (req.method === 'GET'  && p === '/api/reports/umbrellas')           return handleReportUmbrellas(env, req);

      // ====================== PAYMENTS (Bank CSV) ======================
      if (req.method === 'POST' && p === '/api/payments/generate-csv')       return handlePaymentsGenerateCsv(env, req);

      // =============================================================================
      // NEW ROUTES — Rates Presets
      // =============================================================================
      if (req.method === 'POST' && p === '/api/rates/presets') {
        return handleRatesPresetsCreate(env, req);
      }

      if (req.method === 'GET' && p === '/api/rates/presets') {
        return handleRatesPresetsList(env, req);
      }

      {
        const m = matchPath(p, '/api/rates/presets/:id');
        if (m && req.method === 'GET') {
          return handleRatesPresetsGet(env, req, m.id);
        }
        if (m && req.method === 'PATCH') {
          return handleRatesPresetsUpdate(env, req, m.id);
        }
        if (m && req.method === 'DELETE') {
          return handleRatesPresetsDelete(env, req, m.id);
        }
      }

      // ====================== EMAIL (OUTBOX, SEND, TSO) ======================
      if (req.method === 'GET'  && p === '/api/email/outbox')                return handleListOutbox(env, req);
      {
        const outOne = matchPath(p, '/api/email/outbox/:id');
        if (outOne && req.method === 'GET')                                  return handleGetOutboxItem(env, req, outOne.id);
      }
      {
        const outbox = matchPath(p, '/api/outbox/:mail_id');
        if (outbox && req.method === 'GET')                                   return handleGetOutboxItem(env, req, outbox.mail_id);
      }

      if (req.method === 'POST' && p === '/api/email/outbox/drain')          return handleOutboxDrain(env, req);
      {
        const outRetry = matchPath(p, '/api/email/outbox/:id/retry');
        if (outRetry && req.method === 'POST')                               return handleOutboxRetry(env, req, outRetry.id);
      }

      if (req.method === 'POST' && p === '/api/email/outbox/mark-sent')      return handleOutboxMarkSent(env, req);
      if (req.method === 'POST' && p === '/api/email/outbox/mark-failed')    return handleOutboxMarkFailed(env, req);

      if (req.method === 'POST' && p === '/api/email/send')                  return handleEmailSend(env, req);
      if (req.method === 'POST' && p === '/api/email/broadcast')             return handleEmailSend(env, req);

      // ====================== RELATED (generic) ======================
      {
        const relCounts = matchPath(p, '/api/related/:entity/:id/counts');
        if (relCounts && req.method === 'GET') {
          return handleRelatedCounts(env, req, relCounts.entity, relCounts.id);
        }
      }
      {
        const relList = matchPath(p, '/api/related/:entity/:id/:type');
        if (relList && req.method === 'GET') {
          return handleRelatedList(env, req, relList.entity, relList.id, relList.type);
        }
      }

      // ====================== FILES (R2, signed) ======================
      if (req.method === 'POST' && p === '/api/files/presign-upload')        return handleFilePresignUpload(env, req);
      if (req.method === 'PUT'  && p === '/api/files/upload')                return handleFileUpload(env, req, url);
      if (req.method === 'POST' && p === '/api/files/presign-download')      return handleFilePresignDownload(env, req);
      if (req.method === 'GET'  && p === '/api/files/download')              return handleFilesDownload(env, req);

      // =============================================================================
      // NEW ROUTES — Contracts & Weeks
      // =============================================================================

      // Contracts
      if (req.method === 'POST' && p === '/api/contracts') return handleContractsCreate(env, req);
      if (req.method === 'GET'  && p === '/api/contracts') return handleContractsList(env, req);
      if (req.method === 'GET' && p === '/api/contracts/finance-globals') return handleContractsFinanceGlobals(env, req);
// Contracts count (for Summary footer totals)
if (req.method === 'GET' && p === '/api/contracts/count') return handleContractsCount(env, req);

      {
        const m = matchPath(p, '/api/contracts/:id/duplicate');
        if (m && req.method === 'POST') {
          return handleContractsDuplicate(env, req, m.id);
        }
      }
      
      {
        const m = matchPath(p, '/api/contracts/:id');
        if (m && req.method === 'GET')    return handleContractsGet(env, req, m.id);
        if (m && req.method === 'PATCH')  return handleContractsUpdate(env, req, m.id);
        if (m && req.method === 'DELETE') return handleContractsDelete(env, req, m.id);
        if (m && req.method === 'PUT')    return handleContractsReplace(env, req, m.id); 
      }

      {
        const m = matchPath(p, '/api/contracts/:id/generate-weeks');
        if (m && req.method === 'POST') return handleContractsGenerateWeeks(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contracts/:id/clone-and-extend');
        if (m && req.method === 'POST') return handleContractsCloneAndExtend(env, req, m.id);
      }

      // NEW: change contract rates (preview + apply)
      {
        const m = matchPath(p, '/api/contracts/:id/change-rates-outstanding');
        if (m && req.method === 'GET')  return handleContractChangeRatesPreview(env, req, m.id);
        if (m && req.method === 'POST') return handleContractChangeRatesOutstanding(env, req, m.id);
      }

      {
        const m = matchPath(p, '/api/contracts/:id/calendar');
        if (m && req.method === 'GET') return handleContractsCalendar(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contracts/:id/skip-weeks');
        if (m && req.method === 'POST') return handleContractsSkipWeeks(env, req, m.id);
      }

      // POST /api/contracts/check-timesheet-boundary
      if (req.method === 'POST' && p === '/api/contracts/check-timesheet-boundary') {
        return await handleContractsCheckTimesheetBoundary(env, req);
      }
      // POST /api/contracts/check-overlap
      if (req.method === 'POST' && p === '/api/contracts/check-overlap') {
        return await handleContractsCheckOverlap(env, req);
      }

          // Contract weeks
      if (req.method === 'GET' && p === '/api/contract-weeks') return handleContractWeeksList(env, req);
      {
        const m = matchPath(p, '/api/contract-weeks/:id');
        if (m && req.method === 'PATCH') return handleContractWeekUpdate(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contract-weeks/:id/additional');
        if (m && req.method === 'POST') return handleContractWeekCreateAdditional(env, req, m.id);
      }

      // Daily: create additional MANUAL adjustment timesheet
{
  const m = matchPath(p, '/api/timesheets/:id/additional-daily-manual');
  if (m && req.method === 'POST') {
    return handleTimesheetCreateAdditionalDailyManual(env, req, m.id);
  }
}

      {
        const m = matchPath(p, '/api/contract-weeks/:id/switch-mode');
        if (m && req.method === 'POST') return handleContractWeekSwitchMode(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contract-weeks/:id/presign-manual-pdf');
        if (m && req.method === 'POST') return handleContractWeekPresignManualPdf(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contract-weeks/:id/replace-manual-pdf');
        if (m && req.method === 'POST') return handleContractWeekReplaceManualPdf(env, req, m.id);
      }

      // ✅ NEW: draft save for planned MANUAL weeks (does NOT create timesheet)
      {
        const m = matchPath(p, '/api/contract-weeks/:id/manual-draft-upsert');
        if (m && req.method === 'POST') return handleContractWeekManualDraftUpsert(env, req, m.id);
      }

      // Existing: manual upsert (creates/updates real timesheet)
      {
        const m = matchPath(p, '/api/contract-weeks/:id/manual-upsert');
        if (m && req.method === 'POST') return handleContractWeekManualUpsert(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contract-weeks/:id/manual-authorise');
        if (m && req.method === 'POST') return handleContractWeekManualAuthorise(env, req, m.id);
      }

      {
        const m = matchPath(p, '/api/contract-weeks/:id/printable');
        if (m && req.method === 'POST') return handleContractWeekGeneratePrintable(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contracts/:id/truncate-tail');
        if (m && req.method === 'POST') return withCORS(env, req, await handleContractsTruncateTailSafely(env, req, m.id));
      }

     {
  const m = matchPath(p, '/api/contract-weeks/:id/timesheet');
  if (m && req.method === 'DELETE') return handleContractWeekDeleteTimesheet(env, req, m.id);
}

// NEW: planned-only delete (calls contract_week_delete_planned RPC)
{
  const m = matchPath(p, '/api/contract-weeks/:id/delete-planned');
  if (m && req.method === 'POST') return handleContractWeekDeletePlanned(env, req, m.id);
}

      {
        const m = matchPath(p, '/api/contract-weeks/:id/expense-sheet');
        if (m && req.method === 'POST') return handleContractWeekCreateExpenseSheet(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/contracts/:id/plan-ranges');
        if (m && req.method === 'POST')   return handleContractsPlanRanges(env, req, m.id);     // bulk add/extend
        if (m && req.method === 'DELETE') return handleContractsUnplanRanges(env, req, m.id);   // bulk remove
      }
      {
        const m = matchPath(p, '/api/contract-weeks/:id/plan');
        if (m && req.method === 'PATCH')  return handleContractWeekPlanPatch(env, req, m.id);   // per-week add/remove
      }
// Contract week: create additional manual adjustment week + immediate blank HOURS timesheet
{
  const m = matchPath(p, '/api/contract-weeks/:id/additional-weekly-adjustment');
  if (m && req.method === 'POST') {
    return handleContractWeekCreateAdditionalWeeklyAdjustment(env, req, m.id);
  }
}


      // =============================================================================
      // NEW ROUTES — Weekly (electronic) – public broker
      // =============================================================================
      if (req.method === 'POST' && p === '/timesheets/eligibility-weekly') return handleTimesheetsEligibilityWeekly(env, req);
      if (req.method === 'POST' && p === '/timesheets/presign-weekly')     return handleTimesheetsPresignWeekly(env, req);
      if (req.method === 'POST' && p === '/timesheets/submit-weekly')      return handleTimesheetsSubmitWeekly(env, req);


      // =============================================================================
      // NEW ROUTE — QR Scan (broker → backend)
      // =============================================================================
      if (req.method === 'POST' && p === '/api/timesheets/qr-scan') {
        return handleTimesheetQrScan(env, req);
      }

// =============================================================================
// NEW ROUTES — QR Admin actions (resend / refuse / restore / audit)
// =============================================================================
{
  const m = matchPath(p, '/api/timesheets/:id/qr-resend');
  if (m && req.method === 'POST') return handleTimesheetQrResendEmail(env, req, m.id);
}
{
  const m = matchPath(p, '/api/timesheets/:id/qr-refuse');
  if (m && req.method === 'POST') return handleTimesheetQrRefuseAndReset(env, req, m.id);
}
{
  const m = matchPath(p, '/api/timesheets/:id/qr-restore');
  if (m && req.method === 'POST') return handleTimesheetQrRestore(env, req, m.id);
}
{
  const m = matchPath(p, '/api/timesheets/:id/audit-feed');
  if (m && req.method === 'GET') return handleTimesheetAuditFeed(env, req, m.id);
}
      // =============================================================================
      // NEW ROUTES — Manual & Expenses
      // =============================================================================
      if (req.method === 'POST' && p === '/manual/presign') return handleManualPresign(env, req);
      {
        const m = matchPath(p, '/api/timesheets/:id/reference');
        if (m && req.method === 'PATCH') return handleTimesheetUpdateReference(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/timesheets/:id/authorise');
        if (m && req.method === 'POST') return handleTimesheetAuthoriseGeneric(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/timesheets/:id/tsfin/expenses');
        if (m && req.method === 'PATCH') return handleTsfinExpensesPatch(env, req, m.id);
      }

    {
  const m = matchPath(p, '/api/timesheets/:id/tsfin/mileage');
  if (m && req.method === 'PATCH') return handleTsfinMileagePatch(env, req, m.id);
}
  
      {
        const m = matchPath(p, '/api/timesheets/:id/presign-expense-pdf');
        if (m && req.method === 'POST') return handleTimesheetPresignExpensePdf(env, req, m.id);
      }
{
  const m = matchPath(p, '/api/timesheets/:id/switch-to-manual');
  if (m && req.method === 'POST') return handleTimesheetSwitchToManual(env, req, m.id);
}

// NEW: convert QR → plain manual
{
  const m = matchPath(p, '/api/timesheets/:id/convert-qr-to-manual');
  if (m && req.method === 'POST') return handleTimesheetConvertQrToManual(env, req, m.id);
}

// NEW: allow QR again (manual-only → QR Scenario 1)
{
  const m = matchPath(p, '/api/timesheets/:id/allow-qr-again');
  if (m && req.method === 'POST') return handleTimesheetAllowQrAgain(env, req, m.id);
}

// NEW: allow electronic again (manual-only → ELECTRONIC)
{
  const m = matchPath(p, '/api/timesheets/:id/allow-electronic-again');
  if (m && req.method === 'POST') return handleTimesheetAllowElectronicAgain(env, req, m.id);
}

// NEW: switch DAILY electronic → manual
{
  const m = matchPath(p, '/api/timesheets/:id/switch-daily-to-manual');
  if (m && req.method === 'POST') return handleTimesheetSwitchDailyToManual(env, req, m.id);
}

// NEW: generate DAILY QR printable (now auto-emails too in our updated handler)
{
  const m = matchPath(p, '/api/timesheets/:id/daily-qr-printable');
  if (m && req.method === 'POST') return handleTimesheetDailyQrPrintable(env, req, m.id);
}

      // NEW: daily manual upsert (edit daily manual hours + QR hints)
      {
        const m = matchPath(p, '/api/timesheets/:id/daily-manual-upsert');
        if (m && req.method === 'POST') return handleTimesheetDailyManualUpsert(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/timesheets/:id');
        if (m && req.method === 'DELETE') return handleTimesheetDelete(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/timesheets/:id/replace-manual-pdf');
        if (m && req.method === 'POST') return handleTimesheetReplaceManualPdf(env, req, m.id);
      }

      // =============================================================================
      // NEW ROUTES — Manual Timesheet Queue
      // =============================================================================
      if (req.method === 'POST' && p === '/api/manual-timesheet-queue/enqueue') {
        return handleManualTimesheetQueueEnqueue(env, req);
      }
      if (req.method === 'GET' && p === '/api/manual-timesheet-queue') {
        return handleManualTimesheetQueueList(env, req);
      }
      {
        const m = matchPath(p, '/api/manual-timesheet-queue/:id');
        if (m && req.method === 'GET')   return handleManualTimesheetQueueGet(env, req, m.id);
        if (m && req.method === 'DELETE')return handleManualTimesheetQueueDelete(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/manual-timesheet-queue/:id/attach');
        if (m && req.method === 'POST') return handleManualTimesheetQueueAttach(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/manual-timesheet-queue/:id/rotation');
        if (m && req.method === 'PATCH') return handleManualTimesheetQueueRotate(env, req, m.id);
      }

      // Timesheets summary & details (admin)
      if (req.method === 'GET'  && p === '/api/timesheets/summary') {
        return handleTimesheetsSummary(env, req);
      }

      // NEW: Timesheets resolve preview
      if (req.method === 'POST' && p === '/api/timesheets/resolve-preview') {
        return handleTimesheetsResolvePreview(env, req);
      }

      // NEW: Timesheet resolve candidate / client
      {
        const m = matchPath(p, '/api/timesheets/:id/resolve-candidate');
        if (m && req.method === 'POST') return handleTimesheetResolveCandidate(env, req, m.id);
      }
      {
        const m = matchPath(p, '/api/timesheets/:id/resolve-client');
        if (m && req.method === 'POST') return handleTimesheetResolveClient(env, req, m.id);
      }

      {
        const m = matchPath(p, '/api/timesheets/:id/details');
        if (m && req.method === 'GET') {
          return handleTimesheetDetails(env, req, m.id);
        }
      }
      {
        const m = matchPath(p, '/api/timesheets/:id/source-print');
        if (m && req.method === 'GET') {
          return handleTimesheetSourcePrint(env, req, m.id);
        }
      }
      {
        const m = matchPath(p, '/api/timesheets/:id/pdf');
        if (m && req.method === 'GET') {
          return handleTimesheetPdf(env, req, m.id);
        }
      }
      {
        const m = matchPath(p, '/api/timesheets/:id/pay-adjustment');
        if (m && req.method === 'POST') {
          return handleManualPayAdjustmentCreate(env, req, m.id);
        }
      }

      // Manual NHSP weekly shift convenience creator
      if (req.method === 'POST' && p === '/api/timesheets/manual-nhsp')     return handleTimesheetCreateManualNhspShift(env, req);


      // =============================================================================
      // NEW ROUTES — Funnel & Prechecks
      // =============================================================================
      if (req.method === 'GET' && p === '/api/funnel/timesheets') return handleFunnelTimesheets(env, req);
      if (req.method === 'GET' && p === '/api/invoices/precheck') return handleInvoicesPrecheck(env, req);

// ─────────────────────────────────────────────────────────────
// Users (admin) + self-service password change
// ─────────────────────────────────────────────────────────────

// Logged-in user: change password (forces logout; Option A)
if (req.method === 'POST' && p === '/api/users/me/change-password') {
  return withCORS(env, req, await handleUserChangePassword(env, req));
}

// Admin: list + create users
if (req.method === 'GET'  && p === '/api/users') {
  return withCORS(env, req, await handleUsersList(env, req));
}
if (req.method === 'POST' && p === '/api/users') {
  return withCORS(env, req, await handleUsersCreate(env, req));
}

// Admin: patch user + reset password (id routes)
{
  const parts = p.split('/').filter(Boolean); // e.g. ['api','users','<id>'] or ['api','users','<id>','reset-password']
  const isUsers = (parts[0] === 'api' && parts[1] === 'users');

  if (isUsers && req.method === 'PATCH' && parts.length === 3 && parts[2] !== 'me') {
    const userId = parts[2];
    return withCORS(env, req, await handleUsersPatch(env, req, userId));
  }

  if (isUsers && req.method === 'POST' && parts.length === 4 && parts[2] !== 'me' && parts[3] === 'reset-password') {
    const userId = parts[2];
    return withCORS(env, req, await handleUsersResetPassword(env, req, userId));
  }
}

      // FINAL: Not found – now CORS-safe
      return withCORS(env, req, new Response("Not found", {
        status: 404,
        headers: TEXT_PLAIN
      }));
    } catch (e) {
      // Log full error to Worker logs
      console.error("Unhandled error:", e);

      // Expose a useful message to the browser *with* CORS headers,
      // so you see a JSON 500 instead of a misleading CORS failure.
      const msg = (e && e.message) ? e.message : "Unexpected error";
      return withCORS(env, req, serverError(msg));
    }

  },
  /// Cron handler for TSFIN queue processing + Auto-invoice + Email outbox drain
async scheduled(event, env, ctx) {
  const maxBatches      = parseInt(env.TSFIN_MAX_BATCHES || '10', 10);
  const batchSize       = parseInt(env.TSFIN_BATCH_SIZE  || '50', 10);
  const emailBatchLimit = parseInt(env.EMAIL_DRAIN_LIMIT_DEFAULT || '10', 10);

  // TS PDF worker controls (new)
  const tsPdfMaxBatches = parseInt(env.TSPDF_MAX_BATCHES || '5', 10);
  const tsPdfBatchSize  = parseInt(env.TSPDF_BATCH_SIZE  || '5', 10);
  const tsPdfEnqLimit   = parseInt(env.TSPDF_ENQUEUE_LIMIT || '500', 10);

  // Invoice SQL worker controls
  const invMaxBatches   = parseInt(env.INVOICE_MAX_BATCHES || '10', 10);
  const invBatchSize    = parseInt(env.INVOICE_BATCH_SIZE  || '10', 10);    // dequeue size (outbox rows)
  const invEnqLimit     = parseInt(env.INVOICE_ENQUEUE_LIMIT || '500', 10); // enqueue limit
  const invEnqueueFirst = String(env.INVOICE_ENQUEUE_FIRST || 'true').toLowerCase() !== 'false';

  // Actor for audit (optional; SQL audit will fall back to "CloudTMS server" if null)
  const invActorUserId  = (env.INVOICE_ACTOR_USER_ID && String(env.INVOICE_ACTOR_USER_ID).trim())
    ? String(env.INVOICE_ACTOR_USER_ID).trim()
    : null;

  // IMPORTANT: We do NOT "issue" invoices in scheduled.
  // In CloudTMS, ISSUED means "emailed/sent" for normal invoices.
  // Self-bill invoices are handled in SQL generator logic (they can be issued immediately there).
  // Scheduled only creates invoices and drains email outbox.
  ctx.waitUntil((async () => {
    try {
      for (let i = 0; i < maxBatches; i++) {
        const res = await runTsfinWorkerOnce(env, { limit: batchSize });
        if (!res || res.picked === 0) break;
      }
    } catch (e) {
      console.warn('[scheduled] TSFIN worker failed:', e?.message || e);
    }

    // TS PDF worker drain (after TSFIN, before invoices)
    try {
      for (let i = 0; i < tsPdfMaxBatches; i++) {
        const res = await runTsPdfWorkerOnce(env, {
          limit: tsPdfBatchSize,
          enqueueFirst: true,
          enqueueLimit: tsPdfEnqLimit
        });
        if (!res || res.picked === 0) break;
      }
    } catch (e) {
      console.warn('[scheduled] TS PDF worker failed:', e?.message || e);
    }

    // Invoice SQL-first drain (minimal Supabase subrequests)
    try {
      for (let i = 0; i < invMaxBatches; i++) {
        // 1) enqueue auto-invoice BY_WEEK jobs (cron-safe + idempotent)
        // ✅ Use the newer function that respects contracts.auto_invoice OR client_settings.auto_invoice_default
        // ✅ Enqueue functions now also gate by "week has ended" (London date) in SQL
        if (invEnqueueFirst) {
          try {
            await sbRpc(env, 'invoice_enqueue_auto_invoice_ready', { p_limit: invEnqLimit });
          } catch (e) {
            console.warn('[scheduled] invoice_enqueue_auto_invoice_ready failed:', e?.message || e);
          }
        }

        // 2) dequeue a batch of outbox rows (SKIP LOCKED leasing)
        const dq = await sbRpc(env, 'invoice_dequeue_batch_ids', { p_limit: invBatchSize });
        const jobs = Array.isArray(dq) ? dq : (dq?.data || []);
        if (!jobs.length) break;

        const outboxIds = jobs.map(r => r?.outbox_id).filter(Boolean);
        if (!outboxIds.length) break;

        // 3) generate invoices for those jobs (single RPC for the whole batch)
        await sbRpc(env, 'invoice_generate_from_outbox_batch', {
          p_outbox_ids: outboxIds,
          p_actor_user_id: invActorUserId
        });

        // NO AUTO-ISSUE HERE. Issuing is tied to emailing for normal invoices.
      }
    } catch (e) {
      console.warn('[scheduled] Invoice SQL worker failed:', e?.message || e);
    }

    try {
      await drainEmailOutboxOnce(env, { limit: emailBatchLimit });
    } catch (e) {
      console.warn('[scheduled] Email drain failed:', e?.message || e);
    }
  })());
}


};
